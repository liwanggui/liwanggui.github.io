[{"categories":["network"],"content":" 简介headscale 是 tailscale 的开源自托管的实现，更多信息请参考以下链接 Headscale 文档 Tailscale 文档 同类产品 Netbird: 使用内核 WireGuard，有完整管理界面，开源且可以自行部署，部署方法查看文档 Netmaker: 与 Netbird 类似，有完整管理界面，开源且可以自行部署，部署方法查看文档 注: headscale、netbird、netmaker 中 headscale 最轻量 ","date":"2025-05-23","objectID":"/posts/headscale/:1:0","series":null,"tags":["headscale","wireguard"],"title":"Headscale - 异地组网","uri":"/posts/headscale/#简介"},{"categories":["network"],"content":" 安装headscale 支持适用于 Debian 和 Ubuntu 的 DEB 软件包和二进制包安装，本文以二进行包为例进行安装 ","date":"2025-05-23","objectID":"/posts/headscale/:2:0","series":null,"tags":["headscale","wireguard"],"title":"Headscale - 异地组网","uri":"/posts/headscale/#安装"},{"categories":["network"],"content":" 1. 下载符合当前系统的二进制包包 bash sudo wget --output-document=/usr/bin/headscale \\ https://github.com/juanfont/headscale/releases/download/v\u003cHEADSCALE VERSION\u003e/headscale_\u003cHEADSCALE VERSION\u003e_linux_\u003cARCH\u003e ","date":"2025-05-23","objectID":"/posts/headscale/:2:1","series":null,"tags":["headscale","wireguard"],"title":"Headscale - 异地组网","uri":"/posts/headscale/#1-下载符合当前系统的二进制包包"},{"categories":["network"],"content":" 2. 赋于 headscale 执行权限 bash sudo chmod +x /usr/bin/headscale ","date":"2025-05-23","objectID":"/posts/headscale/:2:2","series":null,"tags":["headscale","wireguard"],"title":"Headscale - 异地组网","uri":"/posts/headscale/#2-赋于-headscale-执行权限"},{"categories":["network"],"content":" 3. 创建运行用户添加专用本地用户来运行 headscale bash sudo useradd \\ --create-home \\ --home-dir /var/lib/headscale/ \\ --system \\ --user-group \\ --shell /usr/sbin/nologin \\ headscale ","date":"2025-05-23","objectID":"/posts/headscale/:2:3","series":null,"tags":["headscale","wireguard"],"title":"Headscale - 异地组网","uri":"/posts/headscale/#3-创建运行用户"},{"categories":["network"],"content":" 4. 创建配置文件下载你所选版本的示例配置并将其保存为: /etc/headscale/config.yaml，请根据你的本地环境调整配置 bash sudo mkdir -p /etc/headscale sudo vim /etc/headscale/config.yaml 提示: 示例配置文件在仓库的根目录下，文件名为 config-example.yaml ","date":"2025-05-23","objectID":"/posts/headscale/:2:4","series":null,"tags":["headscale","wireguard"],"title":"Headscale - 异地组网","uri":"/posts/headscale/#4-创建配置文件"},{"categories":["network"],"content":" 5. 创建 Systemd 配置将 headscale 的 systemd 服务文件 复制到 /etc/systemd/system/headscale.service 并根据本地设置进行调整。以下参数可能需要修改：ExecStart、WorkingDirectory、ReadWritePaths bash sudo wget --output-document=/etc/systemd/system/headscale.service \\ https://headscale.net/stable/packaging/headscale.systemd.service ","date":"2025-05-23","objectID":"/posts/headscale/:2:5","series":null,"tags":["headscale","wireguard"],"title":"Headscale - 异地组网","uri":"/posts/headscale/#5-创建-systemd-配置"},{"categories":["network"],"content":" 6. 配置 unix 套接字在 /etc/headscale/config.yaml 中，使用 headscale 用户或组可写入的路径覆盖默认的 headscale unix 套接字 yaml unix_socket: /var/run/headscale/headscale.sock ","date":"2025-05-23","objectID":"/posts/headscale/:2:6","series":null,"tags":["headscale","wireguard"],"title":"Headscale - 异地组网","uri":"/posts/headscale/#6-配置-unix-套接字"},{"categories":["network"],"content":" 7. 重载 systemd重新加载 systemd 以加载新的配置文件 bash systemctl daemon-reload ","date":"2025-05-23","objectID":"/posts/headscale/:2:7","series":null,"tags":["headscale","wireguard"],"title":"Headscale - 异地组网","uri":"/posts/headscale/#7-重载-systemd"},{"categories":["network"],"content":" 8. 开启 headscale 服务启用并启动新的 headscale 服务 bash systemctl enable --now headscale ","date":"2025-05-23","objectID":"/posts/headscale/:2:8","series":null,"tags":["headscale","wireguard"],"title":"Headscale - 异地组网","uri":"/posts/headscale/#8-开启-headscale-服务"},{"categories":["network"],"content":" 9. 验证 headscale验证 headscale 是否按预期运行 bash systemctl status headscale ","date":"2025-05-23","objectID":"/posts/headscale/:2:9","series":null,"tags":["headscale","wireguard"],"title":"Headscale - 异地组网","uri":"/posts/headscale/#9-验证-headscale"},{"categories":["network"],"content":" 使用入门","date":"2025-05-23","objectID":"/posts/headscale/:3:0","series":null,"tags":["headscale","wireguard"],"title":"Headscale - 异地组网","uri":"/posts/headscale/#使用入门"},{"categories":["network"],"content":" 1. 创建用户 bash headscale users create \u003cUSER\u003e ","date":"2025-05-23","objectID":"/posts/headscale/:3:1","series":null,"tags":["headscale","wireguard"],"title":"Headscale - 异地组网","uri":"/posts/headscale/#1-创建用户"},{"categories":["network"],"content":" 2. 查看用户 bash headscale users list ","date":"2025-05-23","objectID":"/posts/headscale/:3:2","series":null,"tags":["headscale","wireguard"],"title":"Headscale - 异地组网","uri":"/posts/headscale/#2-查看用户"},{"categories":["network"],"content":" 3. 交互式，注册节点headscale 兼容 tailscale 客户端工具，所以直接使用 tailscale 客户端软件即可，软件下载地址 bash tailscale up --login-server \u003cYOUR_HEADSCALE_URL\u003e To authenticate, visit: \u003cYOUR_HEADSCALE_URL\u003e/register/nMpEDpqK25qxM51GsvZd37lr 按终端提示打开链接，复制页面命令 (将 USERNAME 修改为之前创建的用户名) 。在 Headscale 服务器上批准并注册该节点 bash headscale nodes register --user USERNAME --key nMpEDpqK25qxM51GsvZd37lr ","date":"2025-05-23","objectID":"/posts/headscale/:3:3","series":null,"tags":["headscale","wireguard"],"title":"Headscale - 异地组网","uri":"/posts/headscale/#3-交互式注册节点"},{"categories":["network"],"content":" 4. 使用预授权密钥，注册节点生成预授权密钥并以非交互方式注册节点。 首先，在 Headscale 实例上生成预授权密钥。默认情况下， 该密钥有效期为一小时，且只能使用一次（其他选项请参阅 headscale preauthkeys --help 命令）： bash headscale preauthkeys create --user \u003cUSER\u003e 该命令成功后将返回 preauthkey，该密钥可用于通过以下 tailscale up 命令将节点连接到 headscale 实例： bash tailscale up --login-server \u003cYOUR_HEADSCALE_URL\u003e --authkey \u003cYOUR_AUTH_KEY\u003e ","date":"2025-05-23","objectID":"/posts/headscale/:3:4","series":null,"tags":["headscale","wireguard"],"title":"Headscale - 异地组网","uri":"/posts/headscale/#4-使用预授权密钥注册节点"},{"categories":["network"],"content":" 5. 查看所有节点查看已注册的所有节点 bash headscale nodes list ","date":"2025-05-23","objectID":"/posts/headscale/:3:5","series":null,"tags":["headscale","wireguard"],"title":"Headscale - 异地组网","uri":"/posts/headscale/#5-查看所有节点"},{"categories":["network"],"content":" 部署中继服务器在上面的 Headscale 搭建完成并添加客户端后, 某些客户端可能无法联通; 这是由于网络复杂情况下导致了 NAT 穿透失败; 为此我们可以搭建一个中继服务器来进行流量转发 自定义 DERP 服务器 ","date":"2025-05-23","objectID":"/posts/headscale/:4:0","series":null,"tags":["headscale","wireguard"],"title":"Headscale - 异地组网","uri":"/posts/headscale/#部署中继服务器"},{"categories":["network"],"content":" 1. 搭建 DERP Server首先需要注意的是, 在需要搭建 DERP Server 的服务器上, 请先安装一个 Tailscale 客户端并注册到 Headscale; 这样做的目的是让搭建的 DERP Server 开启客户端认证, 否则你的 DERP Server 可以被任何人白嫖. 目前 Tailscale 官方并未提供 DERP Server 的安装包, 所以需要我们自行编译安装; 在编译之前请确保安装了最新版本的 Go 语言及其编译环境. bash # 编译 DERP Server go install tailscale.com/cmd/derper@latest # 复制到系统可执行目录 sudo mv ${GOPATH}/bin/derper /usr/local/bin # 创建用户和运行目录 sudo useradd \\ --create-home \\ --home-dir /var/lib/derper/ \\ --system \\ --user-group \\ --shell /usr/sbin/nologin \\ derper 创建 systemd 配置: /lib/systemd/system/derper.service ini [Unit] After=syslog.target After=network.target Description=derper coordination server for Tailscale [Service] Type=simple User=derper Group=derper ExecStart=/usr/local/bin/derper \\ --verify-clients \\ -a :12340 \\ -c /var/lib/derper/private.key ExecReload=/usr/bin/kill -HUP $MAINPID Restart=always RestartSec=5 WorkingDirectory=/var/lib/derper ReadWritePaths=/var/lib/derper /var/run [Install] WantedBy=multi-user.target 提示: --verify-clients 选项用于开启客户端验证，防止 derper 服务被人白嫖 (需在机安装 tailscale 客户端并注册到 headscale) 最后使用以下命令启动 Derper Server 即可 bash systemctl enable derper --now 注意: 默认情况下 Derper Server 会监听在 :443 上, 同时会触发自动 ACME 申请证书. 关于证书逻辑如下: 如果不指定 -a 参数, 则默认监听 :443 如果监听 :443 并且未指定 --certmode=manual 则会强制使用 --hostname 指定的域名进行 ACME 申请证书 如果指定了 --certmode=manual 则会使用 --certdir 指定目录下的证书开启 HTTPS 如果指定了 -a 为非 :443 端口, 且没有指定 --certmode=manual 则只监听 HTTP 如果期望使用 ACME 自动申请只需要不增加 -a 选项即可(占用 443 端口), 如果期望通过负载均衡器负载, 则需要将 -a 选项指定到非 443 端口, 然后配置 Nginx、Caddy 等 LB 软件即可. 最后一点 stun 监听的是 UDP 端口, 请确保防火墙打开此端口 ","date":"2025-05-23","objectID":"/posts/headscale/:4:1","series":null,"tags":["headscale","wireguard"],"title":"Headscale - 异地组网","uri":"/posts/headscale/#1-搭建-derp-server"},{"categories":["network"],"content":" 2. 配置 Headscale在创建完 Derper 中继服务器后, 我们还需要配置 Headscale 来告诉所有客户端在必要时可以使用此中继节点进行通信; 为了达到这个目的, 我们需要在 Headscale 服务器上创建以下配置 yaml regions: 900: regionid: 900 regioncode: private-derper regionname: \"my private derper server\" nodes: - name: a regionid: 900 hostname: derper.xxx.com stunport: 3478 derpport: 443 ipv4: 123.13.12.11 注意: 每个区域都有一个唯一的 region ID。region ID 值 900-999 保留用于自定义用户指定的区域，Tailscale 不会使用。 在创建好基本的 Derper Server 节点信息配置后, 我们需要调整主配置来让 Headscale 加载 yaml derp: server: # 这里关闭 Headscale 默认的 Derper Server enabled: false # urls 留空, 保证不加载官方的默认 Derper urls: [] # 这里填写 Derper 节点信息配置的绝对路径 paths: - /etc/headscale/derper.yaml # If enabled, a worker will be set up to periodically # refresh the given sources and update the derpmap # will be set up. auto_update_enabled: true # How often should we check for DERP updates? update_frequency: 24h 接下来重启 Headscale 并重启 client 上的 tailscale 即可看到中继节点 bash \u003e tailscale netcheck Report: * Time: 2025-05-23T07:14:32.213827081Z * UDP: true * IPv4: yes, 111.11.11.11:57926 * IPv6: no, but OS has support * MappingVariesByDestIP: * PortMapping: UPnP, NAT-PMP, PCP * Nearest DERP: my private derper server * DERP latency: - xxx: 14.3ms (my private derper server) ","date":"2025-05-23","objectID":"/posts/headscale/:4:2","series":null,"tags":["headscale","wireguard"],"title":"Headscale - 异地组网","uri":"/posts/headscale/#2-配置-headscale"},{"categories":["vmware"],"content":" 问题为了解决主机没有显示器又需要远程桌面管理的场景。 虚拟显示器对于没有显示器的服务器，可以启用远程桌面和屏幕流式传输到其他系统，就像安装了显示器一样。 官方仓库: https://github.com/itsmikethetech/Virtual-Display-Driver ","date":"2024-10-24","objectID":"/posts/virtual-display-driver/:1:0","series":null,"tags":["vmware","Virtual-Display-Driver"],"title":"解决 VNC 远程桌面黑屏 - 虚拟显示器驱动","uri":"/posts/virtual-display-driver/#问题"},{"categories":["vmware"],"content":" 安装使用 下载最新版本，并解压到文件夹中，例如放到 C:\\IddSampleDriver 目录下 右键单击并以管理员身份运行 *.bat 文件，将驱动程序证书添加为受信任的根证书。 不要安装 inf。 打开设备管理器，单击任意设备，然后单击 “操作” 菜单并单击 “添加旧版硬件”。 选择 “从列表中添加硬件（高级）”，然后选择显示适配器。 单击 “从磁盘安装…”，然后单击 “浏览…” 按钮。 导航到解压的文件并选择 inf 文件。 安装完成！转到显示设置以自定义附加显示器的分辨率。 您可以启用/禁用显示适配器来切换监视器。 注意：请确保 options.txt 系统可以访问，否则安装将失败。例如: C:\\IddSampleDriver\\options.txt 注意: 请勿重复安装 ","date":"2024-10-24","objectID":"/posts/virtual-display-driver/:2:0","series":null,"tags":["vmware","Virtual-Display-Driver"],"title":"解决 VNC 远程桌面黑屏 - 虚拟显示器驱动","uri":"/posts/virtual-display-driver/#安装使用"},{"categories":["devops"],"content":" 说明键鼠共享软件其实不止 Barrier 这一款，其他的还有: Mouse Without Borders 只适用于 Windows 系统 Synergy 是一款收费软件 sharemouse 同样是款收费软件，可以免费使用，但功能有限制 Deskflow 免费开源 input-leap 免费开源 Barrier 是和 Synergy 同源的一款软件。最初 Synergy 是基于 Chris Schoeneman 编写的 CosmoSynergy 开发的一个免费软件，Synergy 在迭代数个版本后开始收费，于是有团队开始基于 Synergy 的开源内核再次开发出了免费版的 barrier。 Barrier 是一款免费且开源的跨系统键盘鼠标共享软件，主要的特点有： 共享鼠标和共享键盘 共享剪切板 跨系统。适用于 Windows、macOS 和 Linux 系统 免费、开源 注意: Barrier 已处于无人维护状态，input-leap 是 Barrier 的一个活跃的分支，如使用 barrier 有问题，可以尝试使用 input-leap 替代 Barrier ","date":"2024-10-14","objectID":"/posts/barrier/:1:0","series":null,"tags":["Barrier"],"title":"全平台免费键盘鼠标共享软件 Barrier 的安装与使用","uri":"/posts/barrier/#说明"},{"categories":["devops"],"content":" 安装","date":"2024-10-14","objectID":"/posts/barrier/:2:0","series":null,"tags":["Barrier"],"title":"全平台免费键盘鼠标共享软件 Barrier 的安装与使用","uri":"/posts/barrier/#安装"},{"categories":["devops"],"content":" Windows 和 macOSWindows 和 macOS 系统有已经打包好的安装包，可以从 Barrier 开源 GitHub 仓库的发布页面 下载 Windows 系统选择后缀为 exe 的安装包，macOS 系统选择后缀为 dmg 的安装包。 ","date":"2024-10-14","objectID":"/posts/barrier/:2:1","series":null,"tags":["Barrier"],"title":"全平台免费键盘鼠标共享软件 Barrier 的安装与使用","uri":"/posts/barrier/#windows-和-macos"},{"categories":["devops"],"content":" linuxDebian 系的 Linux 系统（如Ubuntu等），可以直接使用包管理工具 apt 安装 bash sudo apt install barrier 其他Linux系统可以通过包管理工具snap安装： bash sudo snap install barrier 如果系统没有自带 snap，则需先安装 snap。 ","date":"2024-10-14","objectID":"/posts/barrier/:2:2","series":null,"tags":["Barrier"],"title":"全平台免费键盘鼠标共享软件 Barrier 的安装与使用","uri":"/posts/barrier/#linux"},{"categories":["devops"],"content":" 设置和使用barrier 的设置分为服务端（server）和客户端（client）。 ","date":"2024-10-14","objectID":"/posts/barrier/:3:0","series":null,"tags":["Barrier"],"title":"全平台免费键盘鼠标共享软件 Barrier 的安装与使用","uri":"/posts/barrier/#设置和使用"},{"categories":["devops"],"content":" 服务端直接连接键盘鼠标的那台电脑是服务端。 打开服务端电脑上的 Barrier, 勾选服务端-共享此电脑的鼠标和键盘。 (记下服务端的IP地址,一般是局域网IP) 选中 “交互式配置” , 点击配置服务器 拖动配置界面右上侧的电脑图标到下方的格子里，双击电脑图标，更改电脑名称为客户端电脑显示的名称（可以在客户端 barrier 软件界面 “屏幕名称” 一栏找到）。两个电脑图标在格子里的相对位置和实际电脑的屏幕位置相对应。 配置服务端1 配置服务端2 ","date":"2024-10-14","objectID":"/posts/barrier/:3:1","series":null,"tags":["Barrier"],"title":"全平台免费键盘鼠标共享软件 Barrier 的安装与使用","uri":"/posts/barrier/#服务端"},{"categories":["devops"],"content":" 客户端要使用服务端电脑键盘鼠标的电脑是客户端 打开客户端电脑上的 Barrier，勾选 Client。 在服务端IP一栏（Server IP）填入服务端的IP地址。如果这一栏不可编辑，则取消勾选“自动配置”（Auto config）。 点击\"开始\"。 ","date":"2024-10-14","objectID":"/posts/barrier/:3:2","series":null,"tags":["Barrier"],"title":"全平台免费键盘鼠标共享软件 Barrier 的安装与使用","uri":"/posts/barrier/#客户端"},{"categories":["devops"],"content":" 常见问题 确保服务端和客户端在同一个局域网内。 如果鼠标键盘不能成功共享，可以检查上述设置，并重启 Barrier 软件。 如果还是不行，可以点击菜单栏“显示日志”（Show Log），查看日志中的报错信息。 日志中出现证书错误，可以参考 ERROR: ssl certificate doesn’t exist ","date":"2024-10-14","objectID":"/posts/barrier/:4:0","series":null,"tags":["Barrier"],"title":"全平台免费键盘鼠标共享软件 Barrier 的安装与使用","uri":"/posts/barrier/#常见问题"},{"categories":["devops"],"content":" 生成ssl证书默认 Barrier 安装完成后可能没有生成证书，导致服务不可用。各系统操作步骤如下: macOS bash $ mkdir -p ~/Library/Application\\ Support/barrier/SSL/Fingerprints; $ openssl req -x509 -nodes -days 365 -subj /CN=Barrier -newkey rsa:4096 -keyout ~/Library/Application\\ Support/barrier/SSL/Barrier.pem -out ~/Library/Application\\ Support/barrier/SSL/Barrier.pem; $ fingerprint=$(openssl x509 -fingerprint -sha256 -noout -in ~/Library/Application\\ Support/barrier/SSL/Barrier.pem | cut -d\"=\" -f2); $ echo \"v2:sha256:$fingerprint\" \u003e ~/Library/Application\\ Support/barrier/SSL/Fingerprints/Local.txt; linux bash $ mkdir -p ~/.local/share/barrier/SSL/Fingerprints; $ openssl req -x509 -nodes -days 365 -subj /CN=Barrier -newkey rsa:4096 -keyout ~/.local/share/barrier/SSL/Barrier.pem -out ~/.local/share/barrier/SSL/Barrier.pem; $ fingerprint=$(openssl x509 -fingerprint -sha256 -noout -in ~/.local/share/barrier/SSL/Barrier.pem | cut -d\"=\" -f2); $ echo \"v2:sha256:$fingerprint\" \u003e ~/.local/share/barrier/SSL/Fingerprints/Local.txt; windows 注意: Windows 依赖 https://gitforwindows.org/ 参考: https://github.com/debauchee/barrier/issues/231#issuecomment-1143791895 powershell # Powershell Set-Alias openssl \"C:\\Program Files\\Git\\usr\\bin\\openssl.exe\" cd ~\\AppData\\Local\\Barrier\\SSL\\ openssl req -x509 -nodes -days 365 -subj /CN=Barrier -newkey rsa:4096 -keyout Barrier.pem -out Barrier.pem ","date":"2024-10-14","objectID":"/posts/barrier/:4:1","series":null,"tags":["Barrier"],"title":"全平台免费键盘鼠标共享软件 Barrier 的安装与使用","uri":"/posts/barrier/#生成ssl证书"},{"categories":["fileserver"],"content":"SAN（Storage Area Network，存储区域网络），是一种基于块存储的存储方式。SAN是一种将存储设备，连接设备和接口集成在一个高速网络中的技术。SAN本身就是一个存储网络，承担了数据存储任务，SAN网络与LAN业务相互隔离，存储数据流不会占用业务带宽 ","date":"2024-08-15","objectID":"/posts/ipsan/:0:0","series":null,"tags":["san"],"title":"部署 iSCSI 存储区域网络（SAN）","uri":"/posts/ipsan/#"},{"categories":["fileserver"],"content":" 一、在存储服务器上配置 iSCSI 目标准备好一块盘: /dev/sdb ","date":"2024-08-15","objectID":"/posts/ipsan/:1:0","series":null,"tags":["san"],"title":"部署 iSCSI 存储区域网络（SAN）","uri":"/posts/ipsan/#一在存储服务器上配置-iscsi-目标"},{"categories":["fileserver"],"content":" 1. 安装 iSCSI Target 软件 bash yum install targetcli ","date":"2024-08-15","objectID":"/posts/ipsan/:1:1","series":null,"tags":["san"],"title":"部署 iSCSI 存储区域网络（SAN）","uri":"/posts/ipsan/#1-安装-iscsi-target-软件"},{"categories":["fileserver"],"content":" 2. 启动并启用 target 服务确保 iSCSI target 服务在系统启动时自动运行。 bash systemctl enable --now target.service ","date":"2024-08-15","objectID":"/posts/ipsan/:1:2","series":null,"tags":["san"],"title":"部署 iSCSI 存储区域网络（SAN）","uri":"/posts/ipsan/#2-启动并启用-target-服务"},{"categories":["fileserver"],"content":" 3. 使用 targetcli 创建iSCSI目标进入 targetcli 的交互式环境，开始配置iSCSI目标。 bash [root@test-01 ~]# targetcli targetcli shell version 2.1.53 Copyright 2011-2013 by Datera, Inc and others. For help on commands, type 'help'. # 创建存储后端（Backstore） /\u003e /backstores/block create name=block1 dev=/dev/sdb Created block storage object block1 using /dev/sdb. # 创建iSCSI目标 # iqn.2024-08.com.liwanggui-iscsi:storage1 是 iSCSI 名称，可以根据实际情况修改 /\u003e /iscsi create wwn=iqn.2024-08.com.liwanggui-iscsi:storage1 Created target iqn.2024-08.com.liwanggui-iscsi:storage1. Created TPG 1. Global pref auto_add_default_portal=true Created default portal listening on all IPs (0.0.0.0), port 3260. # 将后端设备添加到iSCSI目标 /\u003e /iscsi/iqn.2024-08.com.liwanggui-iscsi:storage1/tpg1/luns create /backstores/block/block1 Created LUN 0. # 授权访问客户端 iqn.2024-08.com.liwanggui-iscsi:client1 /\u003e /iscsi/iqn.2024-08.com.liwanggui-iscsi:storage1/tpg1/acls create iqn.2024-08.com.liwanggui-iscsi:client1 Created Node ACL for iqn.2024-08.com.liwanggui-iscsi:client1 Created mapped LUN 0. # 退出 targetcli， 保存配置 /\u003e exit Global pref auto_save_on_exit=true Last 10 configs saved in /etc/target/backup/. Configuration saved to /etc/target/saveconfig.json ","date":"2024-08-15","objectID":"/posts/ipsan/:1:3","series":null,"tags":["san"],"title":"部署 iSCSI 存储区域网络（SAN）","uri":"/posts/ipsan/#3-使用-targetcli-创建iscsi目标"},{"categories":["fileserver"],"content":" 二、在客户端配置 iSCSI 启动器","date":"2024-08-15","objectID":"/posts/ipsan/:2:0","series":null,"tags":["san"],"title":"部署 iSCSI 存储区域网络（SAN）","uri":"/posts/ipsan/#二在客户端配置-iscsi-启动器"},{"categories":["fileserver"],"content":" 1. 在客户端上安装 iSCSI Initiator 工具。 bash yum install iscsi-initiator-utils -y ","date":"2024-08-15","objectID":"/posts/ipsan/:2:1","series":null,"tags":["san"],"title":"部署 iSCSI 存储区域网络（SAN）","uri":"/posts/ipsan/#1-在客户端上安装-iscsi-initiator-工具"},{"categories":["fileserver"],"content":" 2. 启动并启用 iscsid 服务确保 iSCSI 启动器服务在系统启动时自动运行 bash systemctl enable --now iscsid.service ","date":"2024-08-15","objectID":"/posts/ipsan/:2:2","series":null,"tags":["san"],"title":"部署 iSCSI 存储区域网络（SAN）","uri":"/posts/ipsan/#2-启动并启用-iscsid-服务"},{"categories":["fileserver"],"content":" 3. 配置 iSCSI Initiator 名称编辑配置文件 /etc/iscsi/initiatorname.iscsi，设置启动器的IQN名称（使用 iqn.2024-08.com.liwanggui-iscsi:client1） bash InitiatorName=iqn.2024-08.com.liwanggui-iscsi:client1 重启 iscsiad 服务 bash systemctl restart iscsid.service ","date":"2024-08-15","objectID":"/posts/ipsan/:2:3","series":null,"tags":["san"],"title":"部署 iSCSI 存储区域网络（SAN）","uri":"/posts/ipsan/#3-配置-iscsi-initiator-名称"},{"categories":["fileserver"],"content":" 4. 发现并连接 iSCSI 目标使用目标服务器的IP地址发现可用的 iSCSI 目标 bash iscsiadm -m discovery -t sendtargets -p \u003cTarget_IP_Address\u003e 将 \u003cTarget_IP_Address\u003e 替换为目标服务器的IP地址, 例如: 192.168.110.106:3260 ","date":"2024-08-15","objectID":"/posts/ipsan/:2:4","series":null,"tags":["san"],"title":"部署 iSCSI 存储区域网络（SAN）","uri":"/posts/ipsan/#4-发现并连接-iscsi-目标"},{"categories":["fileserver"],"content":" 5. 登录 iSCSI 目标连接到发现的目标： bash [root@test-02 ~]# iscsiadm -m node --targetname iqn.2024-08.com.liwanggui-iscsi:storage1 --portal 192.168.110.106:3260 --login Logging in to [iface: default, target: iqn.2024-08.com.liwanggui-iscsi:storage1, portal: 192.168.110.106,3260] Login to [iface: default, target: iqn.2024-08.com.liwanggui-iscsi:storage1, portal: 192.168.110.106,3260] successful. 查看设备连接情况 bash [root@test-02 ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 200G 0 disk ├─sda1 8:1 0 600M 0 part /boot/efi ├─sda2 8:2 0 1G 0 part /boot └─sda3 8:3 0 198.4G 0 part ├─uos-root 253:0 0 50G 0 lvm / └─uos-data 253:1 0 148.4G 0 lvm /data sdb 8:16 0 10G 0 disk # iSCSI 设备 ","date":"2024-08-15","objectID":"/posts/ipsan/:2:5","series":null,"tags":["san"],"title":"部署 iSCSI 存储区域网络（SAN）","uri":"/posts/ipsan/#5-登录-iscsi-目标"},{"categories":["fileserver"],"content":" 6. 格式化并挂载iSCSI LUN使用 lsblk 或 fdisk -l 命令查看新的 iSCSI 磁盘。 bash [root@test-02 ~]# mkfs.ext4 /dev/sdb [root@test-02 ~]# mount /dev/sdb /mnt/ [root@test-02 ~]# df -hl Filesystem Size Used Avail Use% Mounted on /dev/sdb 9.8G 24K 9.3G 1% /mnt ... 配置 /etc/fstab 文件，以便在系统重启时自动挂载 iSCSI 磁盘。 text /dev/sdb /mnt ext4 _netdev 0 0 注意； _netdev ：这个选项告诉系统，这个设备是通过网络连接的，必须等到网络设备启动后才能挂载。 ","date":"2024-08-15","objectID":"/posts/ipsan/:2:6","series":null,"tags":["san"],"title":"部署 iSCSI 存储区域网络（SAN）","uri":"/posts/ipsan/#6-格式化并挂载iscsi-lun"},{"categories":["fileserver"],"content":" 三、卸载 iSCSI 磁盘 首先，确保设备不再被使用。卸载挂载点以确保文件系统的安全: umount /mnt 从 /etc/fstab 中删除条目, 如果你之前在/etc/fstab中配置了自动挂载，需要删除或注释掉相关条目 断开 iSCSI 会话 查看当前连接的会话： bash iscsiadm -m session -P 3 登出iSCSI会话 bash iscsiadm -m node --targetname \u003cTarget_IQN\u003e --portal \u003cTarget_IP_Address\u003e:3260 --logout 替换 \u003cTarget_IQN\u003e 为目标的IQN，\u003cTarget_IP_Address\u003e 为目标服务器的IP地址 删除 iSCSI 目标配置, 为了确保在下一次系统启动时不再尝试连接，可以删除本地 iSCSI 配置 bash iscsiadm -m node --targetname \u003cTarget_IQN\u003e --portal \u003cTarget_IP_Address\u003e:3260 --op delete ","date":"2024-08-15","objectID":"/posts/ipsan/:3:0","series":null,"tags":["san"],"title":"部署 iSCSI 存储区域网络（SAN）","uri":"/posts/ipsan/#三卸载-iscsi-磁盘"},{"categories":["fileserver"],"content":" 四、其他在 SAN（存储区域网络）环境中，网络单点故障可能导致严重的服务中断。为了提高SAN的可靠性，可以通过以下几种方法来解决网络单点故障问题 使用多路径I/O（Multipath I/O, MPIO）: yum install device-mapper-multipath 使用冗余网络链路 ","date":"2024-08-15","objectID":"/posts/ipsan/:4:0","series":null,"tags":["san"],"title":"部署 iSCSI 存储区域网络（SAN）","uri":"/posts/ipsan/#四其他"},{"categories":["devops","centos"],"content":" 简介通常生产环境由于安全原因都无法访问互联网。此时就需要进行离线安装，主要有两种方式：源码编译、rpm 包安装。 源码编译耗费时间长且缺乏编译环境，所以一般都选择使用离线 rpm 包安装。 ","date":"2024-04-01","objectID":"/posts/yum-download/:1:0","series":null,"tags":["yum"],"title":"YUM 下载全量依赖 rpm 包","uri":"/posts/yum-download/#简介"},{"categories":["devops","centos"],"content":" 查看依赖包可以使用 yum deplist 命令来查找 rpm 包的依赖列表。例如，要查找 “ansible” rpm 的依赖包： bash yum deplist ansible ","date":"2024-04-01","objectID":"/posts/yum-download/:2:0","series":null,"tags":["yum"],"title":"YUM 下载全量依赖 rpm 包","uri":"/posts/yum-download/#查看依赖包"},{"categories":["devops","centos"],"content":" 离线安装方案","date":"2024-04-01","objectID":"/posts/yum-download/:3:0","series":null,"tags":["yum"],"title":"YUM 下载全量依赖 rpm 包","uri":"/posts/yum-download/#离线安装方案"},{"categories":["devops","centos"],"content":" 方案一：repotrack（推荐）安装 yum-utils bash yum -y install yum-utils 下载 ansible 全量依赖包 bash repotrack ansible ","date":"2024-04-01","objectID":"/posts/yum-download/:3:1","series":null,"tags":["yum"],"title":"YUM 下载全量依赖 rpm 包","uri":"/posts/yum-download/#方案一repotrack推荐"},{"categories":["devops","centos"],"content":" 方案二：yumdownloader安装 yum-utils bash yum -y install yum-utils 下载 ansible 依赖包 bash yumdownloader --resolve --destdir=/tmp ansible 参数说明： --destdir：指定 rpm 包下载目录（不指定时，默认为当前目录） --resolve：下载依赖的 rpm 包 注意： 仅会将主软件包和基于你现在的操作系统所缺少的依赖关系包一并下载。 ","date":"2024-04-01","objectID":"/posts/yum-download/:3:2","series":null,"tags":["yum"],"title":"YUM 下载全量依赖 rpm 包","uri":"/posts/yum-download/#方案二yumdownloader"},{"categories":["devops","centos"],"content":" 方案三：yum 的 downloadonly 插件安装插件 bash yum -y install yum-download 下载 ansible 依赖包 bash yum -y install ansible --downloadonly --downloaddir=/tmp 注意： 与 yumdownloader 命令一样，也是仅会将主软件包和基于你现在的操作系统所缺少的依赖关系包一并下载。 ","date":"2024-04-01","objectID":"/posts/yum-download/:3:3","series":null,"tags":["yum"],"title":"YUM 下载全量依赖 rpm 包","uri":"/posts/yum-download/#方案三yum-的-downloadonly-插件"},{"categories":["python"],"content":"本文介绍如何在 linux 系统构建一个可移植的 Python 二进制文件 工具: portable-python ","date":"2024-03-13","objectID":"/posts/portable-python/:0:0","series":null,"tags":["portable-python"],"title":"Linux 环境下构建可移植 Python 二进制文件","uri":"/posts/portable-python/#"},{"categories":["python"],"content":" 安装 portable-pythonportable-python 是一个常规的 python 命令行工具，它可以通过以下方式安装： pickley: bash pickley install portable-python portable-python --help portable-python inspect /usr/bin/python3 Or pipx: bash pipx install portable-python portable-python inspect /usr/bin/python3 Or pip: bash /usr/bin/python3 -mvenv /tmp/pp /tmp/pp/bin/python -mpip install portable-python /tmp/pp/bin/portable-python --help /tmp/pp/bin/portable-python inspect /usr/bin/python3 ","date":"2024-03-13","objectID":"/posts/portable-python/:1:0","series":null,"tags":["portable-python"],"title":"Linux 环境下构建可移植 Python 二进制文件","uri":"/posts/portable-python/#安装-portable-python"},{"categories":["python"],"content":" 构建可移植 Python 安装依赖 安装 gcc 编译器 bash yum install -y gcc gcc-c++ python 编译依赖 bash yum install -y zlib-devel libffi-devel readline-devel bzip2-devel openssl-devel libuuid-devel gdbm-devel tk-devel 查看当前最新的 Python 版本 bash $ portable-python list cpython: 3.12: 3.12.2 3.11: 3.11.8 3.10: 3.10.13 3.9: 3.9.18 3.8: 3.8.18 3.7: 3.7.17 构建一个可移植的 python bash # 创建工作目录 $ mkdir 3.10.13 $ cd 3.10.13 # 开始构建 Python 3.10.13 版本 $ portable-python build 3.10.13 # 构建完成后生成的二进制文件压缩包 $ ls -l dist/cpython-3.10.13-linux-x86_64.tar.gz 构建工作目录结构 portable-python 使用此文件结构（build 和 dist 文件夹可配置）： text build/ ppp-marker/3.10.13/ # 完整安装（构建完成后） components/ # 静态编译扩展模块的构建在这里 deps/ # --prefix=.../deps 传递给所有组件 ./configure 脚本 sources/ xz-5.4.6.tar.gz # 下载的程序码源包（仅下载一次） dist/ cpython-3.10.13-linux-x86_64.tar.gz # 随时可用的便携式二进制压缩包 ","date":"2024-03-13","objectID":"/posts/portable-python/:2:0","series":null,"tags":["portable-python"],"title":"Linux 环境下构建可移植 Python 二进制文件","uri":"/posts/portable-python/#构建可移植-python"},{"categories":["ProxmoxVE"],"content":" 引用源文: https://foxi.buduanwang.vip/virtualization/1754.html/ ","date":"2024-03-06","objectID":"/posts/pve-disk-pass-through/:0:0","series":null,"tags":["ProxmoxVE","PVE"],"title":"ProxmoxVE(PVE) 硬盘直通","uri":"/posts/pve-disk-pass-through/#"},{"categories":["ProxmoxVE"],"content":" 磁盘直通RDM 是引用于VMware的裸磁盘映射。参考 https://kb.vmware.com/s/article/1017530?lang=zh_CN 将单个硬盘或者分区，通过 qemu 进行映射到虚拟机。在KVM上没有找到类似技术的名词，所以用 RDM 代名。 通过这种方式，硬盘会在虚拟机内会认为是一个 qemu-hdd。 RDM 磁盘直通，不需要开启 iommu。只能在 PVE 命令行中添加。 我们可以通过下面命令，列出当前的硬盘列表 ls -la /dev/disk/by-id/ | grep -Ev 'dm|lvm|part' 如下面的例子 bash root@pve:~# ls -la /dev/disk/by-id/ | grep -Ev 'dm|lvm|part' total 0 drwxr-xr-x 2 root root 540 Apr 28 16:39 . drwxr-xr-x 6 root root 120 Mar 3 15:52 .. lrwxrwxrwx 1 root root 13 Apr 28 16:39 nvme-eui.01000000010000005cd2e431fee65251 -\u003e ../../nvme2n1 lrwxrwxrwx 1 root root 13 Mar 3 15:52 nvme-eui.334843304aa010020025385800000004 -\u003e ../../nvme1n1 lrwxrwxrwx 1 root root 13 Apr 28 17:36 nvme-eui.334843304ab005400025385800000004 -\u003e ../../nvme0n1 lrwxrwxrwx 1 root root 13 Apr 28 16:39 nvme-INTEL_SSDPE2KX020T8_BTLJ039307142P0BGN -\u003e ../../nvme2n1 lrwxrwxrwx 1 root root 13 Mar 3 15:52 nvme-SAMSUNG_MZWLL800HEHP-00003_S3HCNX0JA01002 -\u003e ../../nvme1n1 lrwxrwxrwx 1 root root 13 Apr 28 17:36 nvme-SAMSUNG_MZWLL800HEHP-00003_S3HCNX0JB00540 -\u003e ../../nvme0n1 lrwxrwxrwx 1 root root 9 Mar 3 15:52 scsi-35000c500474cd7eb -\u003e ../../sda lrwxrwxrwx 1 root root 9 Mar 3 15:52 wwn-0x5000c500474cd7eb -\u003e ../../sda nvme 开头的是 nvme 硬盘，ata 开头是走 sata 或者 ata 通道的设备。scsi 是 scsi 设备-阵列卡 raid 或者是直通卡上的硬盘。 我们可以通过 qm set \u003cvmid\u003e --scsiX /dev/disk/by-id/xxxxxxx 进行 RDM 直通 例如你有一个虚拟机，虚拟机的 vmid 是 101，--scsiX，这里的 X 是整数，添加硬盘的序号 如果你不清楚vmid这个是什么含义，你可以参考下面文章 认识虚拟机VMID的作用 你打算直通 intel 的一个 nvme 硬盘，那么你可以使用下面命令 bash qm set 101 --scsi1 /dev/disk/by-id/nvme-INTEL_SSDPE2KX020T8_BTLJ039307142P0BGN 执行之后，你可以在面板中看到下面这个硬盘。 当然，你也可以使用ide或者sata形式直通硬盘，如下 bash qm set 101 --sata1 /dev/disk/by-id/nvme-INTEL_SSDPE2KX020T8_BTLJ039307142P0BGN qm set 101 --ide1 /dev/disk/by-id/nvme-INTEL_SSDPE2KX020T8_BTLJ039307142P0BGN 建议为 scsi 设备，这样性能理论上是最优秀的。 需要注意的是，scsi 会有序号，如 scsi1，scsi0。在操作之前，应该要知道哪些 scsi 号是空的。对于 pve 来说，sata 最多有6个设备。 如果要使用 sata 类型直通，请勿超过sata5. 如果想要了解什么最多 6 个 sata，请参考: https://www.intel.com/content/dam/www/public/us/en/documents/product-briefs/q35-chipset-brief.pdf 如果需要取消直通，可以使用命令 qm set \u003cvmid\u003e --delete scsiX 如上面的例子，你应该输入 bash qm set 101 --delete scsi1 出现 update 即代表成功。可返回网页上查看。 bash root@pve:~# qm set 101 --delete scsi1 update VM 101: -delete scsi1 ","date":"2024-03-06","objectID":"/posts/pve-disk-pass-through/:1:0","series":null,"tags":["ProxmoxVE","PVE"],"title":"ProxmoxVE(PVE) 硬盘直通","uri":"/posts/pve-disk-pass-through/#磁盘直通"},{"categories":["vmware"],"content":" 安装 VMware PowerCLI软件包下载地址: https://developer.vmware.com/web/tool/13.1.0/vmware-powercli/ 官方安装教程: https://developer.vmware.com/docs/15315/GUID-3034A439-E9D7-4743-ABC0-EE38610E15F8.html 先下载好 “VMware PowerCLI” 软件包，按下面步骤进行安装 打开 PowerShell 命令窗口 运行下面的命令，查看 PowerShell Modules 存放路径，将 PowerCLI ZIP 文件解压缩 PowerShell Modules 路径下(有多个路径，选一个即可) powershell $env:PSModulePath 将 PowerCLI ZIP 文件的内容提取到列出的文件夹中的任意一个 运行以下命令，解锁阻止复制的文件，C:\\Users\\liwanggui\\Documents\\WindowsPowerShell\\Modules 为第三步提取文件的文件夹路径，需要替换为自己的路径 powershell Get-ChildItem -Path 'C:\\Users\\liwanggui\\Documents\\WindowsPowerShell\\Modules' -Recurse | Unblock-File 验证 PowerCLI 模块是否已成功安装。 powershell Get-Module VMware* -ListAvailable 安装 Python, PowerCLI 依赖于 Python 3.7.1 或更高版本 (安装过程略) 安装以下 Python 模块 bash pip install -i 'https://mirrors.aliyun.com/pypi/simple/' six psutil lxml pyopenssl 为 PowerCLI 配置 python 环境，使用管理员权限运行, 在 Powershell 中执行以下命令(Python 路径替换为自己安装的路径) powershell Set-PowerCLIConfiguration -PythonPath \"C:\\Program Files\\Python311\\python.exe\" -Scope User 注意: Powershell 如有执行策略提示，可以使用 set-ExecutionPolicy RemoteSigned 命令设置执行策略 ","date":"2024-03-04","objectID":"/posts/vmware-esxi/:1:0","series":null,"tags":["vmware","esxi"],"title":"ESXi 集成网卡驱动","uri":"/posts/vmware-esxi/#安装-vmware-powercli"},{"categories":["vmware"],"content":" 使用 PowerCLI 为 ESXi 集成网卡驱动下载 Offline Bundle 版 ESXi 软件包 : VMware vSphere Hypervisor (ESXi) 8.0U2b 下载网卡驱动文件: Community Networking Driver for ESXi USB Network Native Driver for ESXi 集成打包命令如下 powershell # 指定 Office Bundle 版本的 ESXi 路径 $esxiOfflineBundle = \"D:\\backup\\tmp\\VMware-ESXi-8.0U2b-23305546-depot.zip\" # 现有的配置文件名，可在 Office Bundle 版本的 ESXi 包中的 vmw-ESXi-8.0.2-metadata.zip\\profiles 下找到 $esxiImageProfileName = \"ESXi-8.0U2sb-23305545-standard\" # 定义新的配置文件名 $newImageProfileName = \"ESXi-8.0U2sb-23305545-standard-ext\" # 添加 ESXi 离线包至软件仓库 Add-EsxSoftwareDepot $esxiOfflineBundle # 添加网卡驱动软件包 - vmusb Add-EsxSoftwareDepot D:\\backup\\tmp\\driver\\ESXi80U2-VMKUSB-NIC-FLING-67561870-component-22416446.zip # 添加网卡驱动软件包 - 扩展网卡 Add-EsxSoftwareDepot D:\\backup\\tmp\\driver\\Net-Community-Driver_1.2.7.0-1vmw.700.1.0.15843807_19480755.zip # 从现有的配置，克隆一份配置文件， Vendor 名称可自定义 New-EsxImageProfile -CloneProfile $esxiImageProfileName -Name $newImageProfileName -Vendor wglee # 添加网卡驱动到新的配置文件中, 名称可以驱动压缩包的 vib20 目录查看 Add-EsxSoftwarePackage -ImageProfile $newImageProfileName -SoftwarePackage \"vmkusb-nic-fling\" Add-EsxSoftwarePackage -ImageProfile $newImageProfileName -SoftwarePackage \"net-community\" # 使用新的配置文件，打包新镜像 Export-EsxImageProfile -ImageProfile $newImageProfileName -ExportToIso -FilePath \"D:\\backup\\tmp\\ESXi-8.0U2b-23305546-customized.iso\" 注意: 以上命令中的路径记得要替换成自己环境的路径，打包失败 ","date":"2024-03-04","objectID":"/posts/vmware-esxi/:2:0","series":null,"tags":["vmware","esxi"],"title":"ESXi 集成网卡驱动","uri":"/posts/vmware-esxi/#使用-powercli-为-esxi-集成网卡驱动"},{"categories":["vmware"],"content":" ESXi-Customizer-PS 为 ESXi 集成网卡驱动下载最新的 ESXi-Customizer-PS：https://github.com/VFrontDe-Org/ESXi-Customizer-PS 查询网卡名称和下载驱动网址：https://vibsdepot.v-front.de/wiki/index.php/List_of_currently_available_ESXi_packages 在线打包 powershell .\\ESXi-Customizer-PS.ps1 -v80 -vft -load net55-r8168,net51-r8169 离线打包，需要提前下载 Bundle 版本的 ESXi 文件和网卡驱动, 命令如下 powershell .\\ESXi-Customizer-PS.ps1 -nsc -izip .\\VMware-ESXi-8.0U2b-23305546-depot.zip -pkgDir .\\vib ","date":"2024-03-04","objectID":"/posts/vmware-esxi/:3:0","series":null,"tags":["vmware","esxi"],"title":"ESXi 集成网卡驱动","uri":"/posts/vmware-esxi/#esxi-customizer-ps-为-esxi-集成网卡驱动"},{"categories":["vmware"],"content":" 使用 vCenter Auto Deploy 打包 ESXi (推荐)安装 vCenter ， 下载 VMware-VCSA 安装完成后，登录 vSphere Client 页面，选择 Auto Deploy 页面，启动 Auto Deploy 服务。 新建软件库 上传 Offline Bundle 版本的 ESXi 软件包 上传下载好的网卡驱动包 全部上传完成后，在软件仓库选择 ESXi 软件包的仓库名。在映像配置文件，选项卡下，克隆以 standard 结尾的配置文件（有多个，就选择和 Offline Bundle 版本的 ESXi 软件包名称一致的） 配置 “克隆映像配置文件” 完成配置 导出镜像 镜像生成完成后，会出下载选项 附: 如在镜像生成时有错误提示: Entry is too large to be added to cache, remove any unused depots. 这是因为默认缓存过小，因此需要增加缓存大小，使用 ssh 登录 vCenter Server 查看缓存大小 bash less /etc/vmware-imagebuilder/sca-config/imagebuilder-config.props vmomiPort=8098 cacheSize_GB=2 httpPort=8099 loglevel=INFO 如您所见，cacheSize_GB 默认设置为 2GB text vi /etc/vmware-imagebuilder/sca-config/imagebuilder-config.props less /etc/vmware-imagebuilder/sca-config/imagebuilder-config.props vmomiPort=8098 cacheSize_GB=4 httpPort=8099 loglevel=INFO 重新启动 Image Builder 和 Auto Deploy 服务即可解决 bash service-control --restart vmware-imagebuilder service-control --restart vmware-rbd-watchdog 参考文章; https://vninjadfw.github.io/autodeploycache/ ","date":"2024-03-04","objectID":"/posts/vmware-esxi/:4:0","series":null,"tags":["vmware","esxi"],"title":"ESXi 集成网卡驱动","uri":"/posts/vmware-esxi/#使用-vcenter-auto-deploy-打包-esxi-推荐"},{"categories":["devops","git"],"content":" GitHub HTTPS 代理加速国内克隆 github 仓库不稳定时，可以使用网上免费的代理站点加速，也可以自己部署 GitHub 代理加速站点 ","date":"2024-01-26","objectID":"/posts/github-proxy/:1:0","series":null,"tags":["git","github"],"title":"Github 访问代理(HTTPS \u0026 SSH)","uri":"/posts/github-proxy/#github-https-代理加速"},{"categories":["devops","git"],"content":" 方法1网上免费的 GitHub 代理站点: https://ghproxy.org/ https://mirror.ghproxy.com/ https://hub.fgit.cf hub.fgit.cf 使用文档 https://doc.fastgit.org/zh-cn/guide.html 为方便命令行操作可以使用以下命令对 git 进行配置, bash # 使用 https://hub.fgit.cf/ 站点 git config --global url.\"https://hub.fgit.cf/\".insteadOf \"https://github.com/\" git config protocol.https.allow always # 使用 https://ghproxy.org/ 站点 git config --global url.\"https://ghproxy.org/github.com\".insteadOf \"https://github.com\" ","date":"2024-01-26","objectID":"/posts/github-proxy/:1:1","series":null,"tags":["git","github"],"title":"Github 访问代理(HTTPS \u0026 SSH)","uri":"/posts/github-proxy/#方法1"},{"categories":["devops","git"],"content":" 方法2有代理服务器时，可以设置 Http Proxy bash $ git config --global http.proxy socks5://127.0.0.1:7890 因为 git 底层使用 libcurl 发送 http 请求，而 libcurl 的代理使用 socks5:// 时会在本地解析 DNS，实际使用中我们希望 DNS 也在远程（也就是可以访问 google 的代理节点）解析，所以使用 socks5h ，即 bash $ git config --global http.proxy socks5h://127.0.0.1:7890 h 代表 host，包括了域名解析，即域名解析也强制走这个 proxy。另外不需要配置 https.proxy，这些 git server 都会配置 http redirect to https。 推荐使用 socks5 代理，因为 socks5 包含 http(s)。而且 socks5 代理工作在 osi 七层模型中的会话层（第五层），https/http 代理工作在 osi 七层模型的应用层（第七层）, socks 代理更加底层。所以就没必要配置 git config --global http.proxy http://127.0.0.1:7890 了。 像上面这样配置的话会使本机所有的 git 服务都走了代理，假如你在良心云上（国内主机）部署了自己的 gitea，服务地址 https://gitea.example.com，那么可以只配置 GitHub 的 http proxy，即 bash $ git config --global http.https://github.com.proxy socks5://127.0.0.1:7890 这样做实际上是修改了 ~/.gitconfig 文件，添加了如下内容 ini [http \"https://github.com\"] proxy = socks5://127.0.0.1:7890 ","date":"2024-01-26","objectID":"/posts/github-proxy/:1:2","series":null,"tags":["git","github"],"title":"Github 访问代理(HTTPS \u0026 SSH)","uri":"/posts/github-proxy/#方法2"},{"categories":["devops","git"],"content":" 方法3， 自行部署如有需要部署 GitHub 代理加速站点，可以参考 https://github.com/hunshcn/gh-proxy ","date":"2024-01-26","objectID":"/posts/github-proxy/:1:3","series":null,"tags":["git","github"],"title":"Github 访问代理(HTTPS \u0026 SSH)","uri":"/posts/github-proxy/#方法3-自行部署"},{"categories":["devops","git"],"content":" GitHub SSH 代理加速当使用 ssh 协议克隆仓库出错时，可以尝试参考下这篇文档，在 HTTPS 端口使用 SSH 当有跳板服务器（可以正常访问 Github）或代理时，可以通过配置 SSH Proxy 实现加速, 配置文件 ~/.ssh/config 在 HTTPS 端口使用 SSH 有时，防火墙会完全拒绝允许 SSH 连接。 可以尝试使用通过 HTTPS 端口建立的 SSH 连接克隆。 大多数防火墙规则应允许此操作，但代理服务器可能会干扰。 bash Host github.com Hostname ssh.github.com Port 443 User git IdentityFile ~/.ssh/id_rsa 注意：端口 443 的主机名为 ssh.github.com，而不是 github.com 使用跳板服务器 bash Host github.com Hostname github.com IdentityFile ~/.ssh/id_rsa User git Port 22 ProxyCommand ssh -l root -p 22 jumpserver.server.addr -W %h:%p 使用代理服务器 bash Host github.com Hostname github.com IdentityFile ~/.ssh/id_rsa User git Port 22 ProxyCommand nc -v --proxy-type socks5 --proxy 127.0.0.1:7890 %h %p 文档参考: https://hellodk.cn/post/975 ","date":"2024-01-26","objectID":"/posts/github-proxy/:2:0","series":null,"tags":["git","github"],"title":"Github 访问代理(HTTPS \u0026 SSH)","uri":"/posts/github-proxy/#github-ssh-代理加速"},{"categories":["windows"],"content":"配置 Windows 家庭版 本地用户，密码到期策略为 “永不过期” ","date":"2024-01-25","objectID":"/posts/windows-accounts/:0:0","series":null,"tags":["cmd"],"title":"Windows 本地用户密码过期策略设置","uri":"/posts/windows-accounts/#"},{"categories":["windows"],"content":" 添加用户 cmd # net user test 123456 /add ","date":"2024-01-25","objectID":"/posts/windows-accounts/:1:0","series":null,"tags":["cmd"],"title":"Windows 本地用户密码过期策略设置","uri":"/posts/windows-accounts/#添加用户"},{"categories":["windows"],"content":" 查看本地账户默认过期时间默认到期时间为 42 天 cmd # net accounts 强制用户在时间到期之后多久必须注销?: 从不 密码最短使用期限(天): 0 密码最长使用期限(天): 42 密码长度最小值: 0 保持的密码历史记录长度: None 锁定阈值: 从不 锁定持续时间(分): 30 锁定观测窗口(分): 30 计算机角色: WORKSTATION ","date":"2024-01-25","objectID":"/posts/windows-accounts/:2:0","series":null,"tags":["cmd"],"title":"Windows 本地用户密码过期策略设置","uri":"/posts/windows-accounts/#查看本地账户默认过期时间"},{"categories":["windows"],"content":" 查看具体用户 test，默认创建 42 天后到期 cmd # net user test 用户名 test 全名 注释 用户的注释 国家/地区代码 000 (系统默认值) 帐户启用 Yes 帐户到期 从不 上次设置密码 2024/1/25 星期四 17:13:55 密码到期 2024/3/7 星期四 17:13:55 密码可更改 2024/1/25 星期四 17:13:55 需要密码 Yes 用户可以更改密码 Yes 允许的工作站 All 登录脚本 用户配置文件 主目录 上次登录 从不 可允许的登录小时数 All 本地组成员 *Users 全局组成员 *None ","date":"2024-01-25","objectID":"/posts/windows-accounts/:3:0","series":null,"tags":["cmd"],"title":"Windows 本地用户密码过期策略设置","uri":"/posts/windows-accounts/#查看具体用户-test默认创建-42-天后到期"},{"categories":["windows"],"content":" 设置用户 test 密码策略为永不过期 cmd # wmic useraccount where \"Name=\"test\"\" set PasswordExpires=false 正在更新“\\\\DESKTOP-Q3T526A\\ROOT\\CIMV2:Win32_UserAccount.Domain=\"DESKTOP-Q3T526A\",Name=\"test\"”的属性 属性更新成功。 ","date":"2024-01-25","objectID":"/posts/windows-accounts/:4:0","series":null,"tags":["cmd"],"title":"Windows 本地用户密码过期策略设置","uri":"/posts/windows-accounts/#设置用户-test-密码策略为永不过期"},{"categories":["windows"],"content":" 查看具体用户 test，密码到期时间“帐户到期” 已设置为 “从不” cmd # net user test 用户名 test 全名 注释 用户的注释 国家/地区代码 000 (系统默认值) 帐户启用 Yes 帐户到期 从不 上次设置密码 2024/1/25 星期四 17:13:55 密码到期 从不 密码可更改 2024/1/25 星期四 17:13:55 需要密码 Yes 用户可以更改密码 Yes 允许的工作站 All 登录脚本 用户配置文件 主目录 上次登录 从不 可允许的登录小时数 All 本地组成员 *Users 全局组成员 *None ","date":"2024-01-25","objectID":"/posts/windows-accounts/:5:0","series":null,"tags":["cmd"],"title":"Windows 本地用户密码过期策略设置","uri":"/posts/windows-accounts/#查看具体用户-test密码到期时间"},{"categories":["windows"],"content":" 设置系统策略中默认密码最长时间为无限制 cmd # net accounts /maxpwage:unlimited ","date":"2024-01-25","objectID":"/posts/windows-accounts/:6:0","series":null,"tags":["cmd"],"title":"Windows 本地用户密码过期策略设置","uri":"/posts/windows-accounts/#设置系统策略中默认密码最长时间为无限制"},{"categories":["windows"],"content":" 查看本地账户默认过期时间“密码最长使用期限(天)” 已设置为 “Unlimited” cmd # net accounts 强制用户在时间到期之后多久必须注销?: 从不 密码最短使用期限(天): 0 密码最长使用期限(天): Unlimited 密码长度最小值: 0 保持的密码历史记录长度: None 锁定阈值: 从不 锁定持续时间(分): 30 锁定观测窗口(分): 30 计算机角色: WORKSTATION ","date":"2024-01-25","objectID":"/posts/windows-accounts/:7:0","series":null,"tags":["cmd"],"title":"Windows 本地用户密码过期策略设置","uri":"/posts/windows-accounts/#查看本地账户默认过期时间-1"},{"categories":["bash"],"content":"本文主要介绍 Bash {} 的特殊用法 ","date":"2023-12-28","objectID":"/posts/bash-brace-syntax/:0:0","series":null,"tags":["bash"],"title":"Bash {} 的特殊用法","uri":"/posts/bash-brace-syntax/#"},{"categories":["bash"],"content":" 1. 输出变量的值 bash root@DESKTOP-Q3T526A:~# var=\"hello world\" root@DESKTOP-Q3T526A:~# echo ${var} hello world ","date":"2023-12-28","objectID":"/posts/bash-brace-syntax/:1:0","series":null,"tags":["bash"],"title":"Bash {} 的特殊用法","uri":"/posts/bash-brace-syntax/#1-输出变量的值"},{"categories":["bash"],"content":" 2. 设置变量默认值 语法: ${var:-default} 变量 var 没有定义或者值为空时，输出 default，变量的值保持不变(不会对变量进行赋值操作) bash # 变量未定义时 root@DESKTOP-Q3T526A:~# echo ${var:-default} default # 变量值为空时 root@DESKTOP-Q3T526A:~# var= root@DESKTOP-Q3T526A:~# echo ${var:-default2} default2 语法：${var:=default} 变量 var 没有定义或者为空时，输出 default，同时变量 var 的值被设置为 default bash root@DESKTOP-Q3T526A:~# echo ${var:=default} default root@DESKTOP-Q3T526A:~# echo ${var} default ","date":"2023-12-28","objectID":"/posts/bash-brace-syntax/:2:0","series":null,"tags":["bash"],"title":"Bash {} 的特殊用法","uri":"/posts/bash-brace-syntax/#2-设置变量默认值"},{"categories":["bash"],"content":" 3. 判断变量是否定义及非空 语法: ${var+value} 变量 var 被定义时输出 value, 未定义时输出空字符串, 变量 var 保持不变 bash # var 未定义时 root@DESKTOP-Q3T526A:~# echo ${var+define} # var 定义时 root@DESKTOP-Q3T526A:~# var= root@DESKTOP-Q3T526A:~# echo ${var+define} define 语法: ${var:+value} 变量 var 被定义且非空时时输出 value, 未定义时输出空字符串, 变量 var 保持不变 bash # var 未定义时 root@DESKTOP-Q3T526A:~# echo ${var:+define} # var 定义为空时 root@DESKTOP-Q3T526A:~# var= root@DESKTOP-Q3T526A:~# echo ${var:+define} #var 定义且非空时 root@DESKTOP-Q3T526A:~# var=1 root@DESKTOP-Q3T526A:~# echo ${var:+define} define ","date":"2023-12-28","objectID":"/posts/bash-brace-syntax/:3:0","series":null,"tags":["bash"],"title":"Bash {} 的特殊用法","uri":"/posts/bash-brace-syntax/#3-判断变量是否定义及非空"},{"categories":["bash"],"content":" 4. 查看变量语法: ${!PREFIX*} or ${!PREFIX@} 匹配输出所有以 PREFIX 开头的变量名 bash root@DESKTOP-Q3T526A:~# echo ${!SSH*} SSH_CLIENT SSH_CONNECTION SSH_TTY root@DESKTOP-Q3T526A:~# echo ${!SSH@} SSH_CLIENT SSH_CONNECTION SSH_TTY ","date":"2023-12-28","objectID":"/posts/bash-brace-syntax/:4:0","series":null,"tags":["bash"],"title":"Bash {} 的特殊用法","uri":"/posts/bash-brace-syntax/#4-查看变量"},{"categories":["bash"],"content":" 5. 变量嵌套（间接）引用语法: ${!var} 变量间接引入 bash root@DESKTOP-Q3T526A:~# teacher=ZhangSan root@DESKTOP-Q3T526A:~# job=teacher root@DESKTOP-Q3T526A:~# echo ${!job} ZhangSan 等同于 eval \\$$ ","date":"2023-12-28","objectID":"/posts/bash-brace-syntax/:5:0","series":null,"tags":["bash"],"title":"Bash {} 的特殊用法","uri":"/posts/bash-brace-syntax/#5-变量嵌套间接引用"},{"categories":["bash"],"content":" 6. 获取变量长度语法: ${#var} 返回变量字符长度 bash ${#var} ","date":"2023-12-28","objectID":"/posts/bash-brace-syntax/:6:0","series":null,"tags":["bash"],"title":"Bash {} 的特殊用法","uri":"/posts/bash-brace-syntax/#6-获取变量长度"},{"categories":["bash"],"content":" 7. 转换变量值的大小写变量值的大小写转换，不改原变量的值 语法: ${var,,} 将 var 的值转为小写 ${var^^} 将 var 的值转为大写 bash root@DESKTOP-Q3T526A:~# var1=HELLO root@DESKTOP-Q3T526A:~# var2=hello root@DESKTOP-Q3T526A:~# echo ${var1,,} hello root@DESKTOP-Q3T526A:~# echo ${var2^^} HELLO ","date":"2023-12-28","objectID":"/posts/bash-brace-syntax/:7:0","series":null,"tags":["bash"],"title":"Bash {} 的特殊用法","uri":"/posts/bash-brace-syntax/#7-转换变量值的大小写"},{"categories":["bash"],"content":" 8. 变量字符截取语法: ${var:start_position:length} start_position: 截取字符起始点，以索引 0 开始 length：截取字符的长度 bash root@DESKTOP-Q3T526A:~# var2=hello root@DESKTOP-Q3T526A:~# echo ${var2:1} ello root@DESKTOP-Q3T526A:~# echo ${var2:1:2} el ","date":"2023-12-28","objectID":"/posts/bash-brace-syntax/:8:0","series":null,"tags":["bash"],"title":"Bash {} 的特殊用法","uri":"/posts/bash-brace-syntax/#8-变量字符截取"},{"categories":["bash"],"content":" 9. 查找删除字符串","date":"2023-12-28","objectID":"/posts/bash-brace-syntax/:9:0","series":null,"tags":["bash"],"title":"Bash {} 的特殊用法","uri":"/posts/bash-brace-syntax/#9-查找删除字符串"},{"categories":["bash"],"content":" 1. 从头开始查找语法: ${str#substr} : 从头开始查找匹配，删除最短匹配 substr 的子串 ${str##substr}: 从头开始查找匹配，删除最长匹配 substr 的子串 bash root@DESKTOP-Q3T526A:~# str=\"/usr/local/src\" # 删除最短匹配 root@DESKTOP-Q3T526A:~# echo ${str#/*/} local/src # 删除最长匹配 root@DESKTOP-Q3T526A:~# echo ${str##/*/} src ","date":"2023-12-28","objectID":"/posts/bash-brace-syntax/:9:1","series":null,"tags":["bash"],"title":"Bash {} 的特殊用法","uri":"/posts/bash-brace-syntax/#1-从头开始查找"},{"categories":["bash"],"content":" 2. 从尾部开始查找 ${str%substr} : 从尾部开始查找匹配，删除最短匹配 substr 的子串 ${str%%substr}: 从尾部开始查找匹配，删除最长匹配 substr 的子串 bash root@DESKTOP-Q3T526A:~# str=\"/usr/local/src/\" # 删除最短匹配 root@DESKTOP-Q3T526A:~# echo ${str%*/} /usr/local/src # 删除最长匹配 root@DESKTOP-Q3T526A:~# echo ${str%%*/} # 没有输出,删除了所有匹配的字符 ","date":"2023-12-28","objectID":"/posts/bash-brace-syntax/:9:2","series":null,"tags":["bash"],"title":"Bash {} 的特殊用法","uri":"/posts/bash-brace-syntax/#2-从尾部开始查找"},{"categories":["bash"],"content":" 10. 字符串替换语法: ${str/substr/replace} 使用 replace 替换第一个匹配 substr 的字符串 ${str//substr/replace} 使用 replace 替换所有匹配 substr 的字符串 bash root@DESKTOP-Q3T526A:~# str=\"/usr/local/src/test/src\" # 替换第一个 root@DESKTOP-Q3T526A:~# echo ${str/src/bin} /usr/local/bin/test/src # 替换所有 root@DESKTOP-Q3T526A:~# echo ${str//src/bin} /usr/local/bin/test/bin 语法: ${str/#substr/replace} 以 substr 字符开头时，使用 replace 替换一次匹配的 substr 的字符串 ${str/%substr/replace} 以 substr 字符结尾时，使用 replace 替换一次匹配的 substr 的字符串 bash root@DESKTOP-Q3T526A:~# str=\"hello world, hello welcome, he\" root@DESKTOP-Q3T526A:~# echo ${str/#he/ha} hallo world, hello welcome, he root@DESKTOP-Q3T526A:~# echo ${str/%he/ha} hello world, hello welcome, ha ","date":"2023-12-28","objectID":"/posts/bash-brace-syntax/:10:0","series":null,"tags":["bash"],"title":"Bash {} 的特殊用法","uri":"/posts/bash-brace-syntax/#10-字符串替换"},{"categories":["fileserver"],"content":" 概述ossfs 能让您在 Linux 系统中，将对象存储OSS的存储空间（Bucket）挂载到本地文件系统中，您能够像操作本地文件一样操作OSS的对象（Object），实现数据的共享。 ","date":"2023-11-13","objectID":"/posts/ossfs/:1:0","series":null,"tags":["ossfs"],"title":"使用 ossfs 挂载阿里云 OSS 至本地文件系统","uri":"/posts/ossfs/#概述"},{"categories":["fileserver"],"content":" 运行环境ossfs 基于 fuse 用户态文件系统开发，只能运行在支持 fuse 的机器上。OSS 提供了 Ubuntu 和 CentOS 系统的安装包，如果需要在其它环境下运行，可以通过源码方式构建目标程序。 ossfs 支持在阿里云内网以及互联网环境下使用。在内网环境下时，建议使用内网访问域名，以提升访问速度和稳定性。 ","date":"2023-11-13","objectID":"/posts/ossfs/:2:0","series":null,"tags":["ossfs"],"title":"使用 ossfs 挂载阿里云 OSS 至本地文件系统","uri":"/posts/ossfs/#运行环境"},{"categories":["fileserver"],"content":" 安装 ossfs以 CentOS 8.X 为例, ossfs 依赖 fuse ，使用 yum 安装可以解决依赖问题 bash yum install -y https://gosspublic.alicdn.com/ossfs/ossfs_1.91.1_centos8.0_x86_64.rpm ossfs 下载地址 ","date":"2023-11-13","objectID":"/posts/ossfs/:3:0","series":null,"tags":["ossfs"],"title":"使用 ossfs 挂载阿里云 OSS 至本地文件系统","uri":"/posts/ossfs/#安装-ossfs"},{"categories":["fileserver"],"content":" 配置 ossfs配置账号访问信息 将 Bucket 名称以及具有该 Bucket 访问权限的 AccessKey ID 和 AccessKey Secret 信息存放在 /etc/passwd-ossfs 文件中。文件的权限建议设置为640。 bash sudo echo BucketName:yourAccessKeyId:yourAccessKeySecret \u003e /etc/passwd-ossfs sudo chmod 640 /etc/passwd-ossfs BucketName、yourAccessKeyId、yourAccessKeySecret 请按需替换为您实际的Bucket名称、AccessKey ID和AccessKey Secret，例如： bash sudo echo bucket-test:LTAIbZcdVCmQ****:MOk8x0y9hxQ31coh7A5e2MZEUz**** \u003e /etc/passwd-ossfs sudo chmod 640 /etc/passwd-ossfs 将Bucket挂载到指定目录 bash sudo ossfs BucketName mountfolder -o url=Endpoint 示例: 将杭州地域名称为 bucket-test 的 Bucket 挂载到 /tmp/ossfs 目录下的示例如下： bash sudo mkdir /tmp/ossfs sudo ossfs bucket-test /tmp/ossfs -o url=http://oss-cn-hangzhou.aliyuncs.com 如果您不希望继续挂载此 Bucket，您可以将其卸载 bash sudo fusermount -u /tmp/ossfs ","date":"2023-11-13","objectID":"/posts/ossfs/:4:0","series":null,"tags":["ossfs"],"title":"使用 ossfs 挂载阿里云 OSS 至本地文件系统","uri":"/posts/ossfs/#配置-ossfs"},{"categories":["fileserver"],"content":" 高级配置","date":"2023-11-13","objectID":"/posts/ossfs/:5:0","series":null,"tags":["ossfs"],"title":"使用 ossfs 挂载阿里云 OSS 至本地文件系统","uri":"/posts/ossfs/#高级配置"},{"categories":["fileserver"],"content":" 挂载指定文件目录ossfs 除了可以把整个存储空间挂载到本地文件系统外，还可以通过设置前缀，把存储空间下的某个文件目录挂载到本地文件系统。命令格式如下： bash ossfs bucket:/prefix mount_point -ourl=endpoint 通过这个方式挂载时，需要确保存储空间里存在 ${prefix}/ 对象。您可以通过 ossutil 的 stat（查看Bucket和Object信息）命令查询该对象是否存在 示例：将位于杭州地域的存储空间 bucket-ossfs-test 下的 folder 目录挂载到 /tmp/ossfs-folder 下 bash ossfs bucket-ossfs-test:/folder /tmp/ossfs-folder -ourl=http://oss-cn-hangzhou.aliyuncs.com ","date":"2023-11-13","objectID":"/posts/ossfs/:5:1","series":null,"tags":["ossfs"],"title":"使用 ossfs 挂载阿里云 OSS 至本地文件系统","uri":"/posts/ossfs/#挂载指定文件目录"},{"categories":["fileserver"],"content":" 开机自动挂载目录通过 fstab 的方式自动挂载 在 /etc/fstab 中加入如下命令： bash ossfs#zr-repo mount_point fuse _netdev,url=url,allow_other,nonempty 0 0 保存 /etc/fstab 文件。 执行 mount -a命令，如果没有报错，则说明设置正常 通过 systemd 开机自动进行挂载 创建 /usr/lib/systemd/system/ossfs.service 和 /etc/sysconfig/ossfs /usr/lib/systemd/system/ossfs.service ini [Unit] Description=Mount an Alibaba Cloud OSS bucket as a file system After=syslog.target network.target remote-fs.target [Service] Type=forking EnvironmentFile=-/etc/sysconfig/ossfs ExecStartPre= ExecStart=/usr/local/bin/ossfs $BUCKETNAME $MOUNTPOINT -o url=$ENDPOINT ExecReload= ExecStop=/bin/kill -s QUIT $MAINPID PrivateTmp=true [Install] WantedBy=multi-user.target /etc/sysconfig/ossfs bash BUCKETNAME=bucket-ossfs-test MOUNTPOINT=/tmp/ossfs-folder ENDPOINT=http://oss-cn-hangzhou.aliyuncs.com 注意：值需要替换为自己的当前的配置 启动并设置开机自动挂载 bash systemctl enable --now ossfs.service 更新高级配置参考: https://help.aliyun.com/zh/oss/developer-reference/advanced-configurations ","date":"2023-11-13","objectID":"/posts/ossfs/:5:2","series":null,"tags":["ossfs"],"title":"使用 ossfs 挂载阿里云 OSS 至本地文件系统","uri":"/posts/ossfs/#开机自动挂载目录"},{"categories":["mysql"],"content":"本文以 GreatSQL 数据库 为例，介绍构建 MGR 集群配置 ","date":"2023-11-07","objectID":"/posts/mysql-mgr/:0:0","series":null,"tags":["mysql","greatsql"],"title":"构建 MySQL 8.x MGR 集群","uri":"/posts/mysql-mgr/#"},{"categories":["mysql"],"content":" 1. MGR集群规划本次计划在3台服务器上安装 GreatSQL 数据库并部署 MGR 集群： node ip datadir port role GreatSQL-01 10.10.1.24 /data/GreatSQL/ 3306 PRIMARY GreatSQL-02 10.10.2.3 /data/GreatSQL/ 3306 SECONDARY GreatSQL-03 10.10.2.4 /data/GreatSQL/ 3306 SECONDARY 以下安装配置工作先在三个节点都同样操作一遍。 ","date":"2023-11-07","objectID":"/posts/mysql-mgr/:1:0","series":null,"tags":["mysql","greatsql"],"title":"构建 MySQL 8.x MGR 集群","uri":"/posts/mysql-mgr/#1-mgr集群规划"},{"categories":["mysql"],"content":" 2. 下载安装包点击此处 下载最新的安装包，下载以下一个就可以： GreatSQL-8.0.32-24-Linux-glibc2.28-x86_64.tar.xz 将下载的二进制包放到安装目录下，并解压缩： bash $ cd /usr/local/src $ curl -o GreatSQL-8.0.32-24-Linux-glibc2.28-x86_64.tar.xz https://product.greatdb.com/GreatSQL-8.0.32-24/GreatSQL-8.0.32-24-Linux-glibc2.28-x86_64.tar.xz $ tar xf GreatSQL-8.0.32-24-Linux-glibc2.28-x86_64.tar.xz -C /usr/local/ $ cd /usr/local/ $ ln -s GreatSQL-8.0.32-24-Linux-glibc2.28-x86_64 greatsql 同时修改设置，将 GreatSQL 加入 PATH 环境变量： bash $ echo 'export PATH=/usr/local/greatsql/bin:$PATH' \u003e\u003e ~/.bash_profile $ source ~/.bash_profile 提示： 安装 GreatSQL 需要先安装其他依赖包，可执行下面命令完成： yum install -y pkg-config perl libaio-devel numactl-devel numactl-libs net-tools openssl openssl-devel jemalloc jemalloc-devel perl-Data-Dumper perl-Digest-MD5 更详细的请参考：安装准备。 ","date":"2023-11-07","objectID":"/posts/mysql-mgr/:2:0","series":null,"tags":["mysql","greatsql"],"title":"构建 MySQL 8.x MGR 集群","uri":"/posts/mysql-mgr/#2-下载安装包"},{"categories":["mysql"],"content":" 3. 启动前准备修改 /etc/my.cnf 配置文件 可根据实际情况修改，一般主要涉及数据库文件分区、目录，内存配置等少数几个选项。以下面这份为例： ini [client] user = root socket = /data/GreatSQL/mysql.sock [mysqld] user = mysql port = 3306 #主从复制或MGR集群中，server_id记得要不同 #另外，实例启动时会生成 auto.cnf，里面的 server_uuid 值也要不同 #server_uuid 的值还可以自己手动指定，只要符合uuid的格式标准就可以 server_id = 3306 basedir = /usr/local/greatsql datadir = /data/GreatSQL socket = /data/GreatSQL/mysql.sock pid-file = mysql.pid character-set-server = UTF8MB4 skip_name_resolve = 1 #若你的MySQL数据库主要运行在境外，请务必根据实际情况调整本参数 default_time_zone = \"+8:00\" #performance setttings lock_wait_timeout = 3600 open_files_limit = 65535 back_log = 1024 max_connections = 512 max_connect_errors = 1000000 table_open_cache = 1024 table_definition_cache = 1024 thread_stack = 512K sort_buffer_size = 4M join_buffer_size = 4M read_buffer_size = 8M read_rnd_buffer_size = 4M bulk_insert_buffer_size = 64M thread_cache_size = 768 interactive_timeout = 600 wait_timeout = 600 tmp_table_size = 32M max_heap_table_size = 32M max_allowed_packet = 64M net_buffer_shrink_interval = 180 #log settings log_timestamps = SYSTEM log_error = error.log log_error_verbosity = 3 log_bin = binlog binlog_format = ROW sync_binlog = 1 binlog_cache_size = 4M max_binlog_cache_size = 2G max_binlog_size = 1G # 控制binlog总大小，避免磁盘空间被撑爆 binlog_space_limit = 200G binlog_rows_query_log_events = 1 binlog_expire_logs_seconds = 604800 # MySQL 8.0.22前，想启用MGR的话，需要设置binlog_checksum=NONE才行 binlog_checksum = CRC32 gtid_mode = ON enforce_gtid_consistency = TRUE # myisam settings key_buffer_size = 32M myisam_sort_buffer_size = 128M # replication settings relay_log_recovery = 1 slave_parallel_type = LOGICAL_CLOCK # 可以设置为逻辑CPU数量的2倍 slave_parallel_workers = 64 binlog_transaction_dependency_tracking = WRITESET slave_preserve_commit_order = 1 slave_checkpoint_period = 2 # mgr settings loose-plugin_load_add = 'mysql_clone.so' loose-plugin_load_add = 'group_replication.so' loose-group_replication_group_name = \"aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaa1\" # MGR本地节点IP:PORT，请自行替换 loose-group_replication_local_address = \"10.10.1.24:33061\" report_host = \"10.10.1.24\" ##### MGR 集群所有节点IP:PORT，请自行替换 ## MGR 集群主机白名单配置 loose-group_replication_ip_whitelist = \"10.10.1.24,10.10.2.4,10.10.2.3\" # 或者 10.10.0.0/16 ## 指定 MGR 集群主机列表 loose-group_replication_group_seeds = \"10.10.1.24:33061,10.10.2.4:33061,10.10.2.3:33061\" #### 注意: 由于 mysql8.0 之后加密规则变成 caching_sha2_password，所以使用 MGR 方式复制时，需要打开公钥访问 loose-group_replication_recovery_get_public_key = ON loose-group_replication_start_on_boot = OFF loose-group_replication_bootstrap_group = OFF loose-group_replication_exit_state_action = READ_ONLY loose-group_replication_flow_control_mode = \"DISABLED\" loose-group_replication_single_primary_mode = ON loose-group_replication_majority_after_mode = ON loose-group_replication_communication_max_message_size = 10M loose-group_replication_arbitrator = 0 loose-group_replication_single_primary_fast_mode = 1 loose-group_replication_request_time_threshold = 100 loose-group_replication_primary_election_mode = GTID_FIRST loose-group_replication_unreachable_majority_timeout = 30 loose-group_replication_member_expel_timeout = 5 loose-group_replication_autorejoin_tries = 288 # innodb settings innodb_buffer_pool_size = 1G innodb_buffer_pool_instances = 4 innodb_data_file_path = ibdata1:12M:autoextend innodb_flush_log_at_trx_commit = 1 innodb_log_buffer_size = 32M innodb_log_file_size = 2G innodb_log_files_in_group = 3 innodb_redo_log_capacity = 6G innodb_max_undo_log_size = 4G 新建 mysql 用户 bash $ /sbin/groupadd mysql $ /sbin/useradd -g mysql mysql -d /dev/null -s /sbin/nologin 新建数据库主目录，并修改权限模式及属主 bash $ mkdir -p /data/GreatSQL $ chown -R mysql:mysql /data/GreatSQL $ chmod -R 700 /data/GreatSQL 增加 GreatSQL 系统服务 bash $ vim /lib/systemd/system/mysqld.service [Unit] Description=GreatSQL Server Documentation=man:mysqld(8) Documentation=http://dev.mysql.com/doc/refman/en/using-systemd.html After=network.target After=syslog.target [Install] WantedBy=multi-user.target [Service] # some limits # f","date":"2023-11-07","objectID":"/posts/mysql-mgr/:3:0","series":null,"tags":["mysql","greatsql"],"title":"构建 MySQL 8.x MGR 集群","uri":"/posts/mysql-mgr/#3-启动前准备"},{"categories":["mysql"],"content":" 4. 连接登入 GreatSQL默认初始化密码在日志文件中查找 bash $ grep password /data/GreatSQL/error.log 2023-11-07T10:46:02.690847+08:00 0 [Note] [MY-010309] [Server] Auto generated RSA key files through --sha256_password_auto_generate_rsa_keys are placed in data directory. 2023-11-07T10:46:02.690881+08:00 0 [Note] [MY-010308] [Server] Skipping generation of RSA key pair through --caching_sha2_password_auto_generate_rsa_keys as key files are present in data directory. 2023-11-07T10:46:02.711070+08:00 0 [Note] [MY-010137] [Server] Execution of init_file '/var/lib/mysql-files/install-validate-password-plugin.CBx5Ta.sql' started. 2023-11-07T10:46:02.711286+08:00 6 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: Xd:hM8uq;Xyi # 这是初始化密码 2023-11-07T10:46:03.728877+08:00 0 [Note] [MY-010138] [Server] Execution of init_file '/var/lib/mysql-files/install-validate-password-plugin.CBx5Ta.sql' ended. 登录修改 root 密码 bash $ mysql -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 11 Server version: 8.0.32-24 Copyright (c) 2021-2023 GreatDB Software Co., Ltd Copyright (c) 2009-2023 Percona LLC and/or its affiliates Copyright (c) 2000, 2023, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql\u003e set password='Test@123456'; Query OK, 0 rows affected (0.01 sec) ","date":"2023-11-07","objectID":"/posts/mysql-mgr/:4:0","series":null,"tags":["mysql","greatsql"],"title":"构建 MySQL 8.x MGR 集群","uri":"/posts/mysql-mgr/#4-连接登入-greatsql"},{"categories":["mysql"],"content":" 5. 安装 MySQL Shell为了支持仲裁节点特性，需要安装 GreatSQL 提供的 MySQL Shell发行包。打开 GreatSQL 下载页面，找到 7. GreateSQL MySQL Shell，下载相应的 MySQL Shell 安装包（目前只提供二进制安装包）。 P.S，如果暂时不想使用仲裁节点特性的话，则可以继续使用相同版本的官方MySQL Shell安装包，可以直接用YUM方式安装，此处略过。 本文场景中，选择下面的二进制包： greatsql-shell-8.0.25-16-Linux-glibc2.28-x86_64.tar.xz 将二进制文件包放在 /usr/local 目录下，解压缩： bash cd /usr/local/src wget https://product.greatdb.com/GreatSQL-8.0.25-16/greatsql-shell-8.0.25-16-Linux-glibc2.28-x86_64.tar.xz tar xf greatsql-shell-8.0.25-16-Linux-glibc2.28-x86_64.tar.xz -C /usr/local cd .. \u0026\u0026 ln -s greatsql-shell-8.0.25-16-Linux-glibc2.28-x86_64 greatsql-shell 直接运行 /usr/local/greatsql-shell-8.0.25-16-Linux-glibc2.28-x86_64/bin/mysqlsh 会报如下错误 bash ./bin/mysqlsh: error while loading shared libraries: libpython3.8.so.1.0: cannot open shared object file: No such file or directory 这是因为依赖于 python3.8 , 安装 python3.8 后 MySQL Shell 就可以正常使用 bash yum install -y python38 ","date":"2023-11-07","objectID":"/posts/mysql-mgr/:5:0","series":null,"tags":["mysql","greatsql"],"title":"构建 MySQL 8.x MGR 集群","uri":"/posts/mysql-mgr/#5-安装-mysql-shell"},{"categories":["mysql"],"content":" 6. 利用 MySQL Shell 构建 MGR 集群利用 MySQL Shell for GreatSQL 构建 MGR 集群比较简单，主要有几个步骤： 检查实例是否满足条件。 创建并初始化一个集群。 逐个添加实例。 首先，用管理员账号 root 连接到第一个节点： bash # ./bin/mysqlsh -S /data/GreatSQL/mysql.sock root@localhost Please provide the password for 'root@/data%2FGreatSQL%2Fmysql.sock': *********** MySQL Shell 8.0.25 Copyright (c) 2016, 2021, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type '\\help' or '\\?' for help; '\\quit' to exit. Creating a session to 'root@/data%2FGreatSQL%2Fmysql.sock' Fetching schema names for autocompletion... Press ^C to stop. Your MySQL connection id is 13 Server version: 8.0.32-24 GreatSQL, Release 24, Revision 3714067bc8c No default schema selected; type \\use \u003cschema\u003e to set one. WARNING: Found errors loading plugins, for more details look at the log at: /root/.mysqlsh/mysqlsh.log 执行命令 \\status 查看当前节点的状态，确认连接正常可用。 bash MySQL localhost Py \u003e \\status MySQL Shell version 8.0.25 Connection Id: 13 Current schema: Current user: root@localhost SSL: Not in use. Using delimiter: ; Server version: 8.0.32-24 GreatSQL, Release 24, Revision 3714067bc8c Protocol version: Classic 10 Client library: 8.0.25 Connection: Localhost via UNIX socket Unix socket: /data/GreatSQL/mysql.sock Server characterset: utf8mb4 Schema characterset: utf8mb4 Client characterset: utf8mb4 Conn. characterset: utf8mb4 Result characterset: utf8mb4 Compression: Disabled Uptime: 31 min 39.0000 sec Threads: 4 Questions: 13 Slow queries: 0 Opens: 148 Flush tables: 3 Open tables: 64 Queries per second avg: 0.006 执行 dba.configure_instance() 命令开始检查当前实例是否满足安装MGR集群的条件，如果满足可以直接配置成为MGR集群的一个节点， 创建 MGR 集群用户: mgr 密码: Test@123456 bash MySQL localhost Py \u003e dba.configure_instance() Configuring local MySQL instance listening at port 3306 for use in an InnoDB cluster... This instance reports its own address as 10.10.1.24:3306 ERROR: User 'root' can only connect from 'localhost'. New account(s) with proper source address specification to allow remote connection from all instances must be created to manage the cluster. 1) Create remotely usable account for 'root' with same grants and password 2) Create a new admin account for InnoDB cluster with minimal required grants 3) Ignore and continue 4) Cancel Please select an option [1]: 2 # 选择第二项，创建一个新管理账号用于 mgr 集群配置 Please provide an account name (e.g: icroot@%) to have it created with the necessary privileges or leave empty and press Enter to cancel. Account Name: mgr Password for new account: ********** Confirm password: ********** applierWorkerThreads will be set to the default value of 4. The instance '10.10.1.24:3306' is valid to be used in an InnoDB cluster. Cluster admin user 'mgr'@'%' created. The instance '10.10.1.24:3306' is already ready to be used in an InnoDB cluster. WARNING: '@@slave_parallel_workers' is deprecated and will be removed in a future release. Please use replica_parallel_workers instead. (Code 1287). Successfully enabled parallel appliers. 完成检查并创建完新用户后，退出当前的管理员账户，并用新创建的MGR专用账户登入，准备初始化创建一个新集群： bash $ ./bin/mysqlsh -S /data/GreatSQL/mysql.sock mgr@localhost Please provide the password for 'mgr@/data%2FGreatSQL%2Fmysql.sock': ********** MySQL Shell 8.0.25 Copyright (c) 2016, 2021, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type '\\help' or '\\?' for help; '\\quit' to exit. Creating a session to 'mgr@/data%2FGreatSQL%2Fmysql.sock' Fetching schema names for autocompletion... Press ^C to stop. Your MySQL connection id is 16 Server version: 8.0.32-24 GreatSQL, Release 24, Revision 3714067bc8c No default schema selected; type \\use \u003cschema\u003e to set one. WARNING: Found errors loading plugins, for more details look at the log at: /root/.mysqlsh/mysqlsh.log # 定义一个变量名c，方便下面引用 MySQL localhost Py \u003e c = dba.create_cluster('MGR1'); A new InnoDB cluster will be created on instance '/data%2","date":"2023-11-07","objectID":"/posts/mysql-mgr/:6:0","series":null,"tags":["mysql","greatsql"],"title":"构建 MySQL 8.x MGR 集群","uri":"/posts/mysql-mgr/#6-利用-mysql-shell-构建-mgr-集群"},{"categories":["mysql"],"content":" 7. 部署 MGR 集群配置项","date":"2023-11-07","objectID":"/posts/mysql-mgr/:7:0","series":null,"tags":["mysql","greatsql"],"title":"构建 MySQL 8.x MGR 集群","uri":"/posts/mysql-mgr/#7-部署-mgr-集群配置项"},{"categories":["mysql"],"content":" group_replication_start_on_boot初始配置 MGR 集群时 group_replication_start_on_boot 值，需要配置为 OFF ","date":"2023-11-07","objectID":"/posts/mysql-mgr/:7:1","series":null,"tags":["mysql","greatsql"],"title":"构建 MySQL 8.x MGR 集群","uri":"/posts/mysql-mgr/#group_replication_start_on_boot"},{"categories":["mysql"],"content":" group_replication_bootstrap_groupMGR 集群启动时需要一个引导节点，第一个节点先配置 group_replication_bootstrap_group = ON，第一个节点启动完毕后，记得重置选项 group_replication_bootstrap_group=OFF，避免在后续的操作中导致MGR集群分裂。 ","date":"2023-11-07","objectID":"/posts/mysql-mgr/:7:2","series":null,"tags":["mysql","greatsql"],"title":"构建 MySQL 8.x MGR 集群","uri":"/posts/mysql-mgr/#group_replication_bootstrap_group"},{"categories":["mysql"],"content":" group_replication_recovery_get_public_key错误信息如下： text Authentication plugin 'caching_sha2_password' reported error: Authentication requires secure connection. Error_code: MY-002061 这是由于 mysql8.0 之后加密规则变成 caching_sha2_password，所以使用 MGR 方式复制时，需要打开公钥访问 添加 group_replication_recovery_get_public_key = ON 配置项即可解决 在从节点上执行下面命令，为了重启后还有效需要写入配置中文件中 (my.cnf) bash mysql\u003e STOP GROUP_REPLICATION; mysql\u003e SET GLOBAL group_replication_recovery_get_public_key=ON; mysql\u003e START GROUP_REPLICATION; 除了以上的方法，也可以将 MGR 集群用户密码加密插件改为: mysql_native_password sql set session sql_log_bin=0; alter user repl@'%' IDENTIFIED WITH mysql_native_password by 'repl'; set session sql_log_bin=1; 对于新创建的用户,执行以下命令 sql create user repl@'%' IDENTIFIED WITH mysql_native_password by 'repl'; ","date":"2023-11-07","objectID":"/posts/mysql-mgr/:7:3","series":null,"tags":["mysql","greatsql"],"title":"构建 MySQL 8.x MGR 集群","uri":"/posts/mysql-mgr/#group_replication_recovery_get_public_key"},{"categories":["mysql"],"content":" group_replication_ip_whitelist组复制的 IP 白名单，如果 MGR 节点不在同一个子网段下需要显式指定 MGR 组内成员地址，例如: bash group_replication_ip_whitelist = \"10.10.1.24,10.10.2.4,10.10.2.3\" # or 10.10.0.0/16 ","date":"2023-11-07","objectID":"/posts/mysql-mgr/:7:4","series":null,"tags":["mysql","greatsql"],"title":"构建 MySQL 8.x MGR 集群","uri":"/posts/mysql-mgr/#group_replication_ip_whitelist"},{"categories":["mysql"],"content":" 重启 MGR 集群正常情况下，MGR 集群中的 Primary 节点退出时，剩下的节点会自动选出新的 Primary 节点。 当最后一个节点也退出时，相当于整个MGR集群都关闭了。 这时候任何一个节点启动MGR服务后，都不会自动成为 Primary 节点，需要在启动MGR服务前，先设置 group_replication_bootstrap_group=ON，使其成为引导节点，再启动 MGR 服务，它才会成为 Primary 节点，后续启动的其他节点也才能正常加入集群。 可自行测试，这里不再做演示。 P.S，第一个节点启动完毕后，记得重置选项 group_replication_bootstrap_group=OFF，避免在后续的操作中导致 MGR 集群分裂。 如果是用 MySQL Shell for GreatSQL 重启 MGR 集群，调用 json: rebootClusterFromCompleteOutage() , python reboot_cluster_from_complete_outage() 函数即可，它会自动判断各节点的状态，选择其中一个作为 Primary 节点，然后拉起各节点上的 MGR 服务，完成MGR集群重启。 可以参考这篇文章：万答#12，MGR 整个集群挂掉后，如何才能自动选主，不用手动干预 使用 MySQL Shell for GreatSQL 重启(启动) MGR 集群 当 MGR 集群挂掉后，先启动 greatsql 实例，然后再使用 MySQL Shell for GreatSQL 恢复 MGR 集群 bash # 连接其中一个节点 /usr/local/mysqlsh/bin/mysqlsh --uri mgr@10.10.1.24 # 执行：dba.reboot_cluster_from_complete_outage() 恢复 MGR 集群 MySQL localhost Py \u003e dba.reboot_cluster_from_complete_outage() Restoring the default cluster from complete outage... The instance '10.10.2.4:3306' was part of the cluster configuration. Would you like to rejoin it to the cluster? [y/N]: y The instance '10.10.2.3:3306' was part of the cluster configuration. Would you like to rejoin it to the cluster? [y/N]: y Traceback (most recent call last): File \"\u003cstring\u003e\", line 1, in \u003cmodule\u003e # 错误信息提示我们当前节点上没有最新的数据，不能直接启动 MGR，错误信息中还提供了该去哪个节点启动的建议，所以我们改成在 10.10.2.3:3306 节点上执行拉起 MGR： RuntimeError: Dba.reboot_cluster_from_complete_outage: The active session instance (10.10.1.24:3306) isn't the most updated in comparison with the ONLINE instances of the Cluster's metadata. Please use the most up to date instance: '10.10.2.3:3306'. # 连接 10.10.2.3:3306 节点 /usr/local/mysqlsh/bin/mysqlsh --uri mgr@10.10.2.3 MySQL localhost Py \u003e dba.reboot_cluster_from_complete_outage() Restoring the default cluster from complete outage... The instance '10.10.1.24:3306' was part of the cluster configuration. Would you like to rejoin it to the cluster? [y/N]: y The instance '10.10.2.4:3306' was part of the cluster configuration. Would you like to rejoin it to the cluster? [y/N]: y 10.10.2.3:3306 was restored. Rejoining '10.10.1.24:3306' to the cluster. Rejoining instance '10.10.1.24:3306' to cluster 'MGR1'... The instance '10.10.1.24:3306' was successfully rejoined to the cluster. Rejoining '10.10.2.4:3306' to the cluster. Rejoining instance '10.10.2.4:3306' to cluster 'MGR1'... The instance '10.10.2.4:3306' was successfully rejoined to the cluster. The cluster was successfully rebooted. \u003cCluster:MGR1\u003e 可以看到，MGR 集群已经被正常启动了 ","date":"2023-11-07","objectID":"/posts/mysql-mgr/:7:5","series":null,"tags":["mysql","greatsql"],"title":"构建 MySQL 8.x MGR 集群","uri":"/posts/mysql-mgr/#重启-mgr-集群"},{"categories":["network"],"content":"本例使用 CoreDNS + ETCD 为内部主机提供 DNS 解析服务 ","date":"2023-11-06","objectID":"/posts/coredns/:0:0","series":null,"tags":["dns","coredns"],"title":"部署 CoreDNS 为内部 DNS 服务器","uri":"/posts/coredns/#"},{"categories":["network"],"content":" 部署 ETCD这里采用 yum 源直接安装部署 etcd 单实例，详细部署方法可以参考 部署 etcd 集群 bash yum install etcd systemctl enable --now etcd 注意: CroeDNS 需要 etcd 3.5 及以上版本 ","date":"2023-11-06","objectID":"/posts/coredns/:1:0","series":null,"tags":["dns","coredns"],"title":"部署 CoreDNS 为内部 DNS 服务器","uri":"/posts/coredns/#部署-etcd"},{"categories":["network"],"content":" 部署 CoreDNS本例直接使用容器启动 coredns 服务，具体操作过程如下 准备配置文件 Corefile, 以解析 example.net 域名为例 text example.net:53 { etcd { path /skydns endpoint http://localhost:2379 } loadbalance log errors cache } .:53 { forward . 180.76.76.76 114.114.114.114 reload log errors cache } 准备 docker-compose.yml 文件 yml version: '3' services: coredns: image: coredns/coredns network_mode: host volumes: - ./Corefile:/etc/Corefile:ro command: - -conf - /etc/Corefile 启动 coredns 容器 bash docker-cmopose up -d ","date":"2023-11-06","objectID":"/posts/coredns/:2:0","series":null,"tags":["dns","coredns"],"title":"部署 CoreDNS 为内部 DNS 服务器","uri":"/posts/coredns/#部署-coredns"},{"categories":["network"],"content":" 测试 CoreDNS向 etcd 中添加 example.net 域名的解析记录 添加 example.net 多条 A 记录 bash etcdctl put /skydns/net/example/x1 '{\"host\":\"1.1.1.1\",\"ttl\":60}' etcdctl put /skydns/net/example/x2 '{\"host\":\"1.1.1.1\",\"ttl\":60}' 注意: x1 和 x2 可自定义如 a、b、c 等，并且设置多个 AAAA 等方法类似 添加 www.example.net 多条 A 记录 bash etcdctl put /skydns/net/example/www/x1 '{\"host\":\"2.1.1.1\",\"ttl\":60}' etcdctl put /skydns/net/example/www/x2 '{\"host\":\"2.1.1.2\",\"ttl\":60}' 添加 test.example.net 多条 A 记录 bash etcdctl put /skydns/net/example/test/x1 '{\"host\":\"125.45.48.81\",\"ttl\":60}' etcdctl put /skydns/net/example/test/x2 '{\"host\":\"125.45.48.82\",\"ttl\":60}' 使用 nslookup 或 dig 命令测试 bash # 配置 dns 服务器 echo 'nameserver 127.0.0.1' \u003e /etc/resolv.conf # nslookup 命令解析测试 nslookup example.net nslookup www.example.net nslookup test.example.net # dig 命令解析测试 dig example.net dig www.example.net dig test.example.net 参考地址: https://coredns.io/plugins/etcd/ ","date":"2023-11-06","objectID":"/posts/coredns/:3:0","series":null,"tags":["dns","coredns"],"title":"部署 CoreDNS 为内部 DNS 服务器","uri":"/posts/coredns/#测试-coredns"},{"categories":["network"],"content":" 添加解析记录注意点先上示例 为 example.net 、www.example.net 、test.example.net 添加 A 记录 bash etcdctl put /skydns/net/example/ '{\"host\":\"1.1.1.1\",\"ttl\":60}' etcdctl put /skydns/net/example/www/ '{\"host\":\"1.1.1.2\",\"ttl\":60}' etcdctl put /skydns/net/example/test/ '{\"host\":\"1.1.1.3\",\"ttl\":60}' 解析测试 bash # nslookup example.net Server: 127.0.0.1 Address: 127.0.0.1#53 Name: example.net Address: 1.1.1.1 Name: example.net Address: 1.1.1.2 Name: example.net Address: 1.1.1.3 # nslookup www.example.net Server: 127.0.0.1 Address: 127.0.0.1#53 Name: www.example.net Address: 1.1.1.2 # nslookup test.example.net Server: 127.0.0.1 Address: 127.0.0.1#53 Name: test.example.net Address: 1.1.1.3 可以看到解析 example.net 域名时返回的解析记录有三条记录, 记录的值刚好是 www 和 test 的值， 再看单独解析 www 和 test 时，解析结果返回只有一条。 这时候需要思考为什么产生这个结果？？ 参考 coredns 多解析记录的添加方式，就会明白了。 解析 example.net 域名时会返 /skydns/net/example/ 和 /skydns/net/example/*/ 下所有的值 是不是和添加多解析记录一样，只是添加多解析记录示例使用的字符是 x1, x2 ， 但不要忘记了这个字符是可以自定义的， 正是因为如此 coredns 才会将 www 和 test 的值一并取出 为了避免这个问题，添加解析记录时需采用添加多记录的方式添加。 ","date":"2023-11-06","objectID":"/posts/coredns/:4:0","series":null,"tags":["dns","coredns"],"title":"部署 CoreDNS 为内部 DNS 服务器","uri":"/posts/coredns/#添加解析记录注意点"},{"categories":["ProxmoxVE"],"content":"pve 重装后找回 zfs 存储池，使用如下命令 bash zpool import zpool import -f -m data pve 重装后找回虚拟机的方法 创建同名 vmid 的虚拟机，然后执行如下命令就可以了 bash qm disk rescan 参考链接: https://www.right.com.cn/forum/thread-8300683-1-1.html ","date":"2023-11-06","objectID":"/posts/pve-reinstall/:0:0","series":null,"tags":["ProxmoxVE","PVE"],"title":"PVE 重装后重新挂载 zfs 存储池及找回虚拟机","uri":"/posts/pve-reinstall/#"},{"categories":["postgresql"],"content":"服务器列表 节点名 IP 操作系统 安装软件 备注 pg1 192.168.142.11 uos server 20 PostgreSQL 13.3/patroni 3.1.2/etcd 3.5.4 初始主节点 pg2 192.168.142.12 uos server 20 PostgreSQL 13.3/patroni 3.1.2/etcd 3.5.4 初始备节点 pg3 192.168.142.13 uos server 20 PostgreSQL 13.3/patroni 3.1.2/etcd 3.5.4 初始备节点 VIP: 192.168.142.10 ","date":"2023-10-08","objectID":"/posts/postgresql-cluster-patroni/:0:0","series":null,"tags":["postgresql","patroni"],"title":"PostgreSQL 高可用集群之 patroni","uri":"/posts/postgresql-cluster-patroni/#"},{"categories":["postgresql"],"content":" 安装 postgresql由于 uos server 20 仓库源中的 postgresql 版本过低，这里通过源码编译安装 postgresql, 编译安装过程如下 bash yum install -qy gcc gcc-c++ make readline-devel zlib-devel cd /usr/local/src wget https://ftp.postgresql.org/pub/source/v13.3/postgresql-13.3.tar.gz tar xzf postgresql-13.3.tar.gz cd postgresql-13.3 ./configure --prefix=/usr/local/pg13 make -j`nproc` make install cd contrib/ make install echo '/usr/local/pg13/lib' \u003e /etc/ld.so.conf.d/postgresql.conf ldconfig echo 'export PATH=/usr/local/pg13/bin:$PATH' \u003e /etc/profile.d/postgresql.sh source /etc/profile # 创建 postgres 用户 useradd -r -d /var/lib/pg13 -m postgres echo 'postgres ALL=(ALL) NOPASSWD: ALL' \u003e /etc/sudoers.d/postgres ","date":"2023-10-08","objectID":"/posts/postgresql-cluster-patroni/:1:0","series":null,"tags":["postgresql","patroni"],"title":"PostgreSQL 高可用集群之 patroni","uri":"/posts/postgresql-cluster-patroni/#安装-postgresql"},{"categories":["postgresql"],"content":" 部署 etcd安装配置 etcd bash yum install -y etcd # 配置 etcd cat /etc/etcd/etcd.conf | grep -v ^# ETCD_NAME=e1 ETCD_DATA_DIR=\"/var/lib/etcd/default.etcd\" ETCD_LISTEN_PEER_URLS=\"http://192.168.142.11:2380\" ETCD_LISTEN_CLIENT_URLS=\"http://localhost:2379,http://192.168.142.11:2379\" ETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://192.168.142.11:2380\" ETCD_INITIAL_CLUSTER=\"e1=http://192.168.142.11:2380,e2=http://192.168.142.12:2380,e3=http://192.168.142.13:2380\" ETCD_INITIAL_CLUSTER_STATE=\"new\" ETCD_INITIAL_CLUSTER_TOKEN=\"etcd-cluster\" ETCD_ADVERTISE_CLIENT_URLS=\"http://localhost:2379,http://192.168.142.11:2379\" 注意: 在另外两台主机进行相同操作时，注意配置项 IP 地址的不同 启动 etcd bash systemctl enable --now etcd 提示: 关于 etcd 集群详细信息参考 部署 etcd 集群 ","date":"2023-10-08","objectID":"/posts/postgresql-cluster-patroni/:2:0","series":null,"tags":["postgresql","patroni"],"title":"PostgreSQL 高可用集群之 patroni","uri":"/posts/postgresql-cluster-patroni/#部署-etcd"},{"categories":["postgresql"],"content":" 部署 patroni配置 pip 加速 bash mkdir ~/.pip cat \u003e~/.pip/pip.conf\u003c\u003cEOF [global] index-url = https://mirrors.aliyun.com/pypi/simple/ [install] trusted-host=mirrors.aliyun.com EOF 安装 patroni bash yum install -y python36-devel pip3 install psycopg2-binary pip3 install patroni[etcd] 详细安装信息参考: https://patroni.readthedocs.io/en/latest/README.html 安装 watchdog, patroni 使用 watchdog 为防止出现脑裂, 可选 bash yum install -y watchdog # 初始化 watchdog 字符设备 modprobe softdog # 启动 watchdog 服务 systemctl start watchdog systemctl enable watchdog 配置 patroni, 创建 /etc/patroni 目录，编辑 /etc/patroni/patroni.yml 配置文件 yaml scope: pgcluster namespace: /service/ name: pg1 restapi: listen: 0.0.0.0:8008 connect_address: 192.168.142.11:8008 etcd3: hosts: 192.168.142.11:2379,192.168.142.12:2379,192.168.142.13:2379 log: dir: /etc/patroni file_size: 50000000 file_num: 10 dateformat: '%Y-%m-%d %H:%M:%S' loggers: patroni.postmaster: WARNING bootstrap: dcs: ttl: 30 loop_wait: 10 retry_timeout: 10 maximum_lag_on_failover: 1048576 primary_start_timeout: 300 synchronous_mode: true postgresql: use_pg_rewind: true use_slots: true pg_hba: - local all all trust - local replication all trust - host all all 127.0.0.1/32 trust - host all all ::1/128 trust - host all all 0.0.0.0/0 scram-sha-256 - host replication all 127.0.0.1/32 trust - host replication all ::1/128 trust - host replication replicator 192.168.142.0/24 scram-sha-256 parameters: wal_level: logical log_directory: \"pg_log\" log_destination: \"csvlog\" hot_standby: \"on\" wal_keep_segments: 1000 max_connections: 1000 max_wal_senders: 10 max_replication_slots: 10 wal_log_hints: \"on\" initdb: # Note: It needs to be a list (some options need values, others are switches) - encoding: UTF8 - locale: C - lc-ctype: zh_CN.UTF-8 - data-checksums users: admin: password: admin%123 options: - createrole - createdb postgresql: listen: 0.0.0.0:5432 connect_address: 192.168.142.11:5432 data_dir: /var/lib/pg13/data bin_dir: /usr/local/pg13/bin pgpass: /var/lib/pg13/.pgpass authentication: replication: username: replicator password: repl@123 superuser: username: postgres password: 123456 rewind: # Has no effect on postgres 10 and lower username: postgres password: 123456 callbacks: on_start: /bin/bash /etc/patroni/loadvip.sh on_stop: /bin/bash /etc/patroni/loadvip.sh on_restart: /bin/bash /etc/patroni/loadvip.sh on_role_change: /bin/bash /etc/patroni/loadvip.sh watchdog: mode: automatic # Allowed values: off, automatic, required device: /dev/watchdog safety_margin: 5 tags: nofailover: false noloadbalance: false clonefrom: false nosync: false 另外两台服务器配置项修改点 yaml name: pg1 # 不同节点的名称，需要不一样 restapi: connect_address: 192.168.142.11:8008 # 修改 IP 地址 postgresql: connect_address: 192.168.142.11:5432 # 修改 IP 地址 注意: /etc/patroni 目录权限需要赋于 postgres 用户，patroni 服务日志写在此目录下 创建 patroni_callback 脚本 /etc/patroni/loadvip.sh, 通过 patroni_callback 实现 postgresql 集群高可用 bash #!/bin/bash VIP=192.168.142.10 GATEWAY=192.168.142.2 DEV=ens33 action=$1 role=$2 cluster=$3 log() { echo \"loadvip: $*\" | logger } load_vip() { ip address show ${DEV}| grep -w ${VIP} \u003e/dev/null if [ $? -eq 0 ] ; then log \"vip exists, skip load vip\" else sudo ip addr add ${VIP}/32 dev ${DEV} \u003e/dev/null rc=$? if [ $rc -ne 0 ] ;then log \"fail to add vip ${VIP} at dev ${DEV} rc=$rc\" exit 1 fi log \"added vip ${VIP} at dev ${DEV}\" arping -U -I ${DEV} -s ${VIP} ${GATEWAY} -c 5 \u003e/dev/null rc=$? if [ $rc -ne 0 ] ;then log \"fail to call arping to gateway ${GATEWAY} rc=$rc\" exit 1 fi log \"called arping to gateway ${GATEWAY}\" fi } unload_vip() { ip address show ${DEV} | grep -w ${VIP} \u003e/dev/null if [ $? -eq 0 ] ;then sudo ip addr del ${VIP}/32 dev ${DEV} \u003e/dev/null rc=$? if [ $rc -ne 0 ] ;then log \"fail to delete vip ${VIP} at dev ${DEV} rc=$rc\" exit 1 fi log \"deleted vip ${VIP} at dev ${DEV}\" else log \"vip not exists, skip delete vip\" fi } log \"loadvip start args:'$*'\" case $action in on_start|on_restart|on_role_change) case $role in master) load_vip ;; replica) unload_vip ;; *) log \"wrong role '$role'\" exit 1 ;; esac ;; on","date":"2023-10-08","objectID":"/posts/postgresql-cluster-patroni/:3:0","series":null,"tags":["postgresql","patroni"],"title":"PostgreSQL 高可用集群之 patroni","uri":"/posts/postgresql-cluster-patroni/#部署-patroni"},{"categories":["postgresql"],"content":" 启动 postgresql 集群启动 postgresql 集群很简单，只需运行 patroni 服务即可 bash systemctl start patroni.service systemctl enable patroni.service 查看集群状态 bash [root@localhost ~]# patronictl -c /etc/patroni/patroni.yml list + Cluster: pgcluster (7287503432727295215) ----------+----+-----------+ | Member | Host | Role | State | TL | Lag in MB | +--------+----------------+--------------+-----------+----+-----------+ | pg1 | 192.168.142.11 | Replica | streaming | 2 | 0 | | pg2 | 192.168.142.12 | Leader | running | 2 | | | pg3 | 192.168.142.13 | Sync Standby | streaming | 2 | 0 | +--------+----------------+--------------+-----------+----+-----------+ 参考: https://blog.51cto.com/u_13963746/5394725 https://www.modb.pro/db/73762 ","date":"2023-10-08","objectID":"/posts/postgresql-cluster-patroni/:4:0","series":null,"tags":["postgresql","patroni"],"title":"PostgreSQL 高可用集群之 patroni","uri":"/posts/postgresql-cluster-patroni/#启动-postgresql-集群"},{"categories":["kvdb"],"content":"准备 3 台服务器，确保服务器之间网络通信正常，关闭防火墙(或者开放 2379 和 2380 端口), 服务器列表如下 ip 地址 etcd 名称 192.168.142.11 etcd-1 192.168.142.12 etcd-2 192.168.142.13 etcd-3 ","date":"2023-10-07","objectID":"/posts/etcd-cluster/:0:0","series":null,"tags":["etcd"],"title":"部署 etcd 集群","uri":"/posts/etcd-cluster/#"},{"categories":["kvdb"],"content":" 安装 etcd bash wget https://github.com/etcd-io/etcd/releases/download/v3.5.9/etcd-v3.5.9-linux-amd64.tar.gz tar xzf etcd-v3.5.9-linux-amd64.tar.gz cd etcd-v3.5.9-linux-amd64/ mv etcd etcdctl etcdutl /usr/bin/ ","date":"2023-10-07","objectID":"/posts/etcd-cluster/:1:0","series":null,"tags":["etcd"],"title":"部署 etcd 集群","uri":"/posts/etcd-cluster/#安装-etcd"},{"categories":["kvdb"],"content":" 配置 etcd配置 etcd-1 bash useradd -r -d /var/lib/etcd -m etcd mkdir /etc/etcd cat \u003e/etc/etcd/etcd.conf\u003c\u003cEOF name: etcd-1 data-dir: /var/lib/etcd/data listen-client-urls: http://0.0.0.0:2379 advertise-client-urls: http://192.168.142.11:2379,http://localhost:2379 listen-peer-urls: http://192.168.142.11:2380 initial-advertise-peer-urls: http://192.168.142.11:2380 initial-cluster: etcd-1=http://192.168.142.11:2380,etcd-2=http://192.168.142.12:2380,etcd-3=http://192.168.142.13:2380 initial-cluster-token: etcd-cluster initial-cluster-state: new EOF cat \u003e/usr/lib/systemd/system/etcd.service\u003c\u003cEOF [Unit] Description=Etcd Server After=network.target After=network-online.target Wants=network-online.target [Service] Type=notify WorkingDirectory=/var/lib/etcd/ User=etcd ExecStart=/usr/bin/etcd --config-file /etc/etcd/etcd.conf Restart=on-failure LimitNOFILE=65536 [Install] WantedBy=multi-user.target EOF 配置 etcd-2 bash useradd -r -d /var/lib/etcd -m etcd mkdir /etc/etcd cat \u003e/etc/etcd/etcd.conf\u003c\u003cEOF name: etcd-2 data-dir: /var/lib/etcd/data listen-client-urls: http://0.0.0.0:2379 advertise-client-urls: http://192.168.142.12:2379,http://localhost:2379 listen-peer-urls: http://192.168.142.12:2380 initial-advertise-peer-urls: http://192.168.142.12:2380 initial-cluster: etcd-1=http://192.168.142.11:2380,etcd-2=http://192.168.142.12:2380,etcd-3=http://192.168.142.13:2380 initial-cluster-token: etcd-cluster initial-cluster-state: new EOF cat \u003e/usr/lib/systemd/system/etcd.service\u003c\u003cEOF [Unit] Description=Etcd Server After=network.target After=network-online.target Wants=network-online.target [Service] Type=notify WorkingDirectory=/var/lib/etcd/ User=etcd ExecStart=/usr/bin/etcd --config-file /etc/etcd/etcd.conf Restart=on-failure LimitNOFILE=65536 [Install] WantedBy=multi-user.target EOF 配置 etcd-3 bash useradd -r -d /var/lib/etcd -m etcd mkdir /etc/etcd cat \u003e/etc/etcd/etcd.conf\u003c\u003cEOF name: etcd-1 data-dir: /var/lib/etcd/data listen-client-urls: http://0.0.0.0:2379 advertise-client-urls: http://192.168.142.13:2379,http://localhost:2379 listen-peer-urls: http://192.168.142.13:2380 initial-advertise-peer-urls: http://192.168.142.13:2380 initial-cluster: etcd-1=http://192.168.142.11:2380,etcd-2=http://192.168.142.12:2380,etcd-3=http://192.168.142.13:2380 initial-cluster-token: etcd-cluster initial-cluster-state: new EOF cat \u003e/usr/lib/systemd/system/etcd.service\u003c\u003cEOF [Unit] Description=Etcd Server After=network.target After=network-online.target Wants=network-online.target [Service] Type=notify WorkingDirectory=/var/lib/etcd/ User=etcd ExecStart=/usr/bin/etcd --config-file /etc/etcd/etcd.conf Restart=on-failure LimitNOFILE=65536 [Install] WantedBy=multi-user.target EOF etcd 配置项说明 yaml #etcd名称，自定义 name: etcd-1 #存放etcd数据的目录，自定义 data-dir: /opt/etcd-v3.5.0/data #监听URL，用户客户端和SERVER进行通信 listen-client-urls: http://192.168.210.15:2379,http://127.0.0.1:2379 #告知客户端自身的URL，TCP 2379端口用于监听客户端请求 advertise-client-urls: http://192.168.210.15:2379,http://127.0.0.1:2379 #监听URL，用于和其他节点通信 listen-peer-urls: http://192.168.210.15:2380 #告知集群其他节点，端口2380用于集群通信 initial-advertise-peer-urls: http://192.168.210.15:2380 #定义了集群内所有成员 initial-cluster: etcd-1=http://192.168.210.15:2380,etcd-2=http://192.168.108.81:2380,etcd-3=http://192.168.108.33:2380 #集群ID，唯一标识 initial-cluster-token: etcd-cluster-token #集群状态，new为新创建集群，existing为已经存在的集群 initial-cluster-state: new ","date":"2023-10-07","objectID":"/posts/etcd-cluster/:2:0","series":null,"tags":["etcd"],"title":"部署 etcd 集群","uri":"/posts/etcd-cluster/#配置-etcd"},{"categories":["kvdb"],"content":" 启动 etcd 集群在 3 台服务器分别执行以下命令, 启动 etcd bash systemctl start etcd.service 查看集群成员信息 bash [root@localhost etcd]# etcdctl endpoint status --endpoints=192.168.142.11:2379,192.168.142.12:2379,192.168.142.13:2379 -w table +----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+ | ENDPOINT | ID | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS | +----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+ | http://192.168.142.11:2379 | 60f0df9302fbd5e2 | 3.5.4 | 20 kB | true | false | 2 | 10 | 10 | | | http://192.168.142.12:2379 | fc3fb054d5b9a580 | 3.5.4 | 20 kB | false | false | 2 | 10 | 10 | | | http://192.168.142.13:2379 | 875d90cd443032bb | 3.5.4 | 20 kB | false | false | 2 | 10 | 10 | | +----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+ [root@localhost etcd]# etcdctl endpoint health --endpoints=192.168.142.11:2379,192.168.142.12:2379,192.168.142.13:2379 -w table +----------------------------+--------+------------+-------+ | ENDPOINT | HEALTH | TOOK | ERROR | +----------------------------+--------+------------+-------+ | http://192.168.142.11:2379 | true | 4.485896ms | | | http://192.168.142.12:2379 | true | 6.322733ms | | | http://192.168.142.13:2379 | true | 6.230848ms | | +----------------------------+--------+------------+-------+ [root@localhost etcd]# etcdctl member list --endpoints=192.168.142.11:2379,192.168.142.12:2379,192.168.142.13:2379 -w table +------------------+---------+-------+----------------------------+--------------------------------------------------+------------+ | ID | STATUS | NAME | PEER ADDRS | CLIENT ADDRS | IS LEARNER | +------------------+---------+-------+----------------------------+--------------------------------------------------+------------+ | 60f0df9302fbd5e2 | started | etcd0 | http://192.168.142.11:2380 | http://192.168.142.11:2379,http://localhost:2379 | false | | 875d90cd443032bb | started | etcd2 | http://192.168.142.13:2380 | http://192.168.142.13:2379,http://localhost:2379 | false | | fc3fb054d5b9a580 | started | etcd1 | http://192.168.142.12:2380 | http://192.168.142.12:2379,http://localhost:2379 | false | +------------------+---------+-------+----------------------------+--------------------------------------------------+------------+ 管理 etcd cluster 成员注意事项参考: https://www.modb.pro/db/153295 ","date":"2023-10-07","objectID":"/posts/etcd-cluster/:3:0","series":null,"tags":["etcd"],"title":"部署 etcd 集群","uri":"/posts/etcd-cluster/#启动-etcd-集群"},{"categories":["devops"],"content":"由于统信 UOS Server 服务器系统官方没有提供 docker 基础镜像，所以只能自己动手制作，通过在互联网上查找资料后，制作测试成功并已上传至 DockerHub 仓库，如需使用可通过以下命令直接获取 bash docker pull liwanggui/uos-server 下面将介绍镜像制作的具体方法，镜像基于 uos-server-20-1060a-amd64 镜像最小化安装制作 ","date":"2023-09-21","objectID":"/posts/uos-server-docker-image/:0:0","series":null,"tags":["docker","uos server"],"title":"制作 uos server docker 镜像","uri":"/posts/uos-server-docker-image/#"},{"categories":["devops"],"content":" 制作镜像具体镜像制作步骤如下 最小化安装 uos-server-20-1060a 使用如下命令对系统进行打包, 打包时需排除 (dev/proc/boot/run/sys 目录), 使用 -p 选项保持文件目录权限不变 bash tar cvpf uos-server.tar bin etc home lib lib64 media mnt opt root sbin srv sys tmp usr var 将 tar 包导入 docker bash docker import uos-server.tar uos-server:v20-1060a 以上直接打包的 tar 包中会存在一些垃圾文件，可以 tar --delete 命令删除 示例, 删除 var/lock 软链接文件 bash tar --delete --file=uos-server.tar var/lock 提示: 如需要删除一些不必要的软件包，可以在 步骤2 前进行操作 参考文章: https://cloud.tencent.com/developer/article/1920079 ","date":"2023-09-21","objectID":"/posts/uos-server-docker-image/:1:0","series":null,"tags":["docker","uos server"],"title":"制作 uos server docker 镜像","uri":"/posts/uos-server-docker-image/#制作镜像"},{"categories":["devops"],"content":"使用 Chrome 和 Edge 浏览器登录 Cockpit 时，提示 “此浏览器过旧” 的错误，如图 这个浏览器太老，无法运行 Web 控制台（缺少 selector(:is():where())） 解决方法 如果使用的操作系统没有提供 Cockpit 更新包，可以使用以下方法修复这个错误 bash sed -i 's/is():where()/is(*):where(*)/' /usr/share/cockpit/static/login.js 其实这个代码原理就是把文档 login.js 中的 “is():where()” 替换为 “is(*):where(*)” 官方博客链接地址: https://cockpit-project.org/blog/login-issues.html ","date":"2023-09-21","objectID":"/posts/cockpit-unable-to-login/:0:0","series":null,"tags":["cockpit"],"title":"新版本浏览器导致 Cockpit 无法登录的问题","uri":"/posts/cockpit-unable-to-login/#"},{"categories":["devops","ubuntu"],"content":"本实验以 Ubuntu server 22.04 系统为基础进行 ","date":"2023-09-15","objectID":"/posts/ubuntu-tigervnc/:0:0","series":null,"tags":["ubuntu","tigervnc","vnc"],"title":"Ubuntu 安装配置 tigervnc \u0026 noVNC","uri":"/posts/ubuntu-tigervnc/#"},{"categories":["devops","ubuntu"],"content":" 安装 xfce4安装 xfce4 桌面及其终端工具，如果你是 ubuntu 桌面系统，这步可以跳过 bash liwanggui@ubuntu:~$ sudo apt install -y xrdp xfce4 xfce4-terminal 注意: 安装 xrdp 包可以防止在 vnc 远程连接打开软件时，出现 input/output 错误 ","date":"2023-09-15","objectID":"/posts/ubuntu-tigervnc/:1:0","series":null,"tags":["ubuntu","tigervnc","vnc"],"title":"Ubuntu 安装配置 tigervnc \u0026 noVNC","uri":"/posts/ubuntu-tigervnc/#安装-xfce4"},{"categories":["devops","ubuntu"],"content":" 安装配置 tigervnc","date":"2023-09-15","objectID":"/posts/ubuntu-tigervnc/:2:0","series":null,"tags":["ubuntu","tigervnc","vnc"],"title":"Ubuntu 安装配置 tigervnc \u0026 noVNC","uri":"/posts/ubuntu-tigervnc/#安装配置-tigervnc"},{"categories":["devops","ubuntu"],"content":" 安装 tigervnc通过二进制压缩包，安装最新版本的 tigervnc bash liwanggui@ubuntu:~$ wget -qO- https://nchc.dl.sourceforge.net/project/tigervnc/stable/1.13.1/tigervnc-1.13.1.x86_64.tar.gz | sudo tar xz --strip 1 -C / 注意: 通过 apt 安装的 tigervnc 版本较旧一点 ","date":"2023-09-15","objectID":"/posts/ubuntu-tigervnc/:2:1","series":null,"tags":["ubuntu","tigervnc","vnc"],"title":"Ubuntu 安装配置 tigervnc \u0026 noVNC","uri":"/posts/ubuntu-tigervnc/#安装-tigervnc"},{"categories":["devops","ubuntu"],"content":" 配置 tigervnc生成 vnc 密码，如下所示，按提示输入密码 bash liwanggui@ubuntu:~$ vncpasswd Password: Verify: Would you like to enter a view-only password (y/n)? y Password: Verify: liwanggui@ubuntu:~$ ls -lh .vnc/ total 4.0K -rw------- 1 liwanggui liwanggui 16 Sep 15 05:56 passwd 修改 /etc/tigervnc/vncserver.users 配置文件，配置信息可以参考文件中的提示 添加如下配置信息 conf # TigerVNC User assignment # # This file assigns users to specific VNC display numbers. # The syntax is \u003cdisplay\u003e=\u003cusername\u003e. E.g.: # # :2=andrew # :3=lisa :0=liwanggui 提示: display 为 :0 表示使用的 vnc 端口号为 5900, 如果是 :1 端口则是 5900 + 1 为 5901 启动 vncserver bash liwanggui@ubuntu:~$ sudo systemctl start vncserver@:0 liwanggui@ubuntu:~$ sudo systemctl status vncserver@:0 ● vncserver@:0.service - Remote desktop service (VNC) Loaded: loaded (/lib/systemd/system/vncserver@.service; disabled; vendor preset: enabled) Active: active (running) since Fri 2023-09-15 06:03:03 UTC; 3s ago Process: 39543 ExecStart=/usr/libexec/vncsession-start :0 (code=exited, status=0/SUCCESS) Main PID: 39550 (vncsession) Tasks: 0 (limit: 4516) Memory: 744.0K CPU: 14ms CGroup: /system.slice/system-vncserver.slice/vncserver@:0.service ‣ 39550 /usr/sbin/vncsession liwanggui :0 Sep 15 06:03:03 ubuntu systemd[1]: Starting Remote desktop service (VNC)... Sep 15 06:03:03 ubuntu systemd[1]: Started Remote desktop service (VNC). 此时你可以通过 vnc 客户端工具进行远程连接了 提示: 如果要将 vnc 设为开机自启, 可以运行 sudo systemctl enable vncserver@:0 ","date":"2023-09-15","objectID":"/posts/ubuntu-tigervnc/:2:2","series":null,"tags":["ubuntu","tigervnc","vnc"],"title":"Ubuntu 安装配置 tigervnc \u0026 noVNC","uri":"/posts/ubuntu-tigervnc/#配置-tigervnc"},{"categories":["devops","ubuntu"],"content":" noVNCnoVNC 是一个可以通过浏览器操作 vnc 远程桌面的工具，关于 noVNC 的详细信息可以查看其 Github 站点 安装 noVNC bash export GHPROXY=https://gh.wglee.org/ curl -sL ${GHPROXY}https://github.com/novnc/noVNC/archive/refs/tags/v1.4.0.tar.gz | tar xz -C /opt cd /opt/noVNC-1.4.0 \u0026\u0026 ln -sf vnc.html index.html git clone --depth=1 ${GHPROXY}https://github.com/novnc/websockify /opt/noVNC-1.4.0/utils/websockify 通过以下命令，运行 noVNC bash /opt/noVNC-1.4.0/utils/novnc_proxy noVNC 默认监控端口为 6080, 启动成功后，可以能过浏览器访问 http://\u003cserver_ip_address\u003e:6080 提示: noVNC 默认连接的 vnc 端口为 5900，如果你的 vnc 商品不是 5900，请使用 --vnc VNC_HOST:PORT 指定 ","date":"2023-09-15","objectID":"/posts/ubuntu-tigervnc/:3:0","series":null,"tags":["ubuntu","tigervnc","vnc"],"title":"Ubuntu 安装配置 tigervnc \u0026 noVNC","uri":"/posts/ubuntu-tigervnc/#novnc"},{"categories":["container"],"content":" 概述docker-compose 项目是docker官方的开源项目， 负责实现对docker容器集群的快速编排，来轻松高效的管理容器，定义运行多个容器。 docker-compose将所管理的容器分为三层， 分别是工程（project），服务（service）以及容器（containner） docker-compose运行目录下的所有文件（docker-compose.yml文件、extends文件或环境变量等）组成一个工程，如无特殊指定，工程名即为当前目录名。 一个工程当中，可以包含多个服务，每个服务中定义了容器运行的镜像、参数、依赖。 一个服务中可以包括多个容器实例，docker-compose并没有解决负载均衡的问题。因此需要借助其他工具实现服务发现及负载均衡，比如 consul。 docker-compose​的工程配置文件默认为 docker-compose.yml。可以通过环境变量COMPOSE_FILE -f 参数自定义配置文件，其自定义多个有依赖关系的服务及每个人服务运行的容器。 官方文档： https://docs.docker.com/compose/ GitHub： https://github.com/docker/compose/releases/ ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:1:0","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#概述"},{"categories":["container"],"content":" Compose 和 Docker 兼容性Compose 文件格式有多个版本：1、2、2.x、和 3.x。下面的表格是 Compose 文件所支持的指定的 docker 发行版： docke compose \u0026 docker 版本对应图 ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:2:0","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#compose-和-docker-兼容性"},{"categories":["container"],"content":" 安装 docker bash # 安装yum-config-manager配置工具 yum -y install yum-utils # 建议使用阿里云yum源：（推荐） #yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo # 安装docker-ce版本 yum install -y docker-ce # 启动并开机启动 systemctl enable --now docker docker --version 提示: 可以使用 docker 官方提供在线脚本进行安装，参考: docker - 快速安装 ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:3:0","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#安装-docker"},{"categories":["container"],"content":" 安装 docker-compose官方安装地址教程：https://docs.docker.com/compose/install/other/ bash curl -SL https://github.com/docker/compose/releases/download/v2.21.0/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose chmod +x /usr/bin/docker-compose docker-compose --version ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:4:0","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#安装-docker-compose"},{"categories":["container"],"content":" 环境变量Docker Compose 允许你使用多种方法为服务设置环境变量。 这些环境变量可以用来配置你的应用程序或将敏感信息传递给你的容器。 下面是一些设置 Docker Compose 环境变量的方法： 在 docker-compose.yml 文件中设置环境变量 你可以在 docker-compose.yml​ 文件中为每个服务设置环境变量。在服务配置中，使用 environment 关键字，并在其中列出需要设置的环境变量和其值。 yaml services: web: image: nginx environment: MY_VAR: my_value 从 .env 文件中读取环境变量 你可以将环境变量存储在一个 .env​ 文件中，并让 Docker Compose 读取它。在 docker-compose.yml​ 文件中，使用 env_file​ 关键字并指定 .env 文件的路径。 yaml services: web: image: nginx env_file: - .env 使用 shell 环境变量 你也可以在启动 docker-compose 命令时，使用 shell 环境变量传递环境变量值。例如： bash $ export MY_VAR=my_value $ docker-compose up 在 docker-compose.yml​ 文件中使用 ${MY_VAR} 语法来引用 shell 环境变量。 yaml services: web: image: nginx environment: MY_VAR: ${MY_VAR} 使用环境变量可以使你的应用程序更具灵活性，并且可以方便地管理敏感信息。 ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:5:0","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#环境变量"},{"categories":["container"],"content":" 编排中的字段详解在 Docker Compose 编排文件中，有一些重要的字段需要了解： ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:6:0","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#编排中的字段详解"},{"categories":["container"],"content":" versionversion​ 字段指定了 Docker Compose 编排文件的版本。 当前最新版本是 3。 yaml version: '3' ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:6:1","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#version"},{"categories":["container"],"content":" servicesservices 字段指定了在 Docker Compose 编排中要运行的服务。每个服务都有一个名称，并指定要使用的镜像和容器的配置选项。 以下是一个简单的 services 配置的示例： yaml services: web: build: . ports: - \"5000:5000\" redis: image: \"redis:alpine\" ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:6:2","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#services"},{"categories":["container"],"content":" build 与 image build build 字段允许在 Docker Compose 编排中指定 Dockerfile 的位置，从而可以使用 Docker Compose 构建镜像。 例如，以下是使用本地 Dockerfile 的示例： yaml services: web: build: . 也可以指定一个包含 Dockerfile 的目录： yaml services: web: build: ./my-web-app image image 字段指定要使用的 Docker 镜像。例如： yaml services: web: image: nginx 【温馨提示】build 和 image 二选一即可，也可以同时写，但是一般只选择 image 吧。 yaml version: '3.8' services: web: build: ./web image: myapp/web:latest 上面的配置指定了服务名称为 web, Dockerfile 路径为 ./web，镜像名称为 myapp/web​，标签为 latest​。在运行 docker-compose build​ 命令时，会自动构建名为 myapp/web:latest 的镜像。 ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:6:3","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#build-与-image"},{"categories":["container"],"content":" networksnetworks 字段指定了要使用的网络。默认情况下，Docker Compose 创建一个名为 default 的网络。 以下是一个使用自定义网络的示例： yaml networks: my-network: driver: bridge ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:6:4","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#networks"},{"categories":["container"],"content":" volumesvolumes 字段指定了要使用的数据卷。 以下是一个使用数据卷的示例（下面会细讲）： yaml volumes: my-volume: driver: local ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:6:5","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#volumes"},{"categories":["container"],"content":" environment 与 environment_file environment environment 字段指定了要设置的环境变量。以下是一个使用环境变量的示例： yaml environment: MY_VAR: my_value environment_file environment_file：指定从文件中读取环境变量。 yaml environment_file: .env ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:6:6","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#environment-与-environment_file"},{"categories":["container"],"content":" ports 与 expose ports ports 字段指定了要宿主机映射到容器的端口（宿主机端口:容器端口）。以下是一个使用端口映射的示例： yaml ports: - \"8080:80\" expose expose 字段是用于在 Docker 容器内部暴露端口的选项，可以让其他容器连接到这些端口，但不会将它们映射到 Docker 主机上。 在 docker-compose.yml 文件中使用 expose 选项来指定容器内部需要暴露的端口。例如，以下示例定义了一个 web 服务，它暴露了 8000 和 8080 端口： yaml version: '3' services: web: image: myapp:latest expose: - \"8000\" - \"8080\" 当您使用 expose​ 选项时，其他容器可以使用 Docker 的内部网络进行连接。例如，如果您有另一个服务 worker，它需要连接到 web 服务的 8000 端口，则可以在 worker 服务的 docker-compose.yml 文件中使用 links 选项： yaml version: '3' services: worker: image: myworker:latest links: - web ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:6:7","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#ports-与-expose"},{"categories":["container"],"content":" depends_ondepends_on 字段指定了服务之间的依赖关系。例如，如果 web 服务依赖于 db 服务，则可以使用以下示例： yaml depends_on: - db ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:6:8","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#depends_on"},{"categories":["container"],"content":" restartDocker Compose 提供了几种重启策略，以便在容器出现故障时自动重启它们。以下是可用的重启策略： no: 不重启任何容器。如果容器停止，Compose 不会尝试自动重启它们。（默认策略） always: 如果容器停止，Compose 将自动重启它。（常用） on-failure: 只有在容器因非 0 退出码而停止时才会重启。 unless-stopped: 除非手动停止，否则始终重启容器。这相当于使用 docker run 命令时使用的 --restart=unless-stopped 标志。 这些策略可以在 docker-compose.yml 文件中通过 restart 键指定，例如： yaml version: '3' services: web: image: myapp:latest restart: always 这个示例使用 always 策略，这意味着如果 web 容器停止，Compose 将自动重启它。 ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:6:9","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#restart"},{"categories":["container"],"content":" commandcommand 字段可以使用多种写法来指定容器启动时要执行的命令，具体取决于您的需求和偏好。 以下是一些常见的写法示例： 字符串形式 yaml version: '3' services: web: image: myapp:latest command: python manage.py runserver 0.0.0.0:8000 在这个示例中，command 字段的值是一个字符串，表示要执行的命令和参数。 列表形式 yaml version: '3' services: web: image: myapp:latest command: - python - manage.py - runserver - 0.0.0.0:8000 在这个示例中，command 字段的值是一个列表，每个元素都表示要执行的命令或参数。 Shell 命令形式 yaml version: '3' services: web: image: myapp:latest # 两种写法 # command: sh -c \"python manage.py runserver 0.0.0.0:8000\" command: [\"sh\",\"-c\",\"python manage.py runserver 0.0.0.0:8000\"] 使用环境变量形式 yaml version: '3' services: web: image: myapp:latest environment: - ENVIRONMENT=production command: python manage.py runserver 0.0.0.0:${PORT} 在这个示例中，command 字段中的 ${PORT}​ 将被替换为 web 服务的环境变量 PORT 的值。 ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:6:10","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#command"},{"categories":["container"],"content":" configs 与 secrets configs configs：指定容器使用的配置文件。 yaml configs: - source: my-config target: /etc/nginx/conf.d/default.conf 上面的例子中，将名为 my-config 的配置文件复制到容器的 /etc/nginx/conf.d/default.conf 目录下。 secrets secrets： 指定容器使用的机密数据。 yaml secrets: - db_password ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:6:11","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#configs-与-secrets"},{"categories":["container"],"content":" hostname 与 container_namehostname​ 和 container_name 都是用来定义 Docker 容器的标识符，但是它们的含义不同。 hostname hostname 用于设置容器的主机名，也就是在容器内部可以使用的名称。 例如，如果您在容器内部使用 ping hostname 命令，它将解析为容器的 IP 地址。可以使用以下格式设置主机名： yaml version: '3' services: web: image: myapp:latest container_name: myapp 在这个示例中，web 服务的容器主机名被设置为 myapp-container。 container_name container_name 用于给容器命名，也就是在 Docker 主机上使用的名称。可以使用以下格式设置容器名称： yaml version: '3' services: web: image: myapp:latest container_name: myapp 在这个示例中，web 服务的容器名称被设置为 myapp。 总之，hostname 和 container_name 都是用于定义容器的标识符，但是 hostname 用于容器内部的标识，container_name 用于 Docker 主机上的标识。 ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:6:12","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#hostname-与-container_name"},{"categories":["container"],"content":" user在 Docker Compose 中，可以使用 user 字段来指定容器中运行的进程的用户和用户组。它的语法与 docker run​ 命令的 –user 选项类似，有以下三种形式： user:group（推荐） 以 user 用户和 group 用户组的身份运行容器中的进程，例如： yaml version: \"3\" services: web: image: nginx user: nginx:nginx uid:gid 以 uid 用户 ID 和 gid 用户组 ID 的身份运行容器中的进程，例如： yaml version: \"3\" services: web: image: nginx user: \"1000:1000\" user 以 user 用户的身份运行容器中的进程，例如： yaml version: \"3\" services: web: image: nginx user: nginx 需要注意的是，如果在 Docker Compose 中使用了 user 字段，则容器中的所有进程都将以指定的用户身份运行，而不是默认的 root 用户身份运行。这可以提高容器的安全性，避免在容器中使用 root 用户造成潜在的安全风险。 ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:6:13","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#user"},{"categories":["container"],"content":" deploydeploy：指定服务部署配置。 yaml deploy: replicas: 3 resources: limits: cpus: '0.5' memory: '256M' reservations: cpus: '0.25' memory: '128M' 上面的例子中，配置服务的副本数量为 3，限制每个副本使用的 CPU 和内存资源，并保留一部分资源供其他服务使用。 ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:6:14","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#deploy"},{"categories":["container"],"content":" port 和 expose 区别ports​ 和 expose 是两个不同的 Docker Compose 字段，用于在容器中暴露端口。 ports 字段用于将容器内部的端口映射到宿主机上的端口，以便外部网络可以通过宿主机上的端口与容器中运行的应用程序进行通信。这个字段的语法如下： yaml version: \"3\" services: web: image: nginx ports: - \"8080:80\" 这个例子中，容器中运行的 nginx 进程监听的是容器内部的 80 端口，而 ports 字段将宿主机上的 8080 端口映射到了容器内部的 80 端口，这样外部网络就可以通过访问宿主机上的 8080 端口来访问容器中运行的 nginx 应用程序。 expose​ 与 ports 不同的是，expose 字段仅仅是将容器内部的端口暴露给其他容器使用，而不是直接映射到宿主机上的端口。这个字段的语法如下： yaml version: \"3\" services: db: image: mysql expose: - \"3306\" web: image: nginx expose: - \"80\" 这个例子中，db 和 web 两个容器分别暴露了它们内部的 3306 和 80 端口，其他容器可以使用这些端口来与它们通信。 但是，由于这些端口没有被映射到宿主机上，因此外部网络无法直接访问它们。如果要从外部网络访问这些容器，需要使用 ports 字段将它们映射到宿主机上的端口。 ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:7:0","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#port-和-expose-区别"},{"categories":["container"],"content":" configs 与 secrets 区别configs​ 和 secrets 是 Docker Compose 和 Docker Swarm 中用于管理容器配置和敏感数据的两个不同的功能。 它们的区别如下： 用途不同：configs 用于管理容器应用程序的配置文件，例如 nginx 的配置文件、MySQL 的配置文件等，而 secrets 则用于管理敏感数据，例如数据库的密码、API 密钥等。 存储位置不同：configs 存储在 Docker 主机的文件系统中，可以是本地文件系统、NFS 文件系统或远程 S3 存储等，而 secrets 存储在 Docker Swarm 的安全存储中，该存储是加密的、高度安全的，并且只能由授权的 Docker 服务和节点访问。 访问方式不同：configs 可以通过文件挂载或 Docker Compose 文件中的 configs 字段来访问，而 secrets 可以通过文件挂载、Docker Compose 文件中的 secrets 字段、Docker CLI 的 docker secret 命令或容器内部的文件系统来访问。 生命周期不同：configs 的生命周期是独立于服务的，当服务停止时，配置文件仍然可以保留在主机上，而 secrets 的生命周期是与服务绑定的，当服务被删除时，敏感数据也会被删除。 更新方式不同：configs 的更新是通过重新部署服务来实现的，而 secrets 的更新是通过 Docker CLI 的 docker secret 命令或容器内部的文件系统来实现的。 以下是一个使用 configs​ 和 secrets 的 Docker Compose 文件的示例： yaml version: '3.7' services: web: image: nginx:latest ports: - 80:80 configs: - source: nginx_conf target: /etc/nginx/nginx.conf secrets: - source: db_password target: /run/secrets/db_password configs: nginx_conf: file: ./nginx.conf secrets: db_password: file: ./db_password.txt 在上面的示例中，我们定义了一个 web 服务，该服务使用了 nginx:latest 镜像，并将容器内的 80 端口映射到 Docker 主机的 80 端口。此外，我们还定义了两个配置：configs 和 secrets。 configs​ 定义了一个名为 nginx_conf 的配置，该配置从本地的 nginx.conf 文件中读取配置，并将其挂载到容器内的 /etc/nginx/nginx.conf 路径。这样，我们就可以使用自定义的 nginx.conf 配置文件来配置 nginx 服务。 secrets​ 定义了一个名为 db_password 的敏感数据，该数据从本地的 db_password.txt 文件中读取，并将其挂载到容器内的 /run/secrets/db_password 路径。这样，我们就可以在容器内部安全地访问数据库密码，而不必担心密码泄露的风险。 在上述示例中，我们使用了文件挂载来访问 configs​ 和 secrets。这是最常见的访问方式，但并不是唯一的方式。secrets 还可以通过 Docker CLI 的 docker secret 命令或容器内部的文件系统来访问。 ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:8:0","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#configs-与-secrets-区别"},{"categories":["container"],"content":" 挂载在 Docker Compose 中，可以通过挂载主机目录或文件来访问容器内部的文件或目录，以便在容器内外共享数据或配置文件。Docker Compose 支持两种方式进行挂载： 命名卷挂载 命名卷是由 Docker 创建和管理的卷，它们可以用于存储持久化数据，并可以在多个容器之间共享。 在 Docker Compose 中，可以通过 volumes 字段来定义命名卷的挂载路径和主机目录的映射关系。 关于 docker 的卷管理可以参考我这篇文章：Docker 数据卷 —Volumes。 示例例如： yaml version: \"3.7\" services: app: image: myapp:latest volumes: - myapp_data:/app/data volumes: myapp_data: 在上述示例中，我们定义了一个 myapp 服务，该服务使用了 myapp:latest 镜像，并将命名卷 myapp_data 挂载到容器内的 /app/data 目录。 主机目录挂载 主机目录挂载允许将 Docker 主机上的目录或文件夹挂载到容器内部，以便在容器内外共享数据。在 Docker Compose 中，可以通过 volumes 字段来定义主机目录的挂载路径和主机目录的映射关系。例如： yaml version: \"3.7\" services: app: image: myapp:latest volumes: - /host/data:/app/data 在上述示例中，我们定义了一个 myapp 服务，该服务使用了 myapp:latest 镜像，并将宿主机上的 /host/data ​目录挂载到容器内的 /app/data 目录。 注意: 在 Docker Compose 中，如果使用主机目录挂载，则要求主机目录必须存在且具有正确的权限。否则，容器将无法访问该目录。此外，在使用主机目录挂载时，请注意挂载的目录是否包含敏感数据，以避免数据泄露的风险。 ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:9:0","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#挂载"},{"categories":["container"],"content":" 网络Docker Compose 中的网络可以用于在多个容器之间建立通信。通过定义网络，可以让容器之间相互通信，同时将它们与主机网络隔离开来，提高容器应用的安全性。 Docker Compose 提供了三种网络类型：bridge、host 和 none，每种类型都适用于不同的场景。 1）bridge 网络类型 bridge 网络类型是默认的网络类型，它创建一个桥接网络，允许容器之间进行通信。每个容器都有自己的 IP 地址，并且可以通过容器名称来相互访问。如果没有指定网络类型，Docker Compose 将使用 ​bridge 网络类型。 在 bridge 网络类型中，Docker Compose 会为每个服务创建一个容器，并为每个容器分配一个 IP 地址。在同一个网络中的容器可以相互访问。 注意: 如果您使用了 Docker Compose 的网络功能（默认情况下会创建一个网络），则可以在同一网络中的任何容器中使用容器名称来访问服务。如果您没有使用Docker Compose网络功能，则需要手动创建网络，并将所有容器添加到同一网络中。 【示例】假设我们有两个服务：web 和 db。在默认情况下，Docker Compose 使用 bridge 网络类型，我们可以不用特别指定网络类型。以下是一个示例的 docker-compose.yml 文件： yaml version: '3' services: web: build: . ports: - \"80:80\" db: image: mysql:5.7 environment: MYSQL_ROOT_PASSWORD: example 在上述示例中，web 服务将使用本地 Dockerfile 构建，并将容器端口 80 映射到主机端口 80。db 服务将使用 MySQL 5.7 镜像，并设置 MySQL 的 root 用户密码为 example。 通过 docker-compose up 命令启动这个示例，Docker Compose 将为每个服务创建一个容器，并自动创建一个默认的 bridge 网络来使它们互相通信。 host 网络类型 host 网络类型让容器共享主机的网络栈，这意味着容器将与主机具有相同的 IP 地址和网络接口。这样可以提高容器的网络性能和可访问性，但是容器之间不能互相访问，因为它们共享同一个网络栈。 在 host 网络类型中，Docker Compose 会将每个服务直接放在主机网络中，容器将与主机共享 IP 地址和网络接口，因此可以通过主机 IP 地址来访问容器中运行的服务。 【示例】假设我们有一个服务，它需要使用主机网络接口。以下是一个示例的 docker-compose.yml 文件： yaml version: '3' services: web: build: . network_mode: host 在上述示例中，我们使用 build 关键字来指定构建上下文，并使用 network_mode​ 关键字将服务 web 的网络模式设置为 host。这样，web 服务将与主机共享 IP 地址和网络接口，可以通过主机 IP 地址来访问服务。 none 网络类型 none 网络类型表示不为容器分配任何网络资源，容器将没有网络接口。这通常用于某些特殊的容器场景，例如一些只需要与主机交互而不需要网络连接的容器。 在 none 网络类型中，Docker Compose 会将每个服务放在一个单独的网络命名空间中，容器将没有任何网络资源，无法进行网络通信。 【示例】假设我们有一个服务，它不需要任何网络连接。以下是一个示例的 docker-compose.yml 文件： yaml version: '3' services: worker: build: . network_mode: none 在上述示例中，我们使用 build 关键字来指定构建上下文，并使用 network_mode 关键字将服务 worker 的网络模式设置为 none。这样，worker 服务将没有任何网络资源，无法进行网络通信。 自定义网络 Docker Compose 默认会为每个 Compose 项目创建一个网络。这个网络的名称会以 Compose 项目的目录名作为前缀，例如，如果您的 Compose 项目目录名为myproject，则默认创建的网络名称为 myproject_default。 在这个默认创建的网络中，所有的服务和容器都可以通过它们的服务名称或容器名称进行通信。这些名称在默认情况下都是唯一的，因此可以避免名称冲突和混乱。 如果您需要访问不同的网络或自定义网络，则可以使用 Docker Compose 的 networks 属性来创建自定义网络。 例如，以下是一个 Docker Compose 文件，其中定义了一个名为 my_network 的自定义网络： yaml version: '3' services: web: image: nginx networks: - my_network networks: my_network: driver: bridge 在这个示例中，web 服务将被连接到 my_network 网络中，而不是默认创建的网络。该网络的驱动程序为 bridge，这是 Docker Compose 默认使用的网络驱动程序。 Compose 项目目录名解释：Compose 项目目录名是指包含 Docker Compose 文件的目录的名称。 Docker Compose 文件（通常命名为 docker-compose.yml）描述了 Docker Compose 应该如何构建和运行 Docker 容器应用程序。该文件通常存储在Compose项目目录的根目录中。 例如，如果您正在开发一个名为myapp的应用程序，并使用 Docker Compose 来管理它的容器化部署，那么您可能会在以下目录结构中存储您的 Docker Compose 文件： yaml myapp/ ├── docker-compose.yml ├── app/ │ ├── Dockerfile │ └── app.py └── data/ 在这个例子中，myapp 是 Compose 项目目录名，docker-compose.yml 是 Compose 文件的名称，并存储在 myapp 目录的根目录中。myapp 目录还包含了应用程序的代码和数据目录。 ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:10:0","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#网络"},{"categories":["container"],"content":" 域名解析 DNSDocker Compose 中的容器可以使用容器名称或服务名称来相互访问，而不需要使用IP地址。 这是因为 Docker Compose 会为每个服务创建一个DNS记录，这些记录由默认的DNS解析器处理。 默认情况下，Docker Compose 会创建一个名为 “projectname_default” 的网络，并将所有服务连接到该网络中。该网络使用 Docker 内置的 DNS 解析器，为每个服务和容器分配一个 DNS 名称。例如，如果您的 Compose 项目名为 “myproject\"，那么您可以使用以下命令查看所有服务的 DNS 名称： bash docker-compose run \u003cservice\u003e nslookup \u003cservice\u003e 例如，如果您的服务名称为 “web” ，则可以使用以下命令查看 web 服务的 DNS 名称： yaml docker-compose run web nslookup web 这将输出 web 服务的 DNS 记录，包括 IP 地址和 DNS 名称。例如： yaml Server: 127.0.0.11 Address 1: 127.0.0.11 Name: web Address 1: 172.18.0.2 在这个例子中，web 服务的 DNS 名称为 “web\"，IP地址为 172.18.0.2 。您可以使用该名称（\"web\"）来访问该服务，而无需使用 IP 地址。 ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:11:0","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#域名解析-dns"},{"categories":["container"],"content":" 健康检查Docker Compose 支持为服务定义健康检查，用于检查服务是否正常运行。健康检查可以是一个命令、一个 HTTP 请求或者一个 TCP 端口。如果健康检查失败，Docker Compose 将尝试重新启动服务，直到达到最大重试次数或者服务成功运行。 ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:12:0","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#健康检查"},{"categories":["container"],"content":" 健康检查语法在 Docker Compose 中，可以通过 healthcheck 关键字来定义健康检查。具体语法如下： yaml healthcheck: test: [\"CMD-SHELL\", \"command\"] interval: interval timeout: timeout retries: retries 参数解释： test 是健康检查的命令或者请求。 interval​ 是检查健康状态的时间间隔，单位为秒，默认为 30s。 timeout​ 是检查健康状态的超时时间，单位为秒，默认为 30s。 retries​ 是健康检查失败时的重试次数，默认为 3。 ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:12:1","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#健康检查语法"},{"categories":["container"],"content":" 健康检查写法包括以下几种写法： 字符串形式的命令 yaml healthcheck: test: curl --fail http://localhost:80 || exit 1 interval: 30s timeout: 10s retries: 5 在上述示例中，healthcheck 字段的 test 属性是一个字符串，表示需要执行的健康检查命令。在这个示例中，我们使用 curl 命令来测试 localhost:80 是否能够访问。如果健康检查命令返回状态码 0，则表示服务正常，否则表示服务异常。在这个示例中，如果健康检查失败，Docker Compose 将在每 30 秒尝试重新运行健康检查，最多重试 5 次。 数组形式的命令 yaml healthcheck: test: - CMD - curl - --fail - http://localhost:80 interval: 30s timeout: 10s retries: 5 自定义命令 yaml healthcheck: test: [\"CMD-SHELL\", \"curl --fail http://localhost:80 || exit 1\"] interval: 30s timeout: 10s retries: 5 在上述示例中，healthcheck 字段的 test 属性是一个数组，其中第一个元素是 CMD-SHELL，表示使用 shell 执行命令。第二个元素是一个自定义的命令，与前面的示例相同。 ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:12:2","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#健康检查写法"},{"categories":["container"],"content":" CMD-SHELL 与 CMDCMD-SHELL​ 和 CMD​ 都是 Dockerfile​ 中 RUN​ 指令以及 Docker Compose​ 中 healthcheck 指令中常用的命令格式，两者之间的区别如下： CMD-SHELL（这里推荐）：表示使用 shell 执行命令。在 Docker Compose 中，健康检查的 test 属性中可以使用 CMD-SHELL 来执行自定义的 shell 命令。 CMD：表示执行指定的命令或者命令参数。在 Dockerfile 中，CMD 常用于指定容器启动时需要执行的命令，而在 Docker Compose 中，CMD 常用于指定服务启动时需要执行的命令或者命令参数。 两者的使用方式不同，但都可以用于执行命令或者命令参数。在 Dockerfile 中，CMD-SHELL​ 并不是一个有效的指令，而在 Docker Compose 中，CMD 用于定义服务的启动命令，而 healthcheck​ 中的 test 属性可以使用 CMD-SHELL 来执行自定义的 shell 命令。其实CMD在docker compose healthcheck​ 也是可以使用的。只是更建议使用CMD-SHELL。 ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:12:3","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#cmd-shell-与-cmd"},{"categories":["container"],"content":" 示例讲解以下是一个简单的 Docker Compose 文件，其中定义了一个健康检查： yaml version: \"3\" services: web: image: nginx ports: - \"80:80\" healthcheck: #test: [\"CMD\", \"curl\", \"-f\", \"http://localhost\"] test: [\"CMD-SHELL\", \"curl -f http://localhost\"] interval: 1m timeout: 10s retries: 3 在这个例子中，web 服务使用 nginx 镜像，并将端口 80 映射到主机上的端口 80 。此外，它定义了一个健康检查，该检查将定期运行 curl 命令来测试服务是否响应 HTTP 请求。具体来说，该检查将每隔 1 分钟运行一次，超时时间为 10 秒，并尝试重试 3 次。 您可以使用以下命令启动该服务： bash # 也通过-f指定docker-compose文件 docker-compose up 在服务启动后，Compose 将定期运行健康检查，并根据检查结果重启服务。您可以使用以下命令查看服务的健康状态： bash docker-compose ps 此命令将显示服务的健康状态，例如： bash Name Command State Ports ------------------------------------------------------------------- webapp_web_1 nginx -g daemon off; Up (healthy) 0.0.0.0:80-\u003e80/tcp 在这个例子中，服务的健康状态为 “Up (healthy)\"，这表示服务正在运行并且健康检查通过。 ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:12:4","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#示例讲解"},{"categories":["container"],"content":" 常用命令以下是 Docker Compose 中一些常用的命令： docker-compose up：启动 Compose 文件中定义的服务，创建并启动所有容器。 docker-compose down：停止 Compose 文件中定义的服务，删除所有容器和网络。 docker-compose ps：显示 Compose 文件中定义的所有容器的状态。 docker-compose logs：显示 Compose 文件中定义的所有容器的日志。 docker-compose build：根据 Compose 文件中定义的Dockerfile构建所有服务的镜像。 docker-compose pull：拉取 Compose 文件中定义的所有服务的镜像。 docker-compose restart：重启 Compose 文件中定义的所有服务。 docker-compose stop：停止 Compose 文件中定义的所有服务。 docker-compose start：启动 Compose 文件中定义的所有服务。 docker-compose exec：在 Compose 文件中定义的容器中执行命令。 docker-compose run：在 Compose 文件中定义的容器中运行命令。 docker-compose config：检查 Compose 文件的语法，并显示 Compose 文件中定义的所有服务的配置。 这些是 Docker Compose 中一些常用的命令，您可以根据需要使用它们来管理和操作 Compose 项目。 原文地址: https://www.51cto.com/article/750177.html ","date":"2023-09-14","objectID":"/posts/docker-compose-advanced-tutorials/:13:0","series":null,"tags":["docker compose"],"title":"Docker Compose 进阶篇","uri":"/posts/docker-compose-advanced-tutorials/#常用命令"},{"categories":["devops","ansible"],"content":" 使用 register 注册变量当 playbook 运行的时候，经常需要中途收集一些数据，后面使用它。 使用 register 注册变量是最简单、最常用的一种方式。 ","date":"2023-08-30","objectID":"/posts/ansible-register-var/:1:0","series":null,"tags":["ansible"],"title":"Ansible 变量注册","uri":"/posts/ansible-register-var/#使用-register-注册变量"},{"categories":["devops","ansible"],"content":" 执行一条命令并把返回结果注册为变量 yaml - hosts: all tasks: - name: define a var1 shell: \"whoami\" register: whoami - name: show var debug: msg: \"whoami: {{ whoami }}\" - name: show var.stdout debug: msg: \"whoami.stdout: {{ whoami.stdout }}\" 执行结果输出 bash PLAY [all] **************************************************************************************************************** TASK [Gathering Facts] **************************************************************************************************** ok: [192.168.142.20] TASK [define a var1] ****************************************************************************************************** changed: [192.168.142.20] TASK [show var] *********************************************************************************************************** ok: [192.168.142.20] =\u003e { \"msg\": \"whoami: {'cmd': 'whoami', 'stdout': 'root', 'stderr': '', 'rc': 0, 'start': '2023-08-30 16:02:55.497249', 'end': '2023-08-30 16:02:55.501304', 'delta': '0:00:00.004055', 'changed': True, 'stdout_lines': ['root'], 'stderr_lines': [], 'failed': False}\" } TASK [show var.stdout] **************************************************************************************************** ok: [192.168.142.20] =\u003e { \"msg\": \"whoami.stdout: root\" } PLAY RECAP **************************************************************************************************************** 192.168.142.20 : ok=4 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 注意： ansible 执行结果一般都会返回一个字典类型的数据，你会看到很多你不关心的字段，可以通过指定字典的 key，例如 stdout 或stdout_lines ，只看到你关心的数据。 ","date":"2023-08-30","objectID":"/posts/ansible-register-var/:1:1","series":null,"tags":["ansible"],"title":"Ansible 变量注册","uri":"/posts/ansible-register-var/#执行一条命令并把返回结果注册为变量"},{"categories":["devops","ansible"],"content":" 列表遍历的结果注册为变量 yaml - hosts: all vars: userss: [] tasks: - name: define users in a loop shell: \"grep {{ item }} /etc/passwd\" register: users with_items: - root - nginx - name: show users debug: msg: \"{{ users }}\" - name: show users.results debug: msg: \"{{ users.results }}\" - name: define userss by set_fact set_fact: userss: \"{{userss +item.stdout_lines}}\" with_list: \"{{ users.results }}\" - name: print userss debug: msg: \"{{ userss }}\" - name: print userss one by one debug: msg: \"{{ item }}\" with_list: \"{{ userss}}\" - name: print part of userss one by one debug: msg: \"{{ item.split(':')[6] }}\" with_list: \"{{ userss}}\" 执行结果输出 bash PLAY [all] **************************************************************************************************************** TASK [Gathering Facts] **************************************************************************************************** ok: [192.168.142.20] TASK [define users in a loop] ********************************************************************************************* changed: [192.168.142.20] =\u003e (item=root) changed: [192.168.142.20] =\u003e (item=nginx) TASK [show users] ********************************************************************************************************* ok: [192.168.142.20] =\u003e { \"msg\": { \"changed\": true, \"msg\": \"All items completed\", \"results\": [ { \"ansible_loop_var\": \"item\", \"changed\": true, \"cmd\": \"grep root /etc/passwd\", \"delta\": \"0:00:00.003829\", \"end\": \"2023-08-30 16:05:18.237586\", \"failed\": false, \"invocation\": { \"module_args\": { \"_raw_params\": \"grep root /etc/passwd\", \"_uses_shell\": true, \"argv\": null, \"chdir\": null, \"creates\": null, \"executable\": null, \"removes\": null, \"stdin\": null, \"stdin_add_newline\": true, \"strip_empty_ends\": true, \"warn\": true } }, \"item\": \"root\", \"rc\": 0, \"start\": \"2023-08-30 16:05:18.233757\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"root:x:0:0:root:/root:/bin/bash\\noperator:x:11:0:operator:/root:/sbin/nologin\", \"stdout_lines\": [ \"root:x:0:0:root:/root:/bin/bash\", \"operator:x:11:0:operator:/root:/sbin/nologin\" ] }, { \"ansible_loop_var\": \"item\", \"changed\": true, \"cmd\": \"grep nginx /etc/passwd\", \"delta\": \"0:00:00.005357\", \"end\": \"2023-08-30 16:05:18.620858\", \"failed\": false, \"invocation\": { \"module_args\": { \"_raw_params\": \"grep nginx /etc/passwd\", \"_uses_shell\": true, \"argv\": null, \"chdir\": null, \"creates\": null, \"executable\": null, \"removes\": null, \"stdin\": null, \"stdin_add_newline\": true, \"strip_empty_ends\": true, \"warn\": true } }, \"item\": \"nginx\", \"rc\": 0, \"start\": \"2023-08-30 16:05:18.615501\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"nginx:x:1000:1001::/home/nginx:/bin/bash\", \"stdout_lines\": [ \"nginx:x:1000:1001::/home/nginx:/bin/bash\" ] } ] } } TASK [show users.results] ************************************************************************************************* ok: [192.168.142.20] =\u003e { \"msg\": [ { \"ansible_loop_var\": \"item\", \"changed\": true, \"cmd\": \"grep root /etc/passwd\", \"delta\": \"0:00:00.003829\", \"end\": \"2023-08-30 16:05:18.237586\", \"failed\": false, \"invocation\": { \"module_args\": { \"_raw_params\": \"grep root /etc/passwd\", \"_uses_shell\": true, \"argv\": null, \"chdir\": null, \"creates\": null, \"executable\": null, \"removes\": null, \"stdin\": null, \"stdin_add_newline\": true, \"strip_empty_ends\": true, \"warn\": true } }, \"item\": \"root\", \"rc\": 0, \"start\": \"2023-08-30 16:05:18.233757\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"root:x:0:0:root:/root:/bin/bash\\noperator:x:11:0:operator:/root:/sbin/nologin\", \"stdout_lines\": [ \"root:x:0:0:root:/root:/bin/bash\", \"operator:x:11:0:operator:/root:/sbin/nologin\" ] }, { \"ansible_loop_var\": \"item\", \"changed\": true, \"cmd\": \"grep nginx /etc/passwd\", \"delta\": \"0:00:00.005357\", \"end\": \"2023-08-30 16:05:18.620858\", \"failed\": false, \"invocation\": { \"module_args\": { \"_raw_params\": \"grep nginx /etc/passwd\", \"_uses_shell\": true, \"argv\": null, \"chdir\": null, \"creates\": null, \"executable\": null, \"removes\": null, \"stdin\": null, \"stdin_add_newline\": true, \"strip_empty_ends\": true, \"warn\": true } }, \"i","date":"2023-08-30","objectID":"/posts/ansible-register-var/:1:2","series":null,"tags":["ansible"],"title":"Ansible 变量注册","uri":"/posts/ansible-register-var/#列表遍历的结果注册为变量"},{"categories":["devops","ansible"],"content":" 使用 set_fact 注册变量","date":"2023-08-30","objectID":"/posts/ansible-register-var/:2:0","series":null,"tags":["ansible"],"title":"Ansible 变量注册","uri":"/posts/ansible-register-var/#使用-set_fact-注册变量"},{"categories":["devops","ansible"],"content":" 使用 set_fact 注册一个普通变量playbook yaml - hosts: all tasks: - name: define a var1 shell: \"whoami\" register: whoami - debug: msg: \"whoami: {{ whoami }}\" - debug: msg: \"whoami.stdout: {{whoami.stdout}}\" - name: define a var by set_fact set_fact: whoami: \"{{ whoami.stdout }}\" - name: show a var after defined by set_fact debug: msg: \"{{ whoami }}\" 结果输出 bash PLAY [all] **************************************************************************************************************** TASK [Gathering Facts] **************************************************************************************************** ok: [192.168.142.20] TASK [define a var1] ****************************************************************************************************** changed: [192.168.142.20] TASK [debug] ************************************************************************************************************** ok: [192.168.142.20] =\u003e { \"msg\": \"whoami: {'cmd': 'whoami', 'stdout': 'root', 'stderr': '', 'rc': 0, 'start': '2023-08-30 16:08:28.677690', 'end': '2023-08-30 16:08:28.682671', 'delta': '0:00:00.004981', 'changed': True, 'stdout_lines': ['root'], 'stderr_lines': [], 'failed': False}\" } TASK [debug] ************************************************************************************************************** ok: [192.168.142.20] =\u003e { \"msg\": \"whoami.stdout: root\" } TASK [define a var by set_fact] ******************************************************************************************* ok: [192.168.142.20] TASK [show a var after defined by set_fact] ******************************************************************************* ok: [192.168.142.20] =\u003e { \"msg\": \"root\" } PLAY RECAP **************************************************************************************************************** 192.168.142.20 : ok=6 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 来源: https://blog.51cto.com/byygyy/3858303 ","date":"2023-08-30","objectID":"/posts/ansible-register-var/:2:1","series":null,"tags":["ansible"],"title":"Ansible 变量注册","uri":"/posts/ansible-register-var/#使用-set_fact-注册一个普通变量"},{"categories":["devops","ansible"],"content":" 获取当前主机 IP 地址在 ansible 中，可以直接使用命令 {{ inventory_hostname }} 来获取，但此方法获取当前主机 IP 地址 bash # ansible -i hosts all -m shell -a 'echo {{ inventory_hostname }}' 192.168.142.20 | CHANGED | rc=0 \u003e\u003e 192.168.142.20 ","date":"2023-08-30","objectID":"/posts/ansible-inventory-hostname/:1:0","series":null,"tags":["ansible"],"title":"Ansible 获取 hosts 中的分组 ip","uri":"/posts/ansible-inventory-hostname/#获取当前主机-ip-地址"},{"categories":["devops","ansible"],"content":" 获取组内所有 IP 地址如果想要获取到分组内的所有 ip，需要通过 {{ groups[组名称] }} 获取组对象来获取 bash # ansible -i hosts test -m shell -a 'echo {{ groups[\"test\"] }}' 192.168.142.20 | CHANGED | rc=0 \u003e\u003e [192.168.142.20, 192.168.142.22] 192.168.142.22 | CHANGED | rc=0 \u003e\u003e [192.168.142.20, 192.168.142.22] ","date":"2023-08-30","objectID":"/posts/ansible-inventory-hostname/:2:0","series":null,"tags":["ansible"],"title":"Ansible 获取 hosts 中的分组 ip","uri":"/posts/ansible-inventory-hostname/#获取组内所有-ip-地址"},{"categories":["ubuntu"],"content":"Docker 的 Ubuntu 系统安装默认是最小化安装（通过删除用户不登录的系统上不需要的包和内容，该系统已被最小化。） 要恢复此内容， 您可以运行 “unminimize” 命令。 在执行命令的过程中需要频繁的输入 yes，如果不想频繁输入 yes 确认，可以直接执行下面的命令： bash yes | unminimize ","date":"2023-08-28","objectID":"/posts/ubuntu-minimize/:0:0","series":null,"tags":["ubuntu"],"title":"解除 docker 的 ubuntu 系统 minimize（最小化）限制","uri":"/posts/ubuntu-minimize/#"},{"categories":["devops"],"content":" 问题通过 nginx 为 geoserver 配置 https 证书(http 301跳转至 https) 在 https://xx.xx.com/geoserver/web/ 页面输入登录信息时，页面会被重定向到 http://xx.xx.com/geoserver/j_spring_security_check 正常应该还是 https 链接才对，如图 ","date":"2023-07-27","objectID":"/posts/geoserver-ssl/:1:0","series":null,"tags":["geoserver"],"title":"GeoServer 启用 SSL 无法登录问题","uri":"/posts/geoserver-ssl/#问题"},{"categories":["devops"],"content":" 解决方法","date":"2023-07-27","objectID":"/posts/geoserver-ssl/:2:0","series":null,"tags":["geoserver"],"title":"GeoServer 启用 SSL 无法登录问题","uri":"/posts/geoserver-ssl/#解决方法"},{"categories":["devops"],"content":" 方法1修改 web.xml 文件 进入 geoserver/webapps/geoserver/WEB-INF 路径下，修改 web.xml 取消如下标签注释，配置 PROXY_BASE_URL, 保存 xml \u003ccontext-param\u003e \u003cparam-name\u003ePROXY_BASE_URL\u003c/param-name\u003e \u003cparam-value\u003ehttps://xx.xx.com/geoserver\u003c/param-value\u003e \u003c/context-param\u003e 重启 geoserver ","date":"2023-07-27","objectID":"/posts/geoserver-ssl/:2:1","series":null,"tags":["geoserver"],"title":"GeoServer 启用 SSL 无法登录问题","uri":"/posts/geoserver-ssl/#方法1"},{"categories":["devops"],"content":" 方法2通过配置 PROXY_BASE_URL 环境变量来解决, 在 geoserver 启动脚本中添加如下环境变量配置后，重启 geoserver 即可 bash PROXY_BASE_URL=https://xx.xx.com/geoserver 参考文档: https://www.qiniu.com/qfans/qnso-68783126#comments ","date":"2023-07-27","objectID":"/posts/geoserver-ssl/:2:2","series":null,"tags":["geoserver"],"title":"GeoServer 启用 SSL 无法登录问题","uri":"/posts/geoserver-ssl/#方法2"},{"categories":["devops"],"content":"Rocky Linux 无法通过 https://get.docker.com 脚本安装 docker，但可以通过手动添加 CentOS 的 docker-ce yum 源来安装 ","date":"2023-07-26","objectID":"/posts/rocky-linux-docker/:0:0","series":null,"tags":["Rocky Linux"],"title":"Rocky Linux 安装 docker","uri":"/posts/rocky-linux-docker/#"},{"categories":["devops"],"content":" 配置 Docker YUM 源 bash dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 对于国内安装用户可以使用国内源，如: 阿里云源 bash dnf config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 中科大源 bash dnf config-manager --add-repo https://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.repo ","date":"2023-07-26","objectID":"/posts/rocky-linux-docker/:1:0","series":null,"tags":["Rocky Linux"],"title":"Rocky Linux 安装 docker","uri":"/posts/rocky-linux-docker/#配置-docker-yum-源"},{"categories":["devops"],"content":" 安装 docker bash dnf install docker-ce 配置 docker 镜像加速 bash cat \u003e/etc/docker/daemon.json\u003c\u003cEOF { \"registry-mirrors\": [ \"https://docker.mirrors.ustc.edu.cn/\", \"http://hub-mirror.c.163.com\" ] } EOF ","date":"2023-07-26","objectID":"/posts/rocky-linux-docker/:2:0","series":null,"tags":["Rocky Linux"],"title":"Rocky Linux 安装 docker","uri":"/posts/rocky-linux-docker/#安装-docker"},{"categories":["ProxmoxVE"],"content":"在 ProxmoxVE(PVE) 的 VM/VPS 中添加 PCI 设备时候提示：No IOMMU detected, please activate it.See Documentation for further information. 本文将记录如何为ProxmoxVE(PVE) 启用 IOMMU 现行 ProxmoxVE(PVE) 版本内核自带默认开启了 IOMMU 支持 ","date":"2023-07-26","objectID":"/posts/pve-enable-iommu/:0:0","series":null,"tags":["ProxmoxVE","PVE"],"title":"ProxmoxVE(PVE) 启用 IOMMU","uri":"/posts/pve-enable-iommu/#"},{"categories":["ProxmoxVE"],"content":" IOMMU作用IOMMU 允许系统设备在虚拟内存中进行寻址，也就是将虚拟内存地址映射为物理内存地址，让实体设备可以在虚拟的内存环境中工作，这样可以帮助系统扩充内存容量，提升性能。 这么说可能有点复杂不易理解，这么说IOMMU重要用途是在虚拟化技术中，使VM虚拟机能够接入一些物理设备入PCIe中的网卡、声卡、显卡… VM虚拟机可以直接或间接使用它们 ","date":"2023-07-26","objectID":"/posts/pve-enable-iommu/:1:0","series":null,"tags":["ProxmoxVE","PVE"],"title":"ProxmoxVE(PVE) 启用 IOMMU","uri":"/posts/pve-enable-iommu/#iommu作用"},{"categories":["ProxmoxVE"],"content":" 基本要求由于 IOMMU 是一项需要硬件支持的功能，因此需要进行一些检查准备工作。 硬件 主板/硬件: 需要支持 IOMMU CPU: Intel 的 VT-d 技术 AMDYES- 的 Vi 技术 配置 必须在 BIOS/UEFI 中启用 IOMMU 支持，常规的名称可能会为 IOMMU 或 VT-d Intel的VT-d技术 AMDYES- 的 Vi 技术 也需要在 BIOS/UEFI 中对应开启（近代产品基本都支持该技术。intel一般默认关闭，AMD默认开启） 系统/驱动 你的硬件设备至少能基本兼容和运行Linux，并且有对应的驱动 安装了ProxmoxVE系统 推荐为最新发行版截止本文记录时，版本为 7.3-3 系统设置 内核旧版为 5.15 或之前的，在 ProxmoxVE(PVE) 系统内核中，需要手动启用 IOMMU`` 。 5.15 版本以后的 ProxmoxVE(PVE)` 系统内核自带，只要硬件支持(满足上面的3点)时，在虚拟机添加 PCI 硬件设备位置 IOMMU 直接可用。 如 IOMMU 分组功能未开启，则会看到以下界面。 提示：No IOMMU detected, please activate it.See Documentation for further information. 未检测到IOMMU，请激活它。有关详细信息，请参阅文档 说明这时候需要手动开启，如果没有该提示且设备可选，那么就能直接跳过手动开启IOMMU这一整个步骤也可以顺带检查下是否开启PT模式 提示: ProxmoxVE8(PVE) 提示为: ","date":"2023-07-26","objectID":"/posts/pve-enable-iommu/:2:0","series":null,"tags":["ProxmoxVE","PVE"],"title":"ProxmoxVE(PVE) 启用 IOMMU","uri":"/posts/pve-enable-iommu/#基本要求"},{"categories":["ProxmoxVE"],"content":" 手动启用 IOMMU需要通过编辑内核命令行来启用 IOMMU 。 使用文本编辑软件打开您的引导加载程序内核命令行配置文件。 打开WebGUI管理界面定位到：数据中心 -\u003e 节点服务器 -\u003e Shell ","date":"2023-07-26","objectID":"/posts/pve-enable-iommu/:3:0","series":null,"tags":["ProxmoxVE","PVE"],"title":"ProxmoxVE(PVE) 启用 IOMMU","uri":"/posts/pve-enable-iommu/#手动启用-iommu"},{"categories":["ProxmoxVE"],"content":" 对于GRUB引导GRUB引导非常常见，一般也是ProxmoxVE(PVE)系统的默认引导方式 bash vim /etc/default/grub 找到GRUB_CMDLINE_LINUX_DEFAULT这一行 bash ... GRUB_DEFAULT=0 GRUB_TIMEOUT=5 GRUB_DISTRIBUTOR=`lsb_release -i -s \u003cstrong\u003e2\u003c/strong\u003e\u003e /dev/null || echo Debian` GRUB_CMDLINE_LINUX_DEFAULT=\"quiet\" GRUB_CMDLINE_LINUX=\"\" ... interl CPU 如果你的CPU是 Intel CPU 那么就在 GRUB_CMDLINE_LINUX_DEFAULT 这一行的值里加入 text intel_iommu=on 注意是追加，不是覆盖，就得到下面的格式 text GRUB_CMDLINE_LINUX_DEFAULT=\"quiet intel_iommu=on\" 检查无误后，按 esc 键，然后输入 :wq 保存更改 更新 grub bash update-grub AMD CPU 如果你的 CPU 是 AMDYES! CPU 那么就在 GRUB_CMDLINE_LINUX_DEFAULT 这一行的值里加入 text amd_iommu=on 注意是追加，不是覆盖，就得到下面的格式 text GRUB_CMDLINE_LINUX_DEFAULT=\"quiet amd_iommu=on\" 检查无误后，按 esc 键，然后输入 :wq 保存更改 然后，使用以下命令，更新 grub bash update-grub ","date":"2023-07-26","objectID":"/posts/pve-enable-iommu/:3:1","series":null,"tags":["ProxmoxVE","PVE"],"title":"ProxmoxVE(PVE) 启用 IOMMU","uri":"/posts/pve-enable-iommu/#对于grub引导"},{"categories":["ProxmoxVE"],"content":" 对于systemd-boot引导如果引导是 systemd-boot(并不是ProxmoxVE现行版本常见引导方式): bash vim /etc/kernel/cmdline 它的格式是带有选项的单行。如果不存在，您可以为 systemd-boot 新建文件 interl CPU 如果你的CPU是Intel CPU 那么就在第一行末尾添加以下内容 text quiet intel_iommu=on 检查无误后，按 esc 键，然后输入 :wq 保存更改 AMD CPU 如果你的CPU是AMDYES! 那么就在第一行末尾添加以下内容 text quiet amd_iommu=on 检查无误后，按 esc 键，然后输入 :wq 保存更改 然后更新 systemd-boot 引导 bash proxmox-boot-tool refresh ","date":"2023-07-26","objectID":"/posts/pve-enable-iommu/:3:2","series":null,"tags":["ProxmoxVE","PVE"],"title":"ProxmoxVE(PVE) 启用 IOMMU","uri":"/posts/pve-enable-iommu/#对于systemd-boot引导"},{"categories":["ProxmoxVE"],"content":" 重启系统验证 IOMMU 是否已启用 bash dmesg | grep -e DMAR -e IOMMU 应该有一行 DMAR: IOMMU enabled。如果没有输出，则说明有问题需进一步排查 ","date":"2023-07-26","objectID":"/posts/pve-enable-iommu/:3:3","series":null,"tags":["ProxmoxVE","PVE"],"title":"ProxmoxVE(PVE) 启用 IOMMU","uri":"/posts/pve-enable-iommu/#重启系统"},{"categories":["ProxmoxVE"],"content":" 开启PT模式 PT模式：会在IOMMU需要使用时候才启动，适配器不需要使用 DMA 转换到内存，因此可以提高其他没有分配过设备的性能 Intel 和 AMD 芯片都可以使用附加参数 iommu=pt 注意是追加，不是覆盖，就得到下面的格式 text ... GRUB_CMDLINE_LINUX_DEFAULT=\"quiet intel_iommu=on iommu=pt\" ... 基于 5.4 的内核中还需要添加一些模块设置，现行版本已经添加。但最好还是一并检查一下 bash vim /etc/modules 如果没有以下内容则添加，如果有则检查。不能重复也不能少 text vfio vfio_iommu_type1 vfio_pci vfio_virqfd 检查无误后，按 esc 键，然后输入 :wq 保存更改 更改任何相关模块后，您需要刷新 initramfs。通过执行以下命令来完成： bash update-initramfs -u -k all PT模式加入了 grub，也还行执行一次更新 grub bash update-grub ","date":"2023-07-26","objectID":"/posts/pve-enable-iommu/:4:0","series":null,"tags":["ProxmoxVE","PVE"],"title":"ProxmoxVE(PVE) 启用 IOMMU","uri":"/posts/pve-enable-iommu/#开启pt模式"},{"categories":["ProxmoxVE"],"content":" IOMMU 中断重映射如果没有中断重新映射，将无法使用 PCI 直通。设备分配将失败，并显示 Device assignment will fail with ‘Failed to assign device “[device name]”: Operation not permitted’ or ‘Interrupt Remapping hardware not found, passing devices to unprivileged domains is insecure 好在近代的 CPU/主板 只要开启了IOMMU 就会默认支持该功能甚至都没有开关选项，故此处省略记录。如遇到了只能是极个别问题，直接查阅官方文档 Pci_passthrough 参考借鉴解决即可。 文档来源于: https://www.insilen.com/post/501.html ","date":"2023-07-26","objectID":"/posts/pve-enable-iommu/:5:0","series":null,"tags":["ProxmoxVE","PVE"],"title":"ProxmoxVE(PVE) 启用 IOMMU","uri":"/posts/pve-enable-iommu/#iommu-中断重映射"},{"categories":["python"],"content":"使用 “穷举法” 求解鸡兔同笼，Python 代码实现如下 python def chicken_and_rabbit(head: int, foot: int) -\u003e list: if foot % 2 != 0: raise ValueError(\"参数 foot 必须为偶数\") result = [] rabbit, chicken = 0, 0 while rabbit \u003c head: rabbit += 1 chicken = head - rabbit # print(f\"chicken: {chicken}, rabbit: {rabbit}\", rabbit * 4 + chicken * 2) if rabbit * 4 + chicken * 2 == foot: result.append({\"chicken\": chicken, \"rabbit\": rabbit}) return result def main(head: int, foot: int): results = chicken_and_rabbit(head, foot) if not results: print(\"无解\") else: for res in results: print(res) if __name__ == \"__main__\": main(30, 88) ","date":"2023-06-08","objectID":"/posts/python-chicken-and-rabbit/:0:0","series":null,"tags":["chicken-andr-rabbit"],"title":"使用 Python 求解鸡兔同笼","uri":"/posts/python-chicken-and-rabbit/#"},{"categories":["windows"],"content":" WSL 全局配置使用 .wslconfig 为 WSL 上运行的所有已安装的发行版配置全局设置 文件路径位于：C:\\Users\\\u003cUserName\u003e\\.wslconfig ini [experimental] autoMemoryReclaim=gradual # gradual | dropcache | disabled networkingMode=mirrored # 如果值为 mirrored，则会启用镜像网络模式。 默认或无法识别的字符串会生成 NAT 网络。 #dnsTunneling=true firewall=true autoProxy=true ","date":"2023-03-10","objectID":"/posts/wsl/:1:0","series":null,"tags":["wsl"],"title":"Windows linux 子系统 WSL","uri":"/posts/wsl/#wsl-全局配置"},{"categories":["windows"],"content":" WSL 发行版配置wsl.conf 文件会针对每个发行版配置设置 ","date":"2023-03-10","objectID":"/posts/wsl/:2:0","series":null,"tags":["wsl"],"title":"Windows linux 子系统 WSL","uri":"/posts/wsl/#wsl-发行版配置"},{"categories":["windows"],"content":" 启用 systemd许多 Linux 发行版（包括 Ubuntu）默认运行 “systemd”，WSL 最近添加了对此系统/服务管理器的支持，因此 WSL 更类似于在裸机上使用你最爱的 Linux 发行版。 需要 WSL 的 0.67.6+ 版本才能启用 systemd。 使用命令 wsl --version 检查 WSL 版本 若要启用 systemd，请使用 sudo 通过管理员权限在文本编辑器中打开 wsl.conf 文件，并将以下行添加到 /etc/wsl.conf： ini [boot] systemd=true 官方文档: https://learn.microsoft.com/zh-cn/windows/wsl/wsl-config ","date":"2023-03-10","objectID":"/posts/wsl/:2:1","series":null,"tags":["wsl"],"title":"Windows linux 子系统 WSL","uri":"/posts/wsl/#启用-systemd"},{"categories":["windows"],"content":" 开机启动并开启 SSH 服务安装 openssh 服务，提供 ssh 远程连接 bash sudo apt update sudo apt install -y openssh-server /etc/init.d/ssh start 提示: 如开启了 systemd ，可以使用 systemd 管理 ssh 服务，命令: systemctl enable –now ssh ","date":"2023-03-10","objectID":"/posts/wsl/:3:0","series":null,"tags":["wsl"],"title":"Windows linux 子系统 WSL","uri":"/posts/wsl/#开机启动并开启-ssh-服务"},{"categories":["windows"],"content":" 使用 cloud-init 初始化 WSL 实例参考文档 ","date":"2023-03-10","objectID":"/posts/wsl/:4:0","series":null,"tags":["wsl"],"title":"Windows linux 子系统 WSL","uri":"/posts/wsl/#使用-cloud-init-初始化-wsl-实例"},{"categories":["windows"],"content":" 获取 Ubuntu WSL 镜像我们可以从 Ubuntu 镜像服务器 下载 Ubuntu 24.04 WSL 镜像。 在用户主目录下创建一个目录来存储 WSL 映像和安装数据。 powershell mkdir ~\\wsl-images 下载 Ubuntu 24.04 WSL 映像 powershell Invoke-WebRequest -Uri https://cloud-images.ubuntu.com/wsl/noble/current/ubuntu-noble-wsl-amd64-wsl.rootfs.tar.gz -OutFile wsl-images\\ubuntu-noble-wsl-amd64-wsl.rootfs.tar.gz 将 image 导入 WSL 并将其存储在 wsl-images 目录中。 powershell wsl --import Ubuntu-24.04 wsl-images .\\wsl-images\\ubuntu-noble-wsl-amd64-wsl.rootfs.tar.gz ","date":"2023-03-10","objectID":"/posts/wsl/:4:1","series":null,"tags":["wsl"],"title":"Windows linux 子系统 WSL","uri":"/posts/wsl/#获取-ubuntu-wsl-镜像"},{"categories":["windows"],"content":" 创建 cloud-init 初始化配置用户数据是用户自定义 cloud-init 实例的主要方式。打开记事本并粘贴以下内容： yaml #cloud-config apt: sources_list: | Types: deb URIs: http://mirrors.ustc.edu.cn/ubuntu Suites: noble noble-updates noble-backports Components: main universe restricted multiverse Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg ## Ubuntu security updates. Aside from URIs and Suites, ## this should mirror your choices in the previous section. Types: deb URIs: http://security.ubuntu.com/ubuntu Suites: noble-security Components: main universe restricted multiverse Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg package_update: true packages: - openssh-client - openssh-server - git - wget - lrzsz - iotop timezone: Asia/Shanghai write_files: - content: | [network] hostname = wsl2 #generateHosts = false generateResolvConf = false [boot] systemd=true path: /etc/wsl.conf owner: root:root permissions: '0644' - content: | nameserver 180.76.76.76 nameserver 223.5.5.5 path: /etc/resolv.conf owner: root:root permissions: '0644' # 默认用户 user: liwanggui users: - name: liwanggui ssh_authorized_keys: - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCjvxWX2G+cRUn5dFQr4wZEDD7QAI3lWhHLM5e.... ssh_authorized_keys: - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCjvxWX2G+cRUn5dFQr4wZEDD7QAI3lWhHLM5e.... 将文件保存至 %USERPROFILE%\\.cloud-init\\Ubuntu-24.04.user-data 例如，如果您的用户名是 me，则路径为 C:\\Users\\me\\.cloud-init\\Ubuntu-24.04.user-data。确保文件以.user-data扩展名保存，而不是以.txt文件形式保存。 ","date":"2023-03-10","objectID":"/posts/wsl/:4:2","series":null,"tags":["wsl"],"title":"Windows linux 子系统 WSL","uri":"/posts/wsl/#创建-cloud-init-初始化配置"},{"categories":["windows"],"content":" 启动 Ubuntu WSL 实例 powershell wsl --distribution Ubuntu-24.04 ","date":"2023-03-10","objectID":"/posts/wsl/:4:3","series":null,"tags":["wsl"],"title":"Windows linux 子系统 WSL","uri":"/posts/wsl/#启动-ubuntu-wsl-实例"},{"categories":["windows"],"content":" 验证是否 cloud-init 成功在验证用户数据之前，让我们等待 cloud-init 成功完成： bash cloud-init status --wait 其输出结果如下： text status: done 现在我们可以看到 cloud-init 已经检测到我们在 WSL 中运行： bash cloud-id 其输出结果如下： text wsl ","date":"2023-03-10","objectID":"/posts/wsl/:4:4","series":null,"tags":["wsl"],"title":"Windows linux 子系统 WSL","uri":"/posts/wsl/#验证是否-cloud-init-成功"},{"categories":["windows"],"content":" 验证我们的用户数据现在我们知道 cloud-init 已经成功运行，我们可以验证它是否收到了我们之前提供的预期用户数据： bash cloud-init query userdata 这将在终端窗口打印以下内容： yaml #cloud-config apt: sources_list: | Types: deb URIs: http://mirrors.ustc.edu.cn/ubuntu Suites: noble noble-updates noble-backports Components: main universe restricted multiverse Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg ## Ubuntu security updates. Aside from URIs and Suites, ## this should mirror your choices in the previous section. Types: deb URIs: http://security.ubuntu.com/ubuntu Suites: noble-security Components: main universe restricted multiverse Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg package_update: true packages: - openssh-client - openssh-server - git - wget - lrzsz - iotop timezone: Asia/Shanghai write_files: - content: | [network] hostname = wsl2 #generateHosts = false generateResolvConf = false [boot] systemd=true path: /etc/wsl.conf owner: root:root permissions: '0644' - content: | nameserver 180.76.76.76 nameserver 223.5.5.5 path: /etc/resolv.conf owner: root:root permissions: '0644' # 默认用户 user: liwanggui users: - name: liwanggui ssh_authorized_keys: - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCjvxWX2G+cRUn5dFQr4wZEDD7QAI3lWhHLM5e.... ssh_authorized_keys: - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCjvxWX2G+cRUn5dFQr4wZEDD7QAI3lWhHLM5e.... ","date":"2023-03-10","objectID":"/posts/wsl/:4:5","series":null,"tags":["wsl"],"title":"Windows linux 子系统 WSL","uri":"/posts/wsl/#验证我们的用户数据"},{"categories":["windows"],"content":" WSL 开机启动配置开机启动, 按 Win + R 键输入 “shell:startup” 打开启动目录，创建 wsl-start.vbs 文件， 内容如下 vbs Set ws = CreateObject(\"Wscript.Shell\") ws.run \"wsl -d Ubuntu-22.04 -u root\", vbhide 注意: -d 参数为你安装的 linux 发行版名称，使用 wsl -l 查看 ","date":"2023-03-10","objectID":"/posts/wsl/:5:0","series":null,"tags":["wsl"],"title":"Windows linux 子系统 WSL","uri":"/posts/wsl/#wsl-开机启动"},{"categories":["windows"],"content":" 故障问题安装旧版本的 Proxifier 程序会导致 wsl 无法启动，只需要安装 Proxifier 4.x 及以上版本即可解决 ","date":"2023-03-10","objectID":"/posts/wsl/:6:0","series":null,"tags":["wsl"],"title":"Windows linux 子系统 WSL","uri":"/posts/wsl/#故障问题"},{"categories":["fileserver"],"content":" 部署 minio 官方文档: https://min.io/docs/minio/linux/index.html 下载安装 bash wget https://dl.min.io/server/minio/release/linux-amd64/minio -O /usr/local/bin/minio chmod +x /usr/local/bin/minio 创建 systemd service 文件 /usr/lib/systemd/system/minio.service text [Unit] Description=MinIO Documentation=https://min.io/docs/minio/linux/index.html Wants=network-online.target After=network-online.target AssertFileIsExecutable=/usr/local/bin/minio [Service] WorkingDirectory=/usr/local User=minio Group=minio EnvironmentFile=-/etc/default/minio ExecStartPre=/bin/bash -c \"if [ -z \\\"${MINIO_VOLUMES}\\\" ]; then echo \\\"Variable MINIO_VOLUMES not set in /etc/default/minio\\\"; exit 1; fi\" ExecStart=/usr/local/bin/minio server $MINIO_OPTS $MINIO_VOLUMES # Let systemd restart this service always Restart=always # Specifies the maximum file descriptor number that can be opened by this process LimitNOFILE=65536 # Specifies the maximum number of threads this process can create TasksMax=infinity # Disable timeout logic and wait until process is stopped TimeoutStopSec=infinity SendSIGKILL=no [Install] WantedBy=multi-user.target 创建用户和组 bash groupadd -r minio useradd -M -r -g minio minio 创建环境变量文件 /etc/default/minio bash # MINIO_ROOT_USER and MINIO_ROOT_PASSWORD sets the root account for the MinIO server. # This user has unrestricted permissions to perform S3 and administrative API operations on any resource in the deployment. # Omit to use the default values 'minioadmin:minioadmin'. # MinIO recommends setting non-default values as a best practice, regardless of environment MINIO_ROOT_USER=myminioadmin MINIO_ROOT_PASSWORD=minio-secret-key-change-me MINIO_ADDRESS=\":9000\" MINIO_CONSOLE_ADDRESS=\":9001\" # MINIO_VOLUMES sets the storage volume or path to use for the MinIO server. MINIO_VOLUMES=\"/mnt/data\" # MINIO_SERVER_URL sets the hostname of the local machine for use with the MinIO Server # MinIO assumes your network control plane can correctly resolve this hostname to the local machine # Uncomment the following line and replace the value with the correct hostname for the local machine. # 配置 API 域名 #MINIO_SERVER_URL=\"http://minio.example.net\" # 控制台域名 # MINIO_BROWSER_REDIRECT_URL=\"http://console.minio.example.net\" MINIO_ROOT_USER: 管理用户名 MINIO_ROOT_PASSWORD: 管理用户密码，长度最小8位 MINIO_ADDRESS: 指定 API 监听地址和端口 MINIO_CONSOLE_ADDRESS: 指定控制台监听地址和端口 提示: Minio 环境变量配置清单可以参考: https://min.io/docs/minio/linux/reference/minio-server/minio-server.html#environment-variables 准备数据目录 bash chown minio:minio /mnt/data 启动 Minio 服务 bash systemctl start minio.service systemctl enable minio.service ","date":"2023-03-09","objectID":"/posts/minio/:1:0","series":null,"tags":["minio"],"title":"Minio 高性能对象存储","uri":"/posts/minio/#部署-minio"},{"categories":["fileserver"],"content":" 使用 Minio 和 nginx 部署静态站点 创建存储桶 创建存储桶 (wglee) 存储桶开启匿名访问, 开启后可以直接通过 http://\u003capi-address\u003e:\u003cport\u003e/\u003cbuckets-name\u003e/\u003cfilename\u003e 访问存储桶中的文件 存储桶开启匿名访问 (wglee) 上传站点文件 上传站点文件 (wglee) 配置 nginx text server { listen 80; server_name localhost; rewrite ^/$ /index.html last; # 默认访问索引页 index.html rewrite ^/(.*)/$ /$1/index.html last; # 设置子路径下默认索引页 index.html location / { # 反代 wglee 存储桶, 路径最后一个斜杠不能少 proxy_pass http://localhost:9000/wglee/; include proxy.conf; } } ","date":"2023-03-09","objectID":"/posts/minio/:2:0","series":null,"tags":["minio"],"title":"Minio 高性能对象存储","uri":"/posts/minio/#使用-minio-和-nginx-部署静态站点"},{"categories":["macOS"],"content":" 安装和配置 aria2安装 bash berw install aria2 配置 bash mkdir ~/.aria2 cd ~/.aria2 touch aria2.session # 生成配置 aria2.conf 文件 cat \u003earia2.conf\u003c\u003cEOF dir=/Users/liwanggui/Downloads disable-ipv6=true #打开rpc的目的是为了给web管理端用 enable-rpc=true #rpc-secret=thisisasecret rpc-allow-origin-all=true rpc-listen-all=true rpc-listen-port=6800 #断点续传 continue=true input-file=/Users/liwanggui/.aria2/aria2.session save-session=/Users/liwanggui/.aria2/aria2.session #最大同时下载任务数 max-concurrent-downloads=20 save-session-interval=120 # Http/FTP 相关 connect-timeout=120 #lowest-speed-limit=10K #同服务器连接数 max-connection-per-server=10 #max-file-not-found=2 #最小文件分片大小, 下载线程数上限取决于能分出多少片, 对于小文件重要 min-split-size=10M #单文件最大线程数, 路由建议值: 5 split=10 check-certificate=false #http-no-cache=true EOF ","date":"2023-02-25","objectID":"/posts/macos-aria2/:1:0","series":null,"tags":["aria2"],"title":"macOS 安装 Aria2","uri":"/posts/macos-aria2/#安装和配置-aria2"},{"categories":["macOS"],"content":" 配置 macOS 开机启动创建 ~/Library/LaunchAgents/aria2.plist 启动文件，写下如下配置 xml \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\"\u003e \u003cplist version=\"1.0\"\u003e \u003cdict\u003e \u003ckey\u003eKeepAlive\u003c/key\u003e \u003ctrue/\u003e \u003ckey\u003eLabel\u003c/key\u003e \u003cstring\u003earia2\u003c/string\u003e \u003ckey\u003eProgramArguments\u003c/key\u003e \u003carray\u003e \u003cstring\u003e/usr/local/bin/aria2c\u003c/string\u003e \u003c/array\u003e \u003ckey\u003eRunAtLoad\u003c/key\u003e \u003ctrue/\u003e \u003ckey\u003eWorkingDirectory\u003c/key\u003e \u003cstring\u003e/Users/liwanggui/Downloads\u003c/string\u003e \u003c/dict\u003e \u003c/plist\u003e 注意: 修改 WorkingDirectory 路径 检查语法和文件权限 bash plutil ~/Library/LaunchAgents/aria2.plist chmod 644 ~/Library/LaunchAgents/aria2.plist 启动并添加自动项 bash # 添加自动项 launchctl load ~/Library/LaunchAgents/aria2.plist # 删除自启动项 launchctl unload ~/Library/LaunchAgents/aria2.plist # 启动服务 launchctl start aria2 # 停止服务 launchctl stop aria2 ","date":"2023-02-25","objectID":"/posts/macos-aria2/:2:0","series":null,"tags":["aria2"],"title":"macOS 安装 Aria2","uri":"/posts/macos-aria2/#配置-macos-开机启动"},{"categories":["macOS"],"content":" 安装 aria2 浏览器插件 Edge 浏览器安装: Aria2 for Edge 参考文档 ","date":"2023-02-25","objectID":"/posts/macos-aria2/:3:0","series":null,"tags":["aria2"],"title":"macOS 安装 Aria2","uri":"/posts/macos-aria2/#安装-aria2-浏览器插件"},{"categories":["macOS"],"content":"比较简单制作黑苹果系统或者白苹果系统的dmg镜像的方法 借助 gibMacOS 工具获取完整的 macOS 安装文件。gibMacOS：https://github.com/corpnewt/gibMacOS 解压，运行 gibMacOS.command ，使用数字选择对应的想要下载的镜像。 在 gibMacOS-master 目录下，会有一个 macOS Downloads 文件夹，运行里面的 InstallAssistant.pkg 打开 访达，应用程序，可以看到苹果系统的 app 安装程序。 打开 启动台，其他，磁盘工具，点最上面菜单中的 文件，新建映像，新建空白映像。 以 macOS Monterey 为例 存储为: Install macOS Monterey 位置: 桌面 名称: Install macOS Monterey 格式: Mac OS 扩展 日志式 大小: 15GB 分区: 单个分区GUID分区表 确定，耐心等待生成完成。 打开终端，运行 bash sudo /Applications/Install\\ macOS\\ Monterey.app/Contents/Resources/createinstallmedia --volume /Volumes/Install\\ macOS\\ Monterey/ /Applications/Install\\ macOS\\ Monterey.app --nointeraction 输入密码，耐心等待完成，完成后右键推出即可。 这里说一句 可以借助 Hackintool 工具或者 OCC 工具，挂载这个dmg镜像的EFI分区，挂载后可以把准备好的EFI引导文件复制进去，然后再推出，这样就是黑苹果镜像了。 推出后，打开启动台 - 其他 - 磁盘工具 点击菜单 - 映象 - 转换 选中桌面的 Install macOS Monterey.dmg 新名称可以改为 Install macOS Monterey 12.0.1.dmg 之类的，路径选桌面，映像格式选 压缩。 等待压缩完成后，继续打开 启动台 - 其他 - 磁盘工具，点击菜单 - 映象 - 扫描要恢复的映像，然后选中制作好的 Install macOS Monterey 12.0.1.dmg 进行扫描一遍，如果没有错误，就可以把这个dmg文件上传网盘了。 ","date":"2023-02-19","objectID":"/posts/macos-black/:0:0","series":null,"tags":["macOS"],"title":"制作黑苹果或者白苹果系统dmg镜像","uri":"/posts/macos-black/#"},{"categories":["systemd"],"content":"systemctl 是一个 systemd 工具，主要负责控制 systemd 系统和服务管理器。 systemd 是一个系统管理守护进程、工具和库的集合，用于取代 System V 初始进程。 systemd 的功能是用于集中管理和配置 Linux 系统。 以网络服务 network.service 为例： ","date":"2022-12-21","objectID":"/posts/systemctl/:0:0","series":null,"tags":["systemctl"],"title":"systemctl 命令","uri":"/posts/systemctl/#"},{"categories":["systemd"],"content":" 管理服务 bash #查看服务状态 systemctl status network.service #启动服务 systemctl start network.service #重启服务 systemctl restart network.service #停止服务 systemctl stop network.service #开机启动服务 systemctl enable network.servic #停止开机启动 systemctl disable network.servic #清理 systemd 失效的服务 systemctl reset-failed mongodb.service ","date":"2022-12-21","objectID":"/posts/systemctl/:1:0","series":null,"tags":["systemctl"],"title":"systemctl 命令","uri":"/posts/systemctl/#管理服务"},{"categories":["systemd"],"content":" 服务单元查找所有或者某个服务 bash systemctl list-units --type=service | grep network systemctl 接受服务（.service），挂载点（.mount），套接口（.socket）和设备（.device）作为单元 列出所有可用单元 bash systemctl list-unit-files 列出所有运行中单元 bash systemctl list-units 列出所有失败单元 bash systemctl --failed 使用systemctl命令杀死服务 bash systemctl kill network.service 列出所有系统挂载点 bash systemctl list-unit-files --type=mount UNIT FILE STATE dev-hugepages.mount static dev-mqueue.mount static proc-sys-fs-binfmt_misc.mount static sys-fs-fuse-connections.mount static sys-kernel-config.mount static sys-kernel-debug.mount static tmp.mount disabled 挂载、卸载、重新挂载、重载系统挂载点并检查系统中挂载点状态 bash systemctl start tmp.mount systemctl stop tmp.mount systemctl restart tmp.mount systemctl reload tmp.mount systemctl status tmp.mount ","date":"2022-12-21","objectID":"/posts/systemctl/:2:0","series":null,"tags":["systemctl"],"title":"systemctl 命令","uri":"/posts/systemctl/#服务单元"},{"categories":["network"],"content":" 服务端开启一个证书或账户多人同时登录修改 openVPN 配置文件 server.conf ， 内容如下 text port 1194 proto udp dev tun ca ca.crt cert server.crt key server.key # This file should be kept secret dh dh.pem server 10.8.0.0 255.255.255.0 ifconfig-pool-persist ipp.txt push \"route 172.16.1.0 255.255.255.0\" keepalive 10 120 cipher AES-256-CBC persist-key persist-tun status openvpn-status.log verb 3 explicit-exit-notify 1 duplicate-cn duplicate-cn：这字段就是开启一个证书或账户多人同时登录。 ","date":"2022-11-18","objectID":"/posts/openvpn/:1:0","series":null,"tags":["vpn","openvpn"],"title":"OpenVPN 服务端配置","uri":"/posts/openvpn/#服务端开启一个证书或账户多人同时登录"},{"categories":["network"],"content":" 为客户端分配固定IP修改配置 /etc/openvpn/server.conf 配置文件, 添加如下配置后，重启 openvpn-server@server 服务 text client-config-dir /etc/openvpn/client 注意: 如果使用相对路径以 server.conf 目录为基准 配置客户端用户名文件 /etc/openvpn/client/\u003cusername\u003e，例如用户名为: liwanggui 创建 liwanggui 客户端配置文件 /etc/openvpn/client/liwanggui, 添加如下配置 text ifconfig-push 10.8.0.21 255.255.255.0 说明: ifconfig-push 接分配给客户端的 IP 地址和子网掩码 注意: 添加客户端配置不需要重启服务 ","date":"2022-11-18","objectID":"/posts/openvpn/:2:0","series":null,"tags":["vpn","openvpn"],"title":"OpenVPN 服务端配置","uri":"/posts/openvpn/#为客户端分配固定ip"},{"categories":["network"],"content":" Windows 客户端软件包下载地址 macOS 客户端软件包下载地址 macOS 第三方客户端 - Tunnelblick macOS 第三方客户端 - Viscosity 我们因为某些原因需要特定的流量不进VPN隧道或者进VPN隧道转发，我们就可以通过定义路由实现。 路由控制需要由三个参数进行定义： route-nopull 如果在客户端配置文件中配 route-nopull，openvpn 连接后将不会在电脑上添加任何路由，所有流量都将本地转发。 vpn_gateway 如果在客户端配置文件中配vpn_getaway，默认访问网络不走vpn隧道，如果可以通过添加该参数，下发路由，访问目的网络匹配到会自动进入VPN隧道。 text route 10.0.0.0 255.255.255.0 vpn_gateway route 172.16.0.0 255.255.255.0 vpn_gateway net_gateway 这个参数和 vpn_gateway 相反,表示在默认出去的访问全部走 openvpn 时,强行指定部分IP地址段访问不通过 Openvpn 出去。 max-routes 参数表示可以添加路由的条数,默认只允许添加100条路由,如果少于100条路由可不加这个参数。 text max-routes 1000 route 10.100.0.0 255.255.255.0 net_gateway 配置如下： text client dev tun proto tcp remote 114.112.4.6 11194 resolv-retry infinite nobind persist-key persist-tun remote-cert-tls server auth SHA512 cipher AES-256-CBC #ignore-unknown-option block-outside-dns #block-outside-dns verb 3 route-nopull route 192.168.1.0 255.255.255.0 vpn_gateway route xxx.xxx.xxx.0 255.255.255.0 net_gateway 文章源地址 ","date":"2022-11-18","objectID":"/posts/openvpn-client/:0:0","series":null,"tags":["vpn","openvpn"],"title":"OpenVPN 客户端添加路由配置（流量分流）","uri":"/posts/openvpn-client/#"},{"categories":["postgresql"],"content":"postgresql 权限分为 “用户” 和 “角色” 及 “database/schema/table…属主” 举例说明: 用户: postgresql 中两个用户， postgres 管理用户，test 普通用户 数据库: 使用 postgres 用户，创建 testdb 数据库 bash postgres=# create database testdb; CREATE DATABASE postgres=# \\l List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges -----------+----------+----------+-------------+-------------+----------------------- postgres | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | template0 | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | =c/postgres + | | | | | postgres=CTc/postgres template1 | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | =c/postgres + | | | | | postgres=CTc/postgres testdb | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | (4 rows) 数据库创建后，会自动创建 public schema，默认情况下所有用户都拥有 “public” schema 的 “create” 权限 使用 test 用户登录，在 testdb 的 public schema 下创建表 bash [root@MiWiFi-R3G-srv ~]# psql -h localhost -U test -W testdb Password: psql (13.9) Type \"help\" for help. testdb=\u003e create table users(id int, name varchar(64)); CREATE TABLE testdb=\u003e \\dt List of relations Schema | Name | Type | Owner --------+-------+-------+------- public | users | table | test 为了安全，我们需要加收 public 的创建权限, 使用管理用户进行权限回收 bash revoke CREATE on SCHEMA public from PUBLIC; 再次使用 test 用户创建表会发现没有权限 bash testdb=\u003e create table users2(id int, name varchar(64)); ERROR: permission denied for schema public LINE 1: create table users2(id int, name varchar(64)); 使用管理用户在 testdb 创建 test_schema schema, 并在此 schema 下创建一张表 bash testdb=# create schema test_schema; CREATE SCHEMA testdb=# create table test_schema.id(id int); CREATE TABLE # 更新 search_path，不然 \\dt 查不出数据 testdb=# set search_path = \"$user\", public, test_schema; SET testdb=# \\dt List of relations Schema | Name | Type | Owner -------------+-------+-------+---------- public | users | table | test test_schema | id | table | postgres (2 rows) 正常情况下 test 用户是无法在 test_schema 下创建任何对象的, 现在将 test_schema 的属主更改为 test 用户 bash testdb=# alter schema test_schema owner to test; ALTER SCHEMA testdb=# \\dn List of schemas Name | Owner -------------+---------- public | postgres test_schema | test 现在 tets 用户可以在 test_schema 下创建对象了，尝试创建个表 bash testdb=\u003e create table test_schema.test(id int); CREATE TABLE testdb=\u003e \\dt List of relations Schema | Name | Type | Owner -------------+-------+-------+---------- public | users | table | test test_schema | id | table | postgres test_schema | test | table | test testdb=\u003e \\dn List of schemas Name | Owner -------------+---------- public | postgres test_schema | test 从上面的查询结果可以看到 id 表的属主为 postgres 用户，test 表的属主用户为 test 用户 现在尝试使用 test 用户往 id 和 test 表中插入数据及删除 id 和 test 表 bash testdb=\u003e insert into test_schema.id values (1); ERROR: permission denied for table id testdb=\u003e insert into test_schema.test values (1); INSERT 0 1 testdb=\u003e drop table test_schema.id ; DROP TABLE testdb=\u003e drop table test_schema.test ; DROP TABLE 可以发现 test 用户无法在 id 表中插入数据，但可以删除 id 表，这是因为 test_schema schema的属主用户是 test 现在给 test 授于 test_schema schema 下所有表的所有权限 bash testdb=# grant ALL privileges on all tables in schema test_schema to test; GRANT 现在 test 拥有了 test_schema 下所有表的所有权限 通过管理用户在 test_schema 下创建表并插入数据 bash testdb=# create table test_schema.users(id int); CREATE TABLE testdb=# insert into test_schema.users values(1); INSERT 0 1 通过 test 查看及插入新数据 bash testdb=\u003e select * from test_schema.users; ERROR: permission denied for table users testdb=\u003e insert into test_schema.users values(2); ERROR: permission denied for table users 可以发现 test 用户没有权限操作 test_schema.users 表，为什么？？？ 上面明明给 test 用户授予于所有表所有权限。 这是因为授权只针对现有的资源对象，对新创建的资源对象是不生效的，为了让 test 用户对新创建的资源也拥有相应的权限可以设置默认权限的方式, 设置语句如下： bash testdb=# alter default privileges in schema test_schema grant all privileges on tables to test; ALTER DEFAULT PRIVILEGES 再次通过管理用户创建资源对象，test 用户也会拥有相应的权限 ","date":"2022-11-13","objectID":"/posts/postgres-privileges/:0:0","series":null,"tags":["postgresql"],"title":"PostgreSQL 用户授权","uri":"/posts/postgres-privileges/#"},{"categories":["java"],"content":"maven 多仓库配置需要在 profile 节点进行配置，配置方法如下： 编辑 maven 配置文件 settings.xml 添加如下配置 xml \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003csettings xmlns=\"http://maven.apache.org/SETTINGS/1.2.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.2.0 https://maven.apache.org/xsd/settings-1.2.0.xsd\"\u003e \u003cservers\u003e \u003c!-- 当我们仓库需要身份验证时可以在此配置身份验证信息 --\u003e \u003cserver\u003e \u003cid\u003emaven-nexus3\u003c/id\u003e \u003cusername\u003exxx\u003c/username\u003e \u003cpassword\u003exxxx\u003c/password\u003e \u003c/server\u003e \u003c/servers\u003e \u003cmirrors\u003e \u003c!-- 配置Maven仓库代理加速站点 --\u003e \u003cmirror\u003e \u003cid\u003emaven-nexus3\u003c/id\u003e \u003cname\u003e自建内部仓库\u003c/name\u003e \u003c!-- 如果是 * 默认所有仓库都走代理， 可以把不需要走代理的仓库使用!加仓库ID方法，让其不走代理 --\u003e \u003cmirrorOf\u003e*,!osgeo,!osgeo2\u003c/mirrorOf\u003e \u003curl\u003ehttps://maven.liwanggui.com/repository/maven-public/\u003c/url\u003e \u003c/mirror\u003e \u003c/mirrors\u003e \u003cprofiles\u003e \u003c!-- 多仓库配置需要使用 profile 节点进行配置 --\u003e \u003cprofile\u003e \u003c!-- ID必须唯一 --\u003e \u003cid\u003eosgeoreleaseRepo\u003c/id\u003e \u003crepositories\u003e \u003crepository\u003e \u003cid\u003eosgeo\u003c/id\u003e \u003cname\u003eOSGeo Release Repository\u003c/name\u003e \u003curl\u003ehttps://repo.osgeo.org/repository/release/\u003c/url\u003e \u003csnapshots\u003e\u003cenabled\u003efalse\u003c/enabled\u003e\u003c/snapshots\u003e \u003creleases\u003e\u003cenabled\u003etrue\u003c/enabled\u003e\u003c/releases\u003e \u003c/repository\u003e \u003c/repositories\u003e \u003c/profile\u003e \u003cprofile\u003e \u003cid\u003eosgeosnapshotRepo\u003c/id\u003e \u003crepositories\u003e \u003crepository\u003e \u003cid\u003eosgeo2\u003c/id\u003e \u003cname\u003eOSGeo Snapshot Repository\u003c/name\u003e \u003curl\u003ehttps://repo.osgeo.org/repository/snapshot/\u003c/url\u003e \u003csnapshots\u003e\u003cenabled\u003etrue\u003c/enabled\u003e\u003c/snapshots\u003e \u003creleases\u003e\u003cenabled\u003efalse\u003c/enabled\u003e\u003c/releases\u003e \u003c/repository\u003e \u003c/repositories\u003e \u003c/profile\u003e \u003c/profiles\u003e \u003cactiveProfiles\u003e \u003c!-- 启用仓库 --\u003e \u003cactiveProfile\u003eosgeoreleaseRepo\u003c/activeProfile\u003e \u003cactiveProfile\u003eosgeosnapshotRepo\u003c/activeProfile\u003e \u003c/activeProfiles\u003e \u003c/settings\u003e ","date":"2022-11-05","objectID":"/posts/maven/:0:0","series":null,"tags":["maven"],"title":"Maven 多仓库配置","uri":"/posts/maven/#"},{"categories":["container"],"content":"Docker Compose 提供了一种方便的方式来配置网络，本文档将介绍 Docker Compose 的网络相关配置 Docker 官方文档: https://docs.docker.com/compose/compose-file/05-services/#network_mode https://docs.docker.com/compose/compose-file/06-networks ","date":"2022-10-23","objectID":"/posts/docker-compose-network/:0:0","series":null,"tags":["docker compose","docker network"],"title":"Docker Compose 网络配置","uri":"/posts/docker-compose-network/#"},{"categories":["container"],"content":" 默认网络Docker Compose 默认会创建一个以 项目名_default 为名称的网络，它使用 bridge 网络模式，并且所有容器都可以相互通信, 默认网络的配置如下： yaml version: '3' services: service1: image: image1 service2: image: image2 提示: Docker Compose 的 项目名 默认以 当前目录名 命名，可以使用 -p 参数指定或者通过 .env 文件中写入 COMPOSE_PROJECT_NAME=test ","date":"2022-10-23","objectID":"/posts/docker-compose-network/:1:0","series":null,"tags":["docker compose","docker network"],"title":"Docker Compose 网络配置","uri":"/posts/docker-compose-network/#默认网络"},{"categories":["container"],"content":" 自定义网络Docker Compose 支持自定义网络 自定义网络名称 yaml version: '3' services: service1: image: image1 networks: - mynet service2: image: image2 networks: - mynet networks: mynet: driver: bridge 自定义网络地址段 yaml version: '3' services: service1: image: image1 networks: - mynet service2: image: image2 networks: - mynet networks: mynet: driver: bridge ipam: driver: default config: - subnet: 172.16.10.0/24 gateway: 172.16.10.1 为容器固定指定 ip 地址 yaml version: '3' services: service1: image: image1 networks: mynet: ipv4_address: 172.16.10.11 service2: image: image2 networks: - mynet networks: mynet: driver: bridge ipam: driver: default config: - subnet: 172.16.10.0/24 gateway: 172.16.10.1 ","date":"2022-10-23","objectID":"/posts/docker-compose-network/:2:0","series":null,"tags":["docker compose","docker network"],"title":"Docker Compose 网络配置","uri":"/posts/docker-compose-network/#自定义网络"},{"categories":["container"],"content":" 外部网络不同 docker-compose.yml 默认会创建不同的网络，当我们需要共用同一个网络时, 可以启用外部网络 注意: 共用的网络可以手动提前创建好， 命令 docker network create ..., 也可以是其他 services 创建的网络 以公用网络 mynet 为例 yaml version: '3' networks: mynet: external: true services: web: image: 'registry.gitlab.cn/omnibus/gitlab-jh:latest' restart: always hostname: 'gitlab' environment: GITLAB_OMNIBUS_CONFIG: | external_url 'http://gitlab.liwanggui.com' gitlab_rails['gitlab_shell_ssh_port'] = 2222 networks: - mynet # 指定网络 ports: - '8929:80' - '2222:22' volumes: - './gitlab-data/config:/etc/gitlab' - './gitlab-data/logs:/var/log/gitlab' - './gitlab-data/data:/var/opt/gitlab' shm_size: '256m' ","date":"2022-10-23","objectID":"/posts/docker-compose-network/:3:0","series":null,"tags":["docker compose","docker network"],"title":"Docker Compose 网络配置","uri":"/posts/docker-compose-network/#外部网络"},{"categories":["java"],"content":" 部署 nexus3使用容器方式部署 nexus3, docker 镜像站点 准备 docker-compose.yaml 文件 bash mkdir /opt/nexus3 cd /opt/nexus3 cat \u003edocker-compose.yaml\u003c\u003cEOF version: '2.10.2' services: nexus3: image: sonatype/nexus3:3.42.0 container_name: nexus3 restart: always volumes: - ./data:/nexus-data ports: - 8081:8081 EOF 启动 nexus3 容器 bash # 由于 nexus3 容器用户 id 为 200, 我们需要将数据目录权限属主进行修改 mkdir /opt/nexus3/data \u0026\u0026 chown -R 200 /opt/nexus3/data # 启动 nexus3 docker compose up -d 配置 nginx 反向代理 bash cat \u003e /etc/nginx/conf.d/nexus3.conf \u003c\u003cEOF server { listen 80; server_name nexus.liwanggui.com; # 注意替换为自己的域名 location / { proxy_pass http://127.0.0.1:8081; proxy_next_upstream off; proxy_redirect off; proxy_connect_timeout 300s; proxy_send_timeout 900; proxy_read_timeout 900; proxy_buffer_size 32k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_hide_header Vary; proxy_set_header Accept-Encoding ''; proxy_set_header Host $http_host; proxy_set_header Referer $http_referer; proxy_set_header Cookie $http_cookie; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header Connection \"\"; proxy_http_version 1.1; } } ","date":"2022-10-15","objectID":"/posts/nexus/:1:0","series":null,"tags":["nexus"],"title":"使用 Nexus3 部署 maven 私服","uri":"/posts/nexus/#部署-nexus3"},{"categories":["java"],"content":" 配置阿里云源代理加速登录 nexus 仓库, 默认用户名: admin, 密码在数据目录的 admin.password 文件中 创建代理阿里仓库 最后我们将 aliyun 这个仓库加入 maven-public 中 点击 maven-public 进入设置，将 aliyun 移到右侧 最后保存即可 ","date":"2022-10-15","objectID":"/posts/nexus/:2:0","series":null,"tags":["nexus"],"title":"使用 Nexus3 部署 maven 私服","uri":"/posts/nexus/#配置阿里云源代理加速"},{"categories":["java"],"content":" maven 配置在 maven 的 settings.xml 配置文件中添加以下配置 xml \u003cmirror\u003e \u003cid\u003enexus3\u003c/id\u003e \u003cname\u003e内部仓库\u003c/name\u003e \u003cmirrorOf\u003e*\u003c/mirrorOf\u003e \u003curl\u003ehttp://nexus.liwanggui.com/repository/maven-public/\u003c/url\u003e \u003c/mirror\u003e ","date":"2022-10-15","objectID":"/posts/nexus/:3:0","series":null,"tags":["nexus"],"title":"使用 Nexus3 部署 maven 私服","uri":"/posts/nexus/#maven-配置"},{"categories":["macOS"],"content":" 使用前说明 破解补丁包针对版本为 Parallels Desktop 18.0.1-53056 安装成功后不要进行版本升级，否则之前的破解将失效 (可以通过偏好设置禁用更新检测) 如已安装 Parallels Desktop 请先卸载干净后再安装 以下信息均来源于网络，如造成什么后果请自行承担 原 GITHUB 仓库地址(已被封，无法访问): https://github.com/somebasj/ParallelsDesktopCrack ","date":"2022-09-15","objectID":"/posts/parallels-desktop/:1:0","series":null,"tags":["Parallels Desktop"],"title":"永久使用 Parallels Desktop 18","uri":"/posts/parallels-desktop/#使用前说明"},{"categories":["macOS"],"content":" 下载、安装 Parallels Desktop使用浏览器或者下载工具下载 Parallels Desktop 18.0.1-53056 bash https://download.parallels.com/desktop/v18/18.0.1-53056/ParallelsDesktop-18.0.1-53056.dmg 安装 “Parallels Desktop” 过程中如果提示更新版本，可以先选择 “下载安装更新” 然后再取消安装现有版本 注意: 如果有登录 parallels 账号，请退出. ","date":"2022-09-15","objectID":"/posts/parallels-desktop/:2:0","series":null,"tags":["Parallels Desktop"],"title":"永久使用 Parallels Desktop 18","uri":"/posts/parallels-desktop/#下载安装-parallels-desktop"},{"categories":["macOS"],"content":" 破解 Parallels Desktop下载 ParallelsDesktopCrack ParallelsDesktopCrack.zip 下载地址：https://wwc.lanzouw.com/iD64a0bo798f 下载后，双击解压 ParallelsDesktopCrack 压缩包，打开终端进入压缩包目录，执行 bash install.sh 我这的目录路径为 Downloads/ParallelsDesktopCrack bash cd Downloads/ParallelsDesktopCrack bash install.sh ","date":"2022-09-15","objectID":"/posts/parallels-desktop/:3:0","series":null,"tags":["Parallels Desktop"],"title":"永久使用 Parallels Desktop 18","uri":"/posts/parallels-desktop/#破解-parallels-desktop"},{"categories":["macOS"],"content":" 查看激活状态打开 “ParallelsDesktop” 点击 “关于 Parallels Desktop” 就可以看到 “Parallels Desktop” 已经激活了 B站视频教程地址: 永久使用 Parallels Desktop 18 ","date":"2022-09-15","objectID":"/posts/parallels-desktop/:4:0","series":null,"tags":["Parallels Desktop"],"title":"永久使用 Parallels Desktop 18","uri":"/posts/parallels-desktop/#查看激活状态"},{"categories":["macOS"],"content":"macOS 版本 VMware Fusion 虚拟机软件没有像 Windows 那样提供图形化网络配置界面, 当我们需要自定义网络地址段时需要手动编辑配置文件实现 VMware Fusion 有三个网络配置文件：networking、dhcpd.conf 和 nat.conf, 下面介绍如何进行修改 bash # 全局网络配置文件 /Library/Preferences/VMware Fusion/networking # vmnet1 配置文件 /Library/Preferences/VMware Fusion/vmnet1/dhcpd.conf # vmnet8 配置文件 /Library/Preferences/VMware Fusion/vmnet8/dhcpd.conf /Library/Preferences/VMware Fusion/vmnet8/nat.conf 实验版本: VMware Fusion 12.2.3 ","date":"2022-08-19","objectID":"/posts/vmware-fusion/:0:0","series":null,"tags":["VMware Fusion"],"title":"VMware Fusion 自定义网络地址段","uri":"/posts/vmware-fusion/#"},{"categories":["macOS"],"content":" 停止 vmnet 网络服务(可选) bash sudo /Applications/VMware\\ Fusion.app/Contents/Library/vmnet-cli --stop ","date":"2022-08-19","objectID":"/posts/vmware-fusion/:1:0","series":null,"tags":["VMware Fusion"],"title":"VMware Fusion 自定义网络地址段","uri":"/posts/vmware-fusion/#停止-vmnet-网络服务可选"},{"categories":["macOS"],"content":" 修改 networking 配置文件 bash sudo vim /Library/Preferences/VMware\\ Fusion/networking 示例配置, 将 vmnet8 网络地址段配置为 192.168.1.0/24 text VERSION=1,0 answer VNET_1_DHCP yes answer VNET_1_DHCP_CFG_HASH BC187B729C7F983F84061DBC24546E7A35EAC1F7 answer VNET_1_HOSTONLY_NETMASK 255.255.255.0 answer VNET_1_HOSTONLY_SUBNET 172.16.77.0 answer VNET_1_HOSTONLY_UUID AEDCBA4E-12EA-4C77-B679-B304941910A2 answer VNET_1_VIRTUAL_ADAPTER yes answer VNET_8_DHCP yes answer VNET_8_DHCP_CFG_HASH A24D08B25A27C942354C5C1BBC4B18F2154C43F3 answer VNET_8_HOSTONLY_NETMASK 255.255.255.0 answer VNET_8_HOSTONLY_SUBNET 168.168.1.0 answer VNET_8_HOSTONLY_UUID B2D4FBA6-CACA-4EE5-BDF2-ADFBD22FBF06 answer VNET_8_NAT yes answer VNET_8_VIRTUAL_ADAPTER yes ","date":"2022-08-19","objectID":"/posts/vmware-fusion/:2:0","series":null,"tags":["VMware Fusion"],"title":"VMware Fusion 自定义网络地址段","uri":"/posts/vmware-fusion/#修改-networking-配置文件"},{"categories":["macOS"],"content":" 配置网络通过以下命令重新生成 vmnet8 的网络配置文件 bash sudo /Applications/VMware\\ Fusion.app/Contents/Library/vmnet-cli --configure ","date":"2022-08-19","objectID":"/posts/vmware-fusion/:3:0","series":null,"tags":["VMware Fusion"],"title":"VMware Fusion 自定义网络地址段","uri":"/posts/vmware-fusion/#配置网络"},{"categories":["macOS"],"content":" 启动网络服务 bash sudo /Applications/VMware\\ Fusion.app/Contents/Library/vmnet-cli --start ","date":"2022-08-19","objectID":"/posts/vmware-fusion/:4:0","series":null,"tags":["VMware Fusion"],"title":"VMware Fusion 自定义网络地址段","uri":"/posts/vmware-fusion/#启动网络服务"},{"categories":["macOS"],"content":" 验证打开虚拟机将网卡模式配置为 DHCP，自动获取 IP 后, 通过以下命令验证 bash ifconfig # or ip addr 也可以通过在宿主机上查看到虚拟网卡的 ip 验证 ","date":"2022-08-19","objectID":"/posts/vmware-fusion/:5:0","series":null,"tags":["VMware Fusion"],"title":"VMware Fusion 自定义网络地址段","uri":"/posts/vmware-fusion/#验证"},{"categories":["fileserver"],"content":" 简介CuteHttpFileServer/chfs是一个免费的、HTTP协议的文件共享服务器，使用浏览器可以快速访问。它具有以下特点： 单个文件，核心功能无需其他文件 跨平台运行，支持主流平台：Windows，Linux和Mac 界面简洁，简单易用 支持扫码下载和手机端访问，手机与电脑之间共享文件非常方便 支持账户权限控制和地址过滤 支持快速分享文字片段 支持webdav协议 与其他常用文件共享方式（如FTP，飞秋，网盘，自己建站）相比，具有使用简单，适用场景更多的优点，在个人使用以及共享给他人的场景中非常方便快捷。 CuteHttpFileServer 官方站点 | 软件下载地址 ","date":"2022-08-07","objectID":"/posts/chfs/:1:0","series":null,"tags":["chfs"],"title":"跨平台简易文件共享工具","uri":"/posts/chfs/#简介"},{"categories":["fileserver"],"content":" 部署这里以 linux 环境为例 下载安装 bash wget http://iscute.cn/tar/chfs/2.0/chfs-linux-amd64-2.0.zip unzip chfs-linux-amd64-2.0.zip chmod +x chfs mv chfs /usr/bin/ 准备配置文件 /etc/chfs/chfs.ini, 这里以官方提供的模板进行修改 chfs.ini ini #--------------------------------------- # 请注意： # 1，如果不存在键或对应值为空，则不影响对应的配置 # 2，配置项的值，语法如同其对应的命令行参数 #--------------------------------------- # 监听端口 port=80 # 共享根目录，通过字符'|'进行分割 # 注意： # 1，带空格的目录须用引号包住，如 path=\"c:\\a uply name\\folder\" # 2，可配置多个path，分别对应不同的目录 path=/data/fileserver # IP地址过滤 allow= #----------------- 账户控制规则 ------------------- # 注意：该键值可以同时存在多个，你可以将每个用户的访问规则写成一个rule，这样比较清晰，如： # rule=:: # rule=root:123456:RW # rule=readonlyuser:123456:R # 禁止匿名访问 rule=:: rule=lwg:123456:RW # 用户操作日志存放目录，默认为空 # 如果赋值为空，表示禁用日志 log=/var/log/chfs # 网页标题 html.title= # 网页顶部的公告板。可以是文字，也可以是HTML标签，此时，需要适用一对``(反单引号，通过键盘左上角的ESC键下面的那个键输出)来包住所有HTML标签。几个例子： # 1,html.notice=内部资料，请勿传播 # 2,html.notice=`\u003cimg src=\"https://mat1.gtimg.com/pingjs/ext2020/qqindex2018/dist/img/qq_logo_2x.png\" width=\"100%\"/\u003e` # 3,html.notice=`\u003cdiv style=\"background:black;color:white\"\u003e\u003cp\u003e目录说明：\u003c/p\u003e\u003cul\u003e一期工程：一期工程资料目录\u003c/ul\u003e\u003cul\u003e二期工程：二期工程资料目录\u003c/ul\u003e\u003c/div\u003e` html.notice= # 是否启用图片预览(网页中显示图片文件的缩略图)，true表示开启，false为关闭。默认开启 image.preview=true # 下载目录策略。disable:禁用; leaf:仅限叶子目录的下载; enable或其他值:不进行限制。 # 默认值为 enable folder.download=enable #-------------- 设置生效后启用HTTPS，注意监听端口设置为443------------- # 指定certificate文件 ssl.cert= # 指定private key文件 ssl.key= # 设置会话的生命周期，单位：分钟，默认为30分钟 session.timeout= 配置为系统服务 bash cat \u003e/usr/lib/systemd/system/chfs.service\u003c\u003cEOF [Unit] Description=Cute HTTP File Server Documentation=http://iscute.cn/chfs After=network.target [Service] Type=simple ExecStart=/usr/bin/chfs --file /etc/chfs/chfs.ini Restart=on-failure [Install] WantedBy=multi-user.target EOF systemctl daemon-reload systemctl enable chfs.service systemctl start chfs.service 部署完成后，可以在浏览器中打开 http://\u003cyour_server_ip\u003e ","date":"2022-08-07","objectID":"/posts/chfs/:2:0","series":null,"tags":["chfs"],"title":"跨平台简易文件共享工具","uri":"/posts/chfs/#部署"},{"categories":["kvdb"],"content":" 安装 consul bash yum install -y yum-utils yum-config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo yum -y install consul ","date":"2022-07-29","objectID":"/posts/consul/:1:0","series":null,"tags":["consul"],"title":"Consul 单机部署","uri":"/posts/consul/#安装-consul"},{"categories":["kvdb"],"content":" 配置 consul修改 /etc/consul.d/consul.hcl 文件，配置如下: bash log_level = \"INFO\" log_file = \"/var/log/consul/\" log_rotate_bytes = 10485760 log_rotate_max_files = 3 connect = { enabled = true } data_dir = \"/data/consul\" client_addr = \"0.0.0.0\" ui_config{ enabled = true } server = true bootstrap_expect=1 encrypt = \"2choh8YtnexKoVw8M9L6rcKGG21QwjfvnRYaKTJPdSw=\" 由于 consul 部署为单机环境，bootstrap_expect 需要配置为 1, encrypt 参数的值可以通过 consul keygen 命令生成 启动 consul 服务 bash systemctl start consul consul 服务端口说明 8300: 集群内数据的读写和复制 8301: 单个数据中心 gossip 协议通讯 8302: 跨数据中心 gossip 协议通讯 8500: 提供获取服务列表、注册服务、注销服务等HTTP接口；提供UI服务 8600: 采用 DNS 协议提供服务发现功能 ","date":"2022-07-29","objectID":"/posts/consul/:2:0","series":null,"tags":["consul"],"title":"Consul 单机部署","uri":"/posts/consul/#配置-consul"},{"categories":["kvdb"],"content":" ACL 访问控制consul 默认是不启用访问权限控制的，为了服务的安全需要启用访问权限控制 官方文档: https://learn.hashicorp.com/tutorials/consul/access-control-setup-production 准备 acl.hcl 文件 text acl = { enabled = true default_policy = \"deny\" enable_token_persistence = true } 将 acl.hcl 文件放到 /etc/consul.d 目录下，重启 consul 服务 bash mv acl.hcl /etc/consul.d systemctl restart consul 创建初始引导令牌 bash consul acl bootstrap 保存上面命令输出信息 将 SecretID 写入 acl.hcl 文件中 bash acl = { enabled = true default_policy = \"deny\" enable_token_persistence = true tokens = { master = \"\u003ctoken_strings\u003e\" } } 保存，重启 consul 服务即可，以后访问 consul 服务需要带上 token 通过身份验证 ","date":"2022-07-29","objectID":"/posts/consul/:3:0","series":null,"tags":["consul"],"title":"Consul 单机部署","uri":"/posts/consul/#acl-访问控制"},{"categories":["kvdb"],"content":" 配置 consul 键值对浏览器中打开 http://\u003cserver_ip\u003e:8500/ui/dc1/kv 点击 key/value 创建 key/value 值，如下图 ","date":"2022-07-29","objectID":"/posts/consul/:4:0","series":null,"tags":["consul"],"title":"Consul 单机部署","uri":"/posts/consul/#配置-consul-键值对"},{"categories":["devops"],"content":" 问题由于想放开系统最大连接数限制修改了 /etc/security/limits.conf 配置文件，配置如下 bash root soft nofile 6553500 root hard nofile 6553500 * soft nofile 6553500 * hard nofile 6553500 保存退出后， SSH 再也连不上了，通过网络搜索查询得知 limits.conf 文件实际是 Linux PAM（插入式认证模块，Pluggable Authentication Modules）中 pam_limits.so 的配置文件，而且只针对单个会话。即在登录shell时，需要设定limits的值，但由于设定的值过大导致设置失败，无法登录shell，ssh 自然也就连接不上了 limits.conf 最大值不得超过 /proc/sys/fs/nr_open ","date":"2022-05-30","objectID":"/posts/limits/:1:0","series":null,"tags":["limits.conf"],"title":"limits.conf 超过限制导致 ssh 登录失败","uri":"/posts/limits/#问题"},{"categories":["devops"],"content":" firewalld 端口转发 打开内核转发功能 bash echo \"net.ipv4.ip_forward = 1\" \u003e\u003e /etc/sysctl.conf sysctl -p 开启防火墙伪装(开启后才能转发端口) bash firewall-cmd --permanent --add-masquerade 配置端口转发 将访问本机 tcp/222 端口的流量转发到 172.16.174.101 的 tcp/22 端口 bash firewall-cmd --permanent --add-forward-port=port=222:proto=tcp:toport=22:toaddr=172.16.174.101 配置参数说明: –add-forward-port=port=\u003c源端口号\u003e:proto=\u003c协议\u003e:toport=\u003c目标端口号\u003e:toaddr=\u003c目标IP地址\u003e 重载防火墙规则 重载防火墙规则, 使用配置生效 bash firewall-cmd --reload ","date":"2022-05-26","objectID":"/posts/firewalld/:1:0","series":null,"tags":["firewalld"],"title":"Firewall 防火墙","uri":"/posts/firewalld/#firewalld-端口转发"},{"categories":["devops"],"content":" firewalld 富规则只允许 192.168.1.0/24 网段 ssh 服务和 80 端口 bash firewall-cmd --permanent --add-rich-rule=\"rule family=\"ipv4\" source address=\"192.168.1.0/24\" service name=\"ssh\" accept\" firewall-cmd --permanent --add-rich-rule=\"rule family=\"ipv4\" source address=\"192.168.1.0/24\" port port=\"80\" protocol=\"tcp\" accept\" accept：允许 reject: 拒绝 ","date":"2022-05-26","objectID":"/posts/firewalld/:2:0","series":null,"tags":["firewalld"],"title":"Firewall 防火墙","uri":"/posts/firewalld/#firewalld-富规则"},{"categories":["redis"],"content":"Redis 5.x 及以上版本配置分片集群不需要在使用 redis-trib.rb 脚本，默认 redis-cli 已集成集群配置指令 bash [root@localhost ~]# redis-cli --cluster help Cluster Manager Commands: create host1:port1 ... hostN:portN --cluster-replicas \u003carg\u003e check host:port --cluster-search-multiple-owners info host:port fix host:port --cluster-search-multiple-owners reshard host:port --cluster-from \u003carg\u003e --cluster-to \u003carg\u003e --cluster-slots \u003carg\u003e --cluster-yes --cluster-timeout \u003carg\u003e --cluster-pipeline \u003carg\u003e --cluster-replace rebalance host:port --cluster-weight \u003cnode1=w1...nodeN=wN\u003e --cluster-use-empty-masters --cluster-timeout \u003carg\u003e --cluster-simulate --cluster-pipeline \u003carg\u003e --cluster-threshold \u003carg\u003e --cluster-replace add-node new_host:new_port existing_host:existing_port --cluster-slave --cluster-master-id \u003carg\u003e del-node host:port node_id call host:port command arg arg .. arg set-timeout host:port milliseconds import host:port --cluster-from \u003carg\u003e --cluster-copy --cluster-replace help For check, fix, reshard, del-node, set-timeout you can specify the host and port of any working node in the cluster. ","date":"2022-03-25","objectID":"/posts/redis-cluster-2/:0:0","series":null,"tags":["redis"],"title":"Redis 5.x 分片集群部署","uri":"/posts/redis-cluster-2/#"},{"categories":["redis"],"content":" 配置集群准备 6 个 redis 实例： 127.0.0.1:6000 127.0.0.1:6001 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:8000 127.0.0.1:8001 配置集群 bash [root@localhost redis]# redis-cli --cluster create --cluster-replicas 1 127.0.0.1:6000 127.0.0.1:7000 127.0.0.1:8000 127.0.0.1:6001 127.0.0.1:7001 127.0.0.1:8001 \u003e\u003e\u003e Performing hash slots allocation on 6 nodes... Master[0] -\u003e Slots 0 - 5460 Master[1] -\u003e Slots 5461 - 10922 Master[2] -\u003e Slots 10923 - 16383 Adding replica 127.0.0.1:7001 to 127.0.0.1:6000 Adding replica 127.0.0.1:8001 to 127.0.0.1:7000 Adding replica 127.0.0.1:6001 to 127.0.0.1:8000 \u003e\u003e\u003e Trying to optimize slaves allocation for anti-affinity [WARNING] Some slaves are in the same host as their master M: c9f7d10dc6d4f471a9d5660b67c44699474bba9b 127.0.0.1:6000 slots:[0-5460] (5461 slots) master M: cf12b1d7074b1ef58d9f2cd8b3c50d9bdd53c125 127.0.0.1:7000 slots:[5461-10922] (5462 slots) master M: e64e780e3a83e871daca04ddf7d4489624d97054 127.0.0.1:8000 slots:[10923-16383] (5461 slots) master S: 08f1fa2ecd26f2916092695a3aa5bcb4185c1eee 127.0.0.1:6001 replicates cf12b1d7074b1ef58d9f2cd8b3c50d9bdd53c125 S: 2f90e0f293fcf95dada5ec3414d46f90411cd987 127.0.0.1:7001 replicates e64e780e3a83e871daca04ddf7d4489624d97054 S: 2d555ec571b26fe24012f126b600b2d742233574 127.0.0.1:8001 replicates c9f7d10dc6d4f471a9d5660b67c44699474bba9b Can I set the above configuration? (type 'yes' to accept): yes # 输入 yes 后继续 \u003e\u003e\u003e Nodes configuration updated \u003e\u003e\u003e Assign a different config epoch to each node \u003e\u003e\u003e Sending CLUSTER MEET messages to join the cluster Waiting for the cluster to join .. \u003e\u003e\u003e Performing Cluster Check (using node 127.0.0.1:6000) M: c9f7d10dc6d4f471a9d5660b67c44699474bba9b 127.0.0.1:6000 slots:[0-5460] (5461 slots) master 1 additional replica(s) S: 2f90e0f293fcf95dada5ec3414d46f90411cd987 127.0.0.1:7001 slots: (0 slots) slave replicates e64e780e3a83e871daca04ddf7d4489624d97054 S: 2d555ec571b26fe24012f126b600b2d742233574 127.0.0.1:8001 slots: (0 slots) slave replicates c9f7d10dc6d4f471a9d5660b67c44699474bba9b S: 08f1fa2ecd26f2916092695a3aa5bcb4185c1eee 127.0.0.1:6001 slots: (0 slots) slave replicates cf12b1d7074b1ef58d9f2cd8b3c50d9bdd53c125 M: e64e780e3a83e871daca04ddf7d4489624d97054 127.0.0.1:8000 slots:[10923-16383] (5461 slots) master 1 additional replica(s) M: cf12b1d7074b1ef58d9f2cd8b3c50d9bdd53c125 127.0.0.1:7000 slots:[5461-10922] (5462 slots) master 1 additional replica(s) [OK] All nodes agree about slots configuration. \u003e\u003e\u003e Check for open slots... \u003e\u003e\u003e Check slots coverage... [OK] All 16384 slots covered. 提示: 使用方法和 redis-trib.rb 脚本类似 检查集群状态 bash [root@localhost redis]# redis-cli --cluster check 127.0.0.1:6000 127.0.0.1:6000 (c9f7d10d...) -\u003e 0 keys | 5461 slots | 1 slaves. 127.0.0.1:8000 (e64e780e...) -\u003e 0 keys | 5461 slots | 1 slaves. 127.0.0.1:7000 (cf12b1d7...) -\u003e 0 keys | 5462 slots | 1 slaves. [OK] 0 keys in 3 masters. 0.00 keys per slot on average. \u003e\u003e\u003e Performing Cluster Check (using node 127.0.0.1:6000) M: c9f7d10dc6d4f471a9d5660b67c44699474bba9b 127.0.0.1:6000 slots:[0-5460] (5461 slots) master 1 additional replica(s) S: 2f90e0f293fcf95dada5ec3414d46f90411cd987 127.0.0.1:7001 slots: (0 slots) slave replicates e64e780e3a83e871daca04ddf7d4489624d97054 S: 2d555ec571b26fe24012f126b600b2d742233574 127.0.0.1:8001 slots: (0 slots) slave replicates c9f7d10dc6d4f471a9d5660b67c44699474bba9b S: 08f1fa2ecd26f2916092695a3aa5bcb4185c1eee 127.0.0.1:6001 slots: (0 slots) slave replicates cf12b1d7074b1ef58d9f2cd8b3c50d9bdd53c125 M: e64e780e3a83e871daca04ddf7d4489624d97054 127.0.0.1:8000 slots:[10923-16383] (5461 slots) master 1 additional replica(s) M: cf12b1d7074b1ef58d9f2cd8b3c50d9bdd53c125 127.0.0.1:7000 slots:[5461-10922] (5462 slots) master 1 additional replica(s) [OK] All nodes agree about slots configuration. \u003e\u003e\u003e Check for open slots... \u003e\u003e\u003e Check slots coverage... [OK] All 16384 slots covered. 连接 redis 查看状态 bash [root@localhost redis]# redis-cli -p 6000 127.0.0.1:6000\u003e CLUSTER NODES 2f90e0f293fcf95dada5ec3414d46f90411cd987 127.0.0.1:7001@17001 slave e64e780e3a83e8","date":"2022-03-25","objectID":"/posts/redis-cluster-2/:1:0","series":null,"tags":["redis"],"title":"Redis 5.x 分片集群部署","uri":"/posts/redis-cluster-2/#配置集群"},{"categories":["redis"],"content":" 增加节点先创建两个 redis 实例 127.0.0.1:9000 127.0.0.1:9001 将 127.0.0.1:9000 加入为主节点 bash [root@localhost redis]# redis-cli --cluster add-node 127.0.0.1:9000 127.0.0.1:6000 \u003e\u003e\u003e Adding node 127.0.0.1:9000 to cluster 127.0.0.1:6000 \u003e\u003e\u003e Performing Cluster Check (using node 127.0.0.1:6000) M: c9f7d10dc6d4f471a9d5660b67c44699474bba9b 127.0.0.1:6000 slots:[0-5460] (5461 slots) master 1 additional replica(s) S: 2f90e0f293fcf95dada5ec3414d46f90411cd987 127.0.0.1:7001 slots: (0 slots) slave replicates e64e780e3a83e871daca04ddf7d4489624d97054 M: cf12b1d7074b1ef58d9f2cd8b3c50d9bdd53c125 127.0.0.1:7000 slots:[5461-10922] (5462 slots) master 1 additional replica(s) M: e64e780e3a83e871daca04ddf7d4489624d97054 127.0.0.1:8000 slots:[10923-16383] (5461 slots) master 1 additional replica(s) S: 08f1fa2ecd26f2916092695a3aa5bcb4185c1eee 127.0.0.1:6001 slots: (0 slots) slave replicates cf12b1d7074b1ef58d9f2cd8b3c50d9bdd53c125 S: 2d555ec571b26fe24012f126b600b2d742233574 127.0.0.1:8001 slots: (0 slots) slave replicates c9f7d10dc6d4f471a9d5660b67c44699474bba9b [OK] All nodes agree about slots configuration. \u003e\u003e\u003e Check for open slots... \u003e\u003e\u003e Check slots coverage... [OK] All 16384 slots covered. \u003e\u003e\u003e Send CLUSTER MEET to node 127.0.0.1:9000 to make it join the cluster. [OK] New node added correctly. 检查集群状态 可以看到 127.0.0.1:9000 为主节点，哈希槽数当前为 0 bash [root@localhost redis]# redis-cli --cluster check 127.0.0.1:6000 127.0.0.1:6000 (c9f7d10d...) -\u003e 0 keys | 5461 slots | 1 slaves. 127.0.0.1:9000 (b0a13bf5...) -\u003e 0 keys | 0 slots | 0 slaves. 127.0.0.1:7000 (cf12b1d7...) -\u003e 0 keys | 5462 slots | 1 slaves. 127.0.0.1:8000 (e64e780e...) -\u003e 0 keys | 5461 slots | 1 slaves. [OK] 0 keys in 4 masters. 0.00 keys per slot on average. \u003e\u003e\u003e Performing Cluster Check (using node 127.0.0.1:6000) M: c9f7d10dc6d4f471a9d5660b67c44699474bba9b 127.0.0.1:6000 slots:[0-5460] (5461 slots) master 1 additional replica(s) M: b0a13bf57d4e514cffa305c44d41a5a92858eb9a 127.0.0.1:9000 slots: (0 slots) master S: 2f90e0f293fcf95dada5ec3414d46f90411cd987 127.0.0.1:7001 slots: (0 slots) slave replicates e64e780e3a83e871daca04ddf7d4489624d97054 M: cf12b1d7074b1ef58d9f2cd8b3c50d9bdd53c125 127.0.0.1:7000 slots:[5461-10922] (5462 slots) master 1 additional replica(s) M: e64e780e3a83e871daca04ddf7d4489624d97054 127.0.0.1:8000 slots:[10923-16383] (5461 slots) master 1 additional replica(s) S: 08f1fa2ecd26f2916092695a3aa5bcb4185c1eee 127.0.0.1:6001 slots: (0 slots) slave replicates cf12b1d7074b1ef58d9f2cd8b3c50d9bdd53c125 S: 2d555ec571b26fe24012f126b600b2d742233574 127.0.0.1:8001 slots: (0 slots) slave replicates c9f7d10dc6d4f471a9d5660b67c44699474bba9b [OK] All nodes agree about slots configuration. \u003e\u003e\u003e Check for open slots... \u003e\u003e\u003e Check slots coverage... [OK] All 16384 slots covered. 为 127.0.0.1:9000 分配哈希槽 bash [root@localhost redis]# redis-cli --cluster reshard 127.0.0.1:6000 \u003e\u003e\u003e Performing Cluster Check (using node 127.0.0.1:6000) M: c9f7d10dc6d4f471a9d5660b67c44699474bba9b 127.0.0.1:6000 slots:[0-5460] (5461 slots) master 1 additional replica(s) M: b0a13bf57d4e514cffa305c44d41a5a92858eb9a 127.0.0.1:9000 slots: (0 slots) master S: 2f90e0f293fcf95dada5ec3414d46f90411cd987 127.0.0.1:7001 slots: (0 slots) slave replicates e64e780e3a83e871daca04ddf7d4489624d97054 M: cf12b1d7074b1ef58d9f2cd8b3c50d9bdd53c125 127.0.0.1:7000 slots:[5461-10922] (5462 slots) master 1 additional replica(s) M: e64e780e3a83e871daca04ddf7d4489624d97054 127.0.0.1:8000 slots:[10923-16383] (5461 slots) master 1 additional replica(s) S: 08f1fa2ecd26f2916092695a3aa5bcb4185c1eee 127.0.0.1:6001 slots: (0 slots) slave replicates cf12b1d7074b1ef58d9f2cd8b3c50d9bdd53c125 S: 2d555ec571b26fe24012f126b600b2d742233574 127.0.0.1:8001 slots: (0 slots) slave replicates c9f7d10dc6d4f471a9d5660b67c44699474bba9b [OK] All nodes agree about slots configuration. \u003e\u003e\u003e Check for open slots... \u003e\u003e\u003e Check slots coverage... [OK] All 16384 slots covered. How many slots do you want to move (from 1 to 16384)? 4096 这里我们分配 4096 个哈希槽 bash What is the receiving node ID? b0a13bf57d4e5","date":"2022-03-25","objectID":"/posts/redis-cluster-2/:2:0","series":null,"tags":["redis"],"title":"Redis 5.x 分片集群部署","uri":"/posts/redis-cluster-2/#增加节点"},{"categories":["redis"],"content":" 简单介绍高可用 在搭建集群时，会为每一个分片的主节点，对应一个从节点，实现 slaveof 的功能，同时当主节点 down，实现类似于 sentinel 的自动 failover 的功能。 redis会有多组分片构成（3组） redis cluster 使用固定个数的slot存储数据（一共16384slot） 每组分片分得1/3 slot个数（0-5500 5501-11000 11001-16383） 基于CRC16(key) % 16384 ====》值 （槽位号）。 高性能 在多分片节点中，将 16384 个槽位，均匀分布到多个分片节点中 存数据时，将 key 做 crc16(key), 然后和 16384 进行取模，得出槽位值（0-16383之间） 根据计算得出的槽位值，找到相对应的分片节点的主节点，存储到相应槽位上 如果客户端当时连接的节点不是将来要存储的分片节点，分片集群会将客户端连接切换至真正存储节点进行数据存储 ","date":"2022-03-24","objectID":"/posts/redis-cluster-1/:1:0","series":null,"tags":["redis"],"title":"Redis 4.x 分片集群部署","uri":"/posts/redis-cluster-1/#简单介绍"},{"categories":["redis"],"content":" 部署分片集群Redis 集群至少需要三个主节点，一个主节点最少一个从节点，一共需要准备六个节点 ","date":"2022-03-24","objectID":"/posts/redis-cluster-1/:2:0","series":null,"tags":["redis"],"title":"Redis 4.x 分片集群部署","uri":"/posts/redis-cluster-1/#部署分片集群"},{"categories":["redis"],"content":" 编译安装 bash wget http://download.redis.io/releases/redis-4.0.11.tar.gz tar xzf redis-4.0.11.tar.gz cd redis-4.0.11 make make install 提示: make 时如果提示错误，你可能需要到 deps 目录下的应用目录执行 make 使用 redis 提供的脚本配置服务, 进入 utils 目录，执行 bash install_server.sh 命令，按提示进行操作 bash # bash install_server.sh Welcome to the redis service installer This script will help you easily set up a running redis server Please select the redis port for this instance: [6379] Selecting default: 6379 Please select the redis config file name [/etc/redis/6379.conf] Selected default - /etc/redis/6379.conf Please select the redis log file name [/var/log/redis_6379.log] Selected default - /var/log/redis_6379.log Please select the data directory for this instance [/var/lib/redis/6379] Selected default - /var/lib/redis/6379 Please select the redis executable path [/usr/local/bin/redis-server] Selected config: Port : 6379 Config file : /etc/redis/6379.conf Log file : /var/log/redis_6379.log Data dir : /var/lib/redis/6379 Executable : /usr/local/bin/redis-server Cli Executable : /usr/local/bin/redis-cli Is this ok? Then press ENTER to go on or Ctrl-C to abort. 重要执行上面的命令，配置6个redis 实例，实例信息如下 127.0.0.1:6379 127.0.0.1:7379 127.0.0.1:8379 127.0.0.1:6380 127.0.0.1:7380 127.0.0.1:8380 ","date":"2022-03-24","objectID":"/posts/redis-cluster-1/:2:1","series":null,"tags":["redis"],"title":"Redis 4.x 分片集群部署","uri":"/posts/redis-cluster-1/#编译安装"},{"categories":["redis"],"content":" 配置集群修改 redis 实例配置文件，添加以下配置项 (注意区分不同的实例配置项 cluster-config-file) bash appendonly yes cluster-enabled yes cluster-config-file nodes-6379.conf cluster-node-timeout 15000 修改完成后，重启所有 redis 服务 bash cd /etc/init.d/ ls redis_* | while read f; do ./$f restart; sleep 0.5; done 这里我们使用 redis 源码包中的 redis-trib.rb 脚本进行分片集群配置 由于系统默认的 ruby 版本过低，我们先安装高版本的 ruby bash wget https://cache.ruby-lang.org/pub/ruby/2.7/ruby-2.7.3.tar.gz tar xzf ruby-2.7.3.tar.gz cd ruby-2.7.3 ./configure --prefix=/usr/local/ruby make make install # 加入环境变量 echo 'export PATH=/usr/local/ruby/bin:$PATH' \u003e /etc/profile.d/ruby.sh source /etc/profile # 修改国内源 gem sources --add https://gems.ruby-china.com/ --remove https://rubygems.org/ # 安装 redis 模块 gem install redis 开始创建 redis 分片集群 进行入 redis 源码包的中 src 目录中，执行 ./redis-trib.rb create --replicas 1 127.0.0.1:6379 127.0.0.1:7379 127.0.0.1:8379 127.0.0.1:6380 127.0.0.1:7380 127.0.0.1:8380 bash # ./redis-trib.rb create --replicas 1 127.0.0.1:6379 127.0.0.1:7379 127.0.0.1:8379 \\ 127.0.0.1:6380 127.0.0.1:7380 127.0.0.1:8380 \u003e\u003e\u003e Creating cluster \u003e\u003e\u003e Performing hash slots allocation on 6 nodes... Using 3 masters: 127.0.0.1:6379 127.0.0.1:7379 127.0.0.1:8379 Adding replica 127.0.0.1:7380 to 127.0.0.1:6379 Adding replica 127.0.0.1:8380 to 127.0.0.1:7379 Adding replica 127.0.0.1:6380 to 127.0.0.1:8379 \u003e\u003e\u003e Trying to optimize slaves allocation for anti-affinity [WARNING] Some slaves are in the same host as their master M: 7dcdc92a442ff4f8e972d5cf90cfc981371d2f69 127.0.0.1:6379 slots:0-5460 (5461 slots) master M: 1c3116e5046325324085a43ebdf0496aa4ad42e2 127.0.0.1:7379 slots:5461-10922 (5462 slots) master M: 551738168e78c691169141fc6666ad83fffcd5cb 127.0.0.1:8379 slots:10923-16383 (5461 slots) master S: 686fc42d830ce4a8bbda355e0091f4b8f2b7b4a4 127.0.0.1:6380 replicates 551738168e78c691169141fc6666ad83fffcd5cb S: eb2858ad9d61ba694f80a55e7ab141521e9cd253 127.0.0.1:7380 replicates 7dcdc92a442ff4f8e972d5cf90cfc981371d2f69 S: 758a588d3b8f8350797b107a5bad5e9052bdf97f 127.0.0.1:8380 replicates 1c3116e5046325324085a43ebdf0496aa4ad42e2 Can I set the above configuration? (type 'yes' to accept): yes # 确认没有问题，输入 yes 继续 \u003e\u003e\u003e Nodes configuration updated \u003e\u003e\u003e Assign a different config epoch to each node \u003e\u003e\u003e Sending CLUSTER MEET messages to join the cluster Waiting for the cluster to join..... \u003e\u003e\u003e Performing Cluster Check (using node 127.0.0.1:6379) M: 7dcdc92a442ff4f8e972d5cf90cfc981371d2f69 127.0.0.1:6379 slots:0-5460 (5461 slots) master 1 additional replica(s) S: 758a588d3b8f8350797b107a5bad5e9052bdf97f 127.0.0.1:8380 slots: (0 slots) slave replicates 1c3116e5046325324085a43ebdf0496aa4ad42e2 M: 551738168e78c691169141fc6666ad83fffcd5cb 127.0.0.1:8379 slots:10923-16383 (5461 slots) master 1 additional replica(s) S: 686fc42d830ce4a8bbda355e0091f4b8f2b7b4a4 127.0.0.1:6380 slots: (0 slots) slave replicates 551738168e78c691169141fc6666ad83fffcd5cb M: 1c3116e5046325324085a43ebdf0496aa4ad42e2 127.0.0.1:7379 slots:5461-10922 (5462 slots) master 1 additional replica(s) S: eb2858ad9d61ba694f80a55e7ab141521e9cd253 127.0.0.1:7380 slots: (0 slots) slave replicates 7dcdc92a442ff4f8e972d5cf90cfc981371d2f69 [OK] All nodes agree about slots configuration. \u003e\u003e\u003e Check for open slots... \u003e\u003e\u003e Check slots coverage... [OK] All 16384 slots covered. 命令说明 –replicas: 表示主节点下有几个从节点 如何指定实例为主节点？ 只需要将主节点实例写在从节点前面 检查集群状态 bash ./redis-trib.rb check 127.0.0.1:6379 通过 redis-cli 查询集群信息 bash # redis-cli -p 6379 127.0.0.1:6379\u003e cluster info cluster_state:ok cluster_slots_assigned:16384 cluster_slots_ok:16384 cluster_slots_pfail:0 cluster_slots_fail:0 cluster_known_nodes:6 cluster_size:3 cluster_current_epoch:6 cluster_my_epoch:1 cluster_stats_messages_ping_sent:828 cluster_stats_messages_pong_sent:850 cluster_stats_messages_sent:1678 cluster_stats_messages_ping_received:845 cluster_stats_messages_pong_received:828 cluster_stats_messages_meet_received:5 cluster_stats_messages_received:1678 127.0.0.1:6379\u003e cluster nodes 758a588d3b8f8350797b107a5bad5e9052bdf97f 127.0.0.1:8380@18380 slave 1c3116e504632532","date":"2022-03-24","objectID":"/posts/redis-cluster-1/:2:2","series":null,"tags":["redis"],"title":"Redis 4.x 分片集群部署","uri":"/posts/redis-cluster-1/#配置集群"},{"categories":["redis"],"content":" 增加新节点新创建两个 redis 实例 7000/7001, 并启用集群配置，参考上面的集群配置部分 加入新节点 (主节点) 127.0.0.1:7000 要加入集群的节点 127.0.0.1:6379 集群中已存在的节点 bash ./redis-trib.rb add-node 127.0.0.1:7000 127.0.0.1:6379 加入从节点 –master-id 指定为 127.0.0.1:7000 的 ID bash ./redis-trib.rb add-node --slave --master-id 4cd0398657f6b401169939edfb3ec985092b676a 127.0.0.1:7001 127.0.0.1:6379 提示: 命令详细参数说明，可以执行 ./redis-trib.rb 查看 为新加入的节点分配哈希槽 bash # ./redis-trib.rb reshard 127.0.0.1:6379 \u003e\u003e\u003e Performing Cluster Check (using node 127.0.0.1:6379) M: 7dcdc92a442ff4f8e972d5cf90cfc981371d2f69 127.0.0.1:6379 slots:0-5460 (5461 slots) master 1 additional replica(s) S: 758a588d3b8f8350797b107a5bad5e9052bdf97f 127.0.0.1:8380 slots: (0 slots) slave replicates 1c3116e5046325324085a43ebdf0496aa4ad42e2 M: 551738168e78c691169141fc6666ad83fffcd5cb 127.0.0.1:8379 slots:10923-16383 (5461 slots) master 1 additional replica(s) S: 686fc42d830ce4a8bbda355e0091f4b8f2b7b4a4 127.0.0.1:6380 slots: (0 slots) slave replicates 551738168e78c691169141fc6666ad83fffcd5cb S: adb61c6d04f283077383e2dd6ed1323f6fcd2863 127.0.0.1:7001 slots: (0 slots) slave replicates 4cd0398657f6b401169939edfb3ec985092b676a M: 4cd0398657f6b401169939edfb3ec985092b676a 127.0.0.1:7000 slots: (0 slots) master 0 additional replica(s) M: 1c3116e5046325324085a43ebdf0496aa4ad42e2 127.0.0.1:7379 slots:5461-10922 (5462 slots) master 1 additional replica(s) S: eb2858ad9d61ba694f80a55e7ab141521e9cd253 127.0.0.1:7380 slots: (0 slots) slave replicates 7dcdc92a442ff4f8e972d5cf90cfc981371d2f69 [OK] All nodes agree about slots configuration. \u003e\u003e\u003e Check for open slots... \u003e\u003e\u003e Check slots coverage... [OK] All 16384 slots covered. How many slots do you want to move (from 1 to 16384)? 4096 What is the receiving node ID? 4cd0398657f6b401169939edfb3ec985092b676a # 这里是填接收哈希槽主节点ID，也是就是 7000 的 ID Please enter all the source node IDs. Type 'all' to use all the nodes as source nodes for the hash slots. Type 'done' once you entered all the source nodes IDs. Source node #1: all # 这里输入 all ...... Moving slot 1362 from 1c3116e5046325324085a43ebdf0496aa4ad42e2 Moving slot 1363 from 1c3116e5046325324085a43ebdf0496aa4ad42e2 Moving slot 1364 from 1c3116e5046325324085a43ebdf0496aa4ad42e2 Do you want to proceed with the proposed reshard plan (yes/no)? yes # 输入 yes 开始执行 一共存在四个主节点，为了平均分配我们需要给 7000 分配 16384 除以 4 等于 4096 个节点，所以我们输入 4096 Redis 集群节点的删除也可以使用 redis-trib.rb 轻松完成 ","date":"2022-03-24","objectID":"/posts/redis-cluster-1/:2:3","series":null,"tags":["redis"],"title":"Redis 4.x 分片集群部署","uri":"/posts/redis-cluster-1/#增加新节点"},{"categories":["devops"],"content":"如果你没有域名的解析控制权，此方法就非常适合； 如果你有域名的控制权可以使用 acme.sh + dns_api 的方式自动申请 ","date":"2022-03-18","objectID":"/posts/freessl/:0:0","series":null,"tags":["acme.sh","freessl.cn"],"title":"ACME v2 证书自动化申请","uri":"/posts/freessl/#"},{"categories":["devops"],"content":" 安装 acme.sh bash curl https://get.acme.sh | sh -s email=my@example.com 如果上面官方下载地址 失败 或者 太慢，可以选用国内的备用地址 bash curl https://gitcode.net/cert/cn-acme.sh/-/raw/master/install.sh?inline=false | sh -s email=my@example.com 注意：安装完成后，需重载环境变量 source ~/.bashrc，以使 acme.sh 命令生效。 ","date":"2022-03-18","objectID":"/posts/freessl/:1:0","series":null,"tags":["acme.sh","freessl.cn"],"title":"ACME v2 证书自动化申请","uri":"/posts/freessl/#安装-acmesh"},{"categories":["devops"],"content":" 对域名进行授权这步我们在 freessl.cn 站点注册个账号，登录后点击 ACME 自动化 菜单，添加域名，如下图所示 添加域名 获得域名验证（DCV）授权信息 获得域名验证（DCV）授权信息 到您的域名解析服务商添加解析记录，下面以DNSPod为例： 添加解析 ","date":"2022-03-18","objectID":"/posts/freessl/:2:0","series":null,"tags":["acme.sh","freessl.cn"],"title":"ACME v2 证书自动化申请","uri":"/posts/freessl/#对域名进行授权"},{"categories":["devops"],"content":" 申请证书点击【配置完成，立即检测】后获得证书申请命令 部署命令 ","date":"2022-03-18","objectID":"/posts/freessl/:3:0","series":null,"tags":["acme.sh","freessl.cn"],"title":"ACME v2 证书自动化申请","uri":"/posts/freessl/#申请证书"},{"categories":["devops"],"content":" 部署到 WebServerApache example: bash acme.sh --install-cert -d example.com \\ --cert-file /path/to/certfile/in/apache/cert.pem \\ --key-file /path/to/keyfile/in/apache/key.pem \\ --fullchain-file /path/to/fullchain/certfile/apache/fullchain.pem \\ --reloadcmd \"service apache2 force-reload\" Nginx example: bash acme.sh --install-cert -d example.com \\ --key-file /path/to/keyfile/in/nginx/key.pem \\ --fullchain-file /path/to/fullchain/nginx/cert.pem \\ --reloadcmd \"service nginx force-reload\" 证书进入到30天有效期，acme.sh 会自动完成续期 (有计划任务会定期检查)。 ","date":"2022-03-18","objectID":"/posts/freessl/:4:0","series":null,"tags":["acme.sh","freessl.cn"],"title":"ACME v2 证书自动化申请","uri":"/posts/freessl/#部署到-webserver"},{"categories":["mongodb"],"content":"MongoDB 默认是不会进行切割日志的，除非我们配置了 logRotate = rename，并且重启 MongoDB 服务，才会进行切割日志的，那么为了避免实际中我们一个日志文件过大，我们需要对日志进行切割，可使用以下办法： ","date":"2022-03-18","objectID":"/posts/mongodb-log/:0:0","series":null,"tags":["mongodb"],"title":"Mongodb 日志切割","uri":"/posts/mongodb-log/#"},{"categories":["mongodb"],"content":" 通过 MongoDB 管理命令进行切割使用该命令时需要在 MongoDB 运行时指定日志文件路径。–logpath [file] ，或者在配置文件中指定。 text use admin db.runCommand({logRotate:1}) ","date":"2022-03-18","objectID":"/posts/mongodb-log/:1:0","series":null,"tags":["mongodb"],"title":"Mongodb 日志切割","uri":"/posts/mongodb-log/#通过-mongodb-管理命令进行切割"},{"categories":["mongodb"],"content":" 通过向进程发送 SIGUSR1 信号来切割日志如果我们的进程 id 是 19555，那么我们可以通过以下命令来切割日志的。 只要我们执行了该命令，日志就会立即进行切割。 bash kill -SIGUSR1 19555 ","date":"2022-03-18","objectID":"/posts/mongodb-log/:2:0","series":null,"tags":["mongodb"],"title":"Mongodb 日志切割","uri":"/posts/mongodb-log/#通过向进程发送-sigusr1-信号来切割日志"},{"categories":["mongodb"],"content":" 通过 Linux 系统自带的服务 logrotate 进行切割首先我们需要配置 MongoDB 参数 logRotate = reopen， logappend = true，然后通过 Linux 系统自带的 logrotate。 配置文件放置在 /etc/logrotate.d/, 切割配置文件示例： text /var/log/mongo/*.log { rotate 180 daily size 100M olddir /var/log/mongo/oldlog copytruncate dateext compress notifempty missingok } ","date":"2022-03-18","objectID":"/posts/mongodb-log/:3:0","series":null,"tags":["mongodb"],"title":"Mongodb 日志切割","uri":"/posts/mongodb-log/#通过-linux-系统自带的服务-logrotate-进行切割"},{"categories":["python"],"content":" 实现过程终端的字符颜色是用转义序列控制的，是文本模式下的系统显示功能，和具体的语言无关。 转义序列是以 ESC 开头,即用 \\033 来完成（ ESC 的 ASCII 码用十进制表示是 27，用八进制表示就是 033）。 ","date":"2022-01-07","objectID":"/posts/python-color/:1:0","series":null,"tags":["color","terminal"],"title":"Python 终端颜色输出","uri":"/posts/python-color/#实现过程"},{"categories":["python"],"content":" 书写格式开头部分：\\033[显示方式;前景色;背景色m + 结尾部分：\\033[0m 解释： 开头部分的三个参数：显示方式，前景色，背景色是可选参数，可以只写其中的某一个； 由于表示三个参数不同含义的数值都是唯一的没有重复的，所以三个参数的书写先后顺序没有固定要求，系统都能识别； 建议按照默认的格式规范书写。 对于结尾部分，其实也可以省略，但是为了书写规范，建议 \\033[***开头，\\033[0m结尾。 数值表示的参数含义： text 显示方式: 0（默认）、1（高亮）、22（非粗体）、4（下划线）、24（非下划线）、 5（闪烁）、25（非闪烁）、7（反显）、27（非反显） 前景色: 30（黑色）、31（红色）、32（绿色）、 33（黄色）、34（蓝色）、35（洋 红）、36（青色）、37（白色） 背景色: 40（黑色）、41（红色）、42（绿色）、 43（黄色）、44（蓝色）、45（洋 红）、46（青色）、47（白色） ","date":"2022-01-07","objectID":"/posts/python-color/:2:0","series":null,"tags":["color","terminal"],"title":"Python 终端颜色输出","uri":"/posts/python-color/#书写格式"},{"categories":["python"],"content":" 代码示例第一个参数，改变显示方式 python print(\"显示方式：\") print(\"\\033[0;37;40m\\tHello World\\033[0m\") print(\"\\033[1;37;40m\\tHello World\\033[0m\") print(\"\\033[22;37;40m\\tHello World\\033[0m\") print(\"\\033[4;37;40m\\tHello World\\033[0m\") print(\"\\033[24;37;40m\\tHello World\\033[0m\") print(\"\\033[5;37;40m\\tHello World\\033[0m\") print(\"\\033[25;37;40m\\tHello World\\033[0m\") print(\"\\033[7;37;40m\\tHello World\\033[0m\") print(\"\\033[27;37;40m\\tHello World\\033[0m\") 第二个参数，改变字体颜色 python print(\"前景色：\") print(\"\\033[0;30;40m\\tHello World\\033[0m\") print(\"\\033[0;31;40m\\tHello World\\033[0m\") print(\"\\033[0;32;40m\\tHello World\\033[0m\") print(\"\\033[0;33;40m\\tHello World\\033[0m\") print(\"\\033[0;34;40m\\tHello World\\033[0m\") print(\"\\033[0;35;40m\\tHello World\\033[0m\") print(\"\\033[0;36;40m\\tHello World\\033[0m\") print(\"\\033[0;37;40m\\tHello World\\033[0m\") 第三个参数，改变背景颜色 python print(\"背景色：\") print(\"\\033[0;37;40m\\tHello World\\033[0m\") print(\"\\033[0;37;41m\\tHello World\\033[0m\") print(\"\\033[0;37;42m\\tHello World\\033[0m\") print(\"\\033[0;37;43m\\tHello World\\033[0m\") print(\"\\033[0;37;44m\\tHello World\\033[0m\") print(\"\\033[0;37;45m\\tHello World\\033[0m\") print(\"\\033[0;37;46m\\tHello World\\033[0m\") print(\"\\033[0;37;47m\\tHello World\\033[0m\") 源文档: https://www.cnblogs.com/zhuminghui/p/9457185.html ","date":"2022-01-07","objectID":"/posts/python-color/:3:0","series":null,"tags":["color","terminal"],"title":"Python 终端颜色输出","uri":"/posts/python-color/#代码示例"},{"categories":["bash"],"content":" 问题: while read line 无法读取最后一行使用 shell 脚本读取文本文件时，发现无法读取到最后一行，通过使用 hexdump 查看文件内容, 发文件结尾没有 \\n bash $ hexdump -c iccids.csv 0000000 8 9 8 6 0 6 5 3 9 8 7 5 9 8 7 6 0000010 5 3 2 2 \\n 8 9 8 6 0 6 2 1 2 5 0 0000020 0 2 5 4 9 0 0 6 2 \\n 8 9 8 6 0 4 0000030 A 4 1 9 2 1 8 1 6 7 3 6 2 5 \\n 8 0000040 9 8 6 0 6 2 0 1 6 0 0 0 2 3 5 7 0000050 5 5 9 \\n 8 9 8 6 0 6 2 0 1 8 0 0 0000060 2 3 3 7 6 3 8 8 0000068 shell脚本源码如下： bash while read line; do echo $line done \u003c iccids.csv 解决方案 方案一 在利用 while read line 读取文件时： 如果文件最后一行之后没有换行符 \\n，则 read 读取最后一行时遇到文件结束符 EOF，循环即终止。 虽然，此时 $line 内存有最后一行，但程序已经没有机会再处理此行内容。因此导致了这个问题发生。 解决方案如下： bash while read line || [[ -n ${line} ]] 这样当文件没有到最后一行时不会测试 [[ -n ${line} ]] ，当遇到文件结束（最后一行）时，仍然可以通过测试 $line 是否有内容来进行继续处理。 上例子代码如下改进： bash while read iicd || [[ -n $iicd ]]; do echo $iicd done \u003c iccids.csv 方案二 通过分析原因可知，本质原因是因为文件格式不是 unix 导致的，也可以直接通过设置文件格式来处理。 如这样处理，脚本代码不需改动。 ","date":"2022-01-06","objectID":"/posts/bash-while/:1:0","series":null,"tags":["while"],"title":"Bash - while read 问题","uri":"/posts/bash-while/#问题-while-read-line-无法读取最后一行"},{"categories":["bash"],"content":" 问题: while 循环中 read 命令无效问题解决 while 循环中 read 命令无效问题, 代码如下: bash while read ip; do echo $ip read -p \"pause...\" done \u003c ip.list 运行程序时你会发现他根本不会等待你输入，就直接完成了，原因是两个 read 读取了同一个标准输入 解决方法： 将 read 的标准输入变更成其它文件描述符就行了，这样两个 read 就错开了 bash while read -u 5 ip; do echo $ip read -p \"pause...\" done 5\u003c ip.list 注意: 5\u003c 之间不能有空格 ","date":"2022-01-06","objectID":"/posts/bash-while/:2:0","series":null,"tags":["while"],"title":"Bash - while read 问题","uri":"/posts/bash-while/#问题-while-循环中-read-命令无效问题"},{"categories":["devops"],"content":"为虚拟机挂载一块新硬盘，用于实验（/dev/sdb） bash [root@localhost ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 20G 0 disk ├─sda1 8:1 0 1G 0 part /boot └─sda2 8:2 0 19G 0 part ├─centos-root 253:0 0 17G 0 lvm / └─centos-swap 253:1 0 2G 0 lvm [SWAP] sdb 8:16 0 20G 0 disk sr0 11:0 1 906M 0 rom ","date":"2021-12-16","objectID":"/posts/lvm/:0:0","series":null,"tags":["lvm"],"title":"使用 LVM 管理硬盘空间","uri":"/posts/lvm/#"},{"categories":["devops"],"content":" 创建 PV bash pvcreate /dev/sdb ","date":"2021-12-16","objectID":"/posts/lvm/:1:0","series":null,"tags":["lvm"],"title":"使用 LVM 管理硬盘空间","uri":"/posts/lvm/#创建-pv"},{"categories":["devops"],"content":" 加入 VG查看 VG bash [root@localhost ~]# vgdisplay --- Volume group --- VG Name centos System ID Format lvm2 Metadata Areas 1 Metadata Sequence No 3 VG Access read/write VG Status resizable MAX LV 0 Cur LV 2 Open LV 2 Max PV 0 Cur PV 1 Act PV 1 VG Size \u003c19.00 GiB PE Size 4.00 MiB Total PE 4863 Alloc PE / Size 4863 / \u003c19.00 GiB Free PE / Size 0 / 0 VG UUID 85pJBT-lfvE-sptt-ywZF-j8Ya-m1Xg-ch4Qyf 将新硬盘加入 centos VG 中 bash [root@localhost ~]# vgextend centos /dev/sdb Volume group \"centos\" successfully extended 再次查看 VG bash [root@localhost ~]# vgdisplay --- Volume group --- VG Name centos System ID Format lvm2 Metadata Areas 2 Metadata Sequence No 4 VG Access read/write VG Status resizable MAX LV 0 Cur LV 2 Open LV 2 Max PV 0 Cur PV 2 Act PV 2 VG Size 38.99 GiB PE Size 4.00 MiB Total PE 9982 Alloc PE / Size 4863 / \u003c19.00 GiB Free PE / Size 5119 / \u003c20.00 GiB VG UUID 85pJBT-lfvE-sptt-ywZF-j8Ya-m1Xg-ch4Qyf 通过上面的信息可以看出 VG 容量扩大了 ","date":"2021-12-16","objectID":"/posts/lvm/:2:0","series":null,"tags":["lvm"],"title":"使用 LVM 管理硬盘空间","uri":"/posts/lvm/#加入-vg"},{"categories":["devops"],"content":" 创建 LV查看现有的 lv 卷 bash [root@localhost ~]# lvdisplay --- Logical volume --- LV Path /dev/centos/swap LV Name swap VG Name centos LV UUID 52CL0Y-FldW-4wuO-fV1s-qtAl-oKR5-vPI2uZ LV Write Access read/write LV Creation host, time localhost.localdomain, 2021-09-10 12:03:59 +0800 LV Status available # open 2 LV Size 2.00 GiB Current LE 512 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:1 --- Logical volume --- LV Path /dev/centos/root LV Name root VG Name centos LV UUID QL4fK3-RjZ0-5XXd-ghsm-W0DQ-Gp3m-A4z45J LV Write Access read/write LV Creation host, time localhost.localdomain, 2021-09-10 12:03:59 +0800 LV Status available # open 1 LV Size \u003c17.00 GiB Current LE 4351 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:0 目前只有 swap 和 root 两个 lv 创建新的 lv 卷（test_lv） bash [root@localhost ~]# lvcreate -L 5G -n test_lv centos Logical volume \"test_lv\" created. 查看 test_lv bash [root@localhost ~]# lvdisplay /dev/centos/test_lv --- Logical volume --- LV Path /dev/centos/test_lv LV Name test_lv VG Name centos LV UUID qUnC6d-dyn0-7f0C-TC3B-dmi1-ncwF-30CJug LV Write Access read/write LV Creation host, time localhost.localdomain, 2021-12-16 10:36:54 +0800 LV Status available # open 0 LV Size 5.00 GiB Current LE 1280 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:2 使用 test_lv bash [root@localhost ~]# mkfs.ext4 /dev/centos/test_lv mke2fs 1.42.9 (28-Dec-2013) Filesystem label= OS type: Linux Block size=4096 (log=2) Fragment size=4096 (log=2) Stride=0 blocks, Stripe width=0 blocks 327680 inodes, 1310720 blocks 65536 blocks (5.00%) reserved for the super user First data block=0 Maximum filesystem blocks=1342177280 40 block groups 32768 blocks per group, 32768 fragments per group 8192 inodes per group Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736 Allocating group tables: done Writing inode tables: done Creating journal (32768 blocks): done Writing superblocks and filesystem accounting information: done [root@localhost ~]# mkdir /test [root@localhost ~]# mount /dev/centos/test_lv /test [root@localhost ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 20G 0 disk ├─sda1 8:1 0 1G 0 part /boot └─sda2 8:2 0 19G 0 part ├─centos-root 253:0 0 17G 0 lvm / └─centos-swap 253:1 0 2G 0 lvm [SWAP] sdb 8:16 0 20G 0 disk └─centos-test_lv 253:2 0 5G 0 lvm /test sr0 11:0 1 906M 0 rom # 为了开机自动挂载，将挂载信息写入 /etc/fstab 文件中 [root@localhost ~]# echo '/dev/centos/test_lv /test ext4 defaults 0 0' \u003e\u003e /etc/fstab ","date":"2021-12-16","objectID":"/posts/lvm/:3:0","series":null,"tags":["lvm"],"title":"使用 LVM 管理硬盘空间","uri":"/posts/lvm/#创建-lv"},{"categories":["devops"],"content":" 动态 lv 扩容现在需要对 root lv 进行动态扩容，vg 中剩余的所有空间都分给 root lv，操作步骤如下 查看 vg bash [root@localhost ~]# vgdisplay --- Volume group --- VG Name centos System ID Format lvm2 Metadata Areas 2 Metadata Sequence No 7 VG Access read/write VG Status resizable MAX LV 0 Cur LV 3 Open LV 3 Max PV 0 Cur PV 2 Act PV 2 VG Size 38.99 GiB PE Size 4.00 MiB Total PE 9982 Alloc PE / Size 6143 / \u003c24.00 GiB Free PE / Size 3839 / \u003c15.00 GiB VG UUID 85pJBT-lfvE-sptt-ywZF-j8Ya-m1Xg-ch4Qyf 通过上面的信息可以看出，还有 15G 剩余空间可以供分配 (3839 个 PE, 一个 PE 大小为 4M ) 现在将 VG 剩余所有空间分配给 root lv bash [root@localhost ~]# lvextend -l +100%FREE /dev/centos/root Size of logical volume centos/root changed from \u003c17.00 GiB (4351 extents) to 31.99 GiB (8190 extents). Logical volume centos/root successfully resized. -l +100%FREE 表示使用卷组中所有剩余的自由空间。 /dev/centos/root 是逻辑卷的路径，确保使用正确的路径 提示: 如果想分配后刷新分表区信息，需要加入 -r 参数 查看 root lv 信息 bash [root@localhost ~]# lvdisplay /dev/centos/root --- Logical volume --- LV Path /dev/centos/root LV Name root VG Name centos LV UUID QL4fK3-RjZ0-5XXd-ghsm-W0DQ-Gp3m-A4z45J LV Write Access read/write LV Creation host, time localhost.localdomain, 2021-09-10 12:03:59 +0800 LV Status available # open 1 LV Size 31.99 GiB Current LE 8190 Segments 2 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:0 再通过 df 查看 bash [root@localhost ~]# df -hl Filesystem Size Used Avail Use% Mounted on /dev/mapper/centos-root 17G 1.5G 16G 9% / devtmpfs 224M 0 224M 0% /dev tmpfs 236M 0 236M 0% /dev/shm tmpfs 236M 5.5M 230M 3% /run tmpfs 236M 0 236M 0% /sys/fs/cgroup /dev/sda1 1014M 130M 885M 13% /boot tmpfs 48M 0 48M 0% /run/user/0 /dev/mapper/centos-test_lv 4.8G 20M 4.6G 1% /test 可以看出硬盘空间分配成功，但没有刷新 刷新分区信息 bash [root@localhost ~]# resize2fs -f /dev/centos/root resize2fs 1.42.9 (28-Dec-2013) resize2fs: Bad magic number in super-block while trying to open /dev/centos/root Couldn't find valid filesystem superblock. 我们使用 resize2fs 命令刷新分区信息出错，这是由于 root lv 的文件系统为 xfs 需要使用 xfs_growfs 命令 bash [root@localhost ~]# xfs_growfs /dev/centos/root meta-data=/dev/mapper/centos-root isize=512 agcount=4, agsize=1113856 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0 spinodes=0 data = bsize=4096 blocks=4455424, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 data blocks changed from 4455424 to 8386560 再次 df -hl 查看大小 bash [root@localhost ~]# df -hl Filesystem Size Used Avail Use% Mounted on /dev/mapper/centos-root 32G 1.5G 31G 5% / devtmpfs 224M 0 224M 0% /dev tmpfs 236M 0 236M 0% /dev/shm tmpfs 236M 5.5M 230M 3% /run tmpfs 236M 0 236M 0% /sys/fs/cgroup /dev/sda1 1014M 130M 885M 13% /boot tmpfs 48M 0 48M 0% /run/user/0 /dev/mapper/centos-test_lv 4.8G 20M 4.6G 1% /test root lv 的容量大小已刷新成功了 ","date":"2021-12-16","objectID":"/posts/lvm/:4:0","series":null,"tags":["lvm"],"title":"使用 LVM 管理硬盘空间","uri":"/posts/lvm/#动态-lv-扩容"},{"categories":["devops"],"content":" 简介Stunnel 是一个自由的跨平台软件，用于提供全局的TLS/SSL服务。针对本身无法进行TLS或SSL通信的客户端及服务器，Stunnel可提供安全的加密连接。该软件可在许多操作系统下运行，包括Unix-like系统，以及Windows。Stunnel依赖于某个独立的库，如OpenSSL或者SSLeay，以实现TLS或SSL协议。 下面我们通过一个简单的示例，演示 stunnel 的配置及使用 ","date":"2021-12-06","objectID":"/posts/stunnel/:1:0","series":null,"tags":["stunnel"],"title":"使用 stunnel 加密保护你的连接","uri":"/posts/stunnel/#简介"},{"categories":["devops"],"content":" 部署 stunnel安装 bash yum install -y stunnel 准备 systemd service 文件 bash cat \u003e /usr/lib/systemd/system/stunnel.service \u003c\u003cEOF [Unit] Description=TLS tunnel for network daemons After=syslog.target network.target [Service] Type=forking ExecStart=/usr/bin/stunnel /etc/stunnel/stunnel.conf ExecStartPre=-/usr/bin/mkdir -p /var/run/stunnel PrivateTmp=true [Install] WantedBy=multi-user.target EOF ","date":"2021-12-06","objectID":"/posts/stunnel/:2:0","series":null,"tags":["stunnel"],"title":"使用 stunnel 加密保护你的连接","uri":"/posts/stunnel/#部署-stunnel"},{"categories":["devops"],"content":" 配置 stunnel由于 http 默认使用明文进行数据传输，在安全性上得不到保障，现在我们通过 stunnel 加 tls 证书包装一个让其监听 443 端口，为用户提供加密连接服务。 注意: 这里只是个实验用于演示 stunnel，在实际生产环境我们可以使用 nginx 或 apache 配置 https 站点 服务端服务 bash cat \u003e /etc/stunnel/stunnel.conf \u003c\u003cEOF setuid = root setgid = root pid = /var/run/stunnel/stunnel.pid debug = 7 # 指定 ssl 版本 sslVersion = TLSv1.2 [http] accept = 443 connect = 80 cert = /etc/stunnel/ssl/test/fullchain.pem key = /etc/stunnel/ssl/test/key.pem EOF 启动服务 bash systemctl start stunnel systemctl enable stunnel 提示: stunnel 启动后就可以直接使用 443 端口替代 80 端口提供服务了 ","date":"2021-12-06","objectID":"/posts/stunnel/:3:0","series":null,"tags":["stunnel"],"title":"使用 stunnel 加密保护你的连接","uri":"/posts/stunnel/#配置-stunnel"},{"categories":["devops"],"content":" 客户端配置stunnel 的客户端配置可以理解为反向代理服务器; 当我们服务端使用自签证书配置时，客户端请求时还需要带上证书会客户端带来不少麻烦事，如果客户端跑的是已经写好的工具，还得改代码重新启动客户端服务。 为了解决这事我们可以通过配置 stunnel 客户端来解决。 stunnel 客户端与 stunnel 服务端通过 tls 证书建立连接, stunnel 客户端通过在本地监控一个端口用于提供一个不需要证书就可以连接服务，然后我们程序通过连接这个端口就可以正常请求到真正的后端服务了，减少了改动工作量 配置如下 text cat \u003e /etc/stunnel/stunnel.conf \u003c\u003cEOF setuid = root setgid = root pid = /var/run/stunnel/stunnel.pid debug = 7 # 指定 ssl 版本 sslVersion = TLSv1.2 [http] client = yes accept = 80 connect = \u003c服务端地址\u003e:443 cert = /etc/stunnel/ssl/test/fullchain.pem key = /etc/stunnel/ssl/test/key.pem EOF 提示: 与服务端配置的区别就是多了一个 client = yes 的配置项 ","date":"2021-12-06","objectID":"/posts/stunnel/:4:0","series":null,"tags":["stunnel"],"title":"使用 stunnel 加密保护你的连接","uri":"/posts/stunnel/#客户端配置"},{"categories":["devops"],"content":"由于生产环境中有使用 certbot 工具为 apache 的虚拟主机自动申请证书，记录下 certbot 配置操作过程 certbot 官方站点: https://certbot.eff.org/ ","date":"2021-12-06","objectID":"/posts/certbot/:0:0","series":null,"tags":["certbot"],"title":"使用 certbot 自动申请证书","uri":"/posts/certbot/#"},{"categories":["devops"],"content":" 安装 certbotcertbot 为 python 项目可以直接使用 pip 工具进行安装，在 centos 的 epel 源中也有相应的 rpm 包可以使用 yum 安装 ","date":"2021-12-06","objectID":"/posts/certbot/:1:0","series":null,"tags":["certbot"],"title":"使用 certbot 自动申请证书","uri":"/posts/certbot/#安装-certbot"},{"categories":["devops"],"content":" YUM 安装 bash yum install epel-release yum install certbot python2-certbot-apache 注意: 有可能会安装失败 ","date":"2021-12-06","objectID":"/posts/certbot/:1:1","series":null,"tags":["certbot"],"title":"使用 certbot 自动申请证书","uri":"/posts/certbot/#yum-安装"},{"categories":["devops"],"content":" PIP 安装 (推荐)安装 certbot-apache 依赖包 bash yum install -y augeas 安装 certbot 环境 bash python3 -m venv /opt/certbot/ /opt/certbot/bin/pip install --upgrade pip /opt/certbot/bin/pip install certbot certbot-apache ln -s /opt/certbot/bin/certbot /usr/bin/certbot certbot-apache 是 certbot 支持 apache 的插件 ","date":"2021-12-06","objectID":"/posts/certbot/:1:2","series":null,"tags":["certbot"],"title":"使用 certbot 自动申请证书","uri":"/posts/certbot/#pip-安装-推荐"},{"categories":["devops"],"content":" 申请证书为 apache 虚拟主机自动申请证书 bash certbot --apache ","date":"2021-12-06","objectID":"/posts/certbot/:2:0","series":null,"tags":["certbot"],"title":"使用 certbot 自动申请证书","uri":"/posts/certbot/#申请证书"},{"categories":["devops"],"content":" 证书自动续期加入计划任务，每周一检查一次证书有效期，到期就自动续期 bash 0 0 * * 1 /usr/bin/certbot renew \u0026\u003e/dev/null 根据提示信息进行操作即可 证书申请完成后 certbot 会自动修改 apache 配置文件，添加 https 相关配置，文件名为 虚拟主机配置文件名加上 le-ssl 字符，原先的虚拟主机配置会加上 http 跳转至 https 的配置 bash [soperator@iZm5ees9if066t4cmhfx3kZ conf.d]$ ls autoindex.conf php.conf ssl.conf virtualhost.conf welcome.conf enviroment.conf README userdir.conf virtualhost-le-ssl.conf http 跳转 https 配置 bash RewriteEngine on RewriteCond %{SERVER_NAME} =test.liwanggui.com RewriteRule ^ https://%{SERVER_NAME}%{REQUEST_URI} [END,NE,R=permanent] 自动生成配置文件内容: virtualhost-le-ssl.conf bash \u003cIfModule mod_ssl.c\u003e \u003cVirtualHost *:443\u003e DocumentRoot \"/data/www/test\" ServerName test.liwanggui.com \u003cDirectory \"/data/www/test\"\u003e Require all granted AllowOverride all Options -indexes +FollowSymLinks \u003c/Directory\u003e SSLCertificateFile /etc/letsencrypt/live/test.liwanggui.com/cert.pem SSLCertificateKeyFile /etc/letsencrypt/live/test.liwanggui.com/privkey.pem Include /etc/letsencrypt/options-ssl-apache.conf SSLCertificateChainFile /etc/letsencrypt/live/test.liwanggui.com/chain.pem \u003c/VirtualHost\u003e \u003c/IfModule\u003e ","date":"2021-12-06","objectID":"/posts/certbot/:3:0","series":null,"tags":["certbot"],"title":"使用 certbot 自动申请证书","uri":"/posts/certbot/#证书自动续期"},{"categories":["devops","git"],"content":" 环境准备 bash yum install -y curl-devel openssl-devel expat-devel gettext-devel readline-devel zlib-devel asciidoc xmlto docbook2X autoconf yum install -y gcc gcc-c++ make 为了解决二进制命令名称不同 bash ln -s /usr/bin/db2x_docbook2texi /usr/bin/docbook2x-texi ","date":"2021-10-23","objectID":"/posts/git-src/:1:0","series":null,"tags":["git"],"title":"Git 源码编译安装","uri":"/posts/git-src/#环境准备"},{"categories":["devops","git"],"content":" 编译 bash wget --no-check-certificate https://mirrors.edge.kernel.org/pub/software/scm/git/git-2.23.4.tar.gz tar xzf git-2.23.4.tar.gz cd git-2.23.4/ ./configure --prefix=/usr make -j 4 make install ","date":"2021-10-23","objectID":"/posts/git-src/:2:0","series":null,"tags":["git"],"title":"Git 源码编译安装","uri":"/posts/git-src/#编译"},{"categories":["devops","git"],"content":" fpm 打包编译参数 bash make all doc info -j 4 make install install-doc install-html install-info DESTDIR=/tmp/installdir make install DESTDIR=/tmp/installdir 打包命令 bash fpm -s dir -t rpm -n git -v 2.23.4 --iteration 1.el7 -C /tmp/installdir/ usr ","date":"2021-10-23","objectID":"/posts/git-src/:3:0","series":null,"tags":["git"],"title":"Git 源码编译安装","uri":"/posts/git-src/#fpm-打包"},{"categories":["devops","vim"],"content":" Tab 转为 空格在 $HOME/.vimrc 文件中加入以下配置 vim set expandtab set tabstop=4 将现有文件的 Tab 转换为 空格 vim :set ts=4 :set expandtab :%retab! ","date":"2021-09-14","objectID":"/posts/vim/:1:0","series":null,"tags":["vim"],"title":"Vim 常用配置","uri":"/posts/vim/#tab-转为-空格"},{"categories":["devops","vim"],"content":" 取消自动缩进 vim set pastetoggle=\u003cF11\u003e 按 F11 将禁用自动缩进功能 ","date":"2021-09-14","objectID":"/posts/vim/:2:0","series":null,"tags":["vim"],"title":"Vim 常用配置","uri":"/posts/vim/#取消自动缩进"},{"categories":["devops","vim"],"content":" 为 Shell 脚本定制开头片断 vim autocmd BufNewFile *.sh exec \":call SetTitle()\" func SetTitle() if expand(\"%:e\") == 'sh' call setline(1,\"#!/bin/bash\") call setline(2,\"#\") call setline(3,\"#***************************************************************************\") call setline(4,\"# Author: liwanggui\") call setline(5,\"# Email: liwanggui@163.com\") call setline(6,\"# Date: \".strftime(\"%Y-%m-%d\")) call setline(7,\"# FileName: \".expand(\"%\")) call setline(8,\"# Description: This is a test script\") call setline(9,\"# Copyright (C): \".strftime(\"%Y\").\" All rights reserved\") call setline(10,\"#***************************************************************************\") call setline(11,\"#\") call setline(12,\"\") endif endfunc autocmd BufnewFile * normal G ","date":"2021-09-14","objectID":"/posts/vim/:3:0","series":null,"tags":["vim"],"title":"Vim 常用配置","uri":"/posts/vim/#为-shell-脚本定制开头片断"},{"categories":["devops","vim"],"content":" 完整配置 vim set expandtab set tabstop=4 set shiftwidth=4 set ignorecase set cursorline set autoindent set paste set pastetoggle=\u003cF11\u003e autocmd BufNewFile *.sh exec \":call SetTitle()\" func SetTitle() if expand(\"%:e\") == 'sh' call setline(1,\"#!/bin/bash\") call setline(2,\"#\") call setline(3,\"#***************************************************************************\") call setline(4,\"# Author: liwanggui\") call setline(5,\"# Email: liwanggui@163.com\") call setline(6,\"# Date: \".strftime(\"%Y-%m-%d\")) call setline(7,\"# FileName: \".expand(\"%\")) call setline(8,\"# Description: This is a test script\") call setline(9,\"# Copyright (C): \".strftime(\"%Y\").\" All rights reserved\") call setline(10,\"#***************************************************************************\") call setline(11,\"#\") call setline(12,\"\") endif endfunc autocmd BufnewFile * normal G ","date":"2021-09-14","objectID":"/posts/vim/:4:0","series":null,"tags":["vim"],"title":"Vim 常用配置","uri":"/posts/vim/#完整配置"},{"categories":["fileserver"],"content":" 官方文档: https://filebrowser.org/ ","date":"2021-08-23","objectID":"/posts/filebrowser/:0:0","series":null,"tags":["filebrowser"],"title":"Filebrowser 一个简单的在线文件服务","uri":"/posts/filebrowser/#"},{"categories":["fileserver"],"content":" 安装 bash curl -fsSL https://raw.githubusercontent.com/filebrowser/get/master/get.sh | bash ","date":"2021-08-23","objectID":"/posts/filebrowser/:1:0","series":null,"tags":["filebrowser"],"title":"Filebrowser 一个简单的在线文件服务","uri":"/posts/filebrowser/#安装"},{"categories":["fileserver"],"content":" 配置创建配置目录 /etc/filebrowser bash sudo mkdir -p /etc/filebrowser 初始化数据库文件 bash sudo filebrowser config init -d /etc/filebrowser/filebrowser.db 默认 filebrowser.db 是不存在的, filebrowser 配置信息都保存在数据库文件中 配置文件服务的根目录 bash sudo filebrowser config set -r /data/fileserver -d /etc/filebrowser/filebrowser.db 配置服务监听地址及端口 bash sudo filebrowser config set -a 0.0.0.0 -d /etc/filebrowser/filebrowser.db sudo filebrowser config set -p 80 -d /etc/filebrowser/filebrowser.db 添加管理员用户, 用户名: admin 密码: admin bash sudo filebrowser users add admin admin --perm.admin -d /etc/filebrowser/filebrowser.db 配置完成后可以通过 filebrowser -d /etc/filebrowser/filebrowser.db 命令启动服务 ","date":"2021-08-23","objectID":"/posts/filebrowser/:2:0","series":null,"tags":["filebrowser"],"title":"Filebrowser 一个简单的在线文件服务","uri":"/posts/filebrowser/#配置"},{"categories":["fileserver"],"content":" 服务管理为了更好的管理 filebrowser 服务，编写 Unit 配置文件 /usr/lib/systemd/system/filebrowser.service ini [Unit] Description=File Browser Documentation=https://filebrowser.org/ After=network.target [Service] Type=simple WorkingDirectory=/etc/filebrowser ExecStart=/usr/local/bin/filebrowser -d /etc/filebrowser/filebrowser.db Restart=on-failure [Install] WantedBy=multi-user.target 设置为开机自启并启动服务 bash sudo systemctl enable --now filebrowser.service ","date":"2021-08-23","objectID":"/posts/filebrowser/:3:0","series":null,"tags":["filebrowser"],"title":"Filebrowser 一个简单的在线文件服务","uri":"/posts/filebrowser/#服务管理"},{"categories":["webserver"],"content":"Caddy 是一个简单易用的 Web 服务端应用，它可以自动为域名申请证书，自动续期等… 官方文档: https://caddyserver.com/docs/ ","date":"2021-08-23","objectID":"/posts/caddy/:0:0","series":null,"tags":["caddy"],"title":"Caddy 一个简单的 Web 服务","uri":"/posts/caddy/#"},{"categories":["webserver"],"content":" 安装以 Ubuntu 为例，其它安装方式请参考: https://caddyserver.com/docs/install#static-binaries bash sudo apt install -y debian-keyring debian-archive-keyring apt-transport-https curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | sudo tee /etc/apt/trusted.gpg.d/caddy-stable.asc curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | sudo tee /etc/apt/sources.list.d/caddy-stable.list sudo apt update sudo apt install caddy ","date":"2021-08-23","objectID":"/posts/caddy/:1:0","series":null,"tags":["caddy"],"title":"Caddy 一个简单的 Web 服务","uri":"/posts/caddy/#安装"},{"categories":["webserver"],"content":" 配置通过包安装 Caddy 的配置文件默认在 /etc/caddy 目录，配置文件为 Caddyfile caddyfile :80 { # Set this path to your site's directory. root * /usr/share/caddy file_server # Enable the static file server. # file_server browse # Another common task is to set up a reverse proxy: # reverse_proxy localhost:9090 # Or serve a PHP site through php-fpm: # php_fastcgi localhost:9000 } 使用 sudo systemctl start caddy 启动 Caddy 现在你可以在浏览器中输入 http://localhost 访问 caddy 默认页 caddy.service text [Unit] Description=Caddy Documentation=https://caddyserver.com/docs/ After=network.target network-online.target Requires=network-online.target [Service] Type=notify User=caddy Group=caddy ExecStart=/usr/bin/caddy run --environ --config /etc/caddy/Caddyfile ExecReload=/usr/bin/caddy reload --config /etc/caddy/Caddyfile --force TimeoutStopSec=5s LimitNOFILE=1048576 LimitNPROC=512 PrivateTmp=true ProtectSystem=full AmbientCapabilities=CAP_NET_ADMIN CAP_NET_BIND_SERVICE [Install] WantedBy=multi-user.target ","date":"2021-08-23","objectID":"/posts/caddy/:2:0","series":null,"tags":["caddy"],"title":"Caddy 一个简单的 Web 服务","uri":"/posts/caddy/#配置"},{"categories":["webserver"],"content":" 示例","date":"2021-08-23","objectID":"/posts/caddy/:3:0","series":null,"tags":["caddy"],"title":"Caddy 一个简单的 Web 服务","uri":"/posts/caddy/#示例"},{"categories":["webserver"],"content":" 文件服务器修改 Caddyfile , 使用 fileserver browse 指令启用 Caddy 文件服务功能，配置如下： text dl.liwanggui.com { root * /usr/share/caddy file_server browse } ","date":"2021-08-23","objectID":"/posts/caddy/:3:1","series":null,"tags":["caddy"],"title":"Caddy 一个简单的 Web 服务","uri":"/posts/caddy/#文件服务器"},{"categories":["webserver"],"content":" 反向代理Caddy 使用 reverse_proxy 指令启用反向代理功能 语法参考: https://caddyserver.com/docs/caddyfile/directives/reverse_proxy#syntax text liwanggui.com { reverse_proxy localhost:8080 } ","date":"2021-08-23","objectID":"/posts/caddy/:3:2","series":null,"tags":["caddy"],"title":"Caddy 一个简单的 Web 服务","uri":"/posts/caddy/#反向代理"},{"categories":["webserver"],"content":" PHP 站点使用 php_fastcgi 指令来配置 PHP 站点 text liwanggui.com { root * /data/www/typecho php_fastcgi localhost:9000 } ","date":"2021-08-23","objectID":"/posts/caddy/:3:3","series":null,"tags":["caddy"],"title":"Caddy 一个简单的 Web 服务","uri":"/posts/caddy/#php-站点"},{"categories":["webserver"],"content":" 返回客户端地址 text myip.liwanggui.com { respond {remote_host} } ","date":"2021-08-23","objectID":"/posts/caddy/:3:4","series":null,"tags":["caddy"],"title":"Caddy 一个简单的 Web 服务","uri":"/posts/caddy/#返回客户端地址"},{"categories":["webserver"],"content":" 子路径配置目录结构如下: text ├── bar │ └── index.html └── root └── index.html 实现 text liwanggui.com ====\u003e root/index.html liwanggui.com/abc ====\u003e bar/index.html Caddy 配置如下 text liwanggui.com { # 重定向 /abc -\u003e /abc/ redir /abc /abc/ # 匹配以 /abc/ 开头的请求 # handle_path 会去除 /abc 前缀， # 如果不去除 /abc, 访问文件的路径是 /bar/abc/index.html (此路径是不存在的，返回 404) # 去除 /abc 前缀，访问文件的路径是 /bar/index.html handle_path /abc/* { root * /bar file_server } # 匹配所有 handle { root * /root file_server } } 等价于 nginx 的配置如下: text server { listen 80; server_name liwanggui.com; location / { root /foo; } location /abc/ { alias /foo/bar/; } } ","date":"2021-08-23","objectID":"/posts/caddy/:3:5","series":null,"tags":["caddy"],"title":"Caddy 一个简单的 Web 服务","uri":"/posts/caddy/#子路径配置"},{"categories":["devops","command"],"content":"在 Windows 操作系统环境下的 Xshell 等程序中执行 “sz/rz” 命令，会自动弹出一个图形界面窗口（是对ZMODEM协议信号捕获事件的响应），用于选取“从服务器接收文件传输目的路径/待发送到服务器的文件路径”。 而在 Ubuntu Shell 下，可通过 GNU screen 软件包下的 screen 命令环境捕获 ZMODEM 协议信号，从而实现选取 “从服务器接收文件传输目的路径/待发送到服务器的文件路径”。 ","date":"2021-08-16","objectID":"/posts/screen/:0:0","series":null,"tags":["screen"],"title":"screen 实现 lrzsz 文件上传下载","uri":"/posts/screen/#"},{"categories":["devops","command"],"content":" 发送文件到服务器 打开一个 Shell 执行 screen 命令，进入 screen 命令环境 按下 Ctrl+a 组合键，然后再输入 :zmodem catch 命令，设置 screen 命令环境捕获ZMODEM协议信号 在以上 screen 命令环境下与服务器建立 SSH 连接 执行 rz 命令，ZMODEM 协议信号被 screen 命令环境捕获，终端底部出现待补全命令，待补全部分为 “待发送到服务器的文件路径” 输入 “待发送到服务器的文件路径”，成功发送文件到服务器当前所处目录下 ","date":"2021-08-16","objectID":"/posts/screen/:1:0","series":null,"tags":["screen"],"title":"screen 实现 lrzsz 文件上传下载","uri":"/posts/screen/#发送文件到服务器"},{"categories":["devops","command"],"content":" 从服务器接收文件 打开一个 Shell 执行 screen 命令，进入 screen 命令环境 按下 Ctrl+a 组合键，然后再输入 :zmodem catch 命令，设置 screen 命令环境捕获 ZMODEM 协议信号 在以上 screen 命令环境下与服务器建立 SSH 连接 执行 sz 文件路径命令，ZMODEM 协议信号被 screen 命令环境捕获，终端底部会出现可直接执行命令 命令执行后，服务器的文件被传输到本地，自动置于用户主目录下 ","date":"2021-08-16","objectID":"/posts/screen/:2:0","series":null,"tags":["screen"],"title":"screen 实现 lrzsz 文件上传下载","uri":"/posts/screen/#从服务器接收文件"},{"categories":["devops","command"],"content":" screen 配置文件可以通过在用户家目录下创建 .screenrc 配置文件，在文件中写入 zmodem catch 指令，这样就不用每次都要手动敲了 bash cat \u003e ~/.screenrc \u003c\u003cEOF zmodem catch EOF ","date":"2021-08-16","objectID":"/posts/screen/:3:0","series":null,"tags":["screen"],"title":"screen 实现 lrzsz 文件上传下载","uri":"/posts/screen/#screen-配置文件"},{"categories":["macOS"],"content":"当我们在安装 Mac 应用时，遇到提示 “ XXX.app 已损坏，打不开。您应该将它移到废纸篓 ” 或 “ 打不开 XXX.app，因为它来自身份不明的开发者 ” 可以使用以下方法解决 允许从陌生来源安装软件 bash sudo spctl --master-disable 重新打开应用查看是否可正常运行 如已经开启任何来源，但依旧打不开 macOS Sierra 10.12 及以上的用户可能会遇到, 使用以下命令, 然后重新打开 App bash sudo xattr -d com.apple.quarantine /Applications/xxxx.app 注意：/Applications/xxxx.app 换成你的 App 路径 ","date":"2021-08-12","objectID":"/posts/macos-app/:0:0","series":null,"tags":["macOS"],"title":"macOS 应用程序无法打开或文件损坏的处理方法","uri":"/posts/macos-app/#"},{"categories":["devops","command"],"content":" 配置网络配置接口 ip 地址 bash nmcli connection modify eth0 ipv4.method manual \\ ipv4.address \"172.16.1.100/24\" \\ ipv4.geateway \"172.168.1.2\" \\ ipv4.dns \"172.168.1.2\" 以上命令会修改网卡配置文件 /etc/sysocnfig/network-script/ifcfg-eth0，不会立即生效 重载接口配置 bash nmcli connection up eth0 创建网络连接 eth0-1 bash nmcli connection add type ethernet ifname eth0 con-name eth0-1 \\ ipv4.method manual \\ ipv4.addresses 172.16.100.100/24 \\ ipv4.gateway 172.16.100.1 \\ ipv4.dns 172.16.100.1 \\ autoconnect yes 以上命令会为 eth0 接口新增网卡配置文件, ifcfg-eth0-1 切换网络连接为 eth0-1 bash nmcli connection up eth0-1 可以为不同的环境创建不同的网络连接配置文件，使用 nmcli connection 切换 删除连接 bash nmcli connection delete eth0-1 ","date":"2021-08-11","objectID":"/posts/nmcli/:1:0","series":null,"tags":["nmcli"],"title":"使用 nmcli 配置网络","uri":"/posts/nmcli/#配置网络"},{"categories":["devops","command"],"content":" 查看网络查看所有接口状态 bash nmcli device status 查看 eth0 接口详细信息 bash nmcli device show eth0 停止 eth0 接口连接 bash nmcli connection down eth0 # or nmcli device disconnect eth0 启动 eth0 接口连接 bash nmcli connection up eth0 # or nmcli device connect eth0 ","date":"2021-08-11","objectID":"/posts/nmcli/:2:0","series":null,"tags":["nmcli"],"title":"使用 nmcli 配置网络","uri":"/posts/nmcli/#查看网络"},{"categories":["mongodb"],"content":" 环境准备这里使用3台虚拟机来部署 mongodb 分片集群; 各角色使用的 ip, 端口如下表 角色 端口 ip 地址 mongos 28017 172.16.1.100 config 27017 172.16.1.100 config 27018 172.16.1.100 config 27019 172.16.1.100 shard1 27017 172.16.1.101 shard1 27018 172.16.1.101 shard1 27019 172.16.1.101 shard2 27017 172.16.1.102 shard2 27018 172.16.1.102 shard2 27019 172.16.1.102 内部鉴权 节点间鉴权采用 keyfile 方式实现鉴权，mongos 与分片之间、副本集节点之间共享同一套 keyfile 文件 账户设置 管理员账户：admin/admin，具有集群及所有库的管理权限 应用账号：appuser/appuser，具有 appdb 的 owner 权限 关于初始化权限 keyfile 方式默认会开启鉴权，而针对初始化安装的场景，Mongodb 提供了 localhost-exception 机制，可以在首次安装时通过本机创建用户、角色，以及副本集初始化操作。 ","date":"2021-08-11","objectID":"/posts/mongodb-sharding/:1:0","series":null,"tags":["mongodb"],"title":"Mongodb 分片(sharding)集群部署","uri":"/posts/mongodb-sharding/#环境准备"},{"categories":["mongodb"],"content":" 部署集群","date":"2021-08-11","objectID":"/posts/mongodb-sharding/:2:0","series":null,"tags":["mongodb"],"title":"Mongodb 分片(sharding)集群部署","uri":"/posts/mongodb-sharding/#部署集群"},{"categories":["mongodb"],"content":" 准备工作下载 mongodb bash wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel62-3.6.20.tgz 安装 mongodb bash cd /usr/local/src tar xzf mongodb-linux-x86_64-rhel62-3.6.20.tgz -C /usr/local/ cd /usr/local/ ln -s /usr/local/mongodb-linux-x86_64-rhel62-3.6.20 /usr/local/mongodb # 加入环境变量 echo 'export PATH=/usr/local/mongodb/bin:$PATH' \u003e /etc/profile.d/mongo.sh source /etc/profile mongodb 配置所使用的相关路径如下 /data/mongodb/\u003c端口\u003e/etc : 配置文件目录 /data/mongodb/\u003c端口\u003e/data : 数据目录 /data/mongodb/\u003c端口\u003e/logs : 日志目录 /data/mongodb/mongod.key : keyfile 文件路径 mongos 路径 /data/mongos/\u003c端口\u003e/etc : 配置文件目录 /data/mongos/\u003c端口\u003e/logs : 日志目录 生成 keyfile, 所有实例都会用到 bash openssl rand -base64 756 \u003e mongo.key ","date":"2021-08-11","objectID":"/posts/mongodb-sharding/:2:1","series":null,"tags":["mongodb"],"title":"Mongodb 分片(sharding)集群部署","uri":"/posts/mongodb-sharding/#准备工作"},{"categories":["mongodb"],"content":" 部署分片复制集在以下服务器上进行操作，以 172.16.1.101 为例 172.16.1.101 172.16.1.102 在 172.16.1.102 上操作时注意修改相应参数 bash for port in {27017..27019}; do # 创建多实例目录 mkdir -p /data/mongodb/$port/etc mkdir -p /data/mongodb/$port/logs mkdir -p /data/mongodb/$port/data # chown -R mongod.mongod /data/mongodb/$port # 生成配置文件 cat \u003e /data/mongodb/$port/etc/mongod.conf \u003c\u003cEOF systemLog: destination: file path: /data/mongodb/$port/logs/mongodb.log logAppend: true storage: journal: enabled: true dbPath: /data/mongodb/$port/data directoryPerDB: true #engine: wiredTiger wiredTiger: engineConfig: cacheSizeGB: 1 directoryForIndexes: true collectionConfig: blockCompressor: zlib indexConfig: prefixCompression: true processManagement: fork: true net: bindIp: 127.0.0.1,172.16.1.101 port: $port security: keyFile: /data/mongodb/mongod.key replication: oplogSizeMB: 2048 # 同一个分片复制集名称保持一致，不同分片名称必须不同 replSetName: sh1 # 启用分片 sharding: clusterRole: shardsvr EOF echo \"start mongodb $port instance\" echo \"/usr/local/mongodb/bin/mongod -f /data/mongodb/$port/etc/mongod.conf\" done cat \u003e/data/mongodb/mongod.key\u003c\u003cEOF ry2cCv+u8AuoVsKmQqmwOXeP2nfH+CG+VD9dMpUUHcggztWQ09VDyXJTXhGgBnYu a9UH3jvfbmT7mqRV2esOxSnTazcY5mXjyMCMzgaSvpN8OtfuDZXX20v5qpYCqjCj xlLyyDkeFhOeTqWJcQKvwhZnh0SXC65QwGxeEL8DRnLXziBAooR4EYkRGgZnGvmP 23KRhagRgQ7iwivwiXoepf+PwtZ3DKi2wudUTcojvFPa+ls5rhXSnEGChMPlL8zV b+xGDdOe4YDOiDoAATYLRkDUfUpG8DF921azQ4WH1g7BJU/zY2CpAX8nd4lhBA7o 6YD51kR6odBGUGGarZOvk7tW4DY+sWSK5pbc7nttFICUcw87K1R9Hxe1wEVNqo/m xcQ0vtgJ7IvHRwIbvYxmEoEfnBzqOkfZLXKgE/tgEvphdoiUCCyJ89JrkN3W8o2Q yb1RuvEOPE+8MjyE1vKkwuwnn95ePle8AJ8+fb3W5p5n2lNpBYrbe2CfWjRVMqri bnnb93DsG5Qd4U+QYJ/ZSnAofPdSLRxQn54MLIPHRuPlpJuCQXeB0bnQeGbTMjaO 2aaB+kOpwfWMcQBqvdErdQqeFgITFEGTG1sa92Nc+9zO07R6FQ7qveKTOMoH1hLB chfBPAt5pck50h3DtGMZgmhCzR2606VOVgiOw4s4UQoG28fvA9Fhj/xA2qIFcloz Yz9urc0bFMoOQOVPCmClFbUTbG+Jp1O1yc0RbXyBvecPs4BQNdSd+K1KE5BcWGsy RkgmsNUEaPMIqiT7SVYxny59UmegW1uiict3orJtOEAuRlEDAWn6E0E6FYWoy9Qk CYk+X7kB1CF15/KYGCsADxPf5YZy1UpWjiJtWYozKGwH/Ri1dLs3CMUxbNPArcBV THh3GHz4gE31/cZpRSux3LN/uLOEyCQvwHmdwngDantN52Ma/KwQBcbqBGeoTUq3 4VhBTVzaOng/F1t+XAZtrXB0XM6MsztAvYP2Brpw/54DSBTM EOF chmod 600 /data/mongodb/mongod.key 注意：keyfile 的权限必须为 600 启动 mongodb 服务 bash /usr/local/mongodb/bin/mongod -f /data/mongodb/27017/etc/mongod.conf /usr/local/mongodb/bin/mongod -f /data/mongodb/27018/etc/mongod.conf /usr/local/mongodb/bin/mongod -f /data/mongodb/27019/etc/mongod.conf 初始化集群 bash $ mongo --port 27017 admin ## 定义初始化信息 \u003e config = {_id: 'sh1', members: [ {_id: 0, host: '172.16.1.101:27017'}, {_id: 1, host: '172.16.1.101:27018'}, {_id: 2, host: '172.16.1.101:27019'}] } ## 初始化复制集 \u003e rs.initiate(config) ","date":"2021-08-11","objectID":"/posts/mongodb-sharding/:2:2","series":null,"tags":["mongodb"],"title":"Mongodb 分片(sharding)集群部署","uri":"/posts/mongodb-sharding/#部署分片复制集"},{"categories":["mongodb"],"content":" 部署配置集群在 172.16.1.100 服务器上操作 bash for port in {27017..27019}; do # 创建多实例目录 mkdir -p /data/mongodb/$port/etc mkdir -p /data/mongodb/$port/logs mkdir -p /data/mongodb/$port/data chown -R mongod.mongod /data/mongodb/$port # 生成配置文件 cat \u003e /data/mongodb/$port/etc/mongod.conf \u003c\u003cEOF systemLog: destination: file path: /data/mongodb/$port/logs/mongodb.log logAppend: true storage: journal: enabled: true dbPath: /data/mongodb/$port/data directoryPerDB: true #engine: wiredTiger wiredTiger: engineConfig: cacheSizeGB: 1 directoryForIndexes: true collectionConfig: blockCompressor: zlib indexConfig: prefixCompression: true processManagement: fork: true net: bindIp: 127.0.0.1,172.16.1.100 port: $port security: keyFile: /data/mongodb/mongod.key replication: oplogSizeMB: 2048 replSetName: configReplSet # 分片配置服务器 sharding: clusterRole: configsvr EOF echo \"start mongodb $port instance\" echo \"/usr/local/mongodb/bin/mongod -f /data/mongodb/$port/etc/mongod.conf\" done cat \u003e/data/mongodb/mongod.key\u003c\u003cEOF ry2cCv+u8AuoVsKmQqmwOXeP2nfH+CG+VD9dMpUUHcggztWQ09VDyXJTXhGgBnYu a9UH3jvfbmT7mqRV2esOxSnTazcY5mXjyMCMzgaSvpN8OtfuDZXX20v5qpYCqjCj xlLyyDkeFhOeTqWJcQKvwhZnh0SXC65QwGxeEL8DRnLXziBAooR4EYkRGgZnGvmP 23KRhagRgQ7iwivwiXoepf+PwtZ3DKi2wudUTcojvFPa+ls5rhXSnEGChMPlL8zV b+xGDdOe4YDOiDoAATYLRkDUfUpG8DF921azQ4WH1g7BJU/zY2CpAX8nd4lhBA7o 6YD51kR6odBGUGGarZOvk7tW4DY+sWSK5pbc7nttFICUcw87K1R9Hxe1wEVNqo/m xcQ0vtgJ7IvHRwIbvYxmEoEfnBzqOkfZLXKgE/tgEvphdoiUCCyJ89JrkN3W8o2Q yb1RuvEOPE+8MjyE1vKkwuwnn95ePle8AJ8+fb3W5p5n2lNpBYrbe2CfWjRVMqri bnnb93DsG5Qd4U+QYJ/ZSnAofPdSLRxQn54MLIPHRuPlpJuCQXeB0bnQeGbTMjaO 2aaB+kOpwfWMcQBqvdErdQqeFgITFEGTG1sa92Nc+9zO07R6FQ7qveKTOMoH1hLB chfBPAt5pck50h3DtGMZgmhCzR2606VOVgiOw4s4UQoG28fvA9Fhj/xA2qIFcloz Yz9urc0bFMoOQOVPCmClFbUTbG+Jp1O1yc0RbXyBvecPs4BQNdSd+K1KE5BcWGsy RkgmsNUEaPMIqiT7SVYxny59UmegW1uiict3orJtOEAuRlEDAWn6E0E6FYWoy9Qk CYk+X7kB1CF15/KYGCsADxPf5YZy1UpWjiJtWYozKGwH/Ri1dLs3CMUxbNPArcBV THh3GHz4gE31/cZpRSux3LN/uLOEyCQvwHmdwngDantN52Ma/KwQBcbqBGeoTUq3 4VhBTVzaOng/F1t+XAZtrXB0XM6MsztAvYP2Brpw/54DSBTM EOF chmod 0600 /data/mongodb/mongod.key 注意：keyfile 的权限必须为 600 启动 mongodb 服务 bash /usr/local/mongodb/bin/mongod -f /data/mongodb/27017/etc/mongod.conf /usr/local/mongodb/bin/mongod -f /data/mongodb/27018/etc/mongod.conf /usr/local/mongodb/bin/mongod -f /data/mongodb/27019/etc/mongod.conf 初始化集群 bash $ mongo --port 27017 admin ## 定义初始化信息 \u003e config = {_id: 'configReplSet', members: [ {_id: 0, host: '172.16.1.100:27017'}, {_id: 1, host: '172.16.1.100:27018'}, {_id: 2, host: '172.16.1.100:27019'}] } ## 初始化复制集 \u003e rs.initiate(config) ","date":"2021-08-11","objectID":"/posts/mongodb-sharding/:2:3","series":null,"tags":["mongodb"],"title":"Mongodb 分片(sharding)集群部署","uri":"/posts/mongodb-sharding/#部署配置集群"},{"categories":["mongodb"],"content":" 部署 mongos在 172.16.1.100 服务器上操作 bash mkdir -p /data/mongos/{etc,logs} cat \u003e /data/mongos/etc/mongos.conf \u003c\u003cEOF systemLog: destination: file path: /data/mongos/logs/mongos.log logAppend: true net: bindIp: 127.0.0.1,172.16.1.100 port: 28017 security: keyFile: /data/mongodb/mongod.key sharding: configDB: configReplSet/172.16.1.100:27017,172.16.1.100:27018,172.16.1.100:27019 processManagement: fork: true EOF 启动 mongos 服务 bash /usr/local/mongodb/bin/mongos -f /data/mongos/etc/mongos.conf ","date":"2021-08-11","objectID":"/posts/mongodb-sharding/:2:4","series":null,"tags":["mongodb"],"title":"Mongodb 分片(sharding)集群部署","uri":"/posts/mongodb-sharding/#部署-mongos"},{"categories":["mongodb"],"content":" 添加分片服务器通过 mongos 操作, 连接至 mongos 服务器 bash mongo --port 28017 添加分片集群 bash mongos\u003e sh.addShard(\"sh1/172.16.1.101:27017\") mongos\u003e sh.addShard(\"sh2/172.16.1.102:27017\") ","date":"2021-08-11","objectID":"/posts/mongodb-sharding/:3:0","series":null,"tags":["mongodb"],"title":"Mongodb 分片(sharding)集群部署","uri":"/posts/mongodb-sharding/#添加分片服务器"},{"categories":["mongodb"],"content":" 初始化管理用户创建集群管理员账号, 连接至 mongos 输入以下命令 bash use admin db.createUser({ user:'admin', pwd:'admin', roles:[ {role:'clusterAdmin',db:'admin'}, {role:'userAdminAnyDatabase',db:'admin'}, {role:'dbAdminAnyDatabase',db:'admin'}, {role:'readWriteAnyDatabase',db:'admin'} ]}) 检查集群状态命令需要身份验证通过才能执行 bash mongos\u003e sh.status() --- Sharding Status --- sharding version: { \"_id\" : 1, \"minCompatibleVersion\" : 5, \"currentVersion\" : 6, \"clusterId\" : ObjectId(\"611342dcd920275eccff657f\") } shards: { \"_id\" : \"sh1\", \"host\" : \"sh1/172.16.1.101:27017,172.16.1.101:27018,172.16.1.101:27019\", \"state\" : 1 } { \"_id\" : \"sh2\", \"host\" : \"sh2/172.16.1.102:27017,172.16.1.102:27018,172.16.1.102:27019\", \"state\" : 1 } active mongoses: \"3.6.20\" : 1 autosplit: Currently enabled: yes balancer: Currently enabled: yes Currently running: no Failed balancer rounds in last 5 attempts: 0 Migration Results for the last 24 hours: No recent migrations databases: { \"_id\" : \"config\", \"primary\" : \"config\", \"partitioned\" : true } config.system.sessions shard key: { \"_id\" : 1 } unique: false balancing: true chunks: sh1 1 { \"_id\" : { \"$minKey\" : 1 } } --\u003e\u003e { \"_id\" : { \"$maxKey\" : 1 } } on : sh1 Timestamp(1, 0) 关于集群用户与复制集本地用户说明 分片集群中的访问都会通过 mongos 入口，而鉴权数据是存储在 config 副本集中的，即 config 实例中 admin.system.users 数据库存储了集群用户及角色权限配置。 mongos 与 shard 实例则通过内部鉴权 (keyfile 机制) 完成，因此 shard 实例上可以通过添加本地用户以方便操作管理。在一个副本集上，只需要在 Primary 节点上添加用户及权限，相关数据会自动同步到 Secondary 节点 为 sh1/sh2 复制集创建本地管理用户 js use admin db.createUser({user:'root',pwd:'root123',roles:[{role:'root',db:'admin'}]}) ","date":"2021-08-11","objectID":"/posts/mongodb-sharding/:4:0","series":null,"tags":["mongodb"],"title":"Mongodb 分片(sharding)集群部署","uri":"/posts/mongodb-sharding/#初始化管理用户"},{"categories":["mongodb"],"content":" 使用分片集群创建 appuser 用户、为数据库 appdb 启动分片。 bash mongos\u003e use appdb switched to db appdb mongos\u003e db.createUser({user:'appuser',pwd:'appuser',roles:[{role:'dbOwner',db:'appdb'}]}) Successfully added user: { \"user\" : \"appuser\", \"roles\" : [ { \"role\" : \"dbOwner\", \"db\" : \"appdb\" } ] } # 启动分片 mongos\u003e sh.enableSharding(\"appdb\") { \"ok\" : 1, \"operationTime\" : Timestamp(1628653967, 8), \"$clusterTime\" : { \"clusterTime\" : Timestamp(1628653967, 8), \"signature\" : { \"hash\" : BinData(0,\"i1anstgDj52hxkVuk35ovKp4rB0=\"), \"keyId\" : NumberLong(\"6995008158896750620\") } } } 创建集合 book，为其执行分片初始化 bash # 创建 book 集合 mongos\u003e db.createCollection(\"book\") { \"ok\" : 1, \"operationTime\" : Timestamp(1628654035, 2), \"$clusterTime\" : { \"clusterTime\" : Timestamp(1628654035, 2), \"signature\" : { \"hash\" : BinData(0,\"xaHyTUdZgqesb5vp1uwGdD9hhzU=\"), \"keyId\" : NumberLong(\"6995008158896750620\") } } } # 创建索引 mongos\u003e db.book.ensureIndex( { id: 1 } ) { \"raw\" : { \"sh2/172.16.1.102:27017,172.16.1.102:27018,172.16.1.102:27019\" : { \"createdCollectionAutomatically\" : false, \"numIndexesBefore\" : 1, \"numIndexesAfter\" : 2, \"ok\" : 1 } }, \"ok\" : 1, \"operationTime\" : Timestamp(1628654068, 1), \"$clusterTime\" : { \"clusterTime\" : Timestamp(1628654068, 1), \"signature\" : { \"hash\" : BinData(0,\"WgBJJi1ToTcvLrnkV/tl3TU3uWg=\"), \"keyId\" : NumberLong(\"6995008158896750620\") } } } # 开启分片 mongos\u003e sh.shardCollection(\"appdb.book\", {id: \"hashed\"}) { \"collectionsharded\" : \"appdb.book\", \"collectionUUID\" : UUID(\"62617c67-1c9b-453d-8505-4622190fc738\"), \"ok\" : 1, \"operationTime\" : Timestamp(1628654268, 55), \"$clusterTime\" : { \"clusterTime\" : Timestamp(1628654268, 55), \"signature\" : { \"hash\" : BinData(0,\"FScHlkPUhSWN3k7a0RaXRYtBkR4=\"), \"keyId\" : NumberLong(\"6995008158896750620\") } } } 往 book 集合写入 1000W 条记录，观察 chunks 的分布情况 js use appdb var cnt = 0; for(var i=0; i\u003c1000; i++){ var dl = []; for(var j=0; j\u003c100; j++){ dl.push({ \"id\" : \"BBK-\" + i + \"-\" + j, \"type\" : \"Revision\", \"version\" : \"IricSoneVB0001\", \"title\" : \"Jackson's Life\", \"subCount\" : 10, \"location\" : \"China CN Shenzhen Futian District\", \"author\" : { \"name\" : 50, \"email\" : \"RichardFoo@yahoo.com\", \"gender\" : \"female\" }, \"createTime\" : new Date() }); } cnt += dl.length; db.book.insertMany(dl); print(\"insert \", cnt); } 查看 chunks 的分布情况 bash mongos\u003e db.book.getShardDistribution() Shard sh1 at sh1/172.16.1.101:27017,172.16.1.101:27018,172.16.1.101:27019 data : 13.22MiB docs : 49905 chunks : 2 estimated data per chunk : 6.61MiB estimated docs per chunk : 24952 Shard sh2 at sh2/172.16.1.102:27017,172.16.1.102:27018,172.16.1.102:27019 data : 13.27MiB docs : 50095 chunks : 2 estimated data per chunk : 6.63MiB estimated docs per chunk : 25047 Totals data : 26.49MiB docs : 100000 chunks : 4 Shard sh1 contains 49.9% data, 49.9% docs in cluster, avg obj size on shard : 277B Shard sh2 contains 50.09% data, 50.09% docs in cluster, avg obj size on shard : 277B 连接 sh1/sh2 查看 (需要创建本地管理用户账号) sh1 bash sh2:PRIMARY\u003e use admin sh1:PRIMARY\u003e db.auth('root', 'root123') 1 sh1:PRIMARY\u003e use appdb switched to db appdb sh1:PRIMARY\u003e db.book.count() 49905 sh2 bash sh2:PRIMARY\u003e use admin sh2:PRIMARY\u003e db.auth('root', 'root123') 1 sh2:PRIMARY\u003e use appdb switched to db appdb sh2:PRIMARY\u003e db.book.count() 50095 ","date":"2021-08-11","objectID":"/posts/mongodb-sharding/:5:0","series":null,"tags":["mongodb"],"title":"Mongodb 分片(sharding)集群部署","uri":"/posts/mongodb-sharding/#使用分片集群"},{"categories":["mongodb"],"content":" 分片集群的查询及管理判断是否 Shard 集群 bash mongos\u003e use admin mongos\u003e db.runCommand({ isdbgrid : 1}) 列出所有分片信息 bash mongos\u003e use admin mongos\u003e db.runCommand({ listshards : 1}) 列出开启分片的数据库 bash mongos\u003e use config mongos\u003e db.databases.find( { \"partitioned\": true } ) # 或者： mongos\u003e db.databases.find() //列出所有数据库分片情况 查看分片的片键 bash mongos\u003e use config mongos\u003e db.collections.find().pretty() { \"_id\" : \"config.system.sessions\", \"lastmodEpoch\" : ObjectId(\"611343e1d920275eccff6b43\"), \"lastmod\" : ISODate(\"1970-02-19T17:02:47.296Z\"), \"dropped\" : false, \"key\" : { \"_id\" : 1 }, \"unique\" : false, \"uuid\" : UUID(\"1ec5dcd3-bb66-46fb-9a21-8dbb7006a43c\") } { \"_id\" : \"appdb.book\", \"lastmodEpoch\" : ObjectId(\"61134abcd920275eccff9665\"), \"lastmod\" : ISODate(\"1970-02-19T17:02:47.297Z\"), \"dropped\" : false, \"key\" : { \"id\" : \"hashed\" }, \"unique\" : false, \"uuid\" : UUID(\"62617c67-1c9b-453d-8505-4622190fc738\") } 查看分片的详细信息 bash mongos\u003e sh.status() 删除分片节点（谨慎） bash # 确认 blance 是否在工作 sh.getBalancerState() # 删除 sh2 节点(谨慎) mongos\u003e db.runCommand( { removeShard: \"sh2\" } ) 注意：删除操作一定会立即触发 blancer ","date":"2021-08-11","objectID":"/posts/mongodb-sharding/:6:0","series":null,"tags":["mongodb"],"title":"Mongodb 分片(sharding)集群部署","uri":"/posts/mongodb-sharding/#分片集群的查询及管理"},{"categories":["mongodb"],"content":" balancer 操作mongos 的一个重要功能，自动巡查所有 shard 节点上的 chunk 的情况，自动做 chunk 迁移。 什么时候工作？ 自动运行，会检测系统不繁忙的时候做迁移 在做节点删除的时候，立即开始迁移工作 balancer 只能在预设定的时间窗口内运行 有需要时可以关闭和开启 blancer（备份的时候） bash mongos\u003e sh.stopBalancer() mongos\u003e sh.startBalancer() 自定义 blancer 自动平衡进行的时间段 - 官方文档 js use config sh.setBalancerState( true ) db.settings.update( { _id : \"balancer\" }, { $set : { activeWindow : { start : \"3:00\", stop : \"5:00\" } } }, { upsert: true } ) sh.getBalancerWindow() sh.status() 关闭 appdb.book 集合的 balance js sh.disableBalancing(\"appdb.book\") 打开 appdb.book 集合的 balancer js sh.enableBalancing(\"appdb.book\") 确定 appdb.book 集合的 balance 是开启或者关闭 js db.getSiblingDB(\"config\").collections.findOne({_id : \"appdb.book\"}).noBalance ","date":"2021-08-11","objectID":"/posts/mongodb-sharding/:7:0","series":null,"tags":["mongodb"],"title":"Mongodb 分片(sharding)集群部署","uri":"/posts/mongodb-sharding/#balancer-操作"},{"categories":["devops","zabbix"],"content":"由于 zabbix 自身并不支持告警分组及收敛功能，经常会出现告警信息轰炸的情况，为了解决这个情况可以使用 Alertmanager 来管理 zabbix 的告警消息 ","date":"2021-07-28","objectID":"/posts/zabbix-alertmanager/:0:0","series":null,"tags":["zabbix"],"title":"使用 Alertmanager 管理 zabbix 告警消息","uri":"/posts/zabbix-alertmanager/#"},{"categories":["devops","zabbix"],"content":" Alertmanager","date":"2021-07-28","objectID":"/posts/zabbix-alertmanager/:1:0","series":null,"tags":["zabbix"],"title":"使用 Alertmanager 管理 zabbix 告警消息","uri":"/posts/zabbix-alertmanager/#alertmanager"},{"categories":["devops","zabbix"],"content":" 特性Alertmanager 除了提供基本的告警通知能力以外，还主要提供了如：分组、抑制以及静默等告警特性： ","date":"2021-07-28","objectID":"/posts/zabbix-alertmanager/:1:1","series":null,"tags":["zabbix"],"title":"使用 Alertmanager 管理 zabbix 告警消息","uri":"/posts/zabbix-alertmanager/#特性"},{"categories":["devops","zabbix"],"content":" 分组分组机制可以将详细的告警信息合并成一个通知。在某些情况下，比如由于系统宕机导致大量的告警被同时触发，在这种情况下分组机制可以将这些被触发的告警合并为一个告警通知，避免一次性接受大量的告警通知，而无法对问题进行快速定位。 例如，当集群中有数百个正在运行的服务实例，并且为每一个实例设置了告警规则。假如此时发生了网络故障，可能导致大量的服务实例无法连接到数据库，结果就会有数百个告警被发送到 Alertmanager。 而作为用户，可能只希望能够在一个通知中中就能查看哪些服务实例收到影响。这时可以按照服务所在集群或者告警名称对告警进行分组，而将这些告警内聚在一起成为一个通知。 告警分组，告警时间，以及告警的接受方式可以通过 Alertmanager 的配置文件进行配置。 ","date":"2021-07-28","objectID":"/posts/zabbix-alertmanager/:1:2","series":null,"tags":["zabbix"],"title":"使用 Alertmanager 管理 zabbix 告警消息","uri":"/posts/zabbix-alertmanager/#分组"},{"categories":["devops","zabbix"],"content":" 抑制抑制是指当某一告警发出后，可以停止重复发送由此告警引发的其它告警的机制。 例如，当集群不可访问时触发了一次告警，通过配置 Alertmanager 可以忽略与该集群有关的其它所有告警。这样可以避免接收到大量与实际问题无关的告警通知。 抑制机制同样通过 Alertmanager 的配置文件进行设置。 ","date":"2021-07-28","objectID":"/posts/zabbix-alertmanager/:1:3","series":null,"tags":["zabbix"],"title":"使用 Alertmanager 管理 zabbix 告警消息","uri":"/posts/zabbix-alertmanager/#抑制"},{"categories":["devops","zabbix"],"content":" 静默静默提供了一个简单的机制可以快速根据标签对告警进行静默处理。如果接收到的告警符合静默的配置，Alertmanager 则不会发送告警通知。 静默设置需要在 Alertmanager 的 Web 页面上进行设置。 参考: https://yunlzheng.gitbook.io/prometheus-book/parti-prometheus-ji-chu/alert/prometheus-alert-manager-overview ","date":"2021-07-28","objectID":"/posts/zabbix-alertmanager/:1:4","series":null,"tags":["zabbix"],"title":"使用 Alertmanager 管理 zabbix 告警消息","uri":"/posts/zabbix-alertmanager/#静默"},{"categories":["devops","zabbix"],"content":" 客户端接口 官方文档: https://prometheus.io/docs/alerting/latest/clients/ Alertmanager 现在有两个版本的 api 接口可用(v1/v2), 这里使用 v2 版 api, 接口接收数据结构如下: json [ { \"labels\": { \"alertname\": \"\u003crequiredAlertName\u003e\", \"\u003clabelname\u003e\": \"\u003clabelvalue\u003e\", ... }, \"annotations\": { \"\u003clabelname\u003e\": \"\u003clabelvalue\u003e\", }, \"startsAt\": \"\u003crfc3339\u003e\", \"endsAt\": \"\u003crfc3339\u003e\", \"generatorURL\": \"\u003cgenerator_url\u003e\" }, ... ] labels: 告警的标签，可以自定标签，Alertmanager 通过标签来识别的告警信息 annotations: 告警消息标签集合 startsAt: 告警开始时间，格式为 rfc3339 endsAt: 告警恢复时间，格式为 rfc3339 注意: Alertmanager 默认时区 UTC ","date":"2021-07-28","objectID":"/posts/zabbix-alertmanager/:1:5","series":null,"tags":["zabbix"],"title":"使用 Alertmanager 管理 zabbix 告警消息","uri":"/posts/zabbix-alertmanager/#客户端接口"},{"categories":["devops","zabbix"],"content":" 配置 Zabbix 告警","date":"2021-07-28","objectID":"/posts/zabbix-alertmanager/:2:0","series":null,"tags":["zabbix"],"title":"使用 Alertmanager 管理 zabbix 告警消息","uri":"/posts/zabbix-alertmanager/#配置-zabbix-告警"},{"categories":["devops","zabbix"],"content":" 配置报警脚本登录 Zabbix Web 页面，点击 “管理 -\u003e 报警媒介类型 -\u003e 创建媒体类型” 名称: Alertmanager 类型: 脚本 脚本名称: to_alertmanager.py （脚本后面步骤中会提供） 脚本参数: {ALERT.MESSAGE} 配置报警脚本 ","date":"2021-07-28","objectID":"/posts/zabbix-alertmanager/:2:1","series":null,"tags":["zabbix"],"title":"使用 Alertmanager 管理 zabbix 告警消息","uri":"/posts/zabbix-alertmanager/#配置报警脚本"},{"categories":["devops","zabbix"],"content":" 配置用户报警媒介点击 “管理 -\u003e 用户 -\u003e Admin -\u003e 报警媒介 -\u003e 添加” 类型: Alertmanager 收件人: 随意，不起作用 配置用户报警媒介 ","date":"2021-07-28","objectID":"/posts/zabbix-alertmanager/:2:2","series":null,"tags":["zabbix"],"title":"使用 Alertmanager 管理 zabbix 告警消息","uri":"/posts/zabbix-alertmanager/#配置用户报警媒介"},{"categories":["devops","zabbix"],"content":" 配置动作点击 “配置 -\u003e 动作 -\u003e 事件源（触发器）-\u003e 创建动作” 名称: Alertmanager 默认信息: 告警消息内容，这里配置为 json 格式数据，也就是发送脚本的第一个参数 ({ALERT.MESSAGE}) json { \"labels\": { \"alertname\": \"{ITEM.NAME}\", \"instance\": \"{HOST.NAME}({HOST.IP})\", \"severity\": \"{TRIGGER.SEVERITY}\" }, \"annotations\": { \"info\": \"{TRIGGER.NAME} - {ITEM.NAME}:{ITEM.VALUE}\" }, \"failure_time\": \"{EVENT.DATE} {EVENT.TIME}\", \"status\": \"{TRIGGER.STATUS}\" } 勾选恢复信息 恢复信息: 告警恢复时的消息内容，这里配置也为 json 格式数据，也就是发送脚本的第一个参数 ({ALERT.MESSAGE}) json { \"labels\": { \"alertname\": \"{ITEM.NAME}\", \"instance\": \"{HOST.NAME}({HOST.IP})\", \"severity\": \"{TRIGGER.SEVERITY}\" }, \"annotations\": { \"info\": \"{TRIGGER.NAME} - {ITEM.NAME}:{ITEM.VALUE}\" }, \"failure_time\": \"{EVENT.DATE} {EVENT.TIME}\", \"recovery_time\": \"{EVENT.RECOVERY.DATE} {EVENT.RECOVERY.TIME}\", \"status\": \"{TRIGGER.STATUS}\" } 配置动作 点击，操作选项 -\u003e 添加新的动作操作 发送到用户: Admin 仅送到用户: Alertmanager 配置动作 点击添加操作， 点击添加完成动作的配置操作 ","date":"2021-07-28","objectID":"/posts/zabbix-alertmanager/:2:3","series":null,"tags":["zabbix"],"title":"使用 Alertmanager 管理 zabbix 告警消息","uri":"/posts/zabbix-alertmanager/#配置动作"},{"categories":["devops","zabbix"],"content":" 配置 Zabbix Server编辑 zabbix_server.conf 配置文件添加以下配置项 text AlertScriptsPath=/usr/local/zabbix/scripts 创建目录 /usr/local/zabbix/scripts bash mkdir /usr/local/zabbix/scripts 放入告警脚本 to_alertmanage.py 并加上执行权限 chmod +x to_alertmanage.py python #!/usr/bin/env python3 # -*- coding: utf-8 -*- import sys import json from http.client import HTTPConnection from urllib.parse import urlsplit from datetime import datetime, timedelta url = \"http://127.0.0.1:9093\" api_url = f\"{url}/api/v2/alerts\" headers = {\"Content-Type\": \"application/json\"} def to_rfc_3339(dt, flag=False): \"\"\"以 rfc-3339 标准格式化时间 AlertManager 接口只接受 rfc-3339 标准的时间 \"\"\" _d, _t = dt.split() y, m, d = (int(i) for i in _d.split('.')) H, M, S = (int(i) for i in _t.split(':')) t = datetime(y, m, d, H, M, S) if flag: new = t + timedelta(days=2) else: new = t return new.isoformat() + \"+08:00\" def post(url, data, headers): u = urlsplit(url) if not isinstance(data, str): data = json.dumps(data) conn = HTTPConnection(u.netloc) conn.request('POST', u.path, data, headers) response = conn.getresponse() text = response.read().decode() print(text) def main(msg): try: msg = json.loads(msg) except Exception as e: with open('/tmp/alert.txt', 'a') as f: f.write(f\"{datetime.now().isoformat(' ')} {str(e)}\\n\") alert_msg = {} if msg['status'] == \"OK\": # alert_msg['startsAt'] = to_rfc_3339(msg['failure_time']) alert_msg['endsAt'] = to_rfc_3339(msg['recovery_time']) else: alert_msg['startsAt'] = to_rfc_3339(msg['failure_time']) alert_msg['endsAt'] = to_rfc_3339(msg['failure_time'], True) alert_msg['labels'] = msg['labels'] alert_msg['annotations'] = msg['annotations'] # with open('/tmp/alert.txt','a') as f: # f.write(json.dumps(alert_msg, indent=4)) post(api_url, [alert_msg], headers) if __name__ == \"__main__\": main(sys.argv[1]) 脚本需要使用 Python3.5 及以上版本，如系统没有安装请执行 yum install -y python3 重启 Zabbix 服务 bash systemctl restart zabbix-server ","date":"2021-07-28","objectID":"/posts/zabbix-alertmanager/:2:4","series":null,"tags":["zabbix"],"title":"使用 Alertmanager 管理 zabbix 告警消息","uri":"/posts/zabbix-alertmanager/#配置-zabbix-server"},{"categories":["devops","zabbix"],"content":" 部署 Alertmanager","date":"2021-07-28","objectID":"/posts/zabbix-alertmanager/:3:0","series":null,"tags":["zabbix"],"title":"使用 Alertmanager 管理 zabbix 告警消息","uri":"/posts/zabbix-alertmanager/#部署-alertmanager"},{"categories":["devops","zabbix"],"content":" 安装 AlertmanagerAlertmanager 安装在和 Zabbix Server 同一台机上，如有空闲机器也可以单独部署 bash cd /usr/local/src wget https://github.com/prometheus/alertmanager/releases/download/v0.22.2/alertmanager-0.22.2.linux-amd64.tar.gz tar xf alertmanager-0.22.2.linux-amd64.tar.gz -C ../ ln -s /usr/local/alertmanager-0.22.2.linux-amd64 /usr/local/alertmanager cat \u003e /usr/lib/systemd/system/alertmanager.service \u003c\u003cEOF [Unit] Description=Prometheus Alertmanager Documentation=https://prometheus.io After=network.target [Service] Type=simple WorkingDirectory=/usr/local/alertmanager ExecStart=/usr/local/alertmanager/alertmanager --config.file=alertmanager.yml Restart=on-failure [Install] WantedBy=multi-user.target EOF systemctl enable --now alertmanager ","date":"2021-07-28","objectID":"/posts/zabbix-alertmanager/:3:1","series":null,"tags":["zabbix"],"title":"使用 Alertmanager 管理 zabbix 告警消息","uri":"/posts/zabbix-alertmanager/#安装-alertmanager"},{"categories":["devops","zabbix"],"content":" 配置 Alertmanager编辑 alertmanager.yml 示例如下 yaml global: resolve_timeout: 5m wechat_api_url: https://qyapi.weixin.qq.com/cgi-bin/ wechat_api_secret: \u003c企业微信应用密钥\u003e wechat_api_corp_id: \u003c企业微信 ID\u003e # 告警消息模板 templates: - /usr/local/alertmanager/templates/*.tmpl # 告警路由规则 route: group_by: ['alertname'] group_wait: 30s group_interval: 5m repeat_interval: 1h receiver: 'wechat-default' # 默认告警消息接收器，通过 receivers 定义 routes: # 定义路由规则，没有时发送至默认接收器（这里为 wechat-default） - receiver: wechat-info # 定义消息接受者 match: severity: info # 消息匹配规则, 如果告警级别为 info 消息就会发送到 wechat-ops # 接受器配置 # 企业微信相关配置参考: https://prometheus.io/docs/alerting/latest/configuration/#wechat_config receivers: - name: wechat-default wechat_configs: # 企业微信配置 - send_resolved: true # 是否接收恢复消息，默认为 false message_type: text # 消息类型 agent_id: 1000002 # 企业微信应用 ID to_user: LiWanggui # 消息接收人 - name: wechat-info wechat_configs: - send_resolved: true message_type: text agent_id: 1000002 to_user: WangXiaoer # 消息抑制配置项 inhibit_rules: - source_match: severity: 'critical' target_match: severity: 'warning' equal: ['alertname', 'dev', 'instance'] 配置企业微信消息模板 templates/wechat-alert.tmpl text {{ define \"wechat.default.message\" }} {{- if gt (len .Alerts.Firing) 0 -}} {{/* 从 .Alerts.Firing 中取数据可以防止发送恢复通知时数据重复 */}} {{- range $index, $alert := .Alerts.Firing -}} {{- if eq $index 0 -}} **********告警通知********** 告警类型: {{ $alert.Labels.alertname }} 告警级别: {{ $alert.Labels.severity }} {{- end }} ===================== 告警详情: {{ $alert.Annotations.info }} 故障时间: {{ $alert.StartsAt.Local.Format \"2006-01-02 15:04:05\" }} {{ if gt (len $alert.Labels.instance) 0 -}}故障实例: {{ $alert.Labels.instance }}{{- end -}} {{- end }} {{- end }} {{- if gt (len .Alerts.Resolved) 0 -}} {{- range $index, $alert := .Alerts.Resolved -}} {{- if eq $index 0 -}} **********恢复通知********** 告警类型: {{ $alert.Labels.alertname }} 告警级别: {{ $alert.Labels.severity }} {{- end }} ===================== 告警详情: {{ $alert.Annotations.info }} 故障时间: {{ $alert.StartsAt.Local.Format \"2006-01-02 15:04:05\" }} 恢复时间: {{ $alert.EndsAt.Local.Format \"2006-01-02 15:04:05\" }} {{ if gt (len $alert.Labels.instance) 0 -}}故障实例: {{ $alert.Labels.instance }}{{- end -}} {{- end }} {{- end }} {{- end }} 重载 AlertManage 配置 bash curl -iX POST http://localhost:9093/-/reload ","date":"2021-07-28","objectID":"/posts/zabbix-alertmanager/:3:2","series":null,"tags":["zabbix"],"title":"使用 Alertmanager 管理 zabbix 告警消息","uri":"/posts/zabbix-alertmanager/#配置-alertmanager"},{"categories":["devops","zabbix"],"content":" 接收告警信息Zabbix 服务现在可以通过 to_alertmanage.py 将告警消息推送至 Alertmanager，由 Alertmanager 对告警消息进行管理(分组，抑制，静默)和发送至企业微信。 可以找一台机子通过禁 ping 和恢复 ping 进行测试 bash # 禁 ping echo 1 \u003e /proc/sys/net/ipv4/icmp_echo_ignore_all # 恢复 ping echo 0 \u003e /proc/sys/net/ipv4/icmp_echo_ignore_all 告警消息 ","date":"2021-07-28","objectID":"/posts/zabbix-alertmanager/:4:0","series":null,"tags":["zabbix"],"title":"使用 Alertmanager 管理 zabbix 告警消息","uri":"/posts/zabbix-alertmanager/#接收告警信息"},{"categories":["container"],"content":" CentOSCentOS SSH 镜像 Dockerfile text FROM centos:centos7 LABEL maintainer=\"liwanggui\" RUN curl -o /etc/yum.repos.d/CentOS-Base.repo https://repo.huaweicloud.com/repository/conf/CentOS-7-reg.repo \\ \u0026\u0026 yum install -y openssh-server \\ \u0026\u0026 yum install -y inetutils-ping iproute net-tools \\ \u0026\u0026 yum clean all \\ \u0026\u0026 echo '123456' | passwd --stdin root \\ \u0026\u0026 ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key \\ \u0026\u0026 ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key \\ \u0026\u0026 ssh-keygen -t dsa -f /etc/ssh/ssh_host_ed25519_key \\ \u0026\u0026 ssh-keygen -t dsa -f /etc/ssh/ssh_host_ecdsa_key \\ \u0026\u0026 mkdir -m 0700 /root/.ssh # 添加公钥，需要提前准备好 authorized_keys 文件 COPY authorized_keys /root/.ssh EXPOSE 22 CMD [\"/usr/sbin/sshd\", \"-D\"] ","date":"2021-07-18","objectID":"/posts/docker-build-ssh/:1:0","series":null,"tags":["docker"],"title":"docker - 创建 SSH 镜像","uri":"/posts/docker-build-ssh/#centos"},{"categories":["container"],"content":" UbuntuUbuntu SSH 镜像 Dockerfile text FROM ubuntu:20.04 LABEL maintainer=\"liwanggui\" RUN sed -i \"s@http://.*archive.ubuntu.com@http://repo.huaweicloud.com@g\" /etc/apt/sources.list \\ \u0026\u0026 sed -i \"s@http://.*security.ubuntu.com@http://repo.huaweicloud.com@g\" /etc/apt/sources.list \\ \u0026\u0026 apt update \\ \u0026\u0026 DEBIAN_FRONTEND=noninteractive apt install -y openssh-server \\ \u0026\u0026 apt install -y inetutils-ping iproute2 net-tools vim \\ \u0026\u0026 apt clean \\ \u0026\u0026 mkdir /var/run/sshd \\ \u0026\u0026 sed -i -E 's/^(#)?PermitRootLogin.*/PermitRootLogin yes/' /etc/ssh/sshd_config \\ \u0026\u0026 echo \"root:123456\" | chpasswd \\ \u0026\u0026 mkdir -m 0700 /root/.ssh COPY authorized_keys /root/.ssh EXPOSE 22 CMD [\"/usr/sbin/sshd\", \"-D\"] ","date":"2021-07-18","objectID":"/posts/docker-build-ssh/:2:0","series":null,"tags":["docker"],"title":"docker - 创建 SSH 镜像","uri":"/posts/docker-build-ssh/#ubuntu"},{"categories":["devops","command"],"content":" fpm 简介fpm 的目标是使得构建二进制包 (deb, rpm, osx 等) 变得简单快速 fpm 项目地址: https://github.com/jordansissel/fpm fpm 文档地址: https://fpm.readthedocs.io/en/latest/ ","date":"2021-07-03","objectID":"/posts/fpm/:1:0","series":null,"tags":["fpm"],"title":"fpm - 简单的包制作工具","uri":"/posts/fpm/#fpm-简介"},{"categories":["devops","command"],"content":" fpm 依赖fpm 使用 Ruby 开发, 所以你得先安装 Ruby. 有些系统中默认已经安装了 Ruby, 例如: OSX, 有些系统可能没有安装 Ruby, 此时你需要执行下命令进行安装: OSX/macOS: bash brew install gnu-tar brew install rpm Red Hat systems (Fedora 22 or older, CentOS, etc): bash yum install ruby-devel gcc make rpm-build rubygems 注意: CentOS 源中的 ruby 版本过低，需要手动源码编译安装较新的 Ruby 版本 编译安装 Ruby bash yum install gcc openssl-devel make wget https://cache.ruby-lang.org/pub/ruby/2.7/ruby-2.7.3.tar.gz tar xzf ruby-2.7.3.tar.gz cd ruby-2.7.3 ./configure --prefix=/usr/local/ruby make make install 配置环境变量 bash echo 'export PATH=/usr/local/ruby/bin:$PATH' \u003e /etc/profile.d/ruby.sh source /etc/profile 配置 Ruby 源 bash gem sources -l # 查看当前源 gem sources --add https://gems.ruby-china.com/ --remove https://rubygems.org/ Fedora 23 or newer: bash dnf install ruby-devel gcc make rpm-build libffi-devel Oracle Linux 7.x systems: bash yum-config-manager --enable ol7_optional_latest yum install ruby-devel gcc make rpm-build rubygems Debian-derived systems (Debian, Ubuntu, etc): bash apt-get install ruby ruby-dev rubygems build-essential ","date":"2021-07-03","objectID":"/posts/fpm/:2:0","series":null,"tags":["fpm"],"title":"fpm - 简单的包制作工具","uri":"/posts/fpm/#fpm-依赖"},{"categories":["devops","command"],"content":" 安装 fpm可以使用 gem 工具安装 fpm bash gem install --no-document fpm 检查是否安装 bash fpm --version 常用参数说明 text -s 指定源类型 -t 指定目标类型，即想要制作为什么包 -n 指定包的名字 -v 指定包的版本号 -C 在搜索文件之前将目录更改为此处 -d 指定依赖于哪些包 -a 架构名称，通常匹配 'uname -m', 可以使用 '-a all' 或者 '-a native' -f 第二次打包时目录下如果有同名安装包存在，则覆盖它 -p 输出的安装包的目录，不想放在当前目录下就需要指定 --iteration 指定包的发布次数，例 RPM 的 release 字段 --post-install 软件包安装完成之后所要运行的脚本；同 --after-install --pre-install 软件包安装完成之前所要运行的脚本；同 --before-install --post-uninstall 软件包卸载完成之后所要运行的脚本；同 --after-remove --pre-uninstall 软件包卸载完成之前所要运行的脚本；同 --before-remove ","date":"2021-07-03","objectID":"/posts/fpm/:3:0","series":null,"tags":["fpm"],"title":"fpm - 简单的包制作工具","uri":"/posts/fpm/#安装-fpm"},{"categories":["devops","command"],"content":" 使用示例以 nodejs 为例， 将 nodejs 构建成3个包: nodejs, nodejs-dev, nodejs-doc 在示例中需要我们在 make install 时设置 DESTDIR 将编译好的文件安装到特定的目录中 ","date":"2021-07-03","objectID":"/posts/fpm/:4:0","series":null,"tags":["fpm"],"title":"fpm - 简单的包制作工具","uri":"/posts/fpm/#使用示例"},{"categories":["devops","command"],"content":" 制作 nodejs 包正常编译步骤 bash % wget http://nodejs.org/dist/v0.6.0/node-v0.6.0.tar.gz % tar -zxf node-v0.6.0.tar.gz % cd node-v0.6.0 % ./configure --prefix=/usr % make 将 nodejs 安装至临时目录 bash % mkdir /tmp/installdir % make install DESTDIR=/tmp/installdir 制作 nodejs 包 bash # Create a nodejs deb with only bin and lib directories: # The 'VERSION' and 'ARCH' strings are automatically filled in for you # based on the other arguments given. % fpm -s dir -t deb -n nodejs -v 0.6.0 -C /tmp/installdir \\ -p nodejs_VERSION_ARCH.deb \\ -d \"libssl0.9.8 \u003e 0\" \\ -d \"libstdc++6 \u003e= 4.4.3\" \\ usr/bin usr/lib nodejs 包中只包含 usr/bin usr/lib 中的文件，此为 nodejs 基础运行包 安装 nodejs 包，测试一下 text # 'fpm' just produced us a nodejs deb: % file nodejs_0.6.0-1_amd64.deb nodejs_0.6.0-1_amd64.deb: Debian binary package (format 2.0) % sudo dpkg -i nodejs_0.6.0-1_amd64.deb % /usr/bin/node --version v0.6.0 ","date":"2021-07-03","objectID":"/posts/fpm/:4:1","series":null,"tags":["fpm"],"title":"fpm - 简单的包制作工具","uri":"/posts/fpm/#制作-nodejs-包"},{"categories":["devops","command"],"content":" 制作 nodejs-doc 包创建 nodejs 文档手册包 bash # Create a package of the node manpage % fpm -s dir -t deb -p nodejs-doc_VERSION_ARCH.deb -n nodejs-doc -v 0.6.0 -C /tmp/installdir usr/share/man 查看 nodejs-doc 包 bash % dpkg -c nodejs-doc_0.6.0-1_amd64.deb | grep node.1 -rw-r--r-- root/root 945 2011-01-02 18:35 usr/share/man/man1/node.1 ","date":"2021-07-03","objectID":"/posts/fpm/:4:2","series":null,"tags":["fpm"],"title":"fpm - 简单的包制作工具","uri":"/posts/fpm/#制作-nodejs-doc-包"},{"categories":["devops","command"],"content":" 制作 nodejs-dev 包最后，打包用于开发的 headers 文件: bash % fpm -s dir -t deb -p nodejs-dev_VERSION_ARCH.deb -n nodejs-dev -v 0.6.0 -C /tmp/installdir usr/include % dpkg -c nodejs-dev_0.6.0-1_amd64.deb | grep -F .h -rw-r--r-- root/root 14359 2011-01-02 18:33 usr/include/node/eio.h -rw-r--r-- root/root 1118 2011-01-02 18:33 usr/include/node/node_version.h -rw-r--r-- root/root 25318 2011-01-02 18:33 usr/include/node/ev.h ... ","date":"2021-07-03","objectID":"/posts/fpm/:4:3","series":null,"tags":["fpm"],"title":"fpm - 简单的包制作工具","uri":"/posts/fpm/#制作-nodejs-dev-包"},{"categories":["devops","command"],"content":" 注意事项当我们需要将某个目录制作成二进制包时，需要注意 “相对路径” 与 “绝对路径” 问题，以 nginx 为例 相对路径 bash % cd /usr/local/nginx % fpm -s dir -t rpm -n nginx -v 1.16.1 --iteration 1.el7 . no value for epoch is set, defaulting to nil {:level=\u003e:warn} no value for epoch is set, defaulting to nil {:level=\u003e:warn} Created package {:path=\u003e\"nginx-1.16.1-1.el7.x86_64.rpm\"} # 查看 rpm 包文件列表 $ rpm -qpl nginx-1.16.1-1.el7.x86_64.rpm /client_body_temp /conf/extra/dynamic_pools /conf/extra/static_pools ... 绝对路径 bash $ fpm -s dir -t rpm -n nginx -v 1.16.1 --iteration 2.el7 /usr/local/nginx no value for epoch is set, defaulting to nil {:level=\u003e:warn} no value for epoch is set, defaulting to nil {:level=\u003e:warn} Created package {:path=\u003e\"nginx-1.16.1-2.el7.x86_64.rpm\"} # 查看 rpm 包文件列表 $ rpm -qpl nginx-1.16.1-2.el7.x86_64.rpm /usr/local/nginx/client_body_temp /usr/local/nginx/conf/extra/dynamic_pools /usr/local/nginx/conf/extra/static_pools /usr/local/nginx/conf/fastcgi.conf /usr/local/nginx/conf/fastcgi.conf.default ... 更多使用帮助请查看 fpm 官方文档 https://fpm.readthedocs.io/en/latest/ ","date":"2021-07-03","objectID":"/posts/fpm/:5:0","series":null,"tags":["fpm"],"title":"fpm - 简单的包制作工具","uri":"/posts/fpm/#注意事项"},{"categories":["devops","command"],"content":" 简介find 是实时查找工具，通过遍历指定路径完成文件查找 工作特点： 查找速度略慢 精确查找 实时查找 查找条件丰富 只搜索用户具备读取和执行权限的目录 语法格式: bash find [Option]... [查找路径 [查找条件] [处理动作] 查找路径: 指定具体查找目标路径，不指定时默认为当前目录 查找条件：指定的查找标准，可以是文件名，大小，类型，权限等；默认为找出指定路径下的所有文件 处理动作：对符合条件的文件做操作，默认输出至屏幕 ","date":"2021-06-27","objectID":"/posts/find/:1:0","series":null,"tags":["find"],"title":"利用 find 查找文件","uri":"/posts/find/#简介"},{"categories":["devops","command"],"content":" 常用参数","date":"2021-06-27","objectID":"/posts/find/:2:0","series":null,"tags":["find"],"title":"利用 find 查找文件","uri":"/posts/find/#常用参数"},{"categories":["devops","command"],"content":" 指定搜索目录层级 -maxdepth: 最大搜索目录深度，指定的目录下的文件为第1级 -mindepth: 最小搜索目录深度 -depth: 先处理文件再处理目录，默认为是先处理目录后处理文件 ","date":"2021-06-27","objectID":"/posts/find/:2:1","series":null,"tags":["find"],"title":"利用 find 查找文件","uri":"/posts/find/#指定搜索目录层级"},{"categories":["devops","command"],"content":" 根据文件名和 inode 查找 -name: 指定搜索的文件名，支持使用通配符，如: *, ?, [], [^] 等，使用通配符需使用引号引起来 -iname: 指定搜索的文件名，不区分大小写 -inum: 指定 inode 号，通过 inode 号查找文件 -samefile: 指定文件名，查找 inode 号相同的文件 -links: 链接数，查找文件链接数为指定链接数的文件 -regex: 正则表达式，使用正则表达式匹配整个文件路径，而非文件名称 ","date":"2021-06-27","objectID":"/posts/find/:2:2","series":null,"tags":["find"],"title":"利用 find 查找文件","uri":"/posts/find/#根据文件名和-inode-查找"},{"categories":["devops","command"],"content":" 根据属主、属组查找 -user：用户名，根据文件属主查找文件 -group: 组名, 根据文件属组查找文件 -uid: 用户id, 根据用户ID(UID)查找文件 -gid: 组id, 根据组ID(GID)查找文件 -nouser: 查找没属主的文件 ","date":"2021-06-27","objectID":"/posts/find/:2:3","series":null,"tags":["find"],"title":"利用 find 查找文件","uri":"/posts/find/#根据属主属组查找"},{"categories":["devops","command"],"content":" 根据文件类型查找 bash -type TYPE f: 普通文件 d: 目录文件 l: 符号链接文件 s: 套接字文件 b: 块文件 c: 字符设备文件 ","date":"2021-06-27","objectID":"/posts/find/:2:4","series":null,"tags":["find"],"title":"利用 find 查找文件","uri":"/posts/find/#根据文件类型查找"},{"categories":["devops","command"],"content":" 查找空文件或空目录查找空文件与空目录 bash find --empty 查找空文件 bash find -empty -type f 提示: 空文件是指大小 0 的文件 ","date":"2021-06-27","objectID":"/posts/find/:2:5","series":null,"tags":["find"],"title":"利用 find 查找文件","uri":"/posts/find/#查找空文件或空目录"},{"categories":["devops","command"],"content":" 组合条件 与: -a 或: -o 非: -not ! 查找以 .log 或 .txt 结尾的文件 bash find -name \"*.log\" -o -name \"*.txt\" 查找不是符号链接的文件 bash find ! -type l ","date":"2021-06-27","objectID":"/posts/find/:2:6","series":null,"tags":["find"],"title":"利用 find 查找文件","uri":"/posts/find/#组合条件"},{"categories":["devops","command"],"content":" 排除目录 -prune: 排除查找的结果 搜索 /etc 目录下所有 .conf 结尾的文件，排除 /etc/fonts 和 /etc/systemd 目录 bash find /etc \\( -path /etc/fonts -o -path /etc/systemd \\) -a -prune -o -name '*.conf' ","date":"2021-06-27","objectID":"/posts/find/:2:7","series":null,"tags":["find"],"title":"利用 find 查找文件","uri":"/posts/find/#排除目录"},{"categories":["devops","command"],"content":" 根据文件大小查找文件-size: [+/-], 常用单位: k M G c(byte) 查找2k大小的文件 bash find -size 2k 注意: 查找的大小并不精确，查找目标是 2k 大小，实际查找是大于 1k 小于 2k 的文件 如果想精确查找 2k 大小的文件可以写成， find -size 2048c 查找大于 100M 的文件 bash find -size +100M 注意： 大于 100M 并不包括 100M 查找小于 10k 的文件 bash find -size -10k 注意: 查找的文件大小是 0-9k ","date":"2021-06-27","objectID":"/posts/find/:2:8","series":null,"tags":["find"],"title":"利用 find 查找文件","uri":"/posts/find/#根据文件大小查找文件"},{"categories":["devops","command"],"content":" 根据时间查找文件**以天为单位 ** -actim: 文件访问时间（天） -mtime: 文件修改时间（天） -ctime: 状态更新时间（天） 时间范围说明 text +10 表示 11 天之前的 -10 表示 10 天以内，不包括第10天 以分钟为单位 -amin: 文件访问时间（分钟） -mmin: 文件修改时间（分钟） -cmin: 文件状态更新时间（分钟） 查找 3 天前的文件 bash find -type f -mtime +3 注意: 不包含第3天 查看 3 天内的文件 bash find -type f -mtime 3 ","date":"2021-06-27","objectID":"/posts/find/:2:9","series":null,"tags":["find"],"title":"利用 find 查找文件","uri":"/posts/find/#根据时间查找文件"},{"categories":["devops","command"],"content":" 根据权限查找文件查找权限为 777 的文件 bash find -type f -perm 777 查找有读取权限的文件 bash find -type f -perm /444 属主、属组、其他，只要其中有任一有读取权限就可以 注意: 匹配权限时，不加 /- 号表示精确查找，/ 号表示权限的或，- 号表示与 示例 text /444 : 表示查找有读取权限的文件（不管是属主、属组或者其他权限的读取权限） -444 : 表示查找 属主、属组及其他 权限位都有读取权限的文件 ","date":"2021-06-27","objectID":"/posts/find/:2:10","series":null,"tags":["find"],"title":"利用 find 查找文件","uri":"/posts/find/#根据权限查找文件"},{"categories":["devops","command"],"content":" 查找文件后的动作 -print: 默认的处理动作，输出至屏幕 -ls： 类似于对查找的文件执行 ls -l 命令 -delete: 删除查找到的文件 -fls: 将查找到的所有文件的长格式信息保存到指定的文件 -ok：对查找到的每个文件执行指定的命令，对于每个文件执行命令之前，都会交互式要求用户确认 -exec: 对查找到的文件执行指定的命令 {}: 用于引用查找到的文件名称自身 由于分号有 shell 中有特殊的含义所以得转义 \\; 查找 /home 中所有目录 bash find /home -type d -ls 去除 /home 目录下所有文件的执行权限 bash find /home -type f -exec chmod -x {} \\; 查找删除 3天以前的文件 bash find -type f -ctime +3 -ok rm {} \\; ","date":"2021-06-27","objectID":"/posts/find/:2:11","series":null,"tags":["find"],"title":"利用 find 查找文件","uri":"/posts/find/#查找文件后的动作"},{"categories":["devops","jenkins"],"content":" 概述共享库这并不是一个全新的概念，其实具有编程能力的同学应该清楚一些。例如在编程语言 Python 中，我们可以将 Python 代码写到一个文件中，当代码数量增加，我们可以将代码打包成模块然后再以 import 的方式使用此模块中的方法。 在 Jenkins 中使用 Groovy 语法，共享库中存储的每个文件都是一个 Groovy 的类，每个文件（类）中包含一个或多个方法。每个方法包含 Groovy 语句块。 Jenkins 共享参考库: https://github.com/liwanggui/jenkins-share-lib.git ","date":"2021-06-17","objectID":"/posts/jenkins-sharelib/:1:0","series":null,"tags":["jenkins","groovy"],"title":"Jenkins 共享库应用","uri":"/posts/jenkins-sharelib/#概述"},{"categories":["devops","jenkins"],"content":" 共享库内容共享参考库文件结构如下 bash ── vars │ └── getIP.groovy │ └── hello.groovy ├── src │ └── org │ └── devops │ └── HTTP.groovy ├── Jenkinsfile └── README.md src 目录主要存放我们要编写的 Groovy 类，执行流水线时，此目录将添加到 class_path 中。 vars目录主要存放脚本文件，这些脚本文件在流水线中作为变量公开。 resources 目录允许从外部库中使用步骤来加载相关联的非 Groovy 文件。 ","date":"2021-06-17","objectID":"/posts/jenkins-sharelib/:2:0","series":null,"tags":["jenkins","groovy"],"title":"Jenkins 共享库应用","uri":"/posts/jenkins-sharelib/#共享库内容"},{"categories":["devops","jenkins"],"content":" 创建共享库文件 src/org/devops/HTTP.groovy, 在此我将这个文件定义为 HTTP 请求类，主要放一些 HTTP 请求方法。 groovy package org.devops import groovy.json.JsonOutput /** * 发送 HTTP GET 请求 * @param url 请求的网址 * @return String */ def get(url){ return new URL(url).text } /** * 发送 HTTP POST 请求 * @param url 请求的网址 * @param data 请求所需的参数，可选 * @param is_json 请求参数类型是否为 json 格式 * @return String */ def post(url, data = null, is_json = false) { def conn = new URL(url).openConnection() conn.setRequestMethod(\"POST\") if (data) { if (is_json) { conn.setRequestProperty(\"Content-Type\", \"application/json\") data = JsonOutput.toJson(data) } // 输出请求参数 println(data) conn.doOutput = true def writer = new OutputStreamWriter(conn.outputStream) writer.write(data) writer.flush() writer.close() } def result = conn.content.text // 输出请求结果 // result.each({ println it }) return result } ","date":"2021-06-17","objectID":"/posts/jenkins-sharelib/:3:0","series":null,"tags":["jenkins","groovy"],"title":"Jenkins 共享库应用","uri":"/posts/jenkins-sharelib/#创建共享库"},{"categories":["devops","jenkins"],"content":" 使用共享库我们打开 Jenkins 管理页面，依次点击 Manage Jenkins -\u003e System Configuration -\u003e Global Pipeline Libraries 首先，我们为共享库设置一个名称 jenkinslib，注意这个名称后续在 Jenkinsfile 中引用。 再设置一个默认的版本，这里的版本是分支的名称。我默认配置的是 main (github 将 master 改为了 main) 版本。 好，到此共享库在 Jenkins 的配置就完成了，接下来测试在 Jenkinsfile 中引用。 在 Jenkinsfile 中使用 @Library('jenkinslib') _ 来加载共享库，注意后面符号 _ 用于加载。 类的实例化 def http = new org.devops.HTTP(), 使用类中的方法 http.get(\"https://httpbin.org/ip\")。 groovy @Library('jenkinslib') _ import org.devops.HTTP // 创建 HTTP 类实例 def http = new HTTP() pipeline { agent any stages { stage(\"发送 POST 请求\") { steps { println http.post(\"https://httpbin.org/post\") } } stage(\"获取主机公网 IP\") { steps { println getIP() } } } } 接下来在你的 Jenkins 上面运行一下吧 ","date":"2021-06-17","objectID":"/posts/jenkins-sharelib/:4:0","series":null,"tags":["jenkins","groovy"],"title":"Jenkins 共享库应用","uri":"/posts/jenkins-sharelib/#使用共享库"},{"categories":["groovy"],"content":" GET 请求使用 Groovy 发送 GET 请求非常简单，一行代码搞定 groovy def res1 = new URL('https://httpbin.org/ip').text // or def res2 = 'https://httpbin.org/ip'.toURL().text ","date":"2021-06-17","objectID":"/posts/groovy-http/:1:0","series":null,"tags":["groovy"],"title":"Groovy 发送 HTTP 请求","uri":"/posts/groovy-http/#get-请求"},{"categories":["groovy"],"content":" POST 请求使用标准库 URL 类，发送 POST 请求 groovy import groovy.json.JsonOutput import groovy.json.JsonSlurper /** * 发送 HTTP POST 请求 * @param url 请求的网址 * @param data 请求所需的参数，可选 * @param is_json 请求参数类型是否为 json 格式 * @return Map */ def http_post(url, data = null, is_json = false) { def conn = new URL(url).openConnection() conn.setRequestMethod(\"POST\") if (data) { if (is_json) { conn.setRequestProperty(\"Content-Type\", \"application/json\") data = JsonOutput.toJson(data) } // 输出请求参数 println(data) conn.doOutput = true def writer = new OutputStreamWriter(conn.outputStream) writer.write(data) writer.flush() writer.close() } def json = new JsonSlurper() json.parseText(conn.content.text) } http_post('https://httpbin.org/post', '{\"name\": \"John\", \"age\": 34}', true) ","date":"2021-06-17","objectID":"/posts/groovy-http/:2:0","series":null,"tags":["groovy"],"title":"Groovy 发送 HTTP 请求","uri":"/posts/groovy-http/#post-请求"},{"categories":["network"],"content":" NAT 说明NAT 全名是 Network Address Translation，字面上的意思是网络地址转换，它还可以分为源地址转换(SNAT)和目的地址转换(DNAT) SNAT: 将内网主机访问外网的源 IP 地址转换成网关地址，以达到用一个公网 IP 地址上网的目的 DNAT: 将内网主机端口外网关端口绑定，用于将服务暴露在外网，方便外网客户端访问内网服务 ","date":"2021-06-14","objectID":"/posts/iptables-nat/:1:0","series":null,"tags":["iptables"],"title":"iptable Nat 网络地址转换","uri":"/posts/iptables-nat/#nat-说明"},{"categories":["network"],"content":" SNAT","date":"2021-06-14","objectID":"/posts/iptables-nat/:2:0","series":null,"tags":["iptables"],"title":"iptable Nat 网络地址转换","uri":"/posts/iptables-nat/#snat"},{"categories":["network"],"content":" 1. 开启路由转发功能 bash sysctl -w net.ipv4.ip_forward=1 注: 如果想永久生效，编辑 /etc/sysctl.conf 文件，写入 net.ipv4.ip_forward = 1 后，执行 sysctl -p ","date":"2021-06-14","objectID":"/posts/iptables-nat/:2:1","series":null,"tags":["iptables"],"title":"iptable Nat 网络地址转换","uri":"/posts/iptables-nat/#1-开启路由转发功能"},{"categories":["network"],"content":" 2. 配置 SNAT 规则内网所有主机访问外网时，都将源地址转换为 1.1.1.1 (网关 WAN 口地址) bash iptables -t nat -A POSTROUTING -o ens32 -j SNAT --to-source 1.1.1.1 注：如果网关 WAN 没有固定 IP 地址，可以使用命令: iptables -t nat -A POSTROUTING -o ens32 -j MASQUERADE MASQUERADE 将自动对经过网关或路由器的数据包进行源地址伪装 ","date":"2021-06-14","objectID":"/posts/iptables-nat/:2:2","series":null,"tags":["iptables"],"title":"iptable Nat 网络地址转换","uri":"/posts/iptables-nat/#2-配置-snat-规则"},{"categories":["network"],"content":" DNAT假设内网有台服务器，在 80/tcp 端口提供 Web 服务，想让外网的用户也可以访问到此服务，只需配置 DNAT 规则即可 实现方法: 将网关其中一个端口(8000 为例)与服务器的 80 端口进行绑定 bash iptables -t nat -A PREROUTING -p tcp -m tcp --dport 8000 -j DNAT --to-destination 192.168.2.100:80 此时，访问 http://\u003c网关 WAN 口地址\u003e:8000 即可访问到内网 Web 服务 ","date":"2021-06-14","objectID":"/posts/iptables-nat/:3:0","series":null,"tags":["iptables"],"title":"iptable Nat 网络地址转换","uri":"/posts/iptables-nat/#dnat"},{"categories":["python"],"content":" 企业微信 API通过 python 调用企业微信的 api 接口来发送消息，可用于监控告警。使用 requests 模块。 python #!/usr/bin/python # -*- coding: utf-8 -*- # # pip install requests # import os import time import redis import requests class WXWork(object): def __init__(self, corpid, secret, agentid): self.token_file = '/tmp/temp_wechat' self.url = \"https://qyapi.weixin.qq.com/cgi-bin\" self.corpid = corpid self.corpsecret = secret self.agentid = agentid def _get_token(self): # 获取 token 并缓存 response = requests.get(url=self.url + '/gettoken', params=dict(corpid=self.corpid, corpsecret=self.corpsecret)) return response.json() def get_token(self): if os.path.isfile(self.token_file): with open(self.token_file) as f: token_info = f.read() if len(token_info.split()) == 2: expire, token = token_info.split() if float(expire) \u003e time.time(): return token d = self._get_token() try: if d['errcode'] == 0: with open(self.token_file, 'w') as f: f.write(\"%s %s\" % (time.time() + d['expires_in'], d['access_token'])) return d['access_token'] except Exception as e: return False def send(self, msg): token = self.get_token() if token: url = self.url + '/message/send?access_token=%s' % token data = dict( toparty=\"1\", msgtype=\"text\", agentid=self.agentid, text=dict(content=msg), safe=0 ) response = requests.post(url=url, json=data) d = response.json() if d[\"errcode\"] != 0: return 'Send message failed.' else: return 'Get token failed.' if __name__ == '__main__': # 企业ID corpid = \"xxxxxx\" # 应用的凭证密钥 secret = \"xxxxxxxxxxxxxxxxxx\" # 企业应用的id，整型。可在应用的设置页面查看 agentid = 1000002 # 发送的消息 msg = \"这是只个无聊的消息。\" wechat = WXWork(corpid, secret, agentid) wechat.send(msg) ","date":"2021-06-14","objectID":"/posts/python-wechat/:1:0","series":null,"tags":["requests","wechat"],"title":"Python 调用企业微信发送消息","uri":"/posts/python-wechat/#企业微信-api"},{"categories":["python"],"content":" Paramiko Github 仓库: https://github.com/paramiko/paramiko Paramiko 扩展模块 scp.py Github 仓库: https://github.com/jbardin/scp.py ","date":"2021-06-14","objectID":"/posts/python-paramiko/:0:0","series":null,"tags":["paramiko"],"title":"Paramiko SSH 远程连接 Linux 主机","uri":"/posts/python-paramiko/#"},{"categories":["python"],"content":" 安装 paramiko bash pip install paramiko ","date":"2021-06-14","objectID":"/posts/python-paramiko/:1:0","series":null,"tags":["paramiko"],"title":"Paramiko SSH 远程连接 Linux 主机","uri":"/posts/python-paramiko/#安装-paramiko"},{"categories":["python"],"content":" SSH 连接","date":"2021-06-14","objectID":"/posts/python-paramiko/:2:0","series":null,"tags":["paramiko"],"title":"Paramiko SSH 远程连接 Linux 主机","uri":"/posts/python-paramiko/#ssh-连接"},{"categories":["python"],"content":" 用户名密码 python import paramiko client = paramiko.SSHClient() client.set_missing_host_key_policy(paramiko.AutoAddPolicy) client.connect(hostname='192.168.31.100', port=22, username='root', password='123456') stdin, stdout, stderr = client.exec_command('ls') for line in stdout: print('... ' + line.strip('\\n')) client.close() ","date":"2021-06-14","objectID":"/posts/python-paramiko/:2:1","series":null,"tags":["paramiko"],"title":"Paramiko SSH 远程连接 Linux 主机","uri":"/posts/python-paramiko/#用户名密码"},{"categories":["python"],"content":" 使用私钥 python import paramiko client = paramiko.SSHClient() client.set_missing_host_key_policy(paramiko.AutoAddPolicy) client.connect(hostname='192.168.31.100', port=22, username='root', key_filename=\"\u003c你的私钥路径\u003e\", passphrase=\"\u003c私钥密码\u003e\") # pkey = paramiko.RSAKey(data=None, filename='\u003c你的私钥路径\u003e', password='\u003c私钥密码\u003e') # client.connect('118.193.40.147', username='root', pkey=pkey) stdin, stdout, stderr = client.exec_command('ls') for line in stdout: print('... ' + line.strip('\\n')) client.close() ","date":"2021-06-14","objectID":"/posts/python-paramiko/:2:2","series":null,"tags":["paramiko"],"title":"Paramiko SSH 远程连接 Linux 主机","uri":"/posts/python-paramiko/#使用私钥"},{"categories":["python"],"content":" 使用代理paramiko 实现网关代理连接功能 由于 paramiko 在 windows 下不能使用 ssh 代理连接远程主机，经过苦苦寻找，终于在 fabirc 源代码找到解决方案（fabric 命令有一个选项 gateway 允许用户指定一台网关机，然后所有主机连接都会经过这台网关主机中转连接），代码如下： python import paramiko gateway = paramiko.SSHClient() gateway.set_missing_host_key_policy(paramiko.MissingHostKeyPolicy()) gateway.connect(hostname=\"192.168.92.131\", port=22, username=\"root\", password='liwanggui', timeout=5) # 关键就这一步了 sock = gateway.get_transport().open_channel('direct-tcpip', ('192.168.22.2', int(22)), ('', 0)) ssh = paramiko.SSHClient() ssh.set_missing_host_key_policy(paramiko.MissingHostKeyPolicy()) ssh.connect(hostname=\"192.168.22.2\", port=22, username=\"root\", password='liwanggui', sock=sock, timeout=5) session = ssh.get_transport().open_session() session.exec_command('uptime') exit_status = session.recv_exit_status() stdout = session.makefile('r').read() stderr = session.makefile_stderr('r').read() print(exit_status, stdout, stderr) ssh.close() gateway.close() 通过 ProxyCommand 实现 此方法仅适用于类 unix 系统, 代码如下： python import paramiko import time private_key_file = \"/root/.ssh/id_rsa\" proxy_command = r\"ssh -i /root/.ssh/id_rsa -p 22 -o StrictHostKeyChecking=no root@192.168.92.131 -W 192.168.22.2:22\" sock = paramiko.proxy.ProxyCommand(proxy_command) ssh = paramiko.SSHClient() ssh.set_missing_host_key_policy(paramiko.MissingHostKeyPolicy()) ssh.connect(hostname=\"192.168.22.2\", port=22, username=\"root\", key_filename=private_key_file, sock=sock, timeout=5) chan = ssh.get_transport().open_session() chan.exec_command('uptime') # 命令执行退出状态 0 成功， 其他数字 失败 exit_status = chan.recv_exit_status() # 标准输出结果 stdout = chan.makefile('r').read() # 标准错误输出结果 stderr = chan.makefile_stderr('r').read() print(exit_status, stdout, stderr) 通过 socks 代理实现 通过 PySocks 模块实现 socks5 代理功能，在 linux 平台使用没有问题，在 windows 中出错，代码如下： python import socks import socket import paramiko socks.setdefaultproxy(socks.PROXY_TYPE_SOCKS5, '127.0.0.1', 1080) socket.socket = socks.socksocket ssh = paramiko.SSHClient() ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy()) try: ssh.connect('192.168.22.2', 22, 'root', 'liwanggui', timeout=5) except paramiko.AuthenticationException: print('password is error.') chan = ssh.get_transport().open_session() chan.exec_command('uptime') exit_status = chan.recv_exit_status() stdout = chan.makefile('r').read() stderr = chan.makefile_stderr('r').read() print(exit_status, stdout, stderr) ","date":"2021-06-14","objectID":"/posts/python-paramiko/:2:3","series":null,"tags":["paramiko"],"title":"Paramiko SSH 远程连接 Linux 主机","uri":"/posts/python-paramiko/#使用代理"},{"categories":["python"],"content":" 文件操作这我们使用 paramiko 第三方扩展库 scp.py 进行文件上传下载操作，当然你也可以使用 paramiko 库进行文件上传下载 安装 scp.py bash pip instal scp ","date":"2021-06-14","objectID":"/posts/python-paramiko/:3:0","series":null,"tags":["paramiko"],"title":"Paramiko SSH 远程连接 Linux 主机","uri":"/posts/python-paramiko/#文件操作"},{"categories":["python"],"content":" 简单的文件上传 python import paramiko from scp import SCPClient ssh = paramiko.SSHClient() ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy) ssh.connect(hostname='192.168.31.100', port=22, username='root', key_filename=\"\u003c你的私钥路径\u003e\", passphrase=\"\u003c私钥密码\u003e\") scp = SCPClient(ssh.get_transport()) # 上传下载文件，不指定完整路径默认就是用户的家目录 scp.put('/etc/hosts', 'mhost') # 从用户的家目录下载 mhost 文件到当前目录下 scp.get('mhost') # 上传目录至远程主机，并改名为 mail scp.put('postfix', remote_path='/data/mail', recursive=True) # 下载目录到当前路径下 scp.get('/data/mail', recursive=True) scp.close() ","date":"2021-06-14","objectID":"/posts/python-paramiko/:3:1","series":null,"tags":["paramiko"],"title":"Paramiko SSH 远程连接 Linux 主机","uri":"/posts/python-paramiko/#简单的文件上传"},{"categories":["python"],"content":" 使用 with 语法 python from paramiko import SSHClient from scp import SCPClient with SSHClient() as ssh: ssh.load_system_host_keys() ssh.connect('example.com') with SCPClient(ssh.get_transport()) as scp: scp.put('test.txt', 'test2.txt') scp.get('test2.txt') ","date":"2021-06-14","objectID":"/posts/python-paramiko/:3:2","series":null,"tags":["paramiko"],"title":"Paramiko SSH 远程连接 Linux 主机","uri":"/posts/python-paramiko/#使用-with-语法"},{"categories":["python"],"content":" 上传文件类对象使用 putfo 方法可用于上传文件类对象 python import io from paramiko import SSHClient from scp import SCPClient ssh = SSHClient() ssh.load_system_host_keys() ssh.connect('example.com') # SCPCLient takes a paramiko transport as an argument scp = SCPClient(ssh.get_transport()) # generate in-memory file-like object fl = io.BytesIO() fl.write(b'test') fl.seek(0) # upload it directly from memory scp.putfo(fl, '/tmp/test.txt') # close connection scp.close() # close file handler fl.close() ","date":"2021-06-14","objectID":"/posts/python-paramiko/:3:3","series":null,"tags":["paramiko"],"title":"Paramiko SSH 远程连接 Linux 主机","uri":"/posts/python-paramiko/#上传文件类对象"},{"categories":["python"],"content":" 显示文件上传下载进度跟踪文件上载/下载的进度 progress 函数可以作为对 SCPClient 的回调，以处理当前 SCP 操作如何处理传输的进度。在下面的示例中，我们打印文件传输的完成百分比。 python from paramiko import SSHClient from scp import SCPClient import sys ssh = SSHClient() ssh.load_system_host_keys() ssh.connect('example.com') # Define progress callback that prints the current percentage completed for the file def progress(filename, size, sent): sys.stdout.write(\"%s's progress: %.2f%% \\r\" % (filename, float(sent)/float(size)*100) ) # SCPCLient takes a paramiko transport and progress callback as its arguments. scp = SCPClient(ssh.get_transport(), progress=progress) # you can also use progress4, which adds a 4th parameter to track IP and port # useful with multiple threads to track source def progress4(filename, size, sent, peername): sys.stdout.write(\"(%s:%s) %s's progress: %.2f%% \\r\" % (peername[0], peername[1], filename, float(sent)/float(size)*100) ) scp = SCPClient(ssh.get_transport(), progress4=progress4) scp.put('test.txt', '~/test.txt') # Should now be printing the current progress of your put function. scp.close() ","date":"2021-06-14","objectID":"/posts/python-paramiko/:3:4","series":null,"tags":["paramiko"],"title":"Paramiko SSH 远程连接 Linux 主机","uri":"/posts/python-paramiko/#显示文件上传下载进度"},{"categories":["python"],"content":" Github 官方仓库: https://github.com/pyauth/pyotp ","date":"2021-06-14","objectID":"/posts/python-pyopt/:0:0","series":null,"tags":["pyotp"],"title":"PyOTP 实现双重或多因素身份验证","uri":"/posts/python-pyopt/#"},{"categories":["python"],"content":" 生成密钥PyOTP 提供了一个帮助函数来生成一个16个字符的 base32 密钥，与Google Authenticator和其他OTP应用程序兼容： python import pyotp secret = pyotp.random_base32() 某些应用程序希望将密钥格式化为十六进制编码字符串： python pyotp.random_hex() # returns a 32-character hex-encoded secret ","date":"2021-06-14","objectID":"/posts/python-pyopt/:1:0","series":null,"tags":["pyotp"],"title":"PyOTP 实现双重或多因素身份验证","uri":"/posts/python-pyopt/#生成密钥"},{"categories":["python"],"content":" 基于时间的 OTP python import pyotp totp = pyotp.TOTP('base32secret3232') totp.now() # =\u003e '492039' # OTP verified for current time totp.verify('492039') # =\u003e True time.sleep(30) totp.verify('492039') # =\u003e False 客户端可以使用 google 验证器，也可以使用洋葱身份验证器 ","date":"2021-06-14","objectID":"/posts/python-pyopt/:2:0","series":null,"tags":["pyotp"],"title":"PyOTP 实现双重或多因素身份验证","uri":"/posts/python-pyopt/#基于时间的-otp"},{"categories":["python"],"content":" 创建虚拟环境 bash python3 -m venv pyenv source pyenv/bin/activate ","date":"2021-06-13","objectID":"/posts/python-qrcode/:1:0","series":null,"tags":["qrcode"],"title":"Python 批量生成二维码","uri":"/posts/python-qrcode/#创建虚拟环境"},{"categories":["python"],"content":" 安装依赖库 bash pip install Image pip install qrcode ","date":"2021-06-13","objectID":"/posts/python-qrcode/:2:0","series":null,"tags":["qrcode"],"title":"Python 批量生成二维码","uri":"/posts/python-qrcode/#安装依赖库"},{"categories":["python"],"content":" 编写代码 python import qrcode def createQR(name, url): img = qrcode.make(url) name = name + '.png' with open(name, 'wb') as f: img.save(f) print(\"create QR code: \", name) def main(filename): with open(filename) as f: for line in f: name, url = line.split(',') createQR(name, url) if __name__ == '__main__': main('test.txt') ","date":"2021-06-13","objectID":"/posts/python-qrcode/:3:0","series":null,"tags":["qrcode"],"title":"Python 批量生成二维码","uri":"/posts/python-qrcode/#编写代码"},{"categories":["python"],"content":" 准备数据文件程序从文本文件中读取数据，以行为单位，根据每行数据内容生成二维码 格式: 生成二维码文件名,网址 使用逗号为分隔符 示例 test.txt text baidu,https://www.baidu.com tencent,https://www.qq.com ","date":"2021-06-13","objectID":"/posts/python-qrcode/:4:0","series":null,"tags":["qrcode"],"title":"Python 批量生成二维码","uri":"/posts/python-qrcode/#准备数据文件"},{"categories":["python"],"content":" 执行 bash $ python qr.py create QR code: baidu.png create QR code: tencent.png ","date":"2021-06-13","objectID":"/posts/python-qrcode/:5:0","series":null,"tags":["qrcode"],"title":"Python 批量生成二维码","uri":"/posts/python-qrcode/#执行"},{"categories":["devops","jenkins"],"content":" 安装 官方安装文档: https://pkg.jenkins.io/redhat-stable/ bash wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key yum install jenkins ","date":"2021-06-13","objectID":"/posts/jenkins-install/:1:0","series":null,"tags":["jenkins"],"title":"Jenkins 安装配置","uri":"/posts/jenkins-install/#安装"},{"categories":["devops","jenkins"],"content":" 配置","date":"2021-06-13","objectID":"/posts/jenkins-install/:2:0","series":null,"tags":["jenkins"],"title":"Jenkins 安装配置","uri":"/posts/jenkins-install/#配置"},{"categories":["devops","jenkins"],"content":" 配置方法1配置前先启动 jenkins 服务, 在浏览器打开 http://\u003cyour_server_ip_address\u003e:8080 bash systemctl start jenkins 执行以下命令 bash mkdir -p /var/lib/jenkins/update-center-rootCAs wget https://cdn.jsdelivr.net/gh/lework/jenkins-update-center/rootCA/update-center.crt -O /var/lib/jenkins/update-center-rootCAs/update-center.crt chown jenkins.jenkins -R /var/lib/jenkins/update-center-rootCAs sed -i 's#https://updates.jenkins.io/update-center.json#https://cdn.jsdelivr.net/gh/lework/jenkins-update-center/updates/huawei/update-center.json#' /var/lib/jenkins/hudson.model.UpdateCenter.xml 在浏览器进行下一步时如果提示 “安装过程中出现一个错误： No such plugin: cloudbees-folder” 错误信息，这时我们只需要在 url 后面加 /restart 跳过安装插件的界面，重启 jenkins 即可 ","date":"2021-06-13","objectID":"/posts/jenkins-install/:2:1","series":null,"tags":["jenkins"],"title":"Jenkins 安装配置","uri":"/posts/jenkins-install/#配置方法1"},{"categories":["devops","jenkins"],"content":" 配置方法2 启动 jenkins 服务，打开浏览器完成初始化 进入 Manage Jenkins -\u003e Manage Plugin -\u003e Advanced 最下面有 Update Site 设置为：https://mirrors.huaweicloud.com/jenkins/updates/update-center.json， 点击 Submit 提交，然后在点击 check now 修改 jenkins 配置，进入 /var/lib/jenkins 目录 ， 将 updates/default.json 其中的 https://updates.jenkins.io/download 替换为 https://mirrors.huaweicloud.com/jenkins ，然后把 www.google.com 修改为 www.baidu.com 重启 Jenkins 服务 享受加速下载插件的快感吧！ 替换为华为源 bash sed -i 's@https://updates.jenkins.io/download@https://mirrors.huaweicloud.com/jenkins@g' /var/lib/jenkins/updates/default.json 替换为清华大学源 重复以上步骤，地址进行相应的替换 源地址: https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json bash sed -i 's@https://updates.jenkins.io/download@https://mirrors.tuna.tsinghua.edu.cn/jenkins@g' /var/lib/jenkins/updates/default.json ","date":"2021-06-13","objectID":"/posts/jenkins-install/:2:2","series":null,"tags":["jenkins"],"title":"Jenkins 安装配置","uri":"/posts/jenkins-install/#配置方法2"},{"categories":["devops"],"content":"场景: eth0: 192.168.1.10/24 网关: 192.168.1.1 eth1: 10.10.0.10/24 网关: 10.10.0.1 要求: 10.10.0.10 这个 IP 的流量从 10.10.0.1 网关出，保证 10.10.0.10 这个地址可以正常连接, 其他所有流量均从 192.168.1.1 网关出 配置: 将 192.168.1.1 配置为默认网关，写在网卡配置文件中 添加新的路由表规则 bash echo \"200 test\" \u003e\u003e /etc/iproute2/rt_tables ip route add default via 10.10.0.1 dev eth1 table test ip rule add from 10.10.0.10 table test 为了重启后也有效，将配置命令写入 /etc/rc.d/rc.local 文件中，并为此文件赋于运行权限 ","date":"2021-06-13","objectID":"/posts/linux-multi-ip/:0:0","series":null,"tags":["ip"],"title":"Linux 多 ip 源进源出","uri":"/posts/linux-multi-ip/#"},{"categories":["bash"],"content":" 变量Bash 变量为弱类型事先不用指定值的类型，Bash 变量默认为全局变量，可以使用 local 关键字定义局部变量 bash # 默认为全局变量 s='this is a test' # 函数中使用 local 关键字定义局部变量 a() { local s='s in function a' echo $s } # 打印变量长度 echo ${#s} echo $s 注意: local 关键字只能在函数中使用 ","date":"2021-06-13","objectID":"/posts/bash-basice/:1:0","series":null,"tags":["bash"],"title":"Bash 基础","uri":"/posts/bash-basice/#变量"},{"categories":["bash"],"content":" 逻辑运算符 ! : 逻辑非; 表达式为 true 则返回 false，否则返回 true; 例: [ ! false ] 返回 true \u0026\u0026: 逻辑与; 两个表达式都为 true 才返回 true; 等价于 (-a) 表示; 例: [ $a -lt 20 -a $b -gt 100 ] 返回 true ||: 逻辑或; 有一个表达式为 true 则返回 true; 等价于 (-o) 表示; 例: [ $a -lt 20 -o $b -gt 100 ] 返回 false 示例 bash which iftop \u0026\u0026 echo \"iftop exist\" which iftop || echo \"iftop does not exist\" ","date":"2021-06-13","objectID":"/posts/bash-basice/:2:0","series":null,"tags":["bash"],"title":"Bash 基础","uri":"/posts/bash-basice/#逻辑运算符"},{"categories":["bash"],"content":" 比较运算符","date":"2021-06-13","objectID":"/posts/bash-basice/:3:0","series":null,"tags":["bash"],"title":"Bash 基础","uri":"/posts/bash-basice/#比较运算符"},{"categories":["bash"],"content":" 1.数字比较 -gt: 大于 -lt: 小于 -ge: 大于或等于 -le: 小于或等于 -ne: 不等于 -eq: 等于 ","date":"2021-06-13","objectID":"/posts/bash-basice/:3:1","series":null,"tags":["bash"],"title":"Bash 基础","uri":"/posts/bash-basice/#1数字比较"},{"categories":["bash"],"content":" 2.字符比较 [[ $str1 = $str2 ]]: 判断两个字符串是否相等 （等号前后有空格） [[ $str1 == $str2 ]]: 判断两个字符串是否相等，也可以是数字 [[ $str1 != $str2 ]]: 判断两个字符串是否不相等 检查字符串的字母排序情况，具体如下： [[ $str1 \u003e $str2 ]]: 如果 str1 的字母排序比 str2 大，则返回 true [[ $str1 \u003c $str2 ]]: 如果 str1 的字母排序比 str2 小，则返回 true ","date":"2021-06-13","objectID":"/posts/bash-basice/:3:2","series":null,"tags":["bash"],"title":"Bash 基础","uri":"/posts/bash-basice/#2字符比较"},{"categories":["bash"],"content":" 3.变量检测 [[ -z $str1 ]]: 如果字符串长度为 0，则为 true [[ -n $str1 ]]: 如果字符串长度不为 0，则为 true [[ $str1 ]]: 检测字符串是否为空，不为空返回 true ","date":"2021-06-13","objectID":"/posts/bash-basice/:3:3","series":null,"tags":["bash"],"title":"Bash 基础","uri":"/posts/bash-basice/#3变量检测"},{"categories":["bash"],"content":" 4.文件系统选项 [ -f $var ]: 判断是否为文件 [ -x $var ]: 判断文件是否有可执行权限 [ -d $var ]: 判断是否为一个目录 [ -e $var ]: 判断文件是否存在 [ -c $var ]: 判断文件是字符设备 （不知有啥用途） [ -b $var ]: 判断是否为设备文件 [ -w $var ]: 判断文件是否有可写权限”w“ [ -r $var ]: 判断文件是否有可读权限”r\" [ -L $var ]: 判断是否为符号链接 ","date":"2021-06-13","objectID":"/posts/bash-basice/:3:4","series":null,"tags":["bash"],"title":"Bash 基础","uri":"/posts/bash-basice/#4文件系统选项"},{"categories":["bash"],"content":" 数组Bash Shell 只支持一维数组（不支持多维数组），初始化时不需要定义数组大小（与 PHP 类似）。 与大部分编程语言类似，数组元素的下标由 0 开始。 Shell 数组用括号来表示，元素用\"空格\"符号分割开 bash arr=(\"first\" \"second\" \"third\") # 修改数组值 arr[0]='No.1' # 增加值 arr[3]='fourth' # 获取数组所有值 echo ${arr[@]} echo ${arr[*]} # 获取数组长度 echo ${#arr[@]} # 打印所有下标(索引)，从 0 开始 echo ${!arr[@]} # for 遍历数组，这个方法有时达不到理想效果, 参考 for 循环的坑 for a in ${arr[@]}; do echo $a done # for 通过下标遍历数组, 推荐使用这个方式 for i in ${!arr[@]}; do echo ${arr[$i]} done 关联数组，可以理解为 python 的字典 bash declare -A arrary array[\"name\"]=\"xiaoming\" array[\"age\"]=29 for k in ${!array[@]}; do echo \"$k =\u003e ${array[$k]}\" done 注意: 如果 key 字符串中含有空白符，for 循环时需要设定 IFS 才能正常遍历数组 for 循环遍历数组的坑–由 IFS 引起 bash #!/bin/bash string=( \"this is first line\" \"this is second line\" \"this is third line\" ) for line in ${string[@]}; do echo $line sleep 0.5 done 注意: 由于 for 循环是通过空白符(空格，换行，tab)截断数据进行循环的，所以数组中的字符串含有空白符会被截断处理。 ","date":"2021-06-13","objectID":"/posts/bash-basice/:4:0","series":null,"tags":["bash"],"title":"Bash 基础","uri":"/posts/bash-basice/#数组"},{"categories":["bash"],"content":" 条件判断语句","date":"2021-06-13","objectID":"/posts/bash-basice/:5:0","series":null,"tags":["bash"],"title":"Bash 基础","uri":"/posts/bash-basice/#条件判断语句"},{"categories":["bash"],"content":" 1. 使用 test 和 [ ] 进行条件判断test 与 [ ] 是对等的功能一致。 test bash [root@localhost ~]# test -f /etc/passwd \u0026\u0026 echo yes yes [root@localhost ~]# test -d /etc/ \u0026\u0026 echo yes yes 将test 替换为 [ ] bash [root@localhost ~]# [ -f /etc/passwd ] \u0026\u0026 echo yes yes [root@localhost ~]# [ -d /etc ] \u0026\u0026 echo yes yes Tips: [] 与其中的命令两边必须得空格隔开才行，否则会报错 bash [root@localhost ~]# [-d /etc ] \u0026\u0026 echo yes -bash: [-d: command not found 以上就是没有用空格隔开导致的错误 ","date":"2021-06-13","objectID":"/posts/bash-basice/:5:1","series":null,"tags":["bash"],"title":"Bash 基础","uri":"/posts/bash-basice/#1-使用-test-和---进行条件判断"},{"categories":["bash"],"content":" 2. if 语句，条件判断在其他编程语言中，if语句后面的对象是一个值为TRUE或FALSE的等式。bash shell脚本中的if语句不是这样的。 bash shell中的if语句运行在if行定义的命令。如果命令的退出状态是0（成功执行命令），将执行then后面的所有命令。 如果命令的退出状态是0以外的其他值，那么then后面的命令将不会执行，bash shell会移动到脚本的下一条命令。 单分支 bash if [[ $? -eq 0 ]]; then echo \"successfully\" else echo \"failed\" fi 多分支 bash read -p \"please input a number:\" num if [[ $num -le 10 ]]; then echo \"num 小于等于 10\" elif [[ $num -le 20 ]]; then # elif 可以有多个 echo \"num 小于等于 20 fi 扩展：可以直接通过命令执行状态进行判断 示例：服务监控脚本（pptpd 服务器监控） bash #!/bin/bash TIME=5 while :; do if netstat -anptl | grep -q \"pptpd\" # -q 不显示任何内容，此处只是判断不需要显示 then echo \"$(date +%Y-%m-%d' '%H:%M:%S) pptpd is runing...\" \u003e /tmp/pptpd.log else /etc/init.d/pptpd restart-kill /etc/init.d/pptpd start fi sleep $TIME done ","date":"2021-06-13","objectID":"/posts/bash-basice/:5:2","series":null,"tags":["bash"],"title":"Bash 基础","uri":"/posts/bash-basice/#2-if-语句条件判断"},{"categories":["bash"],"content":" 3. case 语句上面提到的『 if …. then …. fi 』对于变量的判断是以『比对』的方式来分辨的， 如果符合状态就进行某些行为，并且透过较多层次 (就是 elif …) 的方式来进行多个变量的程序码编写。 好，那么万一我有多个既定的变量内容，我所需要的变量就是 “hello” 及空字串两个， 那么我只要针对这两个变量来配置状况就好了，对吧？那么可以使用什么方式来设计呢？呵呵～就用 case … in …. esac 吧～，他的语法如下： bash case $变量名 in \"第一个变量值\") # 每个变量内容建议用双引号括起来，关键字则为小括号 echo 'first' ;; # 每项最后用两个分号表示结束。 \"第二个变量值\") echo 'second\" ;; *) # 最一个变量用星号来表示所有其他值 echo \"default\" ;; esac 示例 bash #!/bin/bash clear cat \u003c\u003c EOF Sys Admin Menu 1. Display disk space 2. Display memory usage 0. Exit menu EOF read -n 1 -p \"Enter option:\" option case $option in 1) df -hT ;; 2) free -m ;; 0) exit 0 ;; *) echo \"Warning: wrong choice, please re-select.\" esac ","date":"2021-06-13","objectID":"/posts/bash-basice/:5:3","series":null,"tags":["bash"],"title":"Bash 基础","uri":"/posts/bash-basice/#3-case-语句"},{"categories":["bash"],"content":" 循环语句","date":"2021-06-13","objectID":"/posts/bash-basice/:6:0","series":null,"tags":["bash"],"title":"Bash 基础","uri":"/posts/bash-basice/#循环语句"},{"categories":["bash"],"content":" 1. for 循环 bash # 1. 循环一个列表 for shname in $(ls *.sh) do name=$(echo \"$shname\" | awk -F. '{print $1}') echo $name done # 2. 指定循环次数 （有点像C语法，但记得双括号） for (( i=0;i\u003c10;i++)) { echo $i } # 3. 等价于2 for i in $(seq 1 10) do echo $i done ","date":"2021-06-13","objectID":"/posts/bash-basice/:6:1","series":null,"tags":["bash"],"title":"Bash 基础","uri":"/posts/bash-basice/#1-for-循环"},{"categories":["bash"],"content":" 2. while 循环while 循环，只有结果为真时（在linux退出状态为0）才会执行，直接结果为假时才终止循环。为真时执行，用true作为循环条件可以无限循环。 简单语法演示 bash while : do date +%F sleep 2 done 注意: 在linux中:表示真，可以替代true,以上示例是个死循环，需要添加终止条件。 示例 1 bash min=1 max=100 while [ $min -le $max ] do echo $min min=`expr $min + 1` done 示例 2 双括号形式，内部结构有点像C的语法，注意赋值：i=$(($i+1)) bash i=1 while(($i\u003c100)) do if(($i%4==0)) then echo $i fi i=$(($i+1)) done ","date":"2021-06-13","objectID":"/posts/bash-basice/:6:2","series":null,"tags":["bash"],"title":"Bash 基础","uri":"/posts/bash-basice/#2-while-循环"},{"categories":["bash"],"content":" 3. until 循环直到给定的结果为真时，停止循环。刚好与while循环相反。（貌似不常用） bash x=0 until [ $x -eq 9 ]; do let x++; echo $x; done ","date":"2021-06-13","objectID":"/posts/bash-basice/:6:3","series":null,"tags":["bash"],"title":"Bash 基础","uri":"/posts/bash-basice/#3-until-循环"},{"categories":["bash"],"content":" 4. 生成连续的数字，字母列表（序列） bash # 打印1到100的数字 echo {1..100} seq 100 # 打印小写所有字母 echo {a..z} # 打印大写所有字母 echo {A..Z} ","date":"2021-06-13","objectID":"/posts/bash-basice/:6:4","series":null,"tags":["bash"],"title":"Bash 基础","uri":"/posts/bash-basice/#4-生成连续的数字字母列表序列"},{"categories":["bash"],"content":" 5. 循环控制语句 break 命令不执行当前循环体内break下面的语句从当前循环退出. continue 命令是程序在本循体内忽略下面的语句,从循环头开始执行 ","date":"2021-06-13","objectID":"/posts/bash-basice/:6:5","series":null,"tags":["bash"],"title":"Bash 基础","uri":"/posts/bash-basice/#5-循环控制语句"},{"categories":["bash"],"content":" 函数定义函数 bash function f1() { echo 'this is f1' } function f2 { echo 'this is f2' } f3() { echo 'this is f3' } 函数的调用与传值 bash hello() { echo \"hello ${1}!\" } # 调用函数并传传递参数 hello $1 ","date":"2021-06-13","objectID":"/posts/bash-basice/:7:0","series":null,"tags":["bash"],"title":"Bash 基础","uri":"/posts/bash-basice/#函数"},{"categories":["devops"],"content":"Linux 默认使用密码登录，很不安全容易被暴力破解入侵。使用密钥登录可以增加安全性。下面将介绍如何配置密钥登录验证. ","date":"2021-06-13","objectID":"/posts/ssh-key/:0:0","series":null,"tags":["ssh"],"title":"SSH 密钥对的使用过程","uri":"/posts/ssh-key/#"},{"categories":["devops"],"content":" 生成 ssh 密钥对首先我们需要在自己的电脑上生成密钥对(公私钥) ","date":"2021-06-13","objectID":"/posts/ssh-key/:1:0","series":null,"tags":["ssh"],"title":"SSH 密钥对的使用过程","uri":"/posts/ssh-key/#生成-ssh-密钥对"},{"categories":["devops"],"content":" Linux由于 linux 和 macOS 自带 ssh 软件和终端，直接打开终端输入以下输入命令生成密钥对 bash [root@singhead ~]# ssh-keygen -t rsa Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa. Your public key has been saved in /root/.ssh/id_rsa.pub. The key fingerprint is: 15:a5:d1:4c:bc:dd:fa:0f:78:18:f6:78:4d:04:77:95 root@singhead The key's randomart image is: +--[ RSA 2048]----+ | o*o . *| | ++ E.| | o o ..| | . . ...| | S o ..| | . *.o | | + =..| | o ..| | o| +-----------------+ [root@singhead .ssh]# ls -l total 12 -rw------- 1 root root 1671 Oct 2 00:04 id_rsa -rw-r--r-- 1 root root 395 Oct 2 00:04 id_rsa.pub ","date":"2021-06-13","objectID":"/posts/ssh-key/:1:1","series":null,"tags":["ssh"],"title":"SSH 密钥对的使用过程","uri":"/posts/ssh-key/#linux"},{"categories":["devops"],"content":" Windows由于 Windows 环境问题，我们需要借助于 GitBash 这个工具来生成密钥对，如果你有使用终端管理工具（例如 Xshell, SecureCRT 等）也可以使用终端管理工具生成。 这里只介绍如何使用 GitBash 生成密钥的操作过程 下载安装 Git: https://gitforwindows.org/ 安装完成后，会有一个 GitBash 的终端可用，我们就用这个来操作 打开 GitBash 输入以下命令, 一路按 Enter 键即可完成，密钥对的生成，密钥默认存放 C:\\Users\\\u003c你的用户名\u003e\\.ssh 目录下 bash ssh-keygen -t rsa 不管那个系统平台使用的命令都是一样的 ","date":"2021-06-13","objectID":"/posts/ssh-key/:1:2","series":null,"tags":["ssh"],"title":"SSH 密钥对的使用过程","uri":"/posts/ssh-key/#windows"},{"categories":["devops"],"content":" 推送公钥文件到 linux 服务器中 bash [root@singhead ~]# cd .ssh/ [root@singhead .ssh]# ssh-copy-id -i id_rsa.pub root@192.168.1.20 [root@singhead .ssh]# ssh-copy-id -i id_rsa.pub root@192.168.1.21 Tips: 以上命令将公钥添加至主机的 /root/.ssh/authorized_keys 文件中 ","date":"2021-06-13","objectID":"/posts/ssh-key/:2:0","series":null,"tags":["ssh"],"title":"SSH 密钥对的使用过程","uri":"/posts/ssh-key/#推送公钥文件到-linux-服务器中"},{"categories":["devops"],"content":" 配置 ssh调整 linux 服务器设置,禁用密码验证，启用密钥验证对验证，并重启 SSH 服务 bash [root@singhead ~]# vim /etc/ssh/sshd_config PasswordAuthentication no PubkeyAuthentication yes AuthorizedKeysFile .ssh/authorized_keys [root@singhead ~]# service sshd restart ","date":"2021-06-13","objectID":"/posts/ssh-key/:3:0","series":null,"tags":["ssh"],"title":"SSH 密钥对的使用过程","uri":"/posts/ssh-key/#配置-ssh"},{"categories":["devops"],"content":" 取消初次连接确认在脚本中有时会使用 ssh 进行远程连接操作，如果是第一次 ssh 连接往往会提示你是否确认连接并要求你输入 yes, 才能继续。如何才能避免这个步骤呢？ 1. 通过 .ssh/config 配置文件 bash cat \u003e\u003e ~/.ssh/config \u003c\u003c EOF StrictHostKeyChecking no EOF 2. 在 ssh 命令加上一个参数 bash ssh username@ip_address -p 22 -o StrictHostKeyChecking=no ","date":"2021-06-13","objectID":"/posts/ssh-tips/:1:0","series":null,"tags":["ssh"],"title":"SSH 使用小技巧","uri":"/posts/ssh-tips/#取消初次连接确认"},{"categories":["devops"],"content":" SSH 密钥通过私钥计算公钥 bash ssh-keygen.exe -f ~/.ssh/id_rsa -y 查看公钥的指纹 bash ssh-keygen.exe -f ~/.ssh/id_rsa.pub -l ","date":"2021-06-13","objectID":"/posts/ssh-tips/:2:0","series":null,"tags":["ssh"],"title":"SSH 使用小技巧","uri":"/posts/ssh-tips/#ssh-密钥"},{"categories":["devops"],"content":" SSH agent 转发通过 OpenSSH 的 agent 转发功能，我们可以从 A 服务器直接连接 B 服务器而不需要将私钥放在 A 服务器 前提条件 A，B 服务器上 authorized_keys 文件中有相同的钥，使用这个公钥的私钥进行连接. 通过 .ssh/config 配置文件 写入如下配置, 然后正常连接服务器即可 bash cat \u003e\u003e ~/.ssh/config \u003c\u003c EOF Host example.cn ForwardAgent yes EOF 命令行方式 bash \u003e ssh-add -K ~/.ssh/id_rsa \u003e ssh -A root@example.cn -A：启动 agent 转发，具体可以 man ssh 默认 SSH 是启动 agent 的。如果不成功请检查 /etc/ssh/sshd_config 配置文件 AllowAgentForwarding 选项及 /etc/ssh/ssh_config 文件是否有 ForwardAgent no 配置项，改为 yes 即可。 ","date":"2021-06-13","objectID":"/posts/ssh-tips/:3:0","series":null,"tags":["ssh"],"title":"SSH 使用小技巧","uri":"/posts/ssh-tips/#ssh-agent-转发"},{"categories":["devops"],"content":" ssh 代理设置实验环境 Server： 192.168.0.1 Gateway: 100.100.100.100 Client: 100.100.100.101 说明：其中 Server 不可以访问外网; Gateway 可以访问 Server， 同时与外网互通; Client 不能直接访问 Server 需要先连接 Gateway 才可以访问 Server。 ","date":"2021-06-13","objectID":"/posts/ssh-tips/:4:0","series":null,"tags":["ssh"],"title":"SSH 使用小技巧","uri":"/posts/ssh-tips/#ssh-代理设置"},{"categories":["devops"],"content":" ssh 端口转发ssh 端口转发功能，实现 Clinet 直接访问 Server, 在 Gateway 执行命令如下： bash ssh -CfNg -T -L 2233:192.168.0.1:22 root@192.168.0.1 解释: -C 启用压缩，可以减少网络流量，但会增加 CPU 使用率。 -f 将 SSH 客户端转入后台运行，通常与 -N 一起使用。 -N 不执行远程命令，仅进行端口转发。 -g 允许远程主机连接到本地转发端口。如果在多路复用连接上使用，则必须在主进程上指定此选项。 -T 禁用伪终端分配，适用于执行单个命令时。 -L 是本地端口转发，通过将本地 2233 与 Server 的 22 端口相关联，以使 Client 访问 2233 时自动转发到 Server 的 22 端口。 ","date":"2021-06-13","objectID":"/posts/ssh-tips/:4:1","series":null,"tags":["ssh"],"title":"SSH 使用小技巧","uri":"/posts/ssh-tips/#ssh-端口转发"},{"categories":["devops"],"content":" ssh ProxyCommand通过配置 ~/.ssh/config 文件也可以达到 ssh 代理的功能，具体配置如下（在 Client 上配置） bash [root@localhost ~]# vim .ssh/config Host server HostName 192.168.0.1 Port 22 ProxyCommand ssh -l root -p 22 100.100.100.100 -W %h:%p IdentityFile /root/.ssh/id_rsa # 配置好后，就可以直接通过以下命令连接 Server [root@localhost ~]# ssh root@server 说明 Host 别名，取一个主别名 HostName 主机的ip地址，在此例中是 Server 的 ip 地址，也可以是域名 ProxyCommand ssh 代理的命令 -W 后面是 Server 的 ip 地址及端口，会自动替换 IdentityFile 表示连接使用的私钥 ","date":"2021-06-13","objectID":"/posts/ssh-tips/:4:2","series":null,"tags":["ssh"],"title":"SSH 使用小技巧","uri":"/posts/ssh-tips/#ssh-proxycommand"},{"categories":["devops"],"content":" ssh 命令行实现中转代理当然我们也可以不写配置文件直接通过命令也是可以进行 ssh 代理跳转的，命令如下： bash ssh -t -p 22 userb@123.456.789.110 \"ssh userc@192.168.1.111\" 注： 因为 ssh 是可以直接远程执行命令的, 不可以少 -t 参数 ","date":"2021-06-13","objectID":"/posts/ssh-tips/:4:3","series":null,"tags":["ssh"],"title":"SSH 使用小技巧","uri":"/posts/ssh-tips/#ssh-命令行实现中转代理"},{"categories":["devops"],"content":" ssh socket5 代理执行以下命令就可以创建一个基于 ssh 的 socket5 代理了,最好将此放入后台运行。 bash ssh -D 8080 -f -C -q -N fred@server.example.org # 放入后台运行 nohup ssh -D 8080 -f -C -q -N fred@server.example.org \u0026 ","date":"2021-06-13","objectID":"/posts/ssh-tips/:4:4","series":null,"tags":["ssh"],"title":"SSH 使用小技巧","uri":"/posts/ssh-tips/#ssh-socket5-代理"},{"categories":["devops"],"content":" 通过环境变量 DISPLAY 和 SSH_ASKPASS 获取 ssh key 密码 bash DISPLAY=\":0.0\" SSH_ASKPASS=~/.ssh/askpass.sh ssh-add ~/.ssh/id_rsa ","date":"2021-06-13","objectID":"/posts/ssh-tips/:4:5","series":null,"tags":["ssh"],"title":"SSH 使用小技巧","uri":"/posts/ssh-tips/#通过环境变量-display-和-ssh_askpass-获取-ssh-key-密码"},{"categories":["network"],"content":" 一、规则表 filter表，包含三个规则链：INPUT、FORWARD、OUTPUT。主要用于对数据包进行过滤 nat表，包含三个规则链：PREROUTING、POSTROUTING、OUTPUT。主要用于网络地址转换（修改数据包的IP地址） mangle表，包含五个规则链：PREROUTING、POSTROUTING、INPUT、OUTPUT、FORWARD。主要用于修改数据包的TOS（服务类型）、TTL（生存周期）值以及为数据包设置Mark标记，以实现Qos调整以及策略路由等应用，由于需要相应的路由设备支持，因为应用并不广泛。 raw表，包含两条规则链：OUTPUT、PREROUTING。主要用于决定数据包是否被状态跟踪机制处理。在匹配数据包时，raw表优先于其他表。 ","date":"2021-06-13","objectID":"/posts/iptables/:1:0","series":null,"tags":["iptables"],"title":"iptable 简单入门","uri":"/posts/iptables/#一规则表"},{"categories":["network"],"content":" 二、规则链 INPUT链：当接收到访问防火墙本机地址的数据包（入站）时，应用此链的规则 OUTPUT链：当防火墙本机向外发送数据包（出站）时应用此链的规则 FORWARD链：当接收到需要通过防火墙发送给其他地址的数据包（转发）时，应用此链的规则 PREROUTING链：在对数据包作路由选择之前，应用此链的规则 POSTROUTING链：在对数据包作路由选择之后，应用此链的规则 ","date":"2021-06-13","objectID":"/posts/iptables/:2:0","series":null,"tags":["iptables"],"title":"iptable 简单入门","uri":"/posts/iptables/#二规则链"},{"categories":["network"],"content":" 三、应用顺序 规则表之间的应用顺序 当数据包抵达防火墙时，将依次应用 raw、mangle、nat、filter 表中对应链内的规则（如果有的话）。 规则链之间的应用顺序 入站数据流向：来自外界的数据包到达防火墙后，首先由PREROUTING规则链处理（是否修改数据包地址等），之后会进行路由选择（判断该数据包该发往何处），如果数据包的目标地址是防火墙本机（如Internet 用户访问防火墙中的Web服务的数据包），那么内核将其传递给INPUT链进行处理（决定是否允许通过等），通过以后再交给系统上层的应用程序（如httpd服务器）进行响应。 转发数据流向：来自外界的数据包到达防火墙后，首先被PREROUTING规则处理，之后会进行路由选择，如果数据包的目标地址是其他外部地址（如局域网用户通过网关访问QQ站点的数据包），则内核将其传给FORWARD链进行处理（是否转发或拦截），然后在交给POSTROUTING规则链（是否修改数据包的地址等）进行处理。 出站的数据流向：防火墙本机向外部地址发送的数据包（如防火墙主机中测试公网DNS服务时），首先被OUTPUT规则链处理，之后进行路由选择，然后传递给POSTROUTING规则链（是否修改数据包地址等）进行处理。 ","date":"2021-06-13","objectID":"/posts/iptables/:3:0","series":null,"tags":["iptables"],"title":"iptable 简单入门","uri":"/posts/iptables/#三应用顺序"},{"categories":["network"],"content":" 四、iptables 基础语法","date":"2021-06-13","objectID":"/posts/iptables/:4:0","series":null,"tags":["iptables"],"title":"iptable 简单入门","uri":"/posts/iptables/#四iptables-基础语法"},{"categories":["network"],"content":" 1. iptable 参数说明 bash -A 在链的末尾添加一个规则 -I 在链中插入一条规则，如未指定规则序号，则插入在首行 -D 删除一个规则，按规则序号或内容删除 -F 清空链中所有规则，如未指定链则清空表中所有链的规则 -L 以列表的形式显示规则 -N 新建一个条用户自定义的规则链 -P 指定链的默认规则 -n 以数字的形式显示结果 -v 查看规则列表时显示详细信息 --line-numbers 查看规则列表时，同时显示规则序号 ","date":"2021-06-13","objectID":"/posts/iptables/:4:1","series":null,"tags":["iptables"],"title":"iptable 简单入门","uri":"/posts/iptables/#1-iptable-参数说明"},{"categories":["network"],"content":" 2. 添加及插入规则在 filter 表的 INPUT 链中添加一条规则 bash iptables -t filter -A INPUT -p tcp -j ACCEPT 在 filter 表的 INPUT 链中插入一条规则 bash iptables -t filter -I INPUT -p udp -j ACCEPT 在 filter 表的 INPUT 链中插入一条规则（作为链中的第二条规则） bash iptables -t filter -I INPUT 2 -p icmp -j ACCEPT ","date":"2021-06-13","objectID":"/posts/iptables/:4:2","series":null,"tags":["iptables"],"title":"iptable 简单入门","uri":"/posts/iptables/#2-添加及插入规则"},{"categories":["network"],"content":" 3. 显示规则列表查看 filter 表 INPUT 链中的所有规则，同时显示各条规则的顺序号 bash iptables -L INPUT --line-numbers 查看 filter 表各链所有规则的详细信息，同时以数字（速度更快）的形式显示地址及端口信息 bash iptables -vnL ","date":"2021-06-13","objectID":"/posts/iptables/:4:3","series":null,"tags":["iptables"],"title":"iptable 简单入门","uri":"/posts/iptables/#3-显示规则列表"},{"categories":["network"],"content":" 4. 删除、清空规则删除第二条规则 bash iptables -D INPUT 2 清空 filter 表中所有链内的规则 bash iptables -F iptables -t filter -F 清空 nat/mangle 表中所有链内的规则 bash iptables -t nat -F iptables -t mangle -F ","date":"2021-06-13","objectID":"/posts/iptables/:4:4","series":null,"tags":["iptables"],"title":"iptable 简单入门","uri":"/posts/iptables/#4-删除清空规则"},{"categories":["network"],"content":" 5. 设置规则链的默认策略设置 filter 表的 INPUT 链默认策略为 DROP bash iptables -t filter -P INPUT DROP 设置 filter 表的 OUTPUT 链默认策略为 ACCEPT bash iptables -t filter -P OUTPUT ACCEPT ","date":"2021-06-13","objectID":"/posts/iptables/:4:5","series":null,"tags":["iptables"],"title":"iptable 简单入门","uri":"/posts/iptables/#5-设置规则链的默认策略"},{"categories":["network"],"content":" 6. 获得 iptables 相关选项用法的帮助信息 bash iptables -p icmp -h ","date":"2021-06-13","objectID":"/posts/iptables/:4:6","series":null,"tags":["iptables"],"title":"iptable 简单入门","uri":"/posts/iptables/#6-获得-iptables-相关选项用法的帮助信息"},{"categories":["network"],"content":" 五、iptables 条件匹配协议匹配：用于检查数据包的网络协议，允许使用的协议名包含在 /etc/protocols 文件中。使用 -p 拒绝所有 icmp 包进入 bash iptables -I INPUT -p icmp -j REJECT 允许转发所有非 icmp 协议的数据包（！取反） bash iptables -A FORWARD -p ! icmp -j ACCEPT 地址匹配：用于检查数据包的IP地址、网络地址。使用 -s 拒绝转发源地址为192.168.1.11主机的数据 bash iptables -A FORWARD -s 192.168.1.11 -j REJECT 拒绝转发目标地址为 192.168.2.0/24 网段的数据 bash iptables -A FORWARD -d 192.168.2.0/24 -j REJECT 网络接口匹配：使用 -o 出接口 -i 进接口 bash iptables -A INPUT -i eth1 -s 192.168.0.11 -j DROP iptables -A INPUT -o eth0 -d 192.168.1.10 -j ACCEPT 端口匹配：使用 --dport --sport 需要以 “-p tcp” 或 “-p udp” 为前提 允许转发局域网的 DNS 请求 bash iptables -A FORWARD -s 192.168.0.0/24 -p udp --dport 53 -j ACCEPT iptables -A FORWARD -d 192.168.0.0/24 -p udp --sport 53 -j ACCEPT 允许开放本机从 TCP 端口 20~1024 提供服务 bash iptables -A INPUT -p tcp --dport 20:1024 -j ACCEPT iptables -A OUTPUT -p tcp --dport 20:1024 -j ACCEPT ","date":"2021-06-13","objectID":"/posts/iptables/:5:0","series":null,"tags":["iptables"],"title":"iptable 简单入门","uri":"/posts/iptables/#五iptables-条件匹配"},{"categories":["network"],"content":" 六、示例 bash # Firewall configuration written by system-config-securitylevel # Manual customization of this file is not recommended. *filter # 默认策略 :INPUT DROP [5278:800028] :FORWARD DROP [5278:800028] :OUTPUT ACCEPT [5278:800028] :RH-Firewall-1-INPUT - [5278:800028] # 自定义规则链 -A INPUT -j RH-Firewall-1-INPUT -A FORWARD -j RH-Firewall-1-INPUT # 允许回环接口访问 -A RH-Firewall-1-INPUT -i lo -j ACCEPT # 状态检测，RELATED（相关的状态），ESTABLISHED(建立的) -A RH-Firewall-1-INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT # 允许icmp -A RH-Firewall-1-INPUT -p icmp -m icmp --icmp-type 0 -j ACCEPT # 允许icmp -A RH-Firewall-1-INPUT -p icmp -m icmp --icmp-type 3 -j ACCEPT # 开放相应服务的端口 -A RH-Firewall-1-INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT -A RH-Firewall-1-INPUT -p tcp -m state --state NEW -m tcp --dport 8001:8015 -j ACCEPT -A RH-Firewall-1-INPUT -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEPT -A RH-Firewall-1-INPUT -p tcp -m state --state NEW -m tcp --dport 8080 -j ACCEPT -A RH-Firewall-1-INPUT -p tcp -m state --state NEW -m tcp --dport 3000 -j ACCEPT -A RH-Firewall-1-INPUT -p tcp -m state --state NEW -m tcp --dport 3001 -j ACCEPT -A RH-Firewall-1-INPUT -p tcp -m state --state NEW -m tcp --dport 110 -j ACCEPT -A RH-Firewall-1-INPUT -p tcp -m state --state NEW -m tcp --dport 25 -j ACCEPT -A RH-Firewall-1-INPUT -s 183.62.255.122,183.62.255.123,120.236.168.22,10.30.0.167 -p tcp -m state --state NEW -m tcp --dport 3306 -j ACCEPT # 开放zabbix服务端口 -A RH-Firewall-1-INPUT -s 10.30.0.167 -m state --state NEW -m tcp -p tcp --dport 10050:10051 -j ACCEPT -A RH-Firewall-1-INPUT -s 10.30.0.167 -m state --state NEW -m udp -p udp --dport 10050:10051 -j ACCEPT COMMIT ","date":"2021-06-13","objectID":"/posts/iptables/:6:0","series":null,"tags":["iptables"],"title":"iptable 简单入门","uri":"/posts/iptables/#六示例"},{"categories":["network"],"content":" 穷人的 VPNsshuttle 是一个使用简单的轻量级全局代理工具(穷人的vpn)，以 ubuntu 18.04 为例演示如何使用, 使用前提是你有一台远程的 linux 服务器 Github 官方仓库: https://github.com/sshuttle/sshuttle 安装 bash sudo apt install sshuttle 使用 使用前先将不需要网络代理地址段列出来，例如本地局域网 192.168.1.0/24 bash sshuttle --dns -r username@server_ipaddress:port -x 192.168.1.0/24 -x server_ipaddress 0/0 -D 注意: 如果出现 fatal: server died with error code 255 错误，请使用 -x 选项排除服务器 ip https://github.com/sshuttle/sshuttle/issues/150 ","date":"2021-06-13","objectID":"/posts/sshuttle/:1:0","series":null,"tags":["vpn","sshuttle"],"title":"sshuttle 轻量级全局代理工具","uri":"/posts/sshuttle/#穷人的-vpn"},{"categories":["network"],"content":" 番外其他的全局代理软件 Linux 下的有 proxychains 下载地址 redsocks 下载地址 tsocks 下载地址 sshuttle Github - sshuttle macOS 下的有 Proxifier 下载地址 ProxyCap 下载地址 Windows 下的有 Proxifier 下载地址 ProxyCap 下载地址 ","date":"2021-06-13","objectID":"/posts/sshuttle/:2:0","series":null,"tags":["vpn","sshuttle"],"title":"sshuttle 轻量级全局代理工具","uri":"/posts/sshuttle/#番外"},{"categories":["network"],"content":" ProxifierProxifier 允许不支持通过代理服务器工作的网络应用程序通过SOCKS或HTTPS代理和链进行操作。 操作参考 https://blog.csdn.net/wu_cai_/article/details/80271478 注册码 用户名可以随意填写 Windows 5EZ8G-C3WL5-B56YG-SCXM9-6QZAP G3ZC7-7YGPY-FZD3A-FMNF9-ENTJB YTZGN-FYT53-J253L-ZQZS4-YLBN9 macOS P427L-9Y552-5433E-8DSR3-58Z68 ","date":"2021-06-13","objectID":"/posts/sshuttle/:2:1","series":null,"tags":["vpn","sshuttle"],"title":"sshuttle 轻量级全局代理工具","uri":"/posts/sshuttle/#proxifier"},{"categories":["vmware"],"content":" 1. 安装 vmware-tools 工具 bash [root@localhost ~]# mount /dev/cdrom /mnt mount: block device /dev/sr0 is write-protected, mounting read-only [root@localhost ~]# cp /mnt/VMwareTools-10.0.0-2977863.tar.gz . [root@localhost ~]# tar xzf VMwareTools-10.0.0-2977863.tar.gz [root@localhost ~]# cd vmware-tools-distrib/ [root@localhost vmware-tools-distrib]# ./vmware-install.pl [root@localhost vmware-tools-distrib]# ./vmware-install.real.pl ","date":"2021-06-13","objectID":"/posts/vmware-linux-share/:1:0","series":null,"tags":["vmware"],"title":"VMware - Linux 客户机中装载共享文件夹","uri":"/posts/vmware-linux-share/#1-安装-vmware-tools-工具"},{"categories":["vmware"],"content":" 2. 重启虚拟机，设置共享文件夹，挂载共享文件夹 bash [root@localhost ~]# vmware-hgfsclient data [root@localhost ~]# mount -t vmhgfs .host:/data /mnt [root@localhost ~]# ls /mnt/ bssh env2.7 Fabric-1.13.1 pssh-2.3.1 pytest test WTools ","date":"2021-06-13","objectID":"/posts/vmware-linux-share/:2:0","series":null,"tags":["vmware"],"title":"VMware - Linux 客户机中装载共享文件夹","uri":"/posts/vmware-linux-share/#2-重启虚拟机设置共享文件夹挂载共享文件夹"},{"categories":["devops","git"],"content":"当 ssh key 文件不放在标准目录下， git 进行 clone push 操作时如何使用指定位置的 ssh key ","date":"2021-06-13","objectID":"/posts/git-keys/:0:0","series":null,"tags":["git"],"title":"Git 使用指定的 key 连接","uri":"/posts/git-keys/#"},{"categories":["devops","git"],"content":" 最佳解决方案在 ~/.ssh/config 中添加配置 ssh host github.com HostName github.com IdentityFile /data/sshkey/github_rsa User git 保持密钥的权限为 400 ","date":"2021-06-13","objectID":"/posts/git-keys/:1:0","series":null,"tags":["git"],"title":"Git 使用指定的 key 连接","uri":"/posts/git-keys/#最佳解决方案"},{"categories":["devops","git"],"content":" 次佳解决方案环境变量 GIT_SSH_COMMAND 从 Git 版本 2.3.0 可以使用环境变量 GIT_SSH_COMMAND 如下所示 bash GIT_SSH_COMMAND=\"ssh -i /data/sshkey/github_rsa\" git clone git@github.com:test/test.git 请注意，-i 有时可以被您的配置文件覆盖，在这种情况下，您应该给 SSH 一个空配置文件，如下所示 bash GIT_SSH_COMMAND=\"ssh -i /data/sshkey/github_rsa -F /dev/null\" git clone git@github.com:test/test.git 配置 core.sshCommand： 从 Git 版本 2.10.0，您可以配置每个 repo 或全局，所以您不必再设置环境变量！ bash git config core.sshCommand \"ssh -i ~/.ssh/id_rsa_example -F /dev/null\" git pull git push 参考文档: https://blog.csdn.net/SCHOLAR_II/article/details/72191042 ","date":"2021-06-13","objectID":"/posts/git-keys/:2:0","series":null,"tags":["git"],"title":"Git 使用指定的 key 连接","uri":"/posts/git-keys/#次佳解决方案"},{"categories":["devops","git"],"content":" 安装Git bash yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel perl-devel yum install git 接下来我们 创建一个 git 用户组和用户，用来运行 git 服务： bash useradd -m git ","date":"2021-06-13","objectID":"/posts/git-repo/:1:0","series":null,"tags":["git"],"title":"Git 服务器搭建","uri":"/posts/git-repo/#安装git"},{"categories":["devops","git"],"content":" 创建证书登录收集所有需要登录的用户的公钥，公钥位于id_rsa.pub文件中，把我们的公钥导入到 /home/git/.ssh/authorized_keys 文件里，一行一个。 如果没有该文件创建它： bash su - git mkdir .ssh chmod 755 .ssh touch .ssh/authorized_keys chmod 644 .ssh/authorized_keys ","date":"2021-06-13","objectID":"/posts/git-repo/:2:0","series":null,"tags":["git"],"title":"Git 服务器搭建","uri":"/posts/git-repo/#创建证书登录"},{"categories":["devops","git"],"content":" 初始化 Git 仓库首先我们选定一个目录作为 Git 仓库，假定是 /home/git/gitrepo/runoob.git，在 /home/git/gitrepo 目录下输入命令： bash mkdir gitrepo cd gitrepo git init --bare runoob.git 以上命令 Git 创建一个空仓库，服务器上的 Git 仓库通常都以 .git 结尾。 注意: 如果你操作过程使用的用户不是 git 记得将目录权限改为 git 所有 ","date":"2021-06-13","objectID":"/posts/git-repo/:3:0","series":null,"tags":["git"],"title":"Git 服务器搭建","uri":"/posts/git-repo/#初始化-git-仓库"},{"categories":["devops","git"],"content":" 克隆仓库 bash git clone git@192.168.45.4:gitrepo/runoob.git 192.168.45.4 为 Git 所在服务器 ip ，你需要将其修改为你自己的 Git 服务 ip 这样我们的 Git 服务器安装就完成。 ","date":"2021-06-13","objectID":"/posts/git-repo/:4:0","series":null,"tags":["git"],"title":"Git 服务器搭建","uri":"/posts/git-repo/#克隆仓库"},{"categories":["devops","git"],"content":" 迁移 Git 仓库如果你想从别的 Git 托管服务器那里复制一份源代码到新的 Git 托管服务器上的话，可以通过以下步骤来操作。 这个文档只是让我们知道手动如何操作，大部分的 Git 代码托管平台和管理软件(Github, Gitlab, Gitee，Gogs, Gitea) 都支持仓库的在线克隆 从原地址克隆一份裸版本库，比如原本托管于 GitHub bash git clone --bare git://github.com/username/project.git 然后到新的 Git 服务器上创建一个新项目，比如 GitCafe。 以镜像推送的方式上传代码到 GitCafe 服务器上。 bash cd project.git git push --mirror git@gitcafe.com/username/newproject.git 删除本地代码 bash cd .. rm -rf project.git 到新服务器 GitCafe 上找到 Clone 地址，直接 Clone 到本地就可以了。 bash git clone git@gitcafe.com/username/newproject.git 这种方式可以保留原版本库中的所有内容。提交前要删除本地 remotes 中的分支引用，这样就不会将 remotes 里面的远程分支也推到服务器上去: 来源: http://blog.csdn.net/candyguy242/article/details/45920111 ","date":"2021-06-13","objectID":"/posts/git-migration/:1:0","series":null,"tags":["git"],"title":"Git 仓库完整迁移含历史记录","uri":"/posts/git-migration/#迁移-git-仓库"},{"categories":["devops","git"],"content":"Gitea 的部署安装很简单，直接从官方下载 gitea 二进制包运行就可以了 官方文档: https://docs.gitea.io/zh-cn/install-from-binary/ ","date":"2021-06-13","objectID":"/posts/gitea/:0:0","series":null,"tags":["gitea"],"title":"Gitea 部署安装","uri":"/posts/gitea/#"},{"categories":["devops","git"],"content":" 二进制部署 gitea","date":"2021-06-13","objectID":"/posts/gitea/:1:0","series":null,"tags":["gitea"],"title":"Gitea 部署安装","uri":"/posts/gitea/#二进制部署-gitea"},{"categories":["devops","git"],"content":" 安装 gitgit 版本只能是 2.x 及以上的版本，由于 centos 仓库自带的 git 版本默认为 1.x 不满足 gitea 的需求，需要使用第三方 YUM 安装 git 创建仓库配置文件 /etc/yum.repos.d/wandisco-git.repo ini [wandisco-git] name=Wandisco GIT Repository baseurl=http://opensource.wandisco.com/centos/7/git/$basearch/ enabled=1 gpgcheck=1 gpgkey=http://opensource.wandisco.com/RPM-GPG-KEY-WANdisco 导入验证密钥 bash rpm --import http://opensource.wandisco.com/RPM-GPG-KEY-WANdisco 安装 git bash yum install git git --version 参考文档: https://www.cnblogs.com/zhaoxxnbsp/p/12674339.html ","date":"2021-06-13","objectID":"/posts/gitea/:1:1","series":null,"tags":["gitea"],"title":"Gitea 部署安装","uri":"/posts/gitea/#安装-git"},{"categories":["devops","git"],"content":" 安装 gitea我们需要使用 git 用户运行 gitea，所以需要先创建 git 用户，执行以下命令 bash useradd -d /data/git-data -m git 接下来的操作我们都使用 git 用户进行，执行 su - git 基于二进制的安装非常简单，只要从 下载页面 选择对应平台，拷贝下载 URL，执行以下命令即可（以Linux为例）： bash wget -O gitea https://dl.gitea.io/gitea/1.14.2/gitea-1.14.2-linux-amd64 chmod +x gitea 让 gitea 跑起来，执行命令 bash ./gitea web 现在你可以在浏览器打开 http://\u003cyour_server_ip\u003e:3000 进行配置了 gitea 支持的数据库有 SQLite, MySQL 和 PostgreSQL，你可以选择你喜欢的数据库来存放 gitea 相关的数据，如果是测试可以直接使用 SQLite ","date":"2021-06-13","objectID":"/posts/gitea/:1:2","series":null,"tags":["gitea"],"title":"Gitea 部署安装","uri":"/posts/gitea/#安装-gitea"},{"categories":["devops","git"],"content":" 配置反向代理在日常使用过程最好还是做下反向代理的配置，使用标准的 http(s) 端口提供服务，下面列出了常的 web 应用配置反向的的配置 nginx 配置 text server { listen 80; server_name \u003cyour_domain\u003e; location / { proxy_pass http://127.0.0.1:3000; } } apache 配置 bash \u003cVirtualHost *:80\u003e ServerName \u003cyour_domain\u003e ProxyRequests Off ProxyPreserveHost On ProxyPass / http://127.0.0.1:3000/ ProxyPassReverse / http://127.0.0.1:3000/ \u003cproxy *\u003e AllowOverride None Order Deny,Allow Allow from all \u003c/proxy\u003e \u003c/VirtualHost\u003e caddy2 配置 text \u003cyour_domain\u003e { reverse_proxy localhost:3000 } ","date":"2021-06-13","objectID":"/posts/gitea/:1:3","series":null,"tags":["gitea"],"title":"Gitea 部署安装","uri":"/posts/gitea/#配置反向代理"},{"categories":["devops","git"],"content":" 部署 Gitea 和 Gogs 遇到的坑 Gogs 和 Gitea 依赖于 git 2.0 及以上的版本 Gogs 和 Gitea 查找 git 相关命令的路径固定为 /usr/bin，只配置 PATH 环境变量是没有用的，有以下错误提示: text Failed to execute git command: exec: \"git-upload-pack\": executable file not found in $PATH fatal: Could not read from remote repository. 解决方法：使用软链接将 git 相关命令链接至 /usr/bin 目录下(这个只针对 git 安装命令路径不是 /usr/bin 的情况)， 执行命令 ln -s /usr/local/git/bin/* /usr/bin/ ","date":"2021-06-13","objectID":"/posts/gitea/:2:0","series":null,"tags":["gitea"],"title":"Gitea 部署安装","uri":"/posts/gitea/#部署-gitea-和-gogs-遇到的坑"},{"categories":["macOS"],"content":" 视频格式转换ffmpeg 下载站点 bash ffmpeg -i 2020年MySQL数据库入门到精通.flv -codec copy 2020年MySQL数据库入门到精通.mov ","date":"2021-06-12","objectID":"/posts/macos-cli/:1:0","series":null,"tags":["macOS"],"title":"macOS 命令行","uri":"/posts/macos-cli/#视频格式转换"},{"categories":["macOS"],"content":" 清理DNS缓存 bash sudo killall -HUP mDNSResponder; say DNS cache has been flushed ","date":"2021-06-12","objectID":"/posts/macos-cli/:2:0","series":null,"tags":["macOS"],"title":"macOS 命令行","uri":"/posts/macos-cli/#清理dns缓存"},{"categories":["macOS"],"content":" brew 使用代理如果碰巧你的 brew 更新缓慢，可以试试让 brew 走代理更新程序包。 text export ALL_PROXY=socks5://127.0.0.1:your_port_number ","date":"2021-06-12","objectID":"/posts/macos-cli/:3:0","series":null,"tags":["macOS"],"title":"macOS 命令行","uri":"/posts/macos-cli/#brew-使用代理"},{"categories":["macOS"],"content":" 命令格式化 APFS 格式 U 盘语法 text diskutil eraseDisk format name [APM[Format]|MBR[Format]|GPT[Format]] format: 文件系统 name: 设备卷标名 格式化 U 盘前先用 diskutil list 命令查询设备号 text sudo diskutil eraseDisk FAT32 san MBRFormat /dev/disk3 APFS 格式是无法直接进行格式化的，我们需要首先删除 APFS 容器。执行如下命令 text sudo diskutil apfs deleteContainer /dev/disk3 然后你就会发现，你的 U 盘格式自动变成了 Mac OS 扩展(日志式) ","date":"2021-06-12","objectID":"/posts/macos-cli/:4:0","series":null,"tags":["macOS"],"title":"macOS 命令行","uri":"/posts/macos-cli/#命令格式化-apfs-格式-u-盘"},{"categories":["macOS"],"content":" 显示隐藏文件夹在 Windows 上隐藏文件夹大家应该都是老手了，转到 Mac 后，却发现隐藏文件夹和自己想象有那么一些不一样。为了更好的把大家的「小秘密」藏到内心最深处的地方，也可以使用两段命令来完成操作。跟前文一样，我们需要获取文件夹的路径，然后在终端中输入以下代码： bash chflags hidden ~/Desktop/Hidden 你也可以使用 nohidden 重新让该文件夹显示。如果你要显示全部文件，推荐大家直接使用快捷键「Shift + Command + .」即可显示全部隐藏文件。 ","date":"2021-06-12","objectID":"/posts/macos-cli/:5:0","series":null,"tags":["macOS"],"title":"macOS 命令行","uri":"/posts/macos-cli/#显示隐藏文件夹"},{"categories":["macOS"],"content":" 允许从陌生来源安装软件 bash sudo spctl --master-disable ","date":"2021-06-12","objectID":"/posts/macos-cli/:6:0","series":null,"tags":["macOS"],"title":"macOS 命令行","uri":"/posts/macos-cli/#允许从陌生来源安装软件"},{"categories":["macOS"],"content":" 安装开发组件 - XCode从 App store 或苹果开发者网站安装 Xcode 紧接着，安装 Xcode command line tools，运行： bash xcode-select --install 运行命令后，按照指引，你将完成 Xcode command line tools 安装。 注: 如果你不是一名 iOS 或 OSX 开发者，可以跳过安装 XCode 的过程，直接安装 Xcode command line tools。安装完成后，你将可以直接在 terminal 中使用主要的命令，比如：make, GCC, clang, perl, svn, git, size, strip, strings, libtool, cpp 等等。 如果你想了解 Xcode command line tools 包含多少可用的命令，可以到 /Library/Developer/CommandLineTools/ 查看。 ","date":"2021-06-12","objectID":"/posts/macos-develop/:1:0","series":null,"tags":["macOS"],"title":"macOS 开发配置","uri":"/posts/macos-develop/#安装开发组件---xcode"},{"categories":["macOS"],"content":" 配置源码管理工具 - GitGitHub git 帮助文档: https://docs.github.com/en/get-started/quickstart/set-up-git ","date":"2021-06-12","objectID":"/posts/macos-develop/:2:0","series":null,"tags":["macOS"],"title":"macOS 开发配置","uri":"/posts/macos-develop/#配置源码管理工具---git"},{"categories":["macOS"],"content":" Git 全局配置 bash # 配置 github 加速, 仅适用于 https git config --global url.\"https://gh.wglee.org/github.com\".insteadOf \"https://github.com\" # 配置用户信息 git config --global user.name \"Your Name Here\" git config --global user.email \"your_email@youremail.com\" # 如果你不想每次都输入用户名和密码的话, 执行下面命令 git config --global credential.helper osxkeychain 提示: Git 全局配置文件 ~/.gitconfig ","date":"2021-06-12","objectID":"/posts/macos-develop/:2:1","series":null,"tags":["macOS"],"title":"macOS 开发配置","uri":"/posts/macos-develop/#git-全局配置"},{"categories":["macOS"],"content":" 配置 github ssh 加速 bash cat \u003e\u003e ~/.ssh/config \u003c\u003cEOF Host github.com Hostname ssh.github.com Port 443 User git IdentityFile ~/.ssh/id_rsa EOF ","date":"2021-06-12","objectID":"/posts/macos-develop/:2:2","series":null,"tags":["macOS"],"title":"macOS 开发配置","uri":"/posts/macos-develop/#配置-github-ssh-加速"},{"categories":["macOS"],"content":" Git 全局忽略文件创建一个新文件 ~/.gitignore ，并将以下内容添加进去，这样全部 git 仓库将会忽略以下内容所提及的文件。 text # Folder view configuration files .DS_Store Desktop.ini $RECYCLE.BIN/ # Thumbnail cache files ._* Thumbs.db # Files that might appear on external disks .Spotlight-V100 .Trashes # Compiled Python files *.pyc # Compiled C++ files *.out # Application specific files venv node_modules .sass-cache # vscode .vscode/ ","date":"2021-06-12","objectID":"/posts/macos-develop/:2:3","series":null,"tags":["macOS"],"title":"macOS 开发配置","uri":"/posts/macos-develop/#git-全局忽略文件"},{"categories":["macOS"],"content":" 软件管理工具 - Homebrew 官网地址: https://brew.sh/ 在安装 Homebrew 之前，需要将 Xcode Command Line Tools 安装完成 bash /usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" 安装完成后，Homebrew 会将本地 /usr/local 初始化为 git 的工作树，并将目录所有者变更为当前所操作的用户，将来 brew 的相关操作不需要 sudo ","date":"2021-06-12","objectID":"/posts/macos-develop/:3:0","series":null,"tags":["macOS"],"title":"macOS 开发配置","uri":"/posts/macos-develop/#软件管理工具---homebrew"},{"categories":["macOS"],"content":" 终端管理工具 - iTerm2 iTerm2 下载地址： https://iterm2.com/downloads.html ","date":"2021-06-12","objectID":"/posts/macos-develop/:4:0","series":null,"tags":["macOS"],"title":"macOS 开发配置","uri":"/posts/macos-develop/#终端管理工具---iterm2"},{"categories":["macOS"],"content":" 配置 zmodem（lrzsz）iTerm 默认终端是不支持 sz rz 命令的，iterm2 终端可以配置支持 sz rz 命令，配置方法如下： 1. 安装 lrzsz bash brew install lrzsz 2. 安装 iterm2-zmodem 脚本 bash git clone https://github.com/aikuyun/iterm2-zmodem.git cp iterm2-zmodem/iterm2*.sh /usr/local/bin/ chmod +x /usr/local/bin/iterm2*.sh 3. 配置 iterm2 Triggers bash Regular expression: \\*\\*B0100 Action: Run Silent Coprocess Parameters: /usr/local/bin/iterm2-send-zmodem.sh Regular expression: \\*\\*B00000000000000 Action: Run Silent Coprocess Parameters: /usr/local/bin/iterm2-recv-zmodem.sh 按 command + , 打开配置面板，然后点击 “Profiles”, “Advanced”， “Triggers -\u003e Edit” Tips: 正常连接服务器就可以使用 sz rz 命令了 通过添加 profile 配置主机列表 注意: 需要在服务器上安装 lrzsz 软件包 ","date":"2021-06-12","objectID":"/posts/macos-develop/:4:1","series":null,"tags":["macOS"],"title":"macOS 开发配置","uri":"/posts/macos-develop/#配置-zmodemlrzsz"},{"categories":["macOS"],"content":" 配置 trzsz-iterm2 (trzsz)trzsz-iterm2 是 trzsz 在 iTerm2 上使用的客户端。 官方文档: https://trzsz.github.io/cn/iterm2 安装 trzsz-iterm2 bash brew install trzsz 以安装路径 /usr/local/bin/trzsz-iterm2 为例, 配置步骤如下 打开 iTerm2 -\u003e Preferences… / Settings… -\u003e Profiles -\u003e ( 在左边选中一个 Profile ) -\u003e Advanced -\u003e Triggers -\u003e Edit -\u003e [+]，如下配置： Name Value Note Regular Expression :(:TRZSZ:TRANSFER:[SRD]:\\d+.\\d+.\\d+:\\d+) 前后无空格 Action Run Silent Coprocess… Parameters /usr/local/bin/trzsz-iterm2 -p text \\1 前后无空格 Enabled ✅ 选中 不要选中最下面的 Use interpolated strings for parameters。 注意 /usr/local/bin/trzsz-iterm2 要替换成真实的 trzsz-iterm2 绝对路径。 不同 Profile 的 Trigger 是互相独立的，也就是每个用到的 Profile 都要进行配置。 Trigger 的配置是允许输入多行的，但只会显示一行，注意不要多复制了一个换行符进去。 iterm2 Config 打开 iTerm2 -\u003e Preferences… / Settings… -\u003e General -\u003e Magic，选中 Enable Python API iterm2 Enable Python API 设置 ITERM2_COOKIE 环境变量可以使启动速度更快。 打开 iTerm2 -\u003e Preferences… / Settings… -\u003e Advanced，筛选 COOKIE，选择 Yes iterm2 cookie ","date":"2021-06-12","objectID":"/posts/macos-develop/:4:2","series":null,"tags":["macOS"],"title":"macOS 开发配置","uri":"/posts/macos-develop/#配置-trzsz-iterm2-trzsz"},{"categories":["macOS"],"content":" 常用快捷键 command + d 横向分屏 command + shift + d 水平分屏 command + enter 全屏，取消全屏 command + ; 打开输入历史记录 command + f 打开搜索框 option + command + i 分屏时同时操作多个窗口，重复取消 ","date":"2021-06-12","objectID":"/posts/macos-develop/:4:3","series":null,"tags":["macOS"],"title":"macOS 开发配置","uri":"/posts/macos-develop/#常用快捷键"},{"categories":["macOS"],"content":" 终端 zsh 工具 - “Oh My ZSH”","date":"2021-06-12","objectID":"/posts/macos-develop/:5:0","series":null,"tags":["macOS"],"title":"macOS 开发配置","uri":"/posts/macos-develop/#终端-zsh-工具---oh-my-zsh"},{"categories":["macOS"],"content":" 安装 ohmyzsh 官方站点: https://ohmyz.sh/ bash sh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\" zsh 主题配置项: ZSH_THEME=\"ys\" ","date":"2021-06-12","objectID":"/posts/macos-develop/:5:1","series":null,"tags":["macOS"],"title":"macOS 开发配置","uri":"/posts/macos-develop/#安装-ohmyzsh"},{"categories":["macOS"],"content":" 快捷键配置配置从当前位置删除到行首 Ctrl + U bash cat \u003e\u003e ~/.zshrc \u003c\u003cEOF # 恢复 Crtl + U 快捷键功能 bindkey \\^U backward-kill-line # zsh 默认自动给没有换行符的字符串添加一个百分号%（root 用户是 # 号），同时另起一行显示新的提示符 # 去掉末尾自动添加的符号 (% or #)， unsetopt prompt_cr prompt_sp EOF source ~/.zshrc ","date":"2021-06-12","objectID":"/posts/macos-develop/:5:2","series":null,"tags":["macOS"],"title":"macOS 开发配置","uri":"/posts/macos-develop/#快捷键配置"},{"categories":["macOS"],"content":" 新增命令无法自动识别解决方法在使用 zsh 时，某些命令安装后会找不到，必须手动执行 rehash 才能更新 hash table。这和 zsh 的命令缓存机制有关。 由于 zsh 会将命令路径缓存，以加快命令查找速度。 这个缓存不会自动更新，导致： 安装新命令后，如果之前尝试过运行该命令但未成功，zsh 会认为它 “还是不存在”。 bash rehash # 或者 hash -r ","date":"2021-06-12","objectID":"/posts/macos-develop/:5:3","series":null,"tags":["macOS"],"title":"macOS 开发配置","uri":"/posts/macos-develop/#新增命令无法自动识别解决方法"},{"categories":["macOS"],"content":" 配置 VIM 编辑器创建 ~/.vimrc 配置文件 bash syntax on set autoread set ruler set encoding=utf-8 set clipboard=unnamed set laststatus=2 \" 将制表符转为空格 set expandtab set tabstop=4 set shiftwidth=4 set softtabstop=4 set autoindent set cindent set hlsearch set backspace=2 \" 配置 yaml 文件缩进为二空格 autocmd FileType yaml setlocal autoindent tabstop=2 shiftwidth=2 expandtab \" 记录上次编辑位置 au BufReadPost * if line(\"'\\\"\") \u003e 1 \u0026\u0026 line(\"'\\\"\") \u003c= line(\"$\") | exe \"normal! g'\\\"\" | endif ","date":"2021-06-12","objectID":"/posts/macos-develop/:6:0","series":null,"tags":["macOS"],"title":"macOS 开发配置","uri":"/posts/macos-develop/#配置-vim-编辑器"},{"categories":["macOS"],"content":" 解决 macOS Ventura 下 ssh 无法使用 rsa 密钥验证在 ~/.ssh/config 配置文件中加入以下配置项即可、 bash Host * HostkeyAlgorithms +ssh-rsa PubkeyAcceptedAlgorithms +ssh-rsa ","date":"2021-06-12","objectID":"/posts/macos-develop/:7:0","series":null,"tags":["macOS"],"title":"macOS 开发配置","uri":"/posts/macos-develop/#解决-macos-ventura-下-ssh-无法使用-rsa-密钥验证"},{"categories":["macOS"],"content":" macOS 英文目录显示为中文 以目录名为 Code 进行讲解 在英文目录下新建 .localized 隐藏目录 进入localized 目录创建 zh_CN.strings 文件, 输入 “english” = “中文”; bash mkdir -p Code/.localized cat Code/.localized/zh_CN.strings \"Code\" = \"代码\"; 注意: 不能少了分号 最后将目录名改为以 .localized 结尾即可 bash mv Code Code.localized 参考文档: https://www.bookstack.cn/read/Mac-dev-setup/README.md ","date":"2021-06-12","objectID":"/posts/macos-develop/:8:0","series":null,"tags":["macOS"],"title":"macOS 开发配置","uri":"/posts/macos-develop/#macos-英文目录显示为中文"},{"categories":["devops"],"content":" 重启开机 按 e 编辑启动选项 编辑启动选项-1 编辑修改两处：ro 改为 rw, 在 LANG=en_US.UFT-8 后面添加 init=/bin/bash 编辑启动选项-2 按 Ctrl+X 重启，并修改密码, 输入 passwd root 命令重置 root 密码 由于 selinux 开启着的需要执行以下命令更新系统信息, 否则重启之后密码未生效 bash touch /.autorelabel 重启系统 bash exec /sbin/init ","date":"2021-06-12","objectID":"/posts/centos7-reset-password/:0:0","series":null,"tags":["centos"],"title":"CentOS 7 重置 root 密码","uri":"/posts/centos7-reset-password/#"},{"categories":["windows"],"content":" 好用的工具 Listary: https://www.listarypro.com/ PotPlayer: https://daumpotplayer.com/download/ Microsoft PowerToys: https://docs.microsoft.com/zh-cn/windows/powertoys/ VsCode: https://code.visualstudio.com/docs QuickLook: https://github.com/QL-Win/QuickLook Windows Terminal: 通过 Windows 应用商店安装 Deskreen: 将电脑屏幕共享到浏览器中，做第二块屏幕[Win/macOS/Linux] https://github.com/pavlobu/deskreen Deskflow: 一套键鼠控制多台主机, https://github.com/deskflow/deskflow input-leap: 一套键鼠控制多台主机, https://github.com/input-leap/input-leap ","date":"2021-06-12","objectID":"/posts/windows-tools/:1:0","series":null,"tags":["windows"],"title":"Windows 必备工具","uri":"/posts/windows-tools/#好用的工具"},{"categories":["windows"],"content":" 1. 为 Sublime Text 添加右键菜单 注册表位置： HKEY_CLASSES_ROOT\\*\\shell 菜单名,显示在右键菜单上 icon 字符串值，显示的图标 command (子项） 默认值： 操作的命令 D:\\Program Files\\Sublime Text 3\\sublime_text.exe \"%1\" 添加右键 shell 菜单注册表地址: 计算机\\HKEY_CLASSES_ROOT\\Directory ","date":"2021-06-12","objectID":"/posts/windows-contextmenu/:1:0","series":null,"tags":["regedit"],"title":"Windows 右键菜单管理","uri":"/posts/windows-contextmenu/#1-为-sublime-text-添加右键菜单"},{"categories":["windows"],"content":" 2. 添加 cmd 右键菜单将以下注册表信息保存为 xxx.reg 右键导入即可。 cmd Windows Registry Editor Version 5.00 [HKEY_CLASSES_ROOT\\Directory\\Background\\shell\\cmdPrompt] @=\"Cmd Here\" \"icon\"=\"\\\"C:\\\\Windows\\\\System32\\\\cmd.exe\\\"\" [HKEY_CLASSES_ROOT\\Directory\\Background\\shell\\cmdPrompt\\command] @=\"\\\"C:\\\\Windows\\\\System32\\\\cmd.exe\\\" \\\"--cd=%v.\\\"\" [HKEY_CLASSES_ROOT\\Directory\\shell\\cmdPrompt] @=\"Cmd Here\" \"icon\"=\"\\\"C:\\\\Windows\\\\System32\\\\cmd.exe\\\"\" [HKEY_CLASSES_ROOT\\Directory\\shell\\cmdPrompt\\command] @=\"\\\"C:\\\\Windows\\\\System32\\\\cmd.exe\\\" \\\"--cd=%v.\\\"\" ","date":"2021-06-12","objectID":"/posts/windows-contextmenu/:2:0","series":null,"tags":["regedit"],"title":"Windows 右键菜单管理","uri":"/posts/windows-contextmenu/#2-添加-cmd-右键菜单"},{"categories":["windows"],"content":" VNC Server 下载地址 VNC Viewer 下载地址 realvnc 支持两种授权方式 注册 realvnc 账号，在安装 realvnc server 中输入账号密码即可。通过realvnc平台集中式管理终端，免费账号最多添加5个终端。连接方式也是 realvnc 中转连接。 购买 license key，在安装 realvnc server 中输入 license key 即可, 此种方式可以通过 vnc 协议直连服务器. 在使用 realvnc 的时候需要进行用户设置，可以运行 realvnc 安装目录下的 vnclicensewiz.exe GUI 程序来配置账号或者 License Key. 以下 License Key 支持 4.6 以上 RealvncServer text WHJRK-UXY7V-Q34M9-CZU8L-8KGFA 48R4P-NFZ46-NBCWY-Q2ZJT-3H9RA NGNW9-7Q8BK-UQGY7-J3KAA-6G39 Z456C-LMKTC-NLGWQ-H5CUR-ZVWEA A5HDP-LXKYN-UK4W6-XACZJ-ENWLA NRDX9-ZF9C5-JLGY7-CUC5J-77J2A 579R9-9B92W-4QHM9-6TK6D-H6F9A VETPD-HHC3S-63AH9-YAA26-8WVDA SSEWK-HBDM6-YYCWC-M3BQV-9XMDA LFKRU-DCTWH-6GJH2-7SWYR-D4CPA CQUTS-S5RDR-VT2WJ-9B6TU-DLHPA RR36V-7V29A-EVGJA-AYNEC-3DZYA UNLZ3-EHBVR-VACLK-S8QDH-JZMHA TPSNG-YEUGX-J4HZX-DPYSY-HZKXA UCUXY-TAFLN-YFBVV-D7VZE-9SHJA ANN2U-FM59S-DAGV4-4TK96-BDTKA F4X7H-CYLEV-XZ4ZW-USQ7D-KHMGA 63P3S-TGU8R-3C4ZE-WCKF4-S2W3A Q35YW-ZVH7L-Z94J4-9UJP9-77VFA 3TH6P-DV5AE-BLHY6-PNENS-B3AQA Tips: 以上 License Key 来源于互联网，可能随时会效 ","date":"2021-06-12","objectID":"/posts/windows-vnc/:0:0","series":null,"tags":["realvnc"],"title":"Windows 安装 realvnc","uri":"/posts/windows-vnc/#"},{"categories":["windows"],"content":" 用户","date":"2021-06-12","objectID":"/posts/windows-cmd/:1:0","series":null,"tags":["cmd"],"title":"Windows 常用 CMD 命令","uri":"/posts/windows-cmd/#用户"},{"categories":["windows"],"content":" 激活用户 cmd net user administrator /active:no ","date":"2021-06-12","objectID":"/posts/windows-cmd/:1:1","series":null,"tags":["cmd"],"title":"Windows 常用 CMD 命令","uri":"/posts/windows-cmd/#激活用户"},{"categories":["windows"],"content":" 启用用户 cmd net user administrator /active:yes ","date":"2021-06-12","objectID":"/posts/windows-cmd/:1:2","series":null,"tags":["cmd"],"title":"Windows 常用 CMD 命令","uri":"/posts/windows-cmd/#启用用户"},{"categories":["windows"],"content":" 添加用户 cmd net user username /add ","date":"2021-06-12","objectID":"/posts/windows-cmd/:1:3","series":null,"tags":["cmd"],"title":"Windows 常用 CMD 命令","uri":"/posts/windows-cmd/#添加用户"},{"categories":["windows"],"content":" 删除用户 cmd net user username /del ","date":"2021-06-12","objectID":"/posts/windows-cmd/:1:4","series":null,"tags":["cmd"],"title":"Windows 常用 CMD 命令","uri":"/posts/windows-cmd/#删除用户"},{"categories":["windows"],"content":" 文件共享","date":"2021-06-12","objectID":"/posts/windows-cmd/:2:0","series":null,"tags":["cmd"],"title":"Windows 常用 CMD 命令","uri":"/posts/windows-cmd/#文件共享"},{"categories":["windows"],"content":" 查看系统共享 cmd net share ","date":"2021-06-12","objectID":"/posts/windows-cmd/:2:1","series":null,"tags":["cmd"],"title":"Windows 常用 CMD 命令","uri":"/posts/windows-cmd/#查看系统共享"},{"categories":["windows"],"content":" 删除共享 cmd net share 共享名 /del ","date":"2021-06-12","objectID":"/posts/windows-cmd/:2:2","series":null,"tags":["cmd"],"title":"Windows 常用 CMD 命令","uri":"/posts/windows-cmd/#删除共享"},{"categories":["windows"],"content":" 映射网络驱动器 cmd net use H: \\\\192.168.31.141\\public /user:samba haiersamba ","date":"2021-06-12","objectID":"/posts/windows-cmd/:2:3","series":null,"tags":["cmd"],"title":"Windows 常用 CMD 命令","uri":"/posts/windows-cmd/#映射网络驱动器"},{"categories":["windows"],"content":" 删除网络驱动器 cmd net use /del H: ","date":"2021-06-12","objectID":"/posts/windows-cmd/:2:4","series":null,"tags":["cmd"],"title":"Windows 常用 CMD 命令","uri":"/posts/windows-cmd/#删除网络驱动器"},{"categories":["windows"],"content":" 删除网络连接 cmd net use \\\\192.168.31.141 /del ","date":"2021-06-12","objectID":"/posts/windows-cmd/:2:5","series":null,"tags":["cmd"],"title":"Windows 常用 CMD 命令","uri":"/posts/windows-cmd/#删除网络连接"},{"categories":["windows"],"content":" 删除所有网络连接 cmd net use * /del ","date":"2021-06-12","objectID":"/posts/windows-cmd/:2:6","series":null,"tags":["cmd"],"title":"Windows 常用 CMD 命令","uri":"/posts/windows-cmd/#删除所有网络连接"},{"categories":["windows"],"content":" 查看无线 wifi 密码 cmd # 查看已保存的wifi列表 netsh wlan show profiles # 查看指定wifi的密码 netsh wlan show profile TP-LINK_3E48 key=clear ","date":"2021-06-12","objectID":"/posts/windows-cmd/:2:7","series":null,"tags":["cmd"],"title":"Windows 常用 CMD 命令","uri":"/posts/windows-cmd/#查看无线-wifi-密码"},{"categories":["windows"],"content":" 重命名 cmd rname q.txt q.rar //对单个文件重命名 rname *.png *.jpg //文件批量重命名 ","date":"2021-06-12","objectID":"/posts/windows-cmd/:2:8","series":null,"tags":["cmd"],"title":"Windows 常用 CMD 命令","uri":"/posts/windows-cmd/#重命名"},{"categories":["windows"],"content":" 重启资源管理器 cmd tskill explorer ","date":"2021-06-12","objectID":"/posts/windows-cmd/:2:9","series":null,"tags":["cmd"],"title":"Windows 常用 CMD 命令","uri":"/posts/windows-cmd/#重启资源管理器"},{"categories":["windows"],"content":" 系统服务","date":"2021-06-12","objectID":"/posts/windows-cmd/:3:0","series":null,"tags":["cmd"],"title":"Windows 常用 CMD 命令","uri":"/posts/windows-cmd/#系统服务"},{"categories":["windows"],"content":" 停止 Windows Update 服务 cmd sc stop wuauserv ","date":"2021-06-12","objectID":"/posts/windows-cmd/:3:1","series":null,"tags":["cmd"],"title":"Windows 常用 CMD 命令","uri":"/posts/windows-cmd/#停止-windows-update-服务"},{"categories":["windows"],"content":" 禁用 Windows Update 服务 cmd sc config wuauserv start= disabled //start= 等号后有一个空格 ","date":"2021-06-12","objectID":"/posts/windows-cmd/:3:2","series":null,"tags":["cmd"],"title":"Windows 常用 CMD 命令","uri":"/posts/windows-cmd/#禁用-windows-update-服务"},{"categories":["windows"],"content":" 创建服务 cmd sc create \u003cservice name\u003e [binPath= 程序路径] [displayname= \"service name\"] [start= auto ] 注意: 等号后有一个空格 ","date":"2021-06-12","objectID":"/posts/windows-cmd/:3:3","series":null,"tags":["cmd"],"title":"Windows 常用 CMD 命令","uri":"/posts/windows-cmd/#创建服务"},{"categories":["windows"],"content":" 删除服务 cmd sc delete \u003cservice name\u003e 服务从注册表中删除 导航到 HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services 中删除相应的服务名即可（不推荐） 注意: 在打开 services.msc 服务管理器的情况下，使用命令删除服务会提示标记为删除，要彻底删除请关闭服务管理器 ","date":"2021-06-12","objectID":"/posts/windows-cmd/:3:4","series":null,"tags":["cmd"],"title":"Windows 常用 CMD 命令","uri":"/posts/windows-cmd/#删除服务"},{"categories":["windows"],"content":" 网络","date":"2021-06-12","objectID":"/posts/windows-cmd/:4:0","series":null,"tags":["cmd"],"title":"Windows 常用 CMD 命令","uri":"/posts/windows-cmd/#网络"},{"categories":["windows"],"content":" 设置接口 IP 地址与 DNS cmd netsh interface ip set address \"接口名\" static ip_address submask gateway netsh interface ip set address \"接口名\" source=dhcp //将接口设置为DHCP自动获取 ` netsh interface ip set dnsserver \"接口名\" static dns_ip primary ","date":"2021-06-12","objectID":"/posts/windows-cmd/:4:1","series":null,"tags":["cmd"],"title":"Windows 常用 CMD 命令","uri":"/posts/windows-cmd/#设置接口-ip-地址与-dns"},{"categories":["windows"],"content":" 磁盘","date":"2021-06-12","objectID":"/posts/windows-cmd/:5:0","series":null,"tags":["cmd"],"title":"Windows 常用 CMD 命令","uri":"/posts/windows-cmd/#磁盘"},{"categories":["windows"],"content":" diskpart 分区 cmd shift + f10 diskpart #启动硬盘工具 list disk #选择磁盘 select disk 0 #选择磁盘 clean #清除分区 convert mbr #转换分区表 create partition primary size=102400 #创建主分区 active #激活分区 format fs=ntfs label=\"new volume\" quick compress #格式化 exit ","date":"2021-06-12","objectID":"/posts/windows-cmd/:5:1","series":null,"tags":["cmd"],"title":"Windows 常用 CMD 命令","uri":"/posts/windows-cmd/#diskpart-分区"},{"categories":["devops"],"content":" 1. Cobbler介绍Cobbler是一个Linux服务器安装的服务，可以通过网络启动(PXE)的方式来快速安装、重装物理服务器和虚拟机，同时还可以管理DHCP，DNS等。 Cobbler可以使用命令行方式管理，也提供了基于Web的界面管理工具(cobbler-web)，还提供了API接口，可以方便二次开发使用。 Cobbler是较早前的kickstart的升级版，优点是比较容易配置，还自带web界面比较易于管理。 Cobbler内置了一个轻量级配置管理系统，但它也支持和其它配置管理系统集成，如Puppet，暂时不支持SaltStack。 ","date":"2021-06-12","objectID":"/posts/cobbler/:1:0","series":null,"tags":["cobbler"],"title":"使用 cobbler 批量部署 bclinux7.2","uri":"/posts/cobbler/#1-cobbler介绍"},{"categories":["devops"],"content":" 1.1 Cobbler集成的服务 PXE服务支持 DHCP服务管理 DNS服务管理(可选bind,dnsmasq) 电源管理 Kickstart服务支持 YUM仓库管理 TFTP(PXE启动时需要) Apache(提供kickstart的安装源，并提供定制化的kickstart配置) ","date":"2021-06-12","objectID":"/posts/cobbler/:1:1","series":null,"tags":["cobbler"],"title":"使用 cobbler 批量部署 bclinux7.2","uri":"/posts/cobbler/#11-cobbler集成的服务"},{"categories":["devops"],"content":" 1.2 系统环境准备 bash [root@localhost ~]# cat /etc/redhat-release # 查看发行版本 CentOS Linux release 7.2.1511 (Core) [root@localhost ~]# uname -r # 查看内核版本 3.10.0-327.el7.x86_64 [root@localhost ~]# sed -i 's/SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config # 关闭selinux功能,配置文件修改只有重启系统方可生效(如果不想重启，请使用此命令临时关闭selinux功能：setenforce 0) [root@localhost ~]# systemctl stop firewalld # 停止防火墙 [root@localhost ~]# systemctl disable firewalld # 禁用防火墙 [root@localhost ~]# ip addr show # 查看ip地址 2: eth0: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:4d:04:21 brd ff:ff:ff:ff:ff:ff inet 192.168.92.106/24 brd 192.168.92.255 scope global dynamic eth0 valid_lft 20823sec preferred_lft 20823sec inet6 fe80::20c:29ff:fe4d:421/64 scope link valid_lft forever preferred_lft forever [root@localhost ~]# wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo # 增加阿里云的 epel yum 源(没有此源将无法安装cobbler软件，软件安装完后不用可以删除) ","date":"2021-06-12","objectID":"/posts/cobbler/:1:2","series":null,"tags":["cobbler"],"title":"使用 cobbler 批量部署 bclinux7.2","uri":"/posts/cobbler/#12-系统环境准备"},{"categories":["devops"],"content":" 2. Cobbler的安装","date":"2021-06-12","objectID":"/posts/cobbler/:2:0","series":null,"tags":["cobbler"],"title":"使用 cobbler 批量部署 bclinux7.2","uri":"/posts/cobbler/#2-cobbler的安装"},{"categories":["devops"],"content":" 2.1 安装Cobbler bash # 安装所需软件 [root@localhost ~]# yum -y install cobbler cobbler-web dhcp tftp-server pykickstart httpd xinetd [root@localhost ~]# rpm -ql cobbler # 查看安装的文件，下面列出部分。 /etc/cobbler # 配置文件目录 /etc/cobbler/settings # cobbler主配置文件，这个文件是YAML格式，Cobbler是python写的程序。 /etc/cobbler/dhcp.template # DHCP服务的配置模板 /etc/cobbler/tftpd.template # tftp服务的配置模板 /etc/cobbler/rsync.template # rsync服务的配置模板 /etc/cobbler/iso # iso模板配置文件目录 /etc/cobbler/pxe # pxe模板文件目录 /etc/cobbler/power # 电源的配置文件目录 /etc/cobbler/users.conf # Web服务授权配置文件 /etc/cobbler/users.digest # 用于web访问的用户名密码配置文件 /etc/cobbler/dnsmasq.template # DNS服务的配置模板 /etc/cobbler/modules.conf # Cobbler模块配置文件 /var/lib/cobbler # Cobbler数据目录 /var/lib/cobbler/config # 配置文件 /var/lib/cobbler/kickstarts # 默认存放kickstart文件 /var/lib/cobbler/loaders # 存放的各种引导程序 /var/www/cobbler # 系统安装镜像目录 /var/www/cobbler/ks_mirror # 导入的系统镜像列表 /var/www/cobbler/images # 导入的系统镜像启动文件 /var/www/cobbler/repo_mirror # yum源存储目录 /var/log/cobbler # 日志目录 /var/log/cobbler/install.log # 客户端系统安装日志 /var/log/cobbler/cobbler.log # cobbler日志 ","date":"2021-06-12","objectID":"/posts/cobbler/:2:1","series":null,"tags":["cobbler"],"title":"使用 cobbler 批量部署 bclinux7.2","uri":"/posts/cobbler/#21-安装cobbler"},{"categories":["devops"],"content":" 2.2 配置Cobbler bash [root@localhost ~]# systemctl start httpd # 启动 httpd 服务 [root@localhost ~]# systemctl start cobblerd # 启动 cobbler 服务 [root@localhost ~]# systemctl restart cobblerd # 此次重启是为了在执行 cobbler check 时不报错[root@localhost ~]# cobbler check The following are potential configuration items that you may want to fix: 1 : The 'server' field in /etc/cobbler/settings must be set to something other than localhost, or kickstarting features will not work. This should be a resolvable hostname or IP for the boot server as reachable by all machines that will use it. 2 : For PXE to be functional, the 'next_server' field in /etc/cobbler/settings must be set to something other than 127.0.0.1, and should match the IP of the boot server on the PXE network. 3 : change 'disable' to 'no' in /etc/xinetd.d/tftp 4 : some network boot-loaders are missing from /var/lib/cobbler/loaders, you may run 'cobbler get-loaders' to download them, or, if you only want to handle x86/x86_64netbooting, you may ensure that you have installed a *recent* version of the syslinux package installed and can ignore this message entirely. Files in this directory, should you want to support all architectures, should include pxelinux.0, menu.c32, elilo.efi, and yaboot. The 'cobbler get-loaders' command is the easiest way to resolve these requirements. 5 : enable and start rsyncd.service with systemctl 6 : debmirror package is not installed, it will be required to manage debian deployments and repositories 7 : The default password used by the sample templates for newly installed machines (default_password_crypted in /etc/cobbler/settings) is still set to 'cobbler' and should be changed, try: \"openssl passwd -1 -salt 'random-phrase-here' 'your-password-here'\" to generate new one 8 : fencing tools were not found, and are required to use the (optional) power management features. install cman or fence-agents to use them Restart cobblerd and then run 'cobbler sync' to apply changes. # 上面提示的问题，我们一个一个来解决 [root@localhost ~]# cp /etc/cobbler/settings{,.ori} # 备份 # 第1个问题，server，Cobbler服务器的IP。 [root@localhost ~]# sed -i 's/server: 127.0.0.1/server: 192.168.92.106/' /etc/cobbler/settings # 第2个问题，next_server，如果用Cobbler管理DHCP，修改本项，作用：告知客户端TFTP服务器的ip。 [root@localhost ~]# sed -i 's/next_server: 127.0.0.1/next_server: 192.168.92.106/' /etc/cobbler/settings # 用Cobbler管理DHCP [root@localhost ~]# sed -i 's/manage_dhcp: 0/manage_dhcp: 1/' /etc/cobbler/settings # 防止循环装系统，适用于服务器第一启动项是PXE启动。 [root@localhost ~]# sed -i 's/pxe_just_once: 0/pxe_just_once: 1/' /etc/cobbler/settings # 第7个问题，设置新装系统的默认root密码123456。下面的命令来源于提示6。random-phrase-here为干扰码，可以自行设定。 [root@localhost ~]# openssl passwd -1 -salt 'root' '123456' $1$root$j0bp.KLPyr.u9kgQ428D10 [root@linux-node1 ~]# vim /etc/cobbler/settings default_password_crypted: \"$1$root$j0bp.KLPyr.u9kgQ428D10\" # 第4个问题，会自动从官网下载 [root@localhost ~]# cobbler get-loaders task started: 2017-02-26_113724_get_loaders task started (id=Download Bootloader Content, time=Sun Feb 26 11:37:24 2017) downloading https://cobbler.github.io/loaders/README to /var/lib/cobbler/loaders/README downloading https://cobbler.github.io/loaders/COPYING.elilo to /var/lib/cobbler/loaders/COPYING.elilo downloading https://cobbler.github.io/loaders/COPYING.yaboot to /var/lib/cobbler/loaders/COPYING.yaboot downloading https://cobbler.github.io/loaders/COPYING.syslinux to /var/lib/cobbler/loaders/COPYING.syslinux downloading https://cobbler.github.io/loaders/elilo-3.8-ia64.efi to /var/lib/cobbler/loaders/elilo-ia64.efi downloading https://cobbler.github.io/loaders/yaboot-1.3.17 to /var/lib/cobbler/loaders/yaboot downloading https://cobbler.github.io/loaders/pxelinux.0-3.86 to /var/lib/cobbler/loaders/pxelinux.0 downloading https://cobbler.github.io/loaders/menu.c32-3.86 to /var/lib/cobbler/loaders/menu.c32 downloading https://cobbler.github.io/loaders/grub-0.97-x86.efi to /var/lib/cobbler/loaders/grub-x86.efi downloading https://cobbler.github.io/loaders/grub-0.97-x86_64.efi to /var/lib/cobbler/","date":"2021-06-12","objectID":"/posts/cobbler/:2:2","series":null,"tags":["cobbler"],"title":"使用 cobbler 批量部署 bclinux7.2","uri":"/posts/cobbler/#22-配置cobbler"},{"categories":["devops"],"content":" 2.3 配置DHCP bash # 修改cobbler的dhcp模版，不要直接修改dhcp本身的配置文件，因为cobbler会覆盖。 [root@localhost ~]# vim /etc/cobbler/dhcp.template ...... # 仅列出修改过的字段 subnet 192.168.92.0 netmask 255.255.255.0 { option routers 192.168.92.2; # 指定网关 option domain-name-servers 192.168.92.2; # 指定DNS option subnet-mask 255.255.255.0; range dynamic-bootp 192.168.92.200 192.168.92.254; # 分配的地址段（部署的服务器多可以给大点） ...... ","date":"2021-06-12","objectID":"/posts/cobbler/:2:3","series":null,"tags":["cobbler"],"title":"使用 cobbler 批量部署 bclinux7.2","uri":"/posts/cobbler/#23-配置dhcp"},{"categories":["devops"],"content":" 2.4 同步cobbler配置 bash # 同步最新cobbler配置，它会根据配置自动修改dhcp等服务。 [root@localhost ~]# cobbler sync task started: 2017-02-26_115318_sync task started (id=Sync, time=Sun Feb 26 11:53:18 2017) running pre-sync triggers cleaning trees removing: /var/lib/tftpboot/grub/images copying bootloaders trying hardlink /var/lib/cobbler/loaders/pxelinux.0 -\u003e /var/lib/tftpboot/pxelinux.0 trying hardlink /var/lib/cobbler/loaders/menu.c32 -\u003e /var/lib/tftpboot/menu.c32 trying hardlink /var/lib/cobbler/loaders/yaboot -\u003e /var/lib/tftpboot/yaboot trying hardlink /usr/share/syslinux/memdisk -\u003e /var/lib/tftpboot/memdisk trying hardlink /var/lib/cobbler/loaders/grub-x86.efi -\u003e /var/lib/tftpboot/grub/grub-x86.efi trying hardlink /var/lib/cobbler/loaders/grub-x86_64.efi -\u003e /var/lib/tftpboot/grub/grub-x86_64.efi copying distros to tftpboot copying images generating PXE configuration files generating PXE menu structure rendering DHCP files generating /etc/dhcp/dhcpd.conf rendering TFTPD files generating /etc/xinetd.d/tftp cleaning link caches running post-sync triggers running python triggers from /var/lib/cobbler/triggers/sync/post/* running python trigger cobbler.modules.sync_post_restart_services running: dhcpd -t -q received on stdout: received on stderr: running: service dhcpd restart received on stdout: received on stderr: Redirecting to /bin/systemctl restart dhcpd.service running shell triggers from /var/lib/cobbler/triggers/sync/post/* running python triggers from /var/lib/cobbler/triggers/change/* running python trigger cobbler.modules.scm_track running shell triggers from /var/lib/cobbler/triggers/change/* *** TASK COMPLETE *** ","date":"2021-06-12","objectID":"/posts/cobbler/:2:4","series":null,"tags":["cobbler"],"title":"使用 cobbler 批量部署 bclinux7.2","uri":"/posts/cobbler/#24-同步cobbler配置"},{"categories":["devops"],"content":" 2.5 开机启动 bash # 设置为开机启动 [root@localhost ~]# systemctl enable httpd [root@localhost ~]# systemctl enable rsyncd [root@localhost ~]# systemctl enable xinetd [root@localhost ~]# systemctl enable cobblerd [root@localhost ~]# systemctl enable dhcpd # 重启所有服务 [root@localhost ~]# systemctl restart httpd [root@localhost ~]# systemctl restart rsyncd [root@localhost ~]# systemctl restart xinetd [root@localhost ~]# systemctl restart cobblerd [root@localhost ~]# systemctl restart dhcpd ","date":"2021-06-12","objectID":"/posts/cobbler/:2:5","series":null,"tags":["cobbler"],"title":"使用 cobbler 批量部署 bclinux7.2","uri":"/posts/cobbler/#25-开机启动"},{"categories":["devops"],"content":" 3. cobbler 命令行管理","date":"2021-06-12","objectID":"/posts/cobbler/:3:0","series":null,"tags":["cobbler"],"title":"使用 cobbler 批量部署 bclinux7.2","uri":"/posts/cobbler/#3-cobbler-命令行管理"},{"categories":["devops"],"content":" 3.1 查看命令帮助 bash [root@localhost ~]# cobbler usage ===== cobbler \u003cdistro|profile|system|repo|image|mgmtclass|package|file\u003e ... [add|edit|copy|getks*|list|remove|rename|report] [options|--help] cobbler \u003caclsetup|buildiso|import|list|replicate|report|reposync|sync|validateks|version|signature|get-loaders|hardlink\u003e [options|--help] [root@linux-node1 ~]# cobbler import --help # 导入镜像 Usage: cobbler [options] Options: -h, --help show this help message and exit --arch=ARCH OS architecture being imported --breed=BREED the breed being imported --os-version=OS_VERSION the version being imported --path=PATH local path or rsync location --name=NAME name, ex 'RHEL-5' --available-as=AVAILABLE_AS tree is here, don't mirror --kickstart=KICKSTART_FILE assign this kickstart file --rsync-flags=RSYNC_FLAGS pass additional flags to rsync cobbler check 核对当前设置是否有问题 cobbler list 列出所有的cobbler元素 cobbler report 列出元素的详细信息 cobbler sync 同步配置到数据目录,更改配置最好都要执行下 cobbler reposync 同步yum仓库 cobbler distro 查看导入的发行版系统信息 cobbler system 查看添加的系统信息 cobbler profile 查看配置信息 ","date":"2021-06-12","objectID":"/posts/cobbler/:3:1","series":null,"tags":["cobbler"],"title":"使用 cobbler 批量部署 bclinux7.2","uri":"/posts/cobbler/#31-查看命令帮助"},{"categories":["devops"],"content":" 3.2 导入镜像 bash # 挂载镜像 [root@localhost ~]# mount /dev/cdrom /mnt mount: /dev/sr0 is write-protected, mounting read-only [root@localhost ~]# cobbler import --path=/mnt/ --name=BClinux-7.2-x86_64 --arch=x86_64 # --path 镜像路径 # --name 为安装源定义一个名字 # --arch 指定安装源是32位、64位、ia64, 目前支持的选项有: x86│x86_64│ia64 # 安装源的唯一标示就是根据name参数来定义，本例导入成功后，安装源的唯一标示就是：BClinux-7.2-x86_64，如果重复，系统会提示导入失败。 # 镜像存放目录，cobbler会将镜像中的所有安装文件拷贝到本地一份，放在/var/www/cobbler/ks_mirror下的BClinux-7.2-x86_64目录下。因此/var/www/cobbler目录必须具有足够容纳安装文件的空间。 [root@localhost ~]# cobbler distro list # 查看镜像列表 BClinux-7.2-x86_64 ","date":"2021-06-12","objectID":"/posts/cobbler/:3:2","series":null,"tags":["cobbler"],"title":"使用 cobbler 批量部署 bclinux7.2","uri":"/posts/cobbler/#32-导入镜像"},{"categories":["devops"],"content":" 3.3 指定ks.cfg文件及调整内核参数 bash [root@localhost ~]# cd /var/lib/cobbler/kickstarts/ # Cobbler的ks.cfg文件存放位置 [root@localhost kickstarts]# ls # 自带很多 default.ks esxi5-ks.cfg legacy.ks sample_autoyast.xml sample_esx4.ks sample_esxi5.ks sample_old.seed esxi4-ks.cfg install_profiles pxerescue.ks sample_end.ks sample_esxi4.ks sample.ks sample.seed # 上传准备好的ks文件(anaconda-ks.cfg),上传方式自己选择（sftp,U盘...) [root@localhost kickstarts]# mv anaconda-ks.cfg BClinux-7.2-x86_64.cfg # 在第一次导入系统镜像后，Cobbler会给镜像指定一个默认的kickstart自动安装文件在/var/lib/cobbler/kickstarts下的sample_end.ks。 [root@localhost kickstarts]# cobbler profile report --name=BClinux-7.2-x86_64 Name : BClinux-7.2-x86_64 TFTP Boot Files : {} Comment : DHCP Tag : default Distribution : BClinux-7.2-x86_64 Enable gPXE? : 0 Enable PXE Menu? : 1 Fetchable Files : {} Kernel Options : {} Kernel Options (Post Install) : {} Kickstart : /var/lib/cobbler/kickstarts/sample_end.ks # 默认的ks文件 Kickstart Metadata : {} Management Classes : [] Management Parameters : \u003c\u003cinherit\u003e\u003e Name Servers : [] Name Servers Search Path : [] Owners : ['admin'] Parent Profile : Internal proxy : Red Hat Management Key : \u003c\u003cinherit\u003e\u003e Red Hat Management Server : \u003c\u003cinherit\u003e\u003e Repos : [] Server Override : \u003c\u003cinherit\u003e\u003e Template Files : {} Virt Auto Boot : 1 Virt Bridge : xenbr0 Virt CPUs : 1 Virt Disk Driver Type : raw Virt File Size(GB) : 5 Virt Path : Virt RAM (MB) : 512 Virt Type : kvm # 编辑profile，修改关联的ks文件 [root@localhost kickstarts]# cobbler profile edit --name=BClinux-7.2-x86_64 --kickstart=/var/lib/cobbler/kickstarts/BClinux-7.2-x86_64.cfg # 修改安装系统的内核参数，在CentOS7系统有一个地方变了，就是网卡名变成eno16777736这种形式，但是为了运维标准化，我们需要将它变成我们常用的eth0，因此使用下面的参数。但要注意是CentOS7才需要下面的步骤，CentOS6不需要。（改之前请确认是否需要修改，如不需要请跳过） [root@localhost kickstarts]# cobbler profile edit --name=BClinux-7.2-x86_64 --kopts='net.ifnames=0 biosdevname=0' [root@localhost kickstarts]# cobbler profile report CentOS-7.1-x86_64 Name : BClinux-7.2-x86_64 TFTP Boot Files : {} Comment : DHCP Tag : default Distribution : BClinux-7.2-x86_64 Enable gPXE? : 0 Enable PXE Menu? : 1 Fetchable Files : {} Kernel Options : {'biosdevname': '0', 'net.ifnames': '0'} Kernel Options (Post Install) : {} Kickstart : /var/lib/cobbler/kickstarts/BClinux-7.2-x86_64.cfg Kickstart Metadata : {} Management Classes : [] Management Parameters : \u003c\u003cinherit\u003e\u003e Name Servers : [] Name Servers Search Path : [] Owners : ['admin'] Parent Profile : Internal proxy : Red Hat Management Key : \u003c\u003cinherit\u003e\u003e Red Hat Management Server : \u003c\u003cinherit\u003e\u003e Repos : [] Server Override : \u003c\u003cinherit\u003e\u003e Template Files : {} Virt Auto Boot : 1 Virt Bridge : xenbr0 Virt CPUs : 1 Virt Disk Driver Type : raw Virt File Size(GB) : 5 Virt Path : Virt RAM (MB) : 512 Virt Type : kvm # 每次修改完都要同步一次 [root@localhost kickstarts]# cobbler sync ","date":"2021-06-12","objectID":"/posts/cobbler/:3:3","series":null,"tags":["cobbler"],"title":"使用 cobbler 批量部署 bclinux7.2","uri":"/posts/cobbler/#33-指定kscfg文件及调整内核参数"},{"categories":["devops"],"content":" 3.4 安装系统可以很愉快的告诉你到这里就可以安装系统了！ 修改Cobbler提示 非必须，不想修改请跳过直接开始安装系统 bash [root@localhost ~]# vim /etc/cobbler/pxe/pxedefault.template MENU TITLE Cobbler | http://wglee.org # 此处的网址可以修改为你公司的网址 [root@localhost ~]# cobbler sync # 修改配置都要同步 OK，选择第二项就可以开始装机了。 ","date":"2021-06-12","objectID":"/posts/cobbler/:3:4","series":null,"tags":["cobbler"],"title":"使用 cobbler 批量部署 bclinux7.2","uri":"/posts/cobbler/#34-安装系统"},{"categories":["devops"],"content":" 3.5 ks.cfg 文件 关于ks.cfg文件详细说明请查看：ks.cfg 文件配置 文档 bash [root@localhost kickstarts]# cat BClinux-7.2-x86_64.cfg #version=DEVEL install # System authorization information auth --enableshadow --passalgo=sha512 # Use Network installation url --url=$tree # 这些$开头的变量都是调用配置文件里的值。 # Run the Setup Agent on first boot firstboot --enable ignoredisk --only-use=sda # Keyboard layouts keyboard --vckeymap=us --xlayouts='us' # System language lang en_US.UTF-8 # Network information network --bootproto=dhcp --onboot=on network --hostname=localhost.localdomain # Root password rootpw --iscrypted $default_password_crypted # $开头的变量，调用配置文件里的值。 # System services services --disabled=\"chronyd\" firewall --disabled selinux --disabled # Reboot after installation reboot # System timezone timezone Asia/Shanghai --isUtc # System bootloader configuration bootloader --append=\" crashkernel=auto\" --location=mbr --boot-drive=sda # Partition clearing information clearpart --none --initlabel # Disk partitioning information part /boot --fstype=\"ext4\" --ondisk=sda --size=500 part pv.01 --fstype=\"lvmpv\" --ondisk=sda --grow --size=1 volgroup bclinux pv.01 logvol / --fstype=\"xfs\" --size=10240 --name=root --vgname=bclinux logvol swap --fstype=\"swap\" --size=1024 --name=swap --vgname=bclinux %packages @^minimal @core @security-tools kexec-tools vim wget %end %addon com_redhat_kdump --enable --reserve-mb='auto' %end %post wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo %end ","date":"2021-06-12","objectID":"/posts/cobbler/:3:5","series":null,"tags":["cobbler"],"title":"使用 cobbler 批量部署 bclinux7.2","uri":"/posts/cobbler/#35-kscfg-文件"},{"categories":["devops","ansible"],"content":" playbook 示例1使用 ansible-playbook (单文件)批量安装 vsftp 服务 playbook yaml --- - hosts: all # 指定操作的主机 vars: # 定义变量，此变量会传入模板 userlist: /etc/vsftpd/user_list welcome: /etc/vsftpd/welcome.txt remote_user: root tasks: - name: install vsftpd yum: pkg=vsftpd state=latest - name: write vsftp config file template: src=/root/playbook/templates/vsftpd.conf dest=/etc/vsftpd/vsftpd.conf # 只有配置发生变化才会触发以下任务 notify: # 触发任务，下面指定任务名 - restart vsftpd - name: start vsftpd service: name=vsftpd state=started handlers: # 定义触发任务 - name: restart vsftpd service: name=vsftpd state=restarted templates 模板 bash anonymous_enable=NO local_enable=YES write_enable=YES local_umask=022 local_root=/var/ftp userlist_enable=YES userlist_deny=YES userlist_file={{ userlist }} use_localtime=YES dirmessage_enable=YES xferlog_enable=YES connect_from_port_20=YES xferlog_std_format=YES listen=YES pam_service_name=vsftpd tcp_wrappers=YES banner_file={{ welcome }} chroot_local_user=YES pasv_min_port=65530 pasv_max_port=65535 ","date":"2021-06-12","objectID":"/posts/ansible-playbook/:1:0","series":null,"tags":["ansible"],"title":"Ansible Playbook 示例","uri":"/posts/ansible-playbook/#playbook-示例1"},{"categories":["devops","ansible"],"content":" playbook 示例2将 playbook 分解成多个文件方便复用，文件夹结构如下： bash [root@localhost playbook]# tree . ├── handlers │ └── restart.yaml ├── services │ └── vsftpd.yaml ├── templates │ └── vsftpd.conf └── vsftpd.yaml vsftpd.yaml bash --- - hosts: all remote_user: root vars: userlist: /etc/vsftpd/user_list welcome: /etc/vsftpd/welcome.txt tasks: - include: /root/playbook/services/vsftpd.yaml handlers: - include: /root/playbook/handlers/restart.yaml server_name=vsftpd services/vsftpd.yaml bash --- - name: install vsftpd yum: name=vsftpd state=present - name: start vsftpd service: name=vsftpd state=started - name: configure vsftpd template: src=/root/playbook/templates/vsftpd.conf dest=/etc/vsftpd/vsftpd.conf notify: - restart vsftpd templates/vsftpd.conf bash anonymous_enable=NO local_enable=YES write_enable=YES local_umask=022 local_root=/var/ftp userlist_enable=YES userlist_deny=YES userlist_file={{ userlist }} use_localtime=YES dirmessage_enable=YES xferlog_enable=YES connect_from_port_20=YES xferlog_std_format=YES listen=YES pam_service_name=vsftpd tcp_wrappers=YES banner_file={{ welcome }} chroot_local_user=YES pasv_min_port=65530 pasv_max_port=65535 handlers/restart.yaml bash --- - name: restart {{ server_name }} service: name={{ server_name }} state=restarted ","date":"2021-06-12","objectID":"/posts/ansible-playbook/:2:0","series":null,"tags":["ansible"],"title":"Ansible Playbook 示例","uri":"/posts/ansible-playbook/#playbook-示例2"},{"categories":["devops","ansible"],"content":"ansible 命令格式： bash ansible all -m command -a \"uptime\" -m 指定使用的模块 -a 指定模块的参数 默认使用 /etc/ansible/hosts 文件中定义的主机，也可以使用 -i /path/hosts 主机清单文件的位置 ","date":"2021-06-12","objectID":"/posts/ansible-modules/:0:0","series":null,"tags":["ansible"],"title":"Ansible 常用模块","uri":"/posts/ansible-modules/#"},{"categories":["devops","ansible"],"content":" 1. commandcommand 命令模块, 不支持管道 “|” 与 变量 bash [root@localhost ~]# ansible all -m command -a 'uptime' 192.168.17.130 | SUCCESS | rc=0 \u003e\u003e 03:05:54 up 36 min, 3 users, load average: 0.02, 0.04, 0.05 192.168.17.131 | SUCCESS | rc=0 \u003e\u003e 03:05:54 up 32 min, 3 users, load average: 0.01, 0.03, 0.03 ","date":"2021-06-12","objectID":"/posts/ansible-modules/:1:0","series":null,"tags":["ansible"],"title":"Ansible 常用模块","uri":"/posts/ansible-modules/#1-command"},{"categories":["devops","ansible"],"content":" 2. shellshell 功能基本与 command 类似,但是 shell 使用远程主机的 /bin/sh 运行命令,支持管道 。 bash [root@localhost ~]# ansible webserver -m shell -a '/tmp/test.sh' 192.168.17.131 | SUCCESS | rc=0 \u003e\u003e UserName: root Ip address: 192.168.17.131 192.168.17.130 | SUCCESS | rc=0 \u003e\u003e UserName: root Ip address: 192.168.17.130 ","date":"2021-06-12","objectID":"/posts/ansible-modules/:2:0","series":null,"tags":["ansible"],"title":"Ansible 常用模块","uri":"/posts/ansible-modules/#2-shell"},{"categories":["devops","ansible"],"content":" 3. scriptscript 是对指定的远程主机执行\"本地脚本\"，执行\"远程脚本\"请使用 shell 模块 bash [root@localhost ~]# ls anaconda-ks.cfg test.sh [root@localhost ~]# ansible webserver -m script -a '/root/test.sh' 192.168.17.131 | SUCCESS =\u003e { \"changed\": true, \"rc\": 0, \"stderr\": \"Shared connection to 192.168.17.131 closed.\\r\\n\", \"stdout\": \"UserName: root\\r\\nIp address: 192.168.17.131\\r\\n\", \"stdout_lines\": [ \"UserName: root\", \"Ip address: 192.168.17.131\" ] } 192.168.17.130 | SUCCESS =\u003e { \"changed\": true, \"rc\": 0, \"stderr\": \"Shared connection to 192.168.17.130 closed.\\r\\n\", \"stdout\": \"UserName: root\\r\\nIp address: 192.168.17.130\\r\\n\", \"stdout_lines\": [ \"UserName: root\", \"Ip address: 192.168.17.130\" ] } ","date":"2021-06-12","objectID":"/posts/ansible-modules/:3:0","series":null,"tags":["ansible"],"title":"Ansible 常用模块","uri":"/posts/ansible-modules/#3-script"},{"categories":["devops","ansible"],"content":" 4. copy bash [root@localhost ~]# ansible webserver -m copy -a 'src=/root/test.sh dest=/tmp/test.sh owner=root group=root mode=0755' 192.168.17.131 | SUCCESS =\u003e { \"changed\": true, \"checksum\": \"15bd17b3f24fe74c6b2bd515469510a7c46423c9\", \"dest\": \"/tmp/test.sh\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"ef47fd4c2ae9500503156fea0fa11a12\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 150, \"src\": \"/root/.ansible/tmp/ansible-tmp-1498789225.9-220641470038608/source\", \"state\": \"file\", \"uid\": 0 } 192.168.17.130 | SUCCESS =\u003e { \"changed\": true, \"checksum\": \"15bd17b3f24fe74c6b2bd515469510a7c46423c9\", \"dest\": \"/tmp/test.sh\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"ef47fd4c2ae9500503156fea0fa11a12\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 150, \"src\": \"/root/.ansible/tmp/ansible-tmp-1498789225.91-98116970360767/source\", \"state\": \"file\", \"uid\": 0 } ","date":"2021-06-12","objectID":"/posts/ansible-modules/:4:0","series":null,"tags":["ansible"],"title":"Ansible 常用模块","uri":"/posts/ansible-modules/#4-copy"},{"categories":["devops","ansible"],"content":" 5. stat获取远程文件状态信息，包括：atime ctime mtime md5 uid git 等信息 bash [root@localhost ~]# ansible webserver -m stat -a 'path=/etc/hosts' ","date":"2021-06-12","objectID":"/posts/ansible-modules/:5:0","series":null,"tags":["ansible"],"title":"Ansible 常用模块","uri":"/posts/ansible-modules/#5-stat"},{"categories":["devops","ansible"],"content":" 6. get_url实现远程主机下载指定的 url 到本地 bash [root@localhost ~]# ansible all -m get_url -a 'url=http://www.baidu.com dest=/tmp/baidu.html mode=400 force=yes' ","date":"2021-06-12","objectID":"/posts/ansible-modules/:6:0","series":null,"tags":["ansible"],"title":"Ansible 常用模块","uri":"/posts/ansible-modules/#6-get_url"},{"categories":["devops","ansible"],"content":" 7. yumlinux 平台软件包管理工具操作模块，常见的有 yum apt bash [root@localhost ~]# ansible all -m yum -a 'name=curl state=latest' [root@localhost ~]# ansible all -m apt -a 'pkg=curl state=latest' latest 表示最新版本 ","date":"2021-06-12","objectID":"/posts/ansible-modules/:7:0","series":null,"tags":["ansible"],"title":"Ansible 常用模块","uri":"/posts/ansible-modules/#7-yum"},{"categories":["devops","ansible"],"content":" 8. cron远程主机 crontab 配置 bash [root@localhost ~]# ansible all -m cron -a 'name=\"check dirs\" hour=\"5,2\" job=\"ls -lh\"' 效果如下 bash [root@localhost ~]# crontab -l #Ansible: check dirs * 5,2 * * * ls -lh ","date":"2021-06-12","objectID":"/posts/ansible-modules/:8:0","series":null,"tags":["ansible"],"title":"Ansible 常用模块","uri":"/posts/ansible-modules/#8-cron"},{"categories":["devops","ansible"],"content":" 9. mount远程主机分区挂载 bash [root@localhost ~]# ansible all -m mount -a 'name=/mnt src=/dev/sdb3 fstype=ext3 opts=ro state=present' ","date":"2021-06-12","objectID":"/posts/ansible-modules/:9:0","series":null,"tags":["ansible"],"title":"Ansible 常用模块","uri":"/posts/ansible-modules/#9-mount"},{"categories":["devops","ansible"],"content":" 10. service远程主机系统服务管理 bash [root@localhost ~]# ansible all -m service -a 'name=crond state=stopped' [root@localhost ~]# ansible all -m service -a 'name=crond state=started' [root@localhost ~]# ansible all -m service -a 'name=crond state=restarted' [root@localhost ~]# ansible all -m service -a 'name=crond state=reloaded' stopped 停止 started 启动 restarted 重启 reloaded 重载 ","date":"2021-06-12","objectID":"/posts/ansible-modules/:10:0","series":null,"tags":["ansible"],"title":"Ansible 常用模块","uri":"/posts/ansible-modules/#10-service"},{"categories":["devops","ansible"],"content":" 11. sysctl远程主机 sysctl 配置 bash [root@localhost ~]# ansible all -m sysctl -a 'name=net.ipv4.ip_forward value=1 sysctl_file=/etc/sysctl.conf reload=yes' ","date":"2021-06-12","objectID":"/posts/ansible-modules/:11:0","series":null,"tags":["ansible"],"title":"Ansible 常用模块","uri":"/posts/ansible-modules/#11-sysctl"},{"categories":["devops","ansible"],"content":" 12. user远程主机用户管理 bash # 添加用户 [root@localhost ~]# ansible all -m user -a 'name=liwg shell=/sbin/bash home=/home/liwg' # 删除用户 [root@localhost ~]# ansible all -m user -a 'name=liwg state=absent remove=yes' ","date":"2021-06-12","objectID":"/posts/ansible-modules/:12:0","series":null,"tags":["ansible"],"title":"Ansible 常用模块","uri":"/posts/ansible-modules/#12-user"},{"categories":["devops","ansible"],"content":" 目录结构playbook 目录包括变量定义目录 group_vars、主机组定义文件hosts、全局配置文件site.yml、角色功能目录。 可以使用命令 ansible-galaxy init role_name 生成角色相应目录 bash [root@localhost ~]# tree ansible_roles/ ansible_roles/ ├── common # 公共角色目录 │ ├── handlers │ │ └── main.yml # 定义触发任务 │ ├── tasks │ │ └── main.yml # 定义任务 │ ├── templates │ │ └── ntp.conf.j2 # 定义模板 │ └── vars │ └── main.yml # 定义角色内的变量 ├── ftp # 安装ftp任务角色 │ ├── handlers │ │ └── main.yml │ ├── tasks │ │ └── main.yml │ ├── templates │ │ └── vsftpd2.conf │ └── vars ├── group_vars # 定义组变量，以组名命名文件 │ ├── all │ └── ftpservers # 定义 ftpservers 组主机变量 ├── hosts # 主机清单，非必须，可以使用默认。使用时加 -i 选项 └── site.yml # 程序入口文件 ","date":"2021-06-12","objectID":"/posts/ansible-role/:1:0","series":null,"tags":["ansible"],"title":"Ansible playbook 角色","uri":"/posts/ansible-role/#目录结构"},{"categories":["devops","ansible"],"content":" 角色规范角色定制以下规范，其中 x 为角色名。 如 roles/x/tasks/main.yml 文件存在，其中列出的任务将被添加到执行队列； 如 roles/x/handlers/main.yml 文件存在，其中所列的处理程序将被添加到执行队列； 如 roles/x/vars/main.yml 文件存在，其中列出的变量将被添加到执行队列； 如 roles/x/meta/main.yml 文件存在，所列任何作用的依赖关系将被添加到角色的列表（1.3及更高版本）； 任何副本任务可以引用 roles/x/files/无需写路径，默认相对或绝对引用； 任何模板任务可以引用文件中的 roles/x/templates/ 无需写路径，默认相对或绝对引用。 ","date":"2021-06-12","objectID":"/posts/ansible-role/:2:0","series":null,"tags":["ansible"],"title":"Ansible playbook 角色","uri":"/posts/ansible-role/#角色规范"},{"categories":["devops","ansible"],"content":" hosts 主机配置文件 bash [root@localhost ansible_roles]# cat hosts manages ansible_connection=local ansible_ssh_host=127.0.0.1 [ftpservers] 192.168.17.130 192.168.17.131 ","date":"2021-06-12","objectID":"/posts/ansible-role/:3:0","series":null,"tags":["ansible"],"title":"Ansible playbook 角色","uri":"/posts/ansible-role/#hosts-主机配置文件"},{"categories":["devops","ansible"],"content":" group_vars 定义主机组变量group_vars/ftpservers 此配置文件内变量只对 ftpservers 组内的主机有效 bash [root@localhost ansible_roles]# cat group_vars/ftpservers userlist: /etc/vsftpd/user_list welcome: /etc/vsftpd/welcome.txt group_vars/all 对所有主机有效 bash [root@localhost ansible_roles]# cat group_vars/all ntpserver: ntp.sjtu.edu.cn ","date":"2021-06-12","objectID":"/posts/ansible-role/:4:0","series":null,"tags":["ansible"],"title":"Ansible playbook 角色","uri":"/posts/ansible-role/#group_vars-定义主机组变量"},{"categories":["devops","ansible"],"content":" site.yml 全局配置文件，程序入口 bash [root@localhost ansible_roles]# cat site.yml --- # 任务名 - name: apply common configuration to all nodes hosts: all # 任务操作主机或主机组 roles: # 指定任务角色 - common # 运行 common角色 - name: configure and deploy the ftpservers hosts: ftpservers roles: - ftp 全局配置文件 site.yml 引用了两个角色，一个为公共类的 common，另一个为 ftp 类，分别对应 nginx/common、nginx/web 目录。以此类推，可以引用更多的角色，如 db、nosql、hadoop 等，前提是我们先要进行定义，通常情况下一个角色对应着一个特定功能服务。通过 hosts 参数来绑定角色对应的主机或组. ","date":"2021-06-12","objectID":"/posts/ansible-role/:5:0","series":null,"tags":["ansible"],"title":"Ansible playbook 角色","uri":"/posts/ansible-role/#siteyml-全局配置文件程序入口"},{"categories":["devops","ansible"],"content":" common (公共)角色文件示例角色common定义了handlers、tasks、templates、vars 4个功能类，分别存放处理程序、任务列表、模板、变量的配置文件main.yml，需要注意的是，vars/main.yml中定义的变量优先级高于/nginx/group_vars/all，可以从ansible-playbook的执行结果中得到验证。各功能块配置文件定义如下： common/tasks/main.yml bash [root@localhost ansible_roles]# cat common/tasks/main.yml --- - name: install ntp yum: name=ntp state=present - name: configure ntp file template: src=ntp.conf.j2 dest=/etc/ntp.conf notify: restart ntp - name: start the ntp service service: name=ntpd state=started enabled=true - name: test to see if selinux is running command: getenforce register: sestatus changed_when: false common/handlers/main.yml bash [root@localhost ansible_roles]# cat common/handlers/main.yml --- - name: restart ntp service: name=ntpd state=restarted common/templates/main.yml bash [root@localhost ansible_roles]# cat common/templates/ntp.conf.j2 driftfile /var/lib/ntp/drift restrict 127.0.0.1 restrict -6 ::1 server {{ ntpserver }} includefile /etc/ntp/crypto/pw keys /etc/ntp/keys {{ ntpserver }} 变量将从 common/vars/main.yml 中获取 common/vars/main.yml bash [root@localhost ansible_roles]# cat common/vars/main.yml ntpserver: 210.72.145.44 Tips: 此处定义的变量优先级要高于 group_vars 中定义的变量 ","date":"2021-06-12","objectID":"/posts/ansible-role/:6:0","series":null,"tags":["ansible"],"title":"Ansible playbook 角色","uri":"/posts/ansible-role/#common-公共角色文件示例"},{"categories":["devops","ansible"],"content":" ftp 角色文件示例ftp/tasks/main.yml bash [root@localhost ansible_roles]# cat ftp/tasks/main.yml - name: install vsftpd yum: pkg=vsftpd state=latest - name: write the vsftpd config file template: src=vsftpd2.conf dest=/etc/vsftpd/vsftpd.conf notify: - restart vsftpd - name: start vsftpd service: name=vsftpd state=started ftp/handlers/main.yml bash [root@localhost ansible_roles]# cat ftp/handlers/main.yml --- - name: restart vsftpd service: name=vsftpd state=restarted ftp/templates/vsftpd2.conf bash [root@localhost ansible_roles]# cat ftp/templates/vsftpd2.conf anonymous_enable=NO local_enable=YES write_enable=YES local_umask=022 local_root=/var/ftp userlist_enable=YES userlist_deny=YES userlist_file={{ userlist }} use_localtime=YES dirmessage_enable=YES xferlog_enable=YES connect_from_port_20=YES xferlog_std_format=YES listen=YES pam_service_name=vsftpd tcp_wrappers=YES banner_file={{ welcome }} chroot_local_user=YES pasv_min_port=65530 pasv_max_port=65535 ","date":"2021-06-12","objectID":"/posts/ansible-role/:7:0","series":null,"tags":["ansible"],"title":"Ansible playbook 角色","uri":"/posts/ansible-role/#ftp-角色文件示例"},{"categories":["devops","ansible"],"content":" 主机与组基本配置ansible 默认使用的主机配置文件路径为 /etc/ansible/hosts，使用 ini 文件格式，主机可以使用域名，IP，别名进行标识。 ini mail.example.com 192.168.1.10 [webserver] 192.168.1.11 192.168.1.12 [dbserver] 192.168.1.13:7733 其中 192.168.1.13:7733 的意思是定义一个ssh服务端口为7733的主机。 有时我们也可以使用别名的方式来描述一台主机 ini db1 ansible_ssh_port=4422 ansible_ssh_host=192.168.1.14 db1 为定义一个别名，ansible_ssh_port 为主机 ssh 端口，ansible_ssh_host 为主机 ip 地址，更多保留主机变量如下： ansible_ssh_host，连接目标主机的地址。 ansible_ssh_port，连接目标主机SSH端口，端口22无需指定。 ansible_ssh_user，连接目标主机默认用户。 ansible_ssh_pass，连接目标主机默认用户密码。 ansible_connection，目标主机连接类型，可以是local、ssh或paramiko。 ansible_ssh_private_key_file, 连接目标主机的ssh私钥。 ansible_*_interpreter，指定采用非Python的其他脚本语言，如 Ruby、Perl或其他类似 ansible_python_interpreter 解释器。 当然正则也是可以使用的 ini [webservers] www[01:50].example.com [databases] db-[a:f].example.com [01:50] 表示匹配 01 至 50 所有主机 [a:f] 表示匹配 a 至 f 当中所有的字母 ","date":"2021-06-12","objectID":"/posts/ansible-hosts/:1:0","series":null,"tags":["ansible"],"title":"Ansible 资源配置清单","uri":"/posts/ansible-hosts/#主机与组基本配置"},{"categories":["devops","ansible"],"content":" 定义主机变量主机可以指定变量，以便后面供Playbooks配置使用，比如定义主机 hosts1 及 hosts2 上 Apache 参数 http_port 及 maxRequestsPerChild ，目的是让两台主机产生 Apache 配置文件 httpd.conf 差异化，定义格式如下： ini [atlanta] host1 http_port=80 maxRequestsPerChild=808 host2 http_port=303 maxRequestsPerChild=909 ","date":"2021-06-12","objectID":"/posts/ansible-hosts/:2:0","series":null,"tags":["ansible"],"title":"Ansible 资源配置清单","uri":"/posts/ansible-hosts/#定义主机变量"},{"categories":["devops","ansible"],"content":" 定义组变量组变量的作用域是覆盖组所有成员，通过定义一个新块，块名由组名+“:vars”组成，定义格式如下： ini [atlanta] host1 host2 [atlanta:vars] ntp_server=ntp.atlanta.example.com proxy=proxy.atlanta.example.com ","date":"2021-06-12","objectID":"/posts/ansible-hosts/:3:0","series":null,"tags":["ansible"],"title":"Ansible 资源配置清单","uri":"/posts/ansible-hosts/#定义组变量"},{"categories":["devops","ansible"],"content":" 组嵌套组同时 Ansible 支持组嵌套组，通过定义一个新块，块名由组名+\":children\"组成，格式如下： ini [atlanta] host1 host2 [raleigh] host2 host3 [southeast:children] atlanta raleigh [southeast:vars] some_server=foo.southeast.example.com halon_system_timeout=30 self_destruct_countdown=60 escape_pods=2 [usa:children] southeast northeast southwest southeast 嵌套组只能使用在 /usr/bin/ansible-playbook 中，在 /usr/bin/ansible 中不起作用。 ","date":"2021-06-12","objectID":"/posts/ansible-hosts/:4:0","series":null,"tags":["ansible"],"title":"Ansible 资源配置清单","uri":"/posts/ansible-hosts/#组嵌套组"},{"categories":["devops","rsync"],"content":"需求 有两台 A, B 服务器其中有个目录需要实时双向同步，即 服务器A 目录添加或删除文件需同步给 服务器B，同理 服务器B 也一样 ","date":"2021-06-12","objectID":"/posts/rsync-lsyncd/:0:0","series":null,"tags":["rsync","lsyncd"],"title":"lsyncd 配合 rsync 实现目录实时双向同步","uri":"/posts/rsync-lsyncd/#"},{"categories":["devops","rsync"],"content":" 安装 bash yum install epel-release yum install lsyncd ","date":"2021-06-12","objectID":"/posts/rsync-lsyncd/:1:0","series":null,"tags":["rsync","lsyncd"],"title":"lsyncd 配合 rsync 实现目录实时双向同步","uri":"/posts/rsync-lsyncd/#安装"},{"categories":["devops","rsync"],"content":" rsync","date":"2021-06-12","objectID":"/posts/rsync-lsyncd/:2:0","series":null,"tags":["rsync","lsyncd"],"title":"lsyncd 配合 rsync 实现目录实时双向同步","uri":"/posts/rsync-lsyncd/#rsync"},{"categories":["devops","rsync"],"content":" rsyncd.conf 配置示例以下给出其中一台服务器的配置，另一台只需要修改下 hosts allow 配置即可， 配置文件 /etc/rsyncd.conf bash uid = nobody gid = nobody use chroot = no max connections = 10 strict modes = yes pid file = /var/run/rsyncd.pid lock file = /var/run/rsync.lock log file = /data/rsync/rsyncd.log [pu] path = /data/www/platform_admin/Uploads comment = platform uploads ignore errors read only = no write only = no hosts allow = 10.100.1.16 hosts deny = * list = false uid = www gid = www 注意用户权限 ","date":"2021-06-12","objectID":"/posts/rsync-lsyncd/:2:1","series":null,"tags":["rsync","lsyncd"],"title":"lsyncd 配合 rsync 实现目录实时双向同步","uri":"/posts/rsync-lsyncd/#rsyncdconf-配置示例"},{"categories":["devops","rsync"],"content":" 启动 rsyncd 服务 bash systemctl start rsyncd.service systemctl enable rsyncd.service ","date":"2021-06-12","objectID":"/posts/rsync-lsyncd/:2:2","series":null,"tags":["rsync","lsyncd"],"title":"lsyncd 配合 rsync 实现目录实时双向同步","uri":"/posts/rsync-lsyncd/#启动-rsyncd-服务"},{"categories":["devops","rsync"],"content":" 配置密钥 bash ssh-keygen -t rsa -C rsync ssh-copy-id -i ~/.ssh/id_rsa.pub localhost ssh-copy-id -i ~/.ssh/id_rsa.pub 10.100.1.16 scp -r .ssh 10.100.1.16:/root/ 注意: 将公钥加两台机的 ~/.ssh/authorized_keys 文件中，并复制私钥至另一台的 ~/.ssh 目录下 ","date":"2021-06-12","objectID":"/posts/rsync-lsyncd/:2:3","series":null,"tags":["rsync","lsyncd"],"title":"lsyncd 配合 rsync 实现目录实时双向同步","uri":"/posts/rsync-lsyncd/#配置密钥"},{"categories":["devops","rsync"],"content":" lsyncdLysncd 实际上是 lua 语言封装了 inotify 和 rsync 工具，采用了 Linux 内核（2.6.13 及以后）里的 inotify 触发机制，然后通过 rsync 去差异同步，达到实时的效果。我认为它最令人称道的特性是，完美解决了 inotify + rsync 海量文件同步带来的文件频繁发送文件列表的问题 —— 通过时间延迟或累计触发事件次数实现。另外，它的配置方式很简单，lua 本身就是一种配置语言，可读性非常强。lsyncd 也有多种工作模式可以选择，本地目录 cp，本地目录 rsync，远程目录 rsyncssh 。 ","date":"2021-06-12","objectID":"/posts/rsync-lsyncd/:3:0","series":null,"tags":["rsync","lsyncd"],"title":"lsyncd 配合 rsync 实现目录实时双向同步","uri":"/posts/rsync-lsyncd/#lsyncd"},{"categories":["devops","rsync"],"content":" lsyncd.conf 配置编辑配置文件 /etc/lsyncd.conf bash ---- -- User configuration file for lsyncd. -- -- Simple example for default rsync, but executing moves through on the target. -- -- For more examples, see /usr/share/doc/lsyncd*/examples/ -- -- sync{default.rsyncssh, source=\"/var/www/html\", host=\"localhost\", targetdir=\"/tmp/htmlcopy/\"} settings { logfile =\"/var/log/lsyncd/lsyncd.log\", statusFile =\"/var/local/lsyncd.status\", inotifyMode = \"CloseWrite\", maxProcesses = 7, -- nodaemon =true, } sync { default.rsync, source = \"/data/www/platform_admin/Uploads\", target = \"www@10.100.1.16::pu\", rsync = { binary = \"/usr/bin/rsync\", archive = true, compress = true, verbose = true } } ","date":"2021-06-12","objectID":"/posts/rsync-lsyncd/:3:1","series":null,"tags":["rsync","lsyncd"],"title":"lsyncd 配合 rsync 实现目录实时双向同步","uri":"/posts/rsync-lsyncd/#lsyncdconf-配置"},{"categories":["devops","rsync"],"content":" 启动 lsyncd 服务 bash systemctl start lsyncd systemctl enable lsyncd ","date":"2021-06-12","objectID":"/posts/rsync-lsyncd/:3:2","series":null,"tags":["rsync","lsyncd"],"title":"lsyncd 配合 rsync 实现目录实时双向同步","uri":"/posts/rsync-lsyncd/#启动-lsyncd-服务"},{"categories":["devops","rsync"],"content":" 测试只需要在其中一台服务器的 /data/www/platform_admin/Uploads 中添加文件，然后在另一台服务器查看是否有同步过来，最后在颠倒顺序测试即可。 ","date":"2021-06-12","objectID":"/posts/rsync-lsyncd/:4:0","series":null,"tags":["rsync","lsyncd"],"title":"lsyncd 配合 rsync 实现目录实时双向同步","uri":"/posts/rsync-lsyncd/#测试"},{"categories":["devops","command"],"content":" 基本语法格式 bash sed [option]... 'script' inputfile... 常用选项： -n: 不输出模式空间内容到屏幕，即不自动打印 -e: 多点编辑 -f: 从指定的文件中读取编辑脚本 -r: 支持扩展正则表达式 -i.bak: 备份文件并原处编辑 (.bak 字符是自定义的) ","date":"2021-06-12","objectID":"/posts/sed/:1:0","series":null,"tags":["sed"],"title":"Linux 文本三剑客：sed","uri":"/posts/sed/#基本语法"},{"categories":["devops","command"],"content":" 示例打印文件的最后一行 bash sed -n '$p' /etc/passwd $ 表示最后一行 打印第2行及以下4行 bash seq 10 | sed -n '2,+4p' 打印第2行到第4行 bash seq 10 | sed -n '2,4p' 查找文件中指定字符串行 bash sed -n '/^auth/p' /etc/pam.d/su 判断 /etc/pam.d/su 文件中是否有 auth required pam_securetty.so 配置行 修改行 bash sed -i.bak 's/PermitRoot*/PermitRoot no/g' /etc/ssh/sshd_config -i.bak 在修改文件时会先备份，本例备份文件名为 sshd_config.bak 删除行 bash sed -i '/^PATH/d' /etc/profile ","date":"2021-06-12","objectID":"/posts/sed/:2:0","series":null,"tags":["sed"],"title":"Linux 文本三剑客：sed","uri":"/posts/sed/#示例"},{"categories":["devops","command"],"content":"查看 rename 命令帮助信息 bash [root@localhost ~]# rename --help Usage: rename [options] expression replacement file... rename \u003c要替换的字符\u003e \u003c替换后的字符\u003e \u003c要修改的文件（可以使用通配符批量操作）\u003e Options: -v, --verbose explain what is being done -s, --symlink act on symlink target -h, --help display this help and exit -V, --version output version information and exit 示例 批量将 file 开头的文件, 由 file 改为 linux bash [root@localhost tmp]# ls file* file1 file2 file3 file4 file5 [root@localhost tmp]# rename file linux file* [root@localhost tmp]# ls linux* linux1 linux2 linux3 linux4 linux5 ","date":"2021-06-12","objectID":"/posts/rename/:0:0","series":null,"tags":["rename"],"title":"利用 rename 批量重命名","uri":"/posts/rename/#"},{"categories":["devops","command"],"content":" 官方站点：https://iperf.fr/ 支持平台： windows linux macOS unix 安装方式可以选择二进制文件安装，也可以源码编译安装 bash ./configure \u0026\u0026 make \u0026\u0026 make install iperf 需要两台服务器，一台作服务器，一台作客户端，默认监听 5201 端口 ","date":"2021-06-12","objectID":"/posts/iperf/:0:0","series":null,"tags":["iperf"],"title":"使用 iperf 进行网络性能评估","uri":"/posts/iperf/#"},{"categories":["devops","command"],"content":" 1、启动服务器 bash iperf3 -s -D 说明： -s 以服务的方式运行， -D 以守护进程的方式运行 ","date":"2021-06-12","objectID":"/posts/iperf/:1:0","series":null,"tags":["iperf"],"title":"使用 iperf 进行网络性能评估","uri":"/posts/iperf/#1启动服务器"},{"categories":["devops","command"],"content":" 2、客户端连接测试 bash iperf3 -c iperf3_server_ipaddress 说明： -c 以客户端的方式运行测试 客户端选项 bash -c 以客户端的方式运行 -u 使用udp协议 -b [K|M|G] 指定udp使用的带宽，单位bits/sec。 此选项与-u相关。默认值是1Mbits/sec -t 指定传输数据包的总时间，默认是10s -n [K|M|G] 指定传输数据包的字节数 -l 指定读写缓冲区的长度，TCP方式默认大小为8kb，udp方式默认大小为1470B -P 指定客户端与服务器端之间的线程数，默认是1个线程 -R 切换发送，接收模式，默认客户端发送，服务器端接收。设置此参数将反转。 -w 指定套接字缓冲区大小 -B 用来绑定一个主机地址或接口，适用于有多个网络接口的主机 -M 设置TCP最大信息段的值 -N 设置TCP无延时 客户端与服务器端共用选项 bash -f [k|m|g|K|M|G] 指定带宽输入单位 -p 指定服务器使用的端口或者客户端连接的端口 -i 指定每次报告间隔的时间 -F 指定文件作为数据流进行带宽测试 ","date":"2021-06-12","objectID":"/posts/iperf/:2:0","series":null,"tags":["iperf"],"title":"使用 iperf 进行网络性能评估","uri":"/posts/iperf/#2客户端连接测试"},{"categories":["devops","command"],"content":"首先我们知道通过添加 key 的方式可以实现 ssh 远程免密码执行命令，但是如果我们使用密码的方式该如何不提示输入密码进行 ssh 远程执行命令呢？ 答案就是通过使用 sshpass 工具来实现 ","date":"2021-06-12","objectID":"/posts/sshpass/:0:0","series":null,"tags":["sshpass"],"title":"使用 sshpass 免密码远程执行命令","uri":"/posts/sshpass/#"},{"categories":["devops","command"],"content":" 1. 安装sshpass bash yum install sshpass Tips: 如果系统 yum 源没有 sshpass 包，可以添加阿里云的源。 阿里云开源站点 ","date":"2021-06-12","objectID":"/posts/sshpass/:1:0","series":null,"tags":["sshpass"],"title":"使用 sshpass 免密码远程执行命令","uri":"/posts/sshpass/#1-安装sshpass"},{"categories":["devops","command"],"content":" 2. 示例通过ssh远程登录来测试 sshpass 功能 bash # 本机ip地址 [root@localhost ~]# ifconfig eth0 eth0 Link encap:Ethernet HWaddr 00:0C:29:7B:7C:7E inet addr:192.168.92.132 Bcast:192.168.92.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fe7b:7c7e/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:15089 errors:0 dropped:0 overruns:0 frame:0 TX packets:8054 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:17225172 (16.4 MiB) TX bytes:797990 (779.2 KiB) Interrupt:19 Base address:0x2000 # 输入这条命令不会提示输入密码及确认添加 known_hosts [root@localhost ~]# sshpass -p liwanggui ssh root@192.168.92.133 -o StrictHostKeyChecking=no Last login: Sat Mar 11 07:28:41 2017 from 192.168.92.132 # ssh连接主机的ip地址 [root@localhost ~]# eth0 Link encap:Ethernet HWaddr 00:0C:29:F2:3A:2D inet addr:192.168.92.133 Bcast:192.168.92.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fef2:3a2d/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:225 errors:0 dropped:0 overruns:0 frame:0 TX packets:105 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:23814 (23.2 KiB) TX bytes:14940 (14.5 KiB) Interrupt:19 Base address:0x2000 ","date":"2021-06-12","objectID":"/posts/sshpass/:2:0","series":null,"tags":["sshpass"],"title":"使用 sshpass 免密码远程执行命令","uri":"/posts/sshpass/#2-示例"},{"categories":["devops","command"],"content":" 安装 parted 工具 shell [root@localhost ~]# yum install parted # 包含以下命令 [root@localhost ~]# rpm -ql parted | grep bin /sbin/parted # 分区工具 /sbin/partprobe # 分区表刷新工具 ","date":"2021-06-12","objectID":"/posts/parted/:1:0","series":null,"tags":["parted"],"title":"使用 parted 对 gpt 磁盘分区","uri":"/posts/parted/#安装-parted-工具"},{"categories":["devops","command"],"content":" 使用 parted 分区 shell [root@localhost ~]# parted /dev/sdb GNU Parted 2.1 Using /dev/sdb Welcome to GNU Parted! Type 'help' to view a list of commands. (parted) mklabel gpt # 设置硬盘分区表 Warning: The existing disk label on /dev/sdb will be destroyed and all data on this disk will be lost. Do you want to continue? Yes/No? yes (parted) mkpart # 开始分区 Partition name? []? 1 # 分区表名 File system type? [ext2]? ext4 # 文件系统类型 Start? 1 # 分区空间起始位置 End? 2G # 分区空间结束位置 (parted) mkpart Partition name? []? 2 File system type? [ext2]? ext4 Start? 2G # 这个位置是上分区的结束位置大小 End? 12G # 这个分区的大小加上起始位置就是结束位置大小 (parted) p Model: VMware, VMware Virtual S (scsi) Disk /dev/sdb: 21.5GB Sector size (logical/physical): 512B/512B Partition Table: gpt Number Start End Size File system Name Flags 1 1049kB 2000MB 1999MB 1 2 2000MB 12.0GB 10.0GB 2 ","date":"2021-06-12","objectID":"/posts/parted/:2:0","series":null,"tags":["parted"],"title":"使用 parted 对 gpt 磁盘分区","uri":"/posts/parted/#使用-parted-分区"},{"categories":["devops","command"],"content":" 脚本化分区设置 /dev/sdb 分区表为 gpt, 将所有空间划为一个分区，分区名称为 d1 bash parted -s /dev/sdb mklabel gpt parted -s /dev/sdb mkpart d1 1 100% ","date":"2021-06-12","objectID":"/posts/parted/:3:0","series":null,"tags":["parted"],"title":"使用 parted 对 gpt 磁盘分区","uri":"/posts/parted/#脚本化分区"},{"categories":["devops","command"],"content":"Ncdu 是一个具有 ncurses 接口的磁盘使用率分析器。它的目的是在没有完整图形设置的远程服务器上查找空间占用者，但即使在常规桌面系统上，它也是一个有用的工具。 Ncdu 的目标是快速、简单和易于使用，并且应该能够在安装了 ncurses 的任何最小的类似 POSIX 的环境中运行。 软件官网地址：https://dev.yorhel.nl/ncdu ","date":"2021-06-12","objectID":"/posts/ncdu/:0:0","series":null,"tags":["ncdu"],"title":"使用 ncdu 查找 linux 下最占空间的文件","uri":"/posts/ncdu/#"},{"categories":["devops","command"],"content":" 安装 bash yum install ncdu 你也可以使用源码包进行编译安装 bash wget https://dev.yorhel.nl/download/ncdu-1.15.1.tar.gz tar xzvf ncdu-1.15.1.tar.gz cd ncdu-1.15.1 ./configure make \u0026\u0026 make install ","date":"2021-06-12","objectID":"/posts/ncdu/:1:0","series":null,"tags":["ncdu"],"title":"使用 ncdu 查找 linux 下最占空间的文件","uri":"/posts/ncdu/#安装"},{"categories":["devops","command"],"content":" 使用方法 bash ncdu [dirname] 提示: 按 j k 进行上下移动或者使用上下方向键，Enter 键进行 ","date":"2021-06-12","objectID":"/posts/ncdu/:2:0","series":null,"tags":["ncdu"],"title":"使用 ncdu 查找 linux 下最占空间的文件","uri":"/posts/ncdu/#使用方法"},{"categories":["kubernetes"],"content":" 部署 Jenkinsrbac.yaml 创建 ServiceAccount: jenkins-ci 授予 cluster-admin 权限， jenkins 在 kubernetes 集群中创建工作节点需要权限 你也可以在 kubernetes 插件中配置验证信息 yaml apiVersion: v1 kind: ServiceAccount metadata: name: jenkins-ci namespace: devops --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: jenkins-ci namespace: devops roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: admin subjects: - kind: ServiceAccount name: jenkins-ci namespace: devops pvc.yaml 为 jenkins 划分一块存储，用于持久化 jenkins 数据 yaml --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: jenkins-data namespace: devops spec: storageClassName: managed-nfs-storage accessModes: - ReadWriteMany resources: requests: storage: 5Gi jenkins-ci.yml yaml --- apiVersion: apps/v1 kind: Deployment metadata: name: jenkins namespace: devops spec: selector: matchLabels: app: jenkins template: metadata: labels: app: jenkins spec: terminationGracePeriodSeconds: 10 securityContext: runAsUser: 0 containers: - name: jenkins image: jenkinsci/blueocean:1.24.6 imagePullPolicy: IfNotPresent ports: - containerPort: 8080 name: web protocol: TCP - containerPort: 50000 name: agent protocol: TCP livenessProbe: httpGet: path: /login port: 8080 initialDelaySeconds: 60 timeoutSeconds: 5 failureThreshold: 12 readinessProbe: httpGet: path: /login port: 8080 initialDelaySeconds: 60 timeoutSeconds: 5 failureThreshold: 12 volumeMounts: - name: data mountPath: /var/jenkins_home volumes: - name: data persistentVolumeClaim: claimName: jenkins-data --- apiVersion: v1 kind: Service metadata: labels: app: jenkins name: jenkins namespace: devops spec: ports: - name: \"web\" port: 8080 protocol: TCP targetPort: 8080 - name: \"agent\" port: 50000 protocol: TCP targetPort: 50000 selector: app: jenkins type: ClusterIP ingress-route.yml yaml apiVersion: traefik.containo.us/v1alpha1 kind: IngressRoute metadata: name: jenkins namespace: devops spec: entryPoints: - web routes: - match: Host(`jenkins.host.com`) kind: Rule services: - name: jenkins port: 8080 应用资源配置清单 bash kubectl apply -f rbac.yaml kubectl apply -f pvc.yaml kubectl apply -f configmap.yml kubectl apply -f jenkins-ci.yml kubectl apply -f ingress-route.yml ","date":"2021-04-29","objectID":"/posts/kubernetes-jenkinsci/:1:0","series":null,"tags":["jenkins"],"title":"使用 jenkins 实现 Kubernetes CI","uri":"/posts/kubernetes-jenkinsci/#部署-jenkins"},{"categories":["kubernetes"],"content":" 配置 jenkins","date":"2021-04-29","objectID":"/posts/kubernetes-jenkinsci/:2:0","series":null,"tags":["jenkins"],"title":"使用 jenkins 实现 Kubernetes CI","uri":"/posts/kubernetes-jenkinsci/#配置-jenkins"},{"categories":["kubernetes"],"content":" 首次登录配置在浏览器打开 http://jenkins.host.com 开始配置 jenkins 下一步安装推荐插件即可，等待插件安装完成 创建管理用户 ","date":"2021-04-29","objectID":"/posts/kubernetes-jenkinsci/:2:1","series":null,"tags":["jenkins"],"title":"使用 jenkins 实现 Kubernetes CI","uri":"/posts/kubernetes-jenkinsci/#首次登录配置"},{"categories":["kubernetes"],"content":" 配置管理节点 (kubernetes) kubernetes Cloud通过 kubernetes 插件可以让 jenkins 在 kubernetes 集群以 pod 的方式运行工作节点，下面我们安装 kubernetes 插件, 安装完成后重启生效 现在我们配置 Jenkins 使用 Kubernetes Pod 运行管理节点 依次点击 系统管理 -\u003e 节点管理 -\u003e Configure Clouds -\u003e Add a new cloud 添加 kubernetes 集群 点击 Kubernetes Cloud details 配置 kubernetes 集群 Kubernetes 地址: https://kubernetes.default.svc Jenkins 地址: http://jenkins.devops.svc.cluster.local:8080 Jenkins 通道: jenkins.devops.svc.cluster.local:50000 点击 Save 保存 POD 模板在配置 POD 模板之前，我们需要规划好需要此 POD 工作节点执行哪些操作？ 对项目进行编译 (以 Java 项目为例, 使用 maven 完成) 将编译好的项目制作成 Docker 镜像并推送至 harbor 仓库 (需要调用 docker 命令) 更新 kubernetes 资源配置清单，并应用至 kubernetes 集群中 (需要调用 kubectl 命令) 理清楚步骤后我们开始配置 POD 模板， 依次点击 系统管理 -\u003e 节点管理 -\u003e Configure Clouds -\u003e POD Template -\u003e 添加 POD 模板 名称: maven-3.6 命名空间: devops (默认就是这个；和 jenkins 部署所在 namespace 一致) 容器名: maven Docker 镜像: maven:3.6-openjdk-11 准备挂载 (mount) 资源 给 maven POD 分配一个存储用于缓存从互联网下载的的资源，以便重复利用减少网络带宽占用节约等待时间 maven-pvc.yaml yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: maven-data namespace: devops spec: storageClassName: managed-nfs-storage accessModes: - ReadWriteMany resources: requests: storage: 5Gi 创建 PVC bash kubectl apply -f maven-pvc.yaml 配置 docker push 镜像时所需要的验证信息，并挂载至 pod 容器的 /root/.docker 目录 docker 验证配置以 configmap 的形式存放在 集群中: configmap.yaml yaml apiVersion: v1 data: config.json: \"{\\n\\t\\\"auths\\\": {\\n\\t\\t\\\"harbor.wfugui.com\\\": {\\n\\t\\t\\t\\\"auth\\\": \\\"YWRtaW46SGFyYm9yMTIzNDU=\\\"\\n\\t\\t}\\n\\t},\\n\\t\\\"HttpHeaders\\\": {\\n\\t\\t\\\"User-Agent\\\": \\\"Docker-Client/19.03.15 (linux)\\\"\\n\\t}\\n}\" kind: ConfigMap metadata: creationTimestamp: null name: docker-auth namespace: devops 创建 configmap bash kubectl apply -f configmap.yaml 点击添加卷，添加如下卷 Persistent Volume Claim 申请值: maven-data 挂载路径: /root/.m2 Config Map Volume: Config Map 名称: docker-auth 挂载路径: /root/.docker Host Path Volume: 主机路径: /var/run/docker.sock 挂载路径: /root/.docker Host Path Volume: 主机路径: /usr/bin/docker 挂载路径: /usr/bin/docker Host Path Volume: 主机路径: /usr/bin/kubectl 挂载路径: /usr/bin/kubectl 配置 Server Account 为 jenkins-ci ","date":"2021-04-29","objectID":"/posts/kubernetes-jenkinsci/:2:2","series":null,"tags":["jenkins"],"title":"使用 jenkins 实现 Kubernetes CI","uri":"/posts/kubernetes-jenkinsci/#配置管理节点-kubernetes"},{"categories":["kubernetes"],"content":" 配置管理节点 (kubernetes) kubernetes Cloud通过 kubernetes 插件可以让 jenkins 在 kubernetes 集群以 pod 的方式运行工作节点，下面我们安装 kubernetes 插件, 安装完成后重启生效 现在我们配置 Jenkins 使用 Kubernetes Pod 运行管理节点 依次点击 系统管理 -\u003e 节点管理 -\u003e Configure Clouds -\u003e Add a new cloud 添加 kubernetes 集群 点击 Kubernetes Cloud details 配置 kubernetes 集群 Kubernetes 地址: https://kubernetes.default.svc Jenkins 地址: http://jenkins.devops.svc.cluster.local:8080 Jenkins 通道: jenkins.devops.svc.cluster.local:50000 点击 Save 保存 POD 模板在配置 POD 模板之前，我们需要规划好需要此 POD 工作节点执行哪些操作？ 对项目进行编译 (以 Java 项目为例, 使用 maven 完成) 将编译好的项目制作成 Docker 镜像并推送至 harbor 仓库 (需要调用 docker 命令) 更新 kubernetes 资源配置清单，并应用至 kubernetes 集群中 (需要调用 kubectl 命令) 理清楚步骤后我们开始配置 POD 模板， 依次点击 系统管理 -\u003e 节点管理 -\u003e Configure Clouds -\u003e POD Template -\u003e 添加 POD 模板 名称: maven-3.6 命名空间: devops (默认就是这个；和 jenkins 部署所在 namespace 一致) 容器名: maven Docker 镜像: maven:3.6-openjdk-11 准备挂载 (mount) 资源 给 maven POD 分配一个存储用于缓存从互联网下载的的资源，以便重复利用减少网络带宽占用节约等待时间 maven-pvc.yaml yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: maven-data namespace: devops spec: storageClassName: managed-nfs-storage accessModes: - ReadWriteMany resources: requests: storage: 5Gi 创建 PVC bash kubectl apply -f maven-pvc.yaml 配置 docker push 镜像时所需要的验证信息，并挂载至 pod 容器的 /root/.docker 目录 docker 验证配置以 configmap 的形式存放在 集群中: configmap.yaml yaml apiVersion: v1 data: config.json: \"{\\n\\t\\\"auths\\\": {\\n\\t\\t\\\"harbor.wfugui.com\\\": {\\n\\t\\t\\t\\\"auth\\\": \\\"YWRtaW46SGFyYm9yMTIzNDU=\\\"\\n\\t\\t}\\n\\t},\\n\\t\\\"HttpHeaders\\\": {\\n\\t\\t\\\"User-Agent\\\": \\\"Docker-Client/19.03.15 (linux)\\\"\\n\\t}\\n}\" kind: ConfigMap metadata: creationTimestamp: null name: docker-auth namespace: devops 创建 configmap bash kubectl apply -f configmap.yaml 点击添加卷，添加如下卷 Persistent Volume Claim 申请值: maven-data 挂载路径: /root/.m2 Config Map Volume: Config Map 名称: docker-auth 挂载路径: /root/.docker Host Path Volume: 主机路径: /var/run/docker.sock 挂载路径: /root/.docker Host Path Volume: 主机路径: /usr/bin/docker 挂载路径: /usr/bin/docker Host Path Volume: 主机路径: /usr/bin/kubectl 挂载路径: /usr/bin/kubectl 配置 Server Account 为 jenkins-ci ","date":"2021-04-29","objectID":"/posts/kubernetes-jenkinsci/:2:2","series":null,"tags":["jenkins"],"title":"使用 jenkins 实现 Kubernetes CI","uri":"/posts/kubernetes-jenkinsci/#kubernetes-cloud"},{"categories":["kubernetes"],"content":" 配置管理节点 (kubernetes) kubernetes Cloud通过 kubernetes 插件可以让 jenkins 在 kubernetes 集群以 pod 的方式运行工作节点，下面我们安装 kubernetes 插件, 安装完成后重启生效 现在我们配置 Jenkins 使用 Kubernetes Pod 运行管理节点 依次点击 系统管理 -\u003e 节点管理 -\u003e Configure Clouds -\u003e Add a new cloud 添加 kubernetes 集群 点击 Kubernetes Cloud details 配置 kubernetes 集群 Kubernetes 地址: https://kubernetes.default.svc Jenkins 地址: http://jenkins.devops.svc.cluster.local:8080 Jenkins 通道: jenkins.devops.svc.cluster.local:50000 点击 Save 保存 POD 模板在配置 POD 模板之前，我们需要规划好需要此 POD 工作节点执行哪些操作？ 对项目进行编译 (以 Java 项目为例, 使用 maven 完成) 将编译好的项目制作成 Docker 镜像并推送至 harbor 仓库 (需要调用 docker 命令) 更新 kubernetes 资源配置清单，并应用至 kubernetes 集群中 (需要调用 kubectl 命令) 理清楚步骤后我们开始配置 POD 模板， 依次点击 系统管理 -\u003e 节点管理 -\u003e Configure Clouds -\u003e POD Template -\u003e 添加 POD 模板 名称: maven-3.6 命名空间: devops (默认就是这个；和 jenkins 部署所在 namespace 一致) 容器名: maven Docker 镜像: maven:3.6-openjdk-11 准备挂载 (mount) 资源 给 maven POD 分配一个存储用于缓存从互联网下载的的资源，以便重复利用减少网络带宽占用节约等待时间 maven-pvc.yaml yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: maven-data namespace: devops spec: storageClassName: managed-nfs-storage accessModes: - ReadWriteMany resources: requests: storage: 5Gi 创建 PVC bash kubectl apply -f maven-pvc.yaml 配置 docker push 镜像时所需要的验证信息，并挂载至 pod 容器的 /root/.docker 目录 docker 验证配置以 configmap 的形式存放在 集群中: configmap.yaml yaml apiVersion: v1 data: config.json: \"{\\n\\t\\\"auths\\\": {\\n\\t\\t\\\"harbor.wfugui.com\\\": {\\n\\t\\t\\t\\\"auth\\\": \\\"YWRtaW46SGFyYm9yMTIzNDU=\\\"\\n\\t\\t}\\n\\t},\\n\\t\\\"HttpHeaders\\\": {\\n\\t\\t\\\"User-Agent\\\": \\\"Docker-Client/19.03.15 (linux)\\\"\\n\\t}\\n}\" kind: ConfigMap metadata: creationTimestamp: null name: docker-auth namespace: devops 创建 configmap bash kubectl apply -f configmap.yaml 点击添加卷，添加如下卷 Persistent Volume Claim 申请值: maven-data 挂载路径: /root/.m2 Config Map Volume: Config Map 名称: docker-auth 挂载路径: /root/.docker Host Path Volume: 主机路径: /var/run/docker.sock 挂载路径: /root/.docker Host Path Volume: 主机路径: /usr/bin/docker 挂载路径: /usr/bin/docker Host Path Volume: 主机路径: /usr/bin/kubectl 挂载路径: /usr/bin/kubectl 配置 Server Account 为 jenkins-ci ","date":"2021-04-29","objectID":"/posts/kubernetes-jenkinsci/:2:2","series":null,"tags":["jenkins"],"title":"使用 jenkins 实现 Kubernetes CI","uri":"/posts/kubernetes-jenkinsci/#pod-模板"},{"categories":["kubernetes"],"content":" 使用 Jenkins 实现 CI","date":"2021-04-29","objectID":"/posts/kubernetes-jenkinsci/:3:0","series":null,"tags":["jenkins"],"title":"使用 jenkins 实现 Kubernetes CI","uri":"/posts/kubernetes-jenkinsci/#使用-jenkins-实现-ci"},{"categories":["kubernetes"],"content":" 准备测试项目 登录 http://git.host.com , 创建一个 test 组织, 克隆 https://github.com/liwanggui/spring-boot-helloworld 项目到 test 组织下 创建一个名 jenkins 的用户，将其加入到 test 组织中 项目文件结构 bash ├── Dockerfile # 使用此 Dockerfile build docker 镜像 ├── jenkins │ ├── deliver.sh # jenkins 流水线中会调用此脚本 │ ├── Jenkinsfile # jenkins 声明式流水线配置 │ └── k8s # 项目 kubernetes 资源配置清单 │ ├── deployment.yaml │ ├── ingress.yaml │ └── service.yaml ├── pom.xml ├── README.md └── src ├── main │ └── java │ └── hello │ ├── Application.java │ └── HelloController.java └── test └── java └── hello ├── HelloControllerIT.java └── HelloControllerTest.java ","date":"2021-04-29","objectID":"/posts/kubernetes-jenkinsci/:3:1","series":null,"tags":["jenkins"],"title":"使用 jenkins 实现 Kubernetes CI","uri":"/posts/kubernetes-jenkinsci/#准备测试项目"},{"categories":["kubernetes"],"content":" 配置流水线在 Jenkins 管理界面，点击新建任务创建一个名称为 spring-boot-helloworld 类型为流水线(pipeline)的任务 配置 spring-boot-helloworld 任务配置界面点击流水线，选择 Pipenline script from SCM SCM: Git Repository Url: http://gogs.devops.svc.cluster.local:3000/test/spring-boot-helloworld Credentials: 配置 git 仓库验证信息，使用上面创建的 jenkins 用户 脚本本路径: jenkins/Jenkinsfile 保存 ","date":"2021-04-29","objectID":"/posts/kubernetes-jenkinsci/:3:2","series":null,"tags":["jenkins"],"title":"使用 jenkins 实现 Kubernetes CI","uri":"/posts/kubernetes-jenkinsci/#配置流水线"},{"categories":["kubernetes"],"content":" 构建项目和查看结果 点击开始构建，在构建过程可以点进去查看实时输出日志信息 ","date":"2021-04-29","objectID":"/posts/kubernetes-jenkinsci/:3:3","series":null,"tags":["jenkins"],"title":"使用 jenkins 实现 Kubernetes CI","uri":"/posts/kubernetes-jenkinsci/#构建项目和查看结果"},{"categories":["kubernetes"],"content":" 部署 Gogs互联网常用的 git 代码仓库管理软件有 gitlab, gogs, gitea(gogs 的克隆版) 等，本例为了简单点使用 gogs 作为 git 仓库管理工作部署在 kubernetes 集群中 提示: gitea 部署过和 gogs 基本一致 准备 gogs 资源部署清单，由于 git 代码仓库需要使用持久化存储，因此我们需要为 gogs 创建一个 pvc, gitops 资源统一放在 devops 名称空间下。 bash kubectl create namespace devops pvc.yaml yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: gogs-data namespace: devops spec: storageClassName: managed-nfs-storage accessModes: - ReadWriteMany resources: requests: storage: 10Gi deployment.yaml yaml apiVersion: apps/v1 kind: Deployment metadata: name: gogs namespace: devops spec: selector: matchLabels: app: gogs template: metadata: labels: app: gogs spec: terminationGracePeriodSeconds: 10 # nodeSelector: # workrole: cicd securityContext: runAsUser: 0 containers: - name: gogs image: gogs/gogs:0.12.3 imagePullPolicy: IfNotPresent ports: - containerPort: 3000 name: web protocol: TCP - containerPort: 22 name: ssh protocol: TCP volumeMounts: - name: data mountPath: /data volumes: - name: data persistentVolumeClaim: claimName: gogs-data --- apiVersion: v1 kind: Service metadata: labels: app: gogs name: gogs namespace: devops spec: ports: - name: \"web\" port: 3000 protocol: TCP targetPort: 3000 - name: \"ssh\" port: 22 protocol: TCP targetPort: 22 selector: app: gogs type: ClusterIP ingress-route.yaml yaml apiVersion: traefik.containo.us/v1alpha1 kind: IngressRoute metadata: name: gogs namespace: devops spec: entryPoints: - web routes: - match: Host(`git.host.com`) kind: Rule services: - name: gogs port: 3000 应用资源清单 bash kubectl apply -f pvc.yaml kubectl apply -f deployment.yaml kubectl apply -f ingress-route.yaml ","date":"2021-04-29","objectID":"/posts/kubernetes-git/:1:0","series":null,"tags":["gogs"],"title":"使用 Gogs 服务实现代码仓库管理","uri":"/posts/kubernetes-git/#部署-gogs"},{"categories":["kubernetes"],"content":" 配置 gogs浏览器打开 http://git.host.com 进入 gogs 配置页面 点击 “立即安装” ，安装完成后，进入管理界面 ","date":"2021-04-29","objectID":"/posts/kubernetes-git/:2:0","series":null,"tags":["gogs"],"title":"使用 Gogs 服务实现代码仓库管理","uri":"/posts/kubernetes-git/#配置-gogs"},{"categories":["kubernetes"],"content":" 访问 git 仓库在集群内可以使用 gogs 的集群内部名称来进行访问: http://gogs.devops.svc.cluster.local:3000 在集群外直接使用域名访问即可 如需要使用 ssh 连接 git 仓库需要配置 traefik 的 ingressroutetcp 规则 ","date":"2021-04-29","objectID":"/posts/kubernetes-git/:3:0","series":null,"tags":["gogs"],"title":"使用 Gogs 服务实现代码仓库管理","uri":"/posts/kubernetes-git/#访问-git-仓库"},{"categories":["kubernetes"],"content":" 简介Kubernetes 支持动态申请 PV 和 PVC 的功能，但是 NFS 存储本身不支持这个功能，但是 NFS 存储又是非常常用的一种共享存储。nfs-subdir-external-provisioner 使得 NFS 具备对外提供动态 PV 的能力。 生成的目录为: ${namespace}-${pvcName}-${pvName} 官方主页: https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner ","date":"2021-04-29","objectID":"/posts/kubernetes-nfs-client/:1:0","series":null,"tags":["nfs-subdir-external-provisioner","nfs"],"title":"扩展 NFS 向 Kubernetes 提供动态 PVC 功能","uri":"/posts/kubernetes-nfs-client/#简介"},{"categories":["kubernetes"],"content":" 安装","date":"2021-04-29","objectID":"/posts/kubernetes-nfs-client/:2:0","series":null,"tags":["nfs-subdir-external-provisioner","nfs"],"title":"扩展 NFS 向 Kubernetes 提供动态 PVC 功能","uri":"/posts/kubernetes-nfs-client/#安装"},{"categories":["kubernetes"],"content":" 部署 NFS 文件服务 部署过程请参考 Ubuntu Server 网络文件系统（NFS） ","date":"2021-04-29","objectID":"/posts/kubernetes-nfs-client/:2:1","series":null,"tags":["nfs-subdir-external-provisioner","nfs"],"title":"扩展 NFS 向 Kubernetes 提供动态 PVC 功能","uri":"/posts/kubernetes-nfs-client/#部署-nfs-文件服务"},{"categories":["kubernetes"],"content":" 部署 nfs-subdir-external-provisioner部署使用的资源配置清单官方仓库有提供，地址: https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner/tree/master/deploy 提取 rbac.yaml 和 deployment.yaml 即可 rbac.yaml : https://raw.githubusercontent.com/kubernetes-sigs/nfs-subdir-external-provisioner/master/deploy/rbac.yaml yaml apiVersion: v1 kind: ServiceAccount metadata: name: nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: default --- kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1 metadata: name: nfs-client-provisioner-runner rules: - apiGroups: [\"\"] resources: [\"persistentvolumes\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"delete\"] - apiGroups: [\"\"] resources: [\"persistentvolumeclaims\"] verbs: [\"get\", \"list\", \"watch\", \"update\"] - apiGroups: [\"storage.k8s.io\"] resources: [\"storageclasses\"] verbs: [\"get\", \"list\", \"watch\"] - apiGroups: [\"\"] resources: [\"events\"] verbs: [\"create\", \"update\", \"patch\"] --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: run-nfs-client-provisioner subjects: - kind: ServiceAccount name: nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: default roleRef: kind: ClusterRole name: nfs-client-provisioner-runner apiGroup: rbac.authorization.k8s.io --- kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: name: leader-locking-nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: default rules: - apiGroups: [\"\"] resources: [\"endpoints\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\"] --- kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: leader-locking-nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: default subjects: - kind: ServiceAccount name: nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: default roleRef: kind: Role name: leader-locking-nfs-client-provisioner apiGroup: rbac.authorization.k8s.io deployment.yaml :https://raw.githubusercontent.com/kubernetes-sigs/nfs-subdir-external-provisioner/master/deploy/deployment.yaml 注意: 配置文件中的 nfs server 地址及目录路径需要修改为自己的 yaml apiVersion: apps/v1 kind: Deployment metadata: name: nfs-client-provisioner labels: app: nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: default spec: replicas: 1 strategy: type: Recreate selector: matchLabels: app: nfs-client-provisioner template: metadata: labels: app: nfs-client-provisioner spec: serviceAccountName: nfs-client-provisioner containers: - name: nfs-client-provisioner image: k8s.gcr.io/sig-storage/nfs-subdir-external-provisioner:v4.0.2 volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: k8s-sigs.io/nfs-subdir-external-provisioner - name: NFS_SERVER value: 10.7.79.148 - name: NFS_PATH value: /data/k8s volumes: - name: nfs-client-root nfs: server: 10.7.79.148 path: /data/k8s 修改完成后，向集群应用 nfs-subdir-external-provisioner 资源配置清单 bash kubectl apply -f rbac.yaml kubectl apply -f deployment.yaml ","date":"2021-04-29","objectID":"/posts/kubernetes-nfs-client/:2:2","series":null,"tags":["nfs-subdir-external-provisioner","nfs"],"title":"扩展 NFS 向 Kubernetes 提供动态 PVC 功能","uri":"/posts/kubernetes-nfs-client/#部署-nfs-subdir-external-provisioner"},{"categories":["kubernetes"],"content":" 测试创建 class.yaml yaml apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: managed-nfs-storage provisioner: k8s-sigs.io/nfs-subdir-external-provisioner # or choose another name, must match deployment's env PROVISIONER_NAME' parameters: archiveOnDelete: \"false\" 创建 pvc.yaml yaml kind: PersistentVolumeClaim apiVersion: v1 metadata: name: test-claim spec: storageClassName: managed-nfs-storage accessModes: - ReadWriteMany resources: requests: storage: 1Mi 创建测试 pod.yaml yaml kind: Pod apiVersion: v1 metadata: name: test-pod spec: containers: - name: test-pod image: gcr.io/google_containers/busybox:1.24 command: - \"/bin/sh\" args: - \"-c\" - \"touch /mnt/SUCCESS \u0026\u0026 exit 0 || exit 1\" volumeMounts: - name: nfs-pvc mountPath: \"/mnt\" restartPolicy: \"Never\" volumes: - name: nfs-pvc persistentVolumeClaim: claimName: test-claim 应用 bash kubectl apply -f class.yaml kubectl apply -f pvc.yaml kubectl apply -f pod.yaml 最后进入 pod 查看使用测试下 ","date":"2021-04-29","objectID":"/posts/kubernetes-nfs-client/:3:0","series":null,"tags":["nfs-subdir-external-provisioner","nfs"],"title":"扩展 NFS 向 Kubernetes 提供动态 PVC 功能","uri":"/posts/kubernetes-nfs-client/#测试"},{"categories":["fileserver"],"content":"NFS 允许系统通过网络与他人共享目录和文件。通过使用 NFS，用户和程序可以访问远程系统上的文件，就好像它们是本地文件一样。 NFS 可以提供的一些最显著的好处是： 本地工作站使用较少的磁盘空间，因为常用数据可以存储在单台计算机上，并且仍然可以通过网络为其他人访问。 用户无需在每个网络机器上单独拥有 home 目录。home 目录可在 NFS 服务器上设置，并在整个网络中提供。 软盘、CDROM 驱动器和 USB 拇指驱动器等存储设备可用于网络上的其他计算机。这可能会减少整个网络中的可移动媒体驱动器的数量。 ","date":"2021-04-24","objectID":"/posts/nfs/:0:0","series":null,"tags":["nfs"],"title":"网络文件系统（NFS）","uri":"/posts/nfs/#"},{"categories":["fileserver"],"content":" 安装在终端提示下输入以下命令以安装 NFS 服务器： bash # ubuntu sudo apt install nfs-kernel-server # centos sudo yum install nfs-utils 要启动 NFS 服务器，您可以在终端提示下运行以下命令： bash # ubuntu sudo systemctl start nfs-kernel-server.service # centos sudo systemctl start nfs-server.service ","date":"2021-04-24","objectID":"/posts/nfs/:1:0","series":null,"tags":["nfs"],"title":"网络文件系统（NFS）","uri":"/posts/nfs/#安装"},{"categories":["fileserver"],"content":" 配置您可以通过将目录添加到 NFS 配置文件中来配置要共享的目录。默认配置文件：/etc/exports text /srv *(ro,sync,subtree_check) /scratch *(rw,sync,no_subtree_check,no_all_squash,no_root_squash,insecure) 参数解释: ro 该主机对该共享目录有只读权限 rw 该主机对该共享目录有读写权限 root_squash 客户机用root用户访问该共享文件夹时，将root用户映射成匿名用户 no_root_squash 将客户端使用的是root用户时，则映射到FNS服务器的用户依然为root用户。 all_squash 客户机上的任何用户访问该共享目录时都映射成匿名用户 anonuid 将客户机上的用户映射成指定的本地用户ID的用户 anongid 将客户机上的用户映射成属于指定的本地用户组ID sync 资料同步写入到内存与硬盘中 async 资料会先暂存于内存中，而非直接写入硬盘 secure NFS客户端必须使用NFS保留端口（通常是1024以下的端口），默认选项。 insecure 允许NFS客户端不使用NFS保留端口（通常是1024以上的端口） 确保已创建您添加的任何自定义安装点（/srv 和 /scratch 将存在）： bash sudo mkdir /srv /scratch 注意: 为了让客户机对目录有可读可写权限，给目录赋于 777 权限 重载 NFS 配置文件 bash sudo exportfs -r NFS 常用命令 bash exportfs -v #查看详细的 NFS 信息 exportfs -r #重读配置文件 showmount -e #查看本机发布的 NFS 共享目录 showmount -e +IP #查看 IP 地址发布的 NFS 共享目录 showmount -a +IP #查看有哪些 NFS 客户端挂载了 NFS 服务器上的共享目录 rpcinfo -p localhost #查看rpc注册的端口信息 您可以用具体的主机名替换 *。 使主机名声明尽可能具体。 同步/异步选项可控制更改是否在回复请求之前被限制为稳定存储。因此，async 会带来性能优势，但可能会造成数据丢失或损坏。尽管同步是默认的，但值得设置，因为如果未指定，exportfs 将发出警告。 subtree_check 和 no_subtree_check 启用或禁用安全验证，即客户端尝试为 exported 文件系统安装的子指示器是允许他们进行的安全验证。此验证步骤对某些使用案例（例如文件重命名频繁的家庭目录）有一些性能影响。仅读文件系统更适合启用 subtree_check 。与同步一样，如果未指定，exportfs 将发出警告。 NFS 有许多可选设置，用于调整性能、加强安全性或提供便利。这些设置各有其自身的权衡，因此谨慎使用它们非常重要，仅针对特定用例需要。例如， no_root_squash 增加了便利性，允许任何客户端系统的根用户修改根拥有的文件：在允许在共享安装点上执行可执行项的多用户环境中，这可能导致安全问题。noexec 阻止可执行文件从安装点运行。 ","date":"2021-04-24","objectID":"/posts/nfs/:2:0","series":null,"tags":["nfs"],"title":"网络文件系统（NFS）","uri":"/posts/nfs/#配置"},{"categories":["fileserver"],"content":" NFS 客户端配置要启用客户端系统的 NFS 支持，请在终端提示下输入以下命令： bash # ubuntu sudo apt install nfs-common # centos sudo yum install nfs-utils 使用 mount 命令从另一台机器上挂载共享的 NFS 目录，在终端提示处键入类似于以下命令行： bash sudo mkdir /opt/example sudo mount example.hostname.com:/srv /opt/example ","date":"2021-04-24","objectID":"/posts/nfs/:3:0","series":null,"tags":["nfs"],"title":"网络文件系统（NFS）","uri":"/posts/nfs/#nfs-客户端配置"},{"categories":["fileserver"],"content":" 警告挂载点目录必须存在。目录中不应有任何文件或子目录，否则它们将无法访问，直到 nfs 文件系统卸载。/opt/example/opt/example 挂载 NFS 共享目录的另一种方法是向 /etc/fstab 文件添加一行配置。该行必须说明 NFS 服务器的主机名、及 NFS 共享目录的路径(在 NFS 服务器上的路径)。 /etc/fstab 配置如下 text example.hostname.com:/srv /opt/example nfs nolock,proto=tcp,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,_netdev,noresvport 0 0 挂载命令参数说明: proto: 指定使用的协议，默认为 udp rsize：定义数据块的大小，用于客户端与文件系统之间读取数据。建议值：1048576 wsize：定义数据块的大小，用于客户端与文件系统之间写入数据。建议值：1048576 timeo：指定时长，单位为0.1秒，即NFS客户端在重试向文件系统发送请求之前等待响应的时间。建议值：600（60秒） retrans：NFS客户端重试请求的次数。建议值：2。 noresvport：在网络重连时使用新的TCP端口，保障在网络发生故障恢复时不会中断连接。建议启用该参数。 _netdev: 防止客户端在网络就绪之前开始挂载文件系统。 ","date":"2021-04-24","objectID":"/posts/nfs/:4:0","series":null,"tags":["nfs"],"title":"网络文件系统（NFS）","uri":"/posts/nfs/#警告"},{"categories":["devops"],"content":" CFSSL 简介CFSSL 是 CloudFlare 开源的一款 PKI/TLS 瑞士军刀工具。 CFSSL 既是命令行工具，又是用于签名，验证和捆绑 TLS 证书的 HTTP API 服务器。 使用 Go 1.12+ 语言编写。 官方源码仓库: https://github.com/cloudflare/cfssl ","date":"2021-04-22","objectID":"/posts/cfssl/:1:0","series":null,"tags":["cfssl","cfssl-json","cfssl-certinfo"],"title":"使用 cfssl 自签证书","uri":"/posts/cfssl/#cfssl-简介"},{"categories":["devops"],"content":" 安装 cfssl bash wget https://github.com/cloudflare/cfssl/releases/download/v1.5.0/cfssljson_1.5.0_linux_amd64 -O /usr/local/bin/cfssl-json wget https://github.com/cloudflare/cfssl/releases/download/v1.5.0/cfssl_1.5.0_linux_amd64 -O /usr/local/bin/cfssl wget https://github.com/cloudflare/cfssl/releases/download/v1.5.0/cfssl-certinfo_1.5.0_linux_amd64 -O /usr/local/bin/cfssl-certinfo chmod +x /usr/local/bin/cfssl* ","date":"2021-04-22","objectID":"/posts/cfssl/:2:0","series":null,"tags":["cfssl","cfssl-json","cfssl-certinfo"],"title":"使用 cfssl 自签证书","uri":"/posts/cfssl/#安装-cfssl"},{"categories":["devops"],"content":" 自签证书","date":"2021-04-22","objectID":"/posts/cfssl/:3:0","series":null,"tags":["cfssl","cfssl-json","cfssl-certinfo"],"title":"使用 cfssl 自签证书","uri":"/posts/cfssl/#自签证书"},{"categories":["devops"],"content":" 签发 CA 证书生成 CA 证书签名请求文件 ca-csr.json bash mkdir certs cd certs/ cat \u003e ca-csr.json \u003c\u003cEOF { \"CN\": \"CA\", \"hosts\": [ ], \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"L\": \"BeiJing\", \"O\": \"BJ\", \"ST\": \"BeiJing\", \"OU\": \"CA\" } ], \"ca\": { \"expiry\": \"175200h\" } } EOF 证书签名请求文件可以使用 cfssl print-defaults csr 创建，然后在进行相应的修改 生成 CA 证书 bash cfssl gencert -initca ca-csr.json | cfssl-json -bare ca ","date":"2021-04-22","objectID":"/posts/cfssl/:3:1","series":null,"tags":["cfssl","cfssl-json","cfssl-certinfo"],"title":"使用 cfssl 自签证书","uri":"/posts/cfssl/#签发-ca-证书"},{"categories":["devops"],"content":" 签发域名证书自签发一个域名证书，以 host.com 域名为例 生成证书配置文件 默认配置可以使用 cfssl print-defaults config 命令生成 bash cat \u003e config.json \u003c\u003cEOF { \"signing\": { \"default\": { \"expiry\": \"87600h\" }, \"profiles\": { \"www\": { \"expiry\": \"87600h\", \"usages\": [ \"signing\", \"key encipherment\", \"server auth\" ] }, \"client\": { \"expiry\": \"87600h\", \"usages\": [ \"signing\", \"key encipherment\", \"client auth\" ] } } } } EOF 生成 host.com 域名证书签名请求文件 host-csr.json bash cat \u003e host-csr.json \u003c\u003cEOF { \"CN\": \"host.com\", \"hosts\": [ \"host.com\", \"*.host.com\" ], \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"L\": \"BeiJing\", \"O\": \"BJ\", \"ST\": \"BeiJing\", \"OU\": \"HOST\" } ] } EOF 签发 host.com 域名证书 bash cfssl gencert -ca ca.pem -ca-key ca-key.pem -config config.json -profile www host-csr.json | cfssl-json -bare host 使用 cfssl-certinfo 命令查看证书信息 bash root@10-7-79-148:~/certs# cfssl-certinfo -cert host.pem { \"subject\": { \"common_name\": \"host.com\", \"country\": \"CN\", \"organization\": \"BJ\", \"organizational_unit\": \"HOST\", \"locality\": \"BeiJing\", \"province\": \"BeiJing\", \"names\": [ \"CN\", \"BeiJing\", \"BeiJing\", \"BJ\", \"HOST\", \"host.com\" ] }, \"issuer\": { \"common_name\": \"CA\", \"country\": \"CN\", \"organization\": \"BJ\", \"organizational_unit\": \"CA\", \"locality\": \"BeiJing\", \"province\": \"BeiJing\", \"names\": [ \"CN\", \"BeiJing\", \"BeiJing\", \"BJ\", \"CA\", \"CA\" ] }, \"serial_number\": \"50106944723092673296745532281502755453871335123\", \"sans\": [ \"host.com\", \"*.host.com\" ], \"not_before\": \"2021-04-22T13:28:00Z\", \"not_after\": \"2031-04-20T13:28:00Z\", \"sigalg\": \"SHA256WithRSA\", \"authority_key_id\": \"46:6C:D3:F9:1A:89:A0:B6:11:82:DA:E2:8B:8D:00:24:3E:8F:9E:3D\", \"subject_key_id\": \"6A:E8:F5:D9:E5:14:C0:2E:AE:53:DF:41:AF:9E:FF:A7:9B:D4:6A:80\", \"pem\": \"-----BEGIN CERTIFICATE-----\\nMIID3jCCAsagAwIBAgIUCMbfhCW8BG+QACtbh8V8YVcoJtMwDQYJKoZIhvcNAQEL\\nBQAwWDELMAkGA1UEBhMCQ04xEDAOBgNVBAgTB0JlaUppbmcxEDAOBgNVBAcTB0Jl\\naUppbmcxCzAJBgNVBAoTAkJKMQswCQYDVQQLEwJDQTELMAkGA1UEAxMCQ0EwHhcN\\nMjEwNDIyMTMyODAwWhcNMzEwNDIwMTMyODAwWjBgMQswCQYDVQQGEwJDTjEQMA4G\\nA1UECBMHQmVpSmluZzEQMA4GA1UEBxMHQmVpSmluZzELMAkGA1UEChMCQkoxDTAL\\nBgNVBAsTBEhPU1QxETAPBgNVBAMTCGhvc3QuY29tMIIBIjANBgkqhkiG9w0BAQEF\\nAAOCAQ8AMIIBCgKCAQEA3ZfbPOW2hzTi3Ec/gpufnhaOkRiCZYIcGe5BJx+cip8c\\nh553anDZts2i1ZTYMeTjwtgHbojHqgqGgcF3xsCHQidRwoOhp7UHRgwfAacfmv0U\\nF5qmoPfNcbQzyZXhDJZAZqWLGqDBhCR/hVVugahXmZb8XzkpreTYTGHAiwAgUKXq\\nDEtEDr0D6LRw27+dR/1bwFs0ad2aEeJxvdH5Y40hO796VoPbX6PCI/TPkMnUsdTF\\nL51Ge+WEKk4TwEEghV1fl6+gGg3dmTcHpb8S5/zhe1bDI7Zs9/ErTAxd1HDdlPxt\\n66HtiygfKEjy8qVtsCIz+hzCxn9bZsmwNRdvV0QitQIDAQABo4GXMIGUMA4GA1Ud\\nDwEB/wQEAwIFoDATBgNVHSUEDDAKBggrBgEFBQcDATAMBgNVHRMBAf8EAjAAMB0G\\nA1UdDgQWBBRq6PXZ5RTALq5T30Gvnv+nm9RqgDAfBgNVHSMEGDAWgBRGbNP5Gomg\\nthGC2uKLjQAkPo+ePTAfBgNVHREEGDAWgghob3N0LmNvbYIKKi5ob3N0LmNvbTAN\\nBgkqhkiG9w0BAQsFAAOCAQEAluByuUmRaPi1+SxjosQI8w6CvJC0N5XbAjsyXrDo\\netwpKKty0745aKyCtkFu6KW7bQohoX4JBdSrqve9V1Psm7Iwh6P8LKBRckBn6lMq\\ndavsgoGkyD/RwRMLUpi0TW8bvd0m+BOO2iHb+BSID7C+WPxflZb2Z8z1ljyzFaM6\\nmfevfYMqUiiRP/ztHvrHcZnk9pQi3kserPJg5DIzNvsvMd1T8IwJg36iIt6j4pi1\\nbtmXSWssMSR1vc7ZPWjS3Jc+2nDVjyPvARJsoAy6BBg07Pd41FhgKPgQE8il1oxc\\n3ep1OXlIC5IjfoZWrp80kznOaj++cOzl1Mg3k+eVyKmx1w==\\n-----END CERTIFICATE-----\\n\" } ","date":"2021-04-22","objectID":"/posts/cfssl/:3:2","series":null,"tags":["cfssl","cfssl-json","cfssl-certinfo"],"title":"使用 cfssl 自签证书","uri":"/posts/cfssl/#签发域名证书"},{"categories":["elasticstack"],"content":" 安装配置 filebeat","date":"2021-04-14","objectID":"/posts/filebeat/:1:0","series":null,"tags":["filebeat"],"title":"使用 Filebeat 收集 nginx 日志","uri":"/posts/filebeat/#安装配置-filebeat"},{"categories":["elasticstack"],"content":" 安装 bash root@ubuntu:/opt# wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.12.0-amd64.deb root@ubuntu:/opt# dpkg -i filebeat-7.12.0-amd64.deb ","date":"2021-04-14","objectID":"/posts/filebeat/:1:1","series":null,"tags":["filebeat"],"title":"使用 Filebeat 收集 nginx 日志","uri":"/posts/filebeat/#安装"},{"categories":["elasticstack"],"content":" 配置filebeat.yml bash root@ubuntu:/etc/filebeat# cat filebeat.yml filebeat.inputs: - type: log enabled: true paths: - /usr/local/nginx/logs/access.log json.keys_under_root: true json.overwrite_keys: true #filebeat.config.modules: # path: ${path.config}/modules.d/*.yml # reload.enabled: true setup.template.settings: index.number_of_shards: 3 # 配置索引分片数 # #setup.kibana: # output.elasticsearch: hosts: [\"192.168.16.102:9200\",\"192.168.16.103:9200\",\"192.168.16.104:9200\"] # 配置索引名为 nginx-日期，用于区分应用 index: \"nginx-%{+YYYY-MM}\" setup.template.enable: true setup.template.name: \"nginx\" setup.template.pattern: \"nginx-*\" setup.ilm.enabled: false #setup.ilm.rollover_alias: \"nginx\" #setup.ilm.pattern: \"{now/d}-000001\" # #processors: # - add_host_metadata: # when.not.contains.tags: forwarded # - add_cloud_metadata: ~ # - add_docker_metadata: ~ # - add_kubernetes_metadata: ~ ","date":"2021-04-14","objectID":"/posts/filebeat/:1:2","series":null,"tags":["filebeat"],"title":"使用 Filebeat 收集 nginx 日志","uri":"/posts/filebeat/#配置"},{"categories":["elasticstack"],"content":" 配置 nginx 日志格式 bash root@nginx-1:~# cat /etc/nginx/log-json log_format json '{\"remote_addr\":\"$remote_addr\", \"time_local\": \"$time_local\", \"domain\":\"$host\", \"request\":\"$request\", ' '\"status\":\"$status\", \"body_bytes_sent\":\"$body_bytes_sent\", \"method\":\"$request_method\", ' '\"http_referer\":\"$http_referer\", \"request_time\":\"$request_time\", ' '\"http_user_agent\":\"$http_user_agent\", \"http_x_forwarded_for\":\"$http_x_forwarded_for\", ' '\"upstream_addr\":\"$upstream_addr\", \"upstream_response_time\":\"$upstream_response_time\"}'; # 在 nginx 配置文件中引入，并指定 access_log 使用 json 格式记录日志 root@nginx-1:~# vim /etc/nginx/nginx.conf include /etc/nginx/log-json; access_log /var/log/nginx/access.log json; ","date":"2021-04-14","objectID":"/posts/filebeat/:2:0","series":null,"tags":["filebeat"],"title":"使用 Filebeat 收集 nginx 日志","uri":"/posts/filebeat/#配置-nginx-日志格式"},{"categories":["elasticstack"],"content":" 环境准备本文使用 Ubuntu 20.04 安装 elasticsearch 集群，准备三台机。 192.168.16.102 192.168.16.103 192.168.16.104 ","date":"2021-04-10","objectID":"/posts/elasticsearch/:1:0","series":null,"tags":["elasticsearch"],"title":"部署 ElasticSearch 集群","uri":"/posts/elasticsearch/#环境准备"},{"categories":["elasticstack"],"content":" 安装配置 elasticsearch 集群","date":"2021-04-10","objectID":"/posts/elasticsearch/:2:0","series":null,"tags":["elasticsearch"],"title":"部署 ElasticSearch 集群","uri":"/posts/elasticsearch/#安装配置-elasticsearch-集群"},{"categories":["elasticstack"],"content":" 安装 elasticsearch bash root@ubuntu:/opt# wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.12.0-linux-x86_64.tar.gz root@ubuntu:/opt# tar xzf elasticsearch-7.12.0-linux-x86_64.tar.gz root@ubuntu:/opt# ln -s elasticsearch-7.12.0 elasticsearch ","date":"2021-04-10","objectID":"/posts/elasticsearch/:2:1","series":null,"tags":["elasticsearch"],"title":"部署 ElasticSearch 集群","uri":"/posts/elasticsearch/#安装-elasticsearch"},{"categories":["elasticstack"],"content":" 配置 elasticsearch bash root@ubuntu:/opt# cd elasticsearch/config root@ubuntu:/opt/elasticsearch/config# cat \u003e elasticsearch.yml \u003c\u003cEOF # 集群名 cluster.name: my-application # 集群内同时启动的数据任务个数，默认是2个 cluster.routing.allocation.cluster_concurrent_rebalance: 16 # 添加或删除节点为及负载均衡时并发恢复的线程个数，默认是4个 cluster.routing.allocation.node_concurrent_recoveries: 16 # 初始化数据恢复时，并发恢复线程的个数，默认4个 cluster.routing.allocation.node_initial_primaries_recoveries: 16 # 节点名 node.name: node-1 # 是否有资格成为主节点 node.master: true # 是否为数据节点 node.data: true path.data: /data/elasticsearch/data path.logs: /data/elasticsearch/logs # 监听的网络地址 network.host: 0.0.0.0 network.tcp.keep_alive: true network.tcp.no_delay: true transport.tcp.compress: true gateway.recover_after_nodes: 2 # 用于 HTTP 客户端通信的端口 http.port: 9200 # 用于节点之间通信的端口 transport.port: 9300 # head 管理插件需要打开跨域配置 http.cors.allow-origin: \"*\" http.cors.enabled: true http.max_content_length: 200mb # 节点发现 discovery.seed_hosts: [\"192.168.16.102:9300\",\"192.168.16.103:9300\",\"192.168.16.104:9300\"] # 初始化一个集群时需要此配置来选举 master cluster.initial_master_nodes: [\"node-1\"] EOF # 配置 jvm 堆内存大小 root@ubuntu:/opt/elasticsearch/config# grep '^-Xm' jvm.options -Xms4g -Xmx4g ","date":"2021-04-10","objectID":"/posts/elasticsearch/:2:2","series":null,"tags":["elasticsearch"],"title":"部署 ElasticSearch 集群","uri":"/posts/elasticsearch/#配置-elasticsearch"},{"categories":["elasticstack"],"content":" 系统配置 bash root@ubuntu:/opt/elasticsearch# useradd -m -s /bin/bash elasticsearch root@ubuntu:/opt/elasticsearch# mkdir -p /data/elasticsearch/{data,logs} root@ubuntu:/opt/elasticsearch# chown -R elasticsearch.elasticsearch /data/elasticsearch root@ubuntu:/opt/elasticsearch# chown -R elasticsearch.elasticsearch /opt/elasticsearch-7.12.0 root@ubuntu:/opt/elasticsearch/config# cat \u003e\u003e /etc/security/limits.conf \u003c\u003cEOF * soft nproc unlimited * hard nproc unlimited * soft core unlimited * soft nofile 65535 * hard nofile 65535 EOF root@ubuntu:/opt/elasticsearch/config# echo 'vm.max_map_count=262144' \u003e\u003e /etc/sysctl.conf root@ubuntu:/opt/elasticsearch/config# sysctl -p ","date":"2021-04-10","objectID":"/posts/elasticsearch/:2:3","series":null,"tags":["elasticsearch"],"title":"部署 ElasticSearch 集群","uri":"/posts/elasticsearch/#系统配置"},{"categories":["elasticstack"],"content":" 启动 elasticsearch 服务 bash root@ubuntu:~# su - elasticsearch elasticsearch@ubuntu:~$ cd /opt/elasticsearch elasticsearch@ubuntu:/opt/elasticsearch$ ./bin/elasticsearch elasticsearch 默认不允许使用 root 用户启动， 需要切换至 elasticsearch 用户启动； -d 选项可以将程序设置为守护进程 提示：以相同的操作方法配置另两台节点，注意节点名不要重复 ","date":"2021-04-10","objectID":"/posts/elasticsearch/:2:4","series":null,"tags":["elasticsearch"],"title":"部署 ElasticSearch 集群","uri":"/posts/elasticsearch/#启动-elasticsearch-服务"},{"categories":["elasticstack"],"content":" elasticsearch 安全验证elasticsearch 7.7 以后的版本将安全认证功能免费开放了。 并将 X-pack 插件集成了到了开源的 ElasticSearch 版本中。下面介绍如何利用 X-pack 给 ElasticSearch 相关组件设置用户名和密码 bash # 配置 xpack, 启用验证功能 root@ubuntu:/opt/elasticsearch# cat \u003e\u003econfig/elasticsearch.yml \u003c\u003cEOF xpack.security.enabled: true xpack.security.transport.ssl.enabled: true EOF # 重启 elasticsearch 服务 root@ubuntu:/opt/elasticsearch# kill \u003celasticsearch-pid\u003e root@ubuntu:/opt/elasticsearch# su - elasticsearch elasticsearch@ubuntu:~$ cd /opt/elasticsearch elasticsearch@ubuntu:/opt/elasticsearch$ ./bin/elasticsearch -d # 使用交互命令行模式配置验证密码 elasticsearch@ubuntu:/opt/elasticsearch$ ./bin/elasticsearch-setup-passwords interactive Initiating the setup of passwords for reserved users elastic,apm_system,kibana,kibana_system,logstash_system,beats_system,remote_monitoring_user. You will be prompted to enter passwords as the process progresses. Please confirm that you would like to continue [y/N]y Enter password for [elastic]: Reenter password for [elastic]: Enter password for [apm_system]: Reenter password for [apm_system]: Enter password for [kibana_system]: Reenter password for [kibana_system]: Enter password for [logstash_system]: Reenter password for [logstash_system]: Enter password for [beats_system]: Reenter password for [beats_system]: Enter password for [remote_monitoring_user]: Reenter password for [remote_monitoring_user]: 到此已经完成ES及相关组件的加密了, 后续访问和使用相关组件都需要验证用户名和密码了 (请记好你配置的密码) 验证密码信息存储在 .security-7 索引中 不带密码访问时 bash root@ubuntu:~# curl -I localhost:9200 HTTP/1.1 401 Unauthorized WWW-Authenticate: Basic realm=\"security\" charset=\"UTF-8\" content-type: application/json; charset=UTF-8 content-length: 381 带密码访问 bash root@ubuntu:~# curl -i localhost:9200 -u elastic:JEd01cn6hj0qm2mO HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 content-length: 530 { \"name\" : \"node-1\", \"cluster_name\" : \"my-application\", \"cluster_uuid\" : \"G6jxloWFR1SpCJ5cqb4EKA\", \"version\" : { \"number\" : \"7.12.0\", \"build_flavor\" : \"default\", \"build_type\" : \"tar\", \"build_hash\" : \"78722783c38caa25a70982b5b042074cde5d3b3a\", \"build_date\" : \"2021-03-18T06:17:15.410153305Z\", \"build_snapshot\" : false, \"lucene_version\" : \"8.8.0\", \"minimum_wire_compatibility_version\" : \"6.8.0\", \"minimum_index_compatibility_version\" : \"6.0.0-beta1\" }, \"tagline\" : \"You Know, for Search\" } ","date":"2021-04-10","objectID":"/posts/elasticsearch/:3:0","series":null,"tags":["elasticsearch"],"title":"部署 ElasticSearch 集群","uri":"/posts/elasticsearch/#elasticsearch-安全验证"},{"categories":["elasticstack"],"content":" 重置 elasticsearch 密码 官方文档: https://www.elastic.co/guide/en/elasticsearch/reference/7.4/security-api-change-password.html 修改 elastic 用户的密码 bash root@ubuntu:~# curl -X POST localhost:9200/_security/user/elastic/_password \\ -d '{\"password\":\"123456\"}' \\ -u elastic:JEd01cn6hj0qm2mO \\ -H 'content-type: application/json' 也可以使用 ./bin/elasticsearch-setup-passwords interactive 命令重新设置 ","date":"2021-04-10","objectID":"/posts/elasticsearch/:4:0","series":null,"tags":["elasticsearch"],"title":"部署 ElasticSearch 集群","uri":"/posts/elasticsearch/#重置-elasticsearch-密码"},{"categories":["nginx"],"content":"nginx 的 ngx_http_auth_basic_module 模块允许通过使用 “HTTP Basic Authentication” 协议验证用户名和密码来限制对资源的访问， 当站点本身不支持身份验证，又需要添加身份验证时就可以使用此模块来实现 ","date":"2021-04-02","objectID":"/posts/nginx-auth-basic/:0:0","series":null,"tags":["nginx"],"title":"nginx - 基础身份验证 (auth_basic)","uri":"/posts/nginx-auth-basic/#"},{"categories":["nginx"],"content":" 配置 auth_basic text location / { auth_basic \"closed site\"; auth_basic_user_file conf/htpasswd; } ","date":"2021-04-02","objectID":"/posts/nginx-auth-basic/:1:0","series":null,"tags":["nginx"],"title":"nginx - 基础身份验证 (auth_basic)","uri":"/posts/nginx-auth-basic/#配置-auth_basic"},{"categories":["nginx"],"content":" 准备用户身份验证文件用户身份验证文件 conf/htpasswd 格式如下: text # comment name1:password1 name2:password2:comment name3:password3 注意: 用户密码可以使用 htpasswd (htpasswd 是 apache web 服务的实用工具) 或 openssl passwd -apr1 命令生成 生成用户身份验证文件, 用户: zhangshan 密码: test@123 bash echo \"zhangshan:$(openssl passwd -apr1 test@123):张三\" \u003e\u003e conf/htpasswd ","date":"2021-04-02","objectID":"/posts/nginx-auth-basic/:2:0","series":null,"tags":["nginx"],"title":"nginx - 基础身份验证 (auth_basic)","uri":"/posts/nginx-auth-basic/#准备用户身份验证文件"},{"categories":["nginx"],"content":" 使用 logrotate 管理 nginx 日志随着时间的推移 nginx 的日志会越来越大，为了减少 nginx 日志的体积大小，使用 logrotate 工具每天对 nginx 日志进行切割处理 nginx logrotate 配置文件: /etc/logrotate.d/nginx bash /usr/local/nginx/logs/*.log { daily missingok rotate 30 compress dateext delaycompress notifempty sharedscripts postrotate if [ -f /usr/local/nginx/logs/nginx.pid ]; then kill -USR1 `cat /usr/local/nginx/logs/nginx.pid` fi endscript } 更多 logrotate 配置参数请参考 man 手册 man logrotate ","date":"2021-04-01","objectID":"/posts/nginx-logrotate/:1:0","series":null,"tags":["nginx"],"title":"nginx - 日志轮转","uri":"/posts/nginx-logrotate/#使用-logrotate-管理-nginx-日志"},{"categories":["nginx"],"content":" alias 与 root 区别nginx 是通过 alias 设置虚拟目录，在 nginx 的配置中， alias 目录和 root 目录是有区别的 alias 指定的目录是准确的，即 location 匹配访问的 path 目录下的文件直接是在 alias 目录下查找的； root 指定的目录是 location 匹配访问的 path 目录的上一级目录, 这个 path 目录一定要是真实存在 root 指定目录下的； 使用 alias 标签的目录块中不能使用 rewrite 的 break（具体原因不明）；另外， alias 指定的目录后面必须要加上 \"/\" 符号！ alias 虚拟目录配置中，location 匹配的 path 目录如果后面不带 \"/\" ，那么访问的url地址中这个 path 目录后面加不加 \"/\" 不影响访问，访问时它会自动加上 \"/\" ； 但是如果 location 匹配的 path 目录后面加上 \"/\"，那么访问的 url 地址中这个 path 目录必须要加上 \"/\"，访问时它不会自动加上 \"/\"。如果不加上 \"/\"，访问就会失败！ root 目录配置中，location 匹配的 path 目录后面带不带 \"/\"，都不会影响访问。 ","date":"2021-04-01","objectID":"/posts/nginx-alias-root/:1:0","series":null,"tags":["nginx"],"title":"nginx - alias 与 root 区别","uri":"/posts/nginx-alias-root/#alias-与-root-区别"},{"categories":["nginx"],"content":" 举例说明比如 nginx 配置的域名是 liwanggui.com text location /huan/ { alias /home/www/huan/; } 在上面 alias 虚拟目录配置下，访问 http://liwanggui.com/huan/a.html 实际指定的是 /home/www/huan/a.html。 注意: alias 指定的目录后面必须要加上 \"/\"，即 /home/www/huan/ 不能改成 /home/www/huan 上面的配置也可以改成 root 目录配置，如下 这样 nginx 就会去 /home/www/huan 下寻找 http://liwanggui.com/huan/a.html 资源，两者配置后的访问效果是一样的！ text location /huan/ { root /home/www/; } ","date":"2021-04-01","objectID":"/posts/nginx-alias-root/:2:0","series":null,"tags":["nginx"],"title":"nginx - alias 与 root 区别","uri":"/posts/nginx-alias-root/#举例说明"},{"categories":["nginx"],"content":" 域名重定向当用户访问 http://liwanggui.com 时 url 重定向至 https://liwanggui.com， 实现 http -\u003e https 重定向，实现方式有两种： 通过 rewrite 模块的 permanent 参数实现永久重定向的 http 状态 301 通过 return 指令实现 （推荐） rewrite 实现 bash server { listen 80; server_name liwanggui.com; access_log off; rewrite ^/(.*)$ https://$host/$1 permanent; # 匹配以斜杠开头之后的所有字符 $1 表示小括号内匹配的字符 permanent 表示永久301跳转 } return 实现: 推荐做法 bash server { listen 80; server_name liwanggui.com; access_log off; return 301 https://$host$request_uri; } $host: 表示 HTTP 请求头中的 Host 值 $request_uri: 表示 HTTP 请求 uri ","date":"2021-04-01","objectID":"/posts/nginx-syntax/:1:0","series":null,"tags":["nginx"],"title":"nginx - 常用指令语法","uri":"/posts/nginx-syntax/#域名重定向"},{"categories":["nginx"],"content":" 多域名跳转应用实例使用 nginx 做反向代理，当用户访问 www.liwanggui.com 时就代理到 192.168.1.100:8080 的 web 目录下， 当用户访问 http://www.liwanggui.com/admin 时就代理到 192.168.1.100:8080 的 admin 目录下， 当用户访问 wap.liwanggui.com 时就代理到 192.168.1.100:8080 的 wap 目录下 bash server_name www.liwanggui.com; location / { proxy_pass http://192.168.1.100:8080/web/; } location /admin { proxy_pass http://192.168.1.100:8080/admin; } server_name wap.liwanggui.com; location / { proxy_pass http://192.168.1.100:8080/wap/; } 注意：在 proxy_pass 配置两个代理目录 web 和 wap 后面必须加一个斜杠，否则 nginx 会报错，仔细看上面代理配置中两种写法的区别就明白了 ","date":"2021-04-01","objectID":"/posts/nginx-syntax/:2:0","series":null,"tags":["nginx"],"title":"nginx - 常用指令语法","uri":"/posts/nginx-syntax/#多域名跳转应用实例"},{"categories":["nginx"],"content":" nginx 常用指令nginx 的 URL 重写模块是用得比较多的模块之一，常用的 URL 重写模块命令有 if 、rewrite、 set、 break ","date":"2021-04-01","objectID":"/posts/nginx-syntax/:3:0","series":null,"tags":["nginx"],"title":"nginx - 常用指令语法","uri":"/posts/nginx-syntax/#nginx-常用指令"},{"categories":["nginx"],"content":" if 命令 语法： if (condition) {....} 默认值： none 使用字段: server 、location 默认情况下，if 命令默认值为空，可在 nginx 配置文件的 server、location 部分使用，另外，if 命令可以在在判断语句中指定正则或匹配条件等，相关匹配条件如下： if 与小括号之间有一个空格 正则表达式匹配 ~ 表示区分大小写匹配 ~* 表示不区分大小写匹配 !~ 表示区分大小写不匹配， !~* 表示不区分大小写不匹配 文件及目录匹配 -f 和 !-f 用来判断是否存在文件 -d 和 !-d 用来判断是否存在目录 -e 和 !-e 用来判断是否存在文件和目录 -x 和 !-x 用来判断文件是否可执行 nginx 配置文件中有很多内置变量，这些变量经常和if命令一起使用。常见的内置变量有如下几种: $args, 此变量与请求行中的参数相等 $document_root， 此变量等同于当前请求的 root 命令指定的值 $uri, 此变量等同于当前 request 中的 uri $document_uri， 此变量与 $uri 含义一样 $host， 此变量与请求头部中的 “Host” 行指定的值一致 $limit_rate, 此变量用来设置限制连接的速率 $request_method, 此变量等同于 request 的 method，通常是’GET’,‘POST’ $remote_addr, 此变量表示客户端的IP地址 $remote_port, 此变量表示客户端端口 $remote_user, 此变量等同于用户名，由 ngx_http_auth_basic_module 认证 $request_filename, 此变量表示当前请求的文件的路径名，由 root 或 alias 与 URI request 组合而成 $request_uri, 此变量表示含有参数的完整的初始 URI $query_string, 此变量与$args含义一致 $server_name, 此变量表示请求到达的服务器名 $server_port, 此变量表示请示到达的服务器端口 例：uri为：http://localhost:88/test1/test2/test.php 各变量值如下： text $host： localhost $server_port： 88 $request_uri： http://localhost:88/test1/test2/test.php $document_uri： /test1/test2/test.php $document_root： /var/www/html $request_filename： /var/www/html/test1/test2/test.php 配置实例 text server { listen 80; server_name www.liwanggui.com; access_log logs/host.access.log main; index index.html index.htm; root /var/www/html; location ~*\\.(gif|jpg|jpeg|png|bmp|swf|htm|html|css|js)$ { root /usr/local/nginx/www/img; if (!-f $request_filename){ root /var/www/html/img; } if (!-f $request_filename){ root /apps/images; } } location ~*\\.(jsp)${ root /webdata/webapp/www/ROOT; if (!-f $request_filename){ root /usr/local/nginx/www/jsp; } proxy_pass http://127.0.0.1:8888; } } 这段代码主要完成对 www.liwanggui.com 这个域名的资源访问配置， www.liwanggui.com 这个域名的根目录为 /var/www/html, 而静态资源分别位于 /usr/local/nginx/www/img, /var/www/html/img, /apps/images 三个目录下， 请求静态资源的方式依次在三个目录中找，如果第一个目录找不到，就找第二目录，以此类推，如果都找不到，将提示404错误； 动态资源分别位于 /webdata/webapp/www/ROOT,/usr/local/nginx/www/jsp, 两个目录下，如果客户端请求的的资源是以 .jsp 结尾的，那么将依次在这两个动态程序目录下查找资源。 而于没有在这两个目录中定义的资源，将全部从根目录 /var/www/html 进行查找。 ","date":"2021-04-01","objectID":"/posts/nginx-syntax/:3:1","series":null,"tags":["nginx"],"title":"nginx - 常用指令语法","uri":"/posts/nginx-syntax/#if-命令"},{"categories":["nginx"],"content":" rewrite 命令nginx 通过 ngx_http_rewrite_module 模块支持URL重写和if条件判断，但要使用 rewrite 功能，需要 pcre 支持，应在编译 nginx 时指定 pcre 源码目录. rewrite 的使用语法如下： 语法： rewrite regex flag 默认值： none 使用字段： server location if 在默认情况下，rewrite 命令默认值为空，可以 nginx 配置文件的 server,location,if 部分使用，rewrite 命令的最后一项参数为 flag 标记,其支持的 flag 标记主要有以下几种： last, 相当于 apache 里的 L 标记，表示完成 rewrite 之后搜索相应的 uri 或 location break, 表示终止匹配，不再匹配后面的规则 redirect, 将返回 302 临时重定向，在浏览器地址会显示跳转后的 URL 地址。 permanent, 将返回 301 永久重定向，在浏览器地址会显示跳转后的 URL 地址。 last 一般写在 server 和 if 中，而 break 一般使用在 location 中 last 不终止重写后的 url 匹配，即新的 url 会再从 server 走一遍匹配流程，而 break 终止重写后的匹配 break 和 last 都能组织继续执行后面的 rewrite 指令 其中 last 和 break 用来实现 URL 重写，浏览器地址不变。下面是一个示例配置： bash location ~ ^/best/ { rewrite ^/best/(.*)$ /best/$1 break; proxy_pass http://www.liwanggui.com; } 这个例子使用了 break 标记，可实现将请求为 http://www.lwg.com/best/webinfo.html 的页面重定向到 http://www.liwanggui.com/best/webinfo.html 页面而不引起浏览器地址栏中 URL 的变化。 这个功能在新旧网站交替的时候非常有用（最好实践下，感觉有问题） ","date":"2021-04-01","objectID":"/posts/nginx-syntax/:3:2","series":null,"tags":["nginx"],"title":"nginx - 常用指令语法","uri":"/posts/nginx-syntax/#rewrite-命令"},{"categories":["nginx"],"content":" set 命令通过 set 命令可以设置一个变量并为其赋值，其值可以是文本、变量或他们的组合。也可以使用set定义一个新的变量，但是不能使用 set 设置 $http_xxx 头部变量 set 的使用方法如下： 语法： set variable value 默认值： none 使用字段： server location if 在默认情况下，set 命令默认值为空，可以 nginx 配置文件的 server location if 部分使用，下面是一个示例配置 text location / { proxy_pass http://127.0.0.1:8080/; set $query $query_string; rewrite /dede /wordpress?$query?; } 在这个例子中，要实现将请求 http://www.liwanggui.com/dede/wp?p=160 的页面，重写到地址 http://www.liwanggui.com/wordpress/?p=160, 也就是重写带参数的 URL. 这里涉及 $query_string 变量，这个变量相当于请求行中的参数，也就是？ 后面的内容。也可以用 $args 代替 $query_string 变量 ","date":"2021-04-01","objectID":"/posts/nginx-syntax/:3:3","series":null,"tags":["nginx"],"title":"nginx - 常用指令语法","uri":"/posts/nginx-syntax/#set-命令"},{"categories":["nginx"],"content":" break 命令break 的用法在前面的介绍中其实已经出现过，它表示完成当前设置的规则后，不再匹配后面的重写规则。 break的使用语法如下： 语法： break 默认值： none 使用字段： server lcoation if 在默认情况下，break 命令的值为空，可以 nginx 配置文件的 server lcoation if 部分使用，下面是一个示例配置 text server { listen 80; server_name www.lwg.com www.liwanggui.com; if ($host != 'www.wb.com'){ rewrite ^/(.*)$ http://www.lwg.com/error.txt break; rewrite ^/(.*)$ http://www.lwg.com/$1 permanent; } } 这个例子定义了两个域名 www.lwg.com 和 www.liwanggui.com, 当通过域名 www.liwanggui.com 访问网站时，会将请求重定向到 http://www.lwg.com/error.txt 页面，由于设置了 break 命令，因此下面的 rewrite 规则不再执行，直接退出。 ","date":"2021-04-01","objectID":"/posts/nginx-syntax/:3:4","series":null,"tags":["nginx"],"title":"nginx - 常用指令语法","uri":"/posts/nginx-syntax/#break-命令"},{"categories":["devops","centos"],"content":"yum 主要用于自动安装、升级 rpm 软件包，它能自动查找并解决 rpm 包之间的依赖关系。要成功的使用 yum 工具安装更新软件或系统，就需要有一个包含各种rpm软件包的 repository（软件仓库），这个软件仓库我们习惯称为 yum 源。网络上有大量的 yum 源，但由于受到网络环境的限制，导致软件安装耗时过长甚至失败。特别是当有大量服务器大量软件包需要安装时，缓慢的进度条令人难以忍受。因此我们在优化系统时，都会更换国内的源。 相比较而言，本地 yum 源服务器最大优点是局域网的快速网络连接和稳定性。有了局域网中的 yum 源服务器，即便在 Internet 连接中断的情况下，也不会影响其他 yum 客户端的软件安装和升级。 ","date":"2021-04-01","objectID":"/posts/yum-repo/:0:0","series":null,"tags":["yum"],"title":"部署 YUM 本地仓库","uri":"/posts/yum-repo/#"},{"categories":["devops","centos"],"content":" 创建 yum 仓库目录 bash mkdir -p /data/yum/centos/{6,7}/x86_64 上传 rpm 包到 /data/yum/centos/6/x86_64 和 /data/yum/centos/7/x86_64 目录 ","date":"2021-04-01","objectID":"/posts/yum-repo/:1:0","series":null,"tags":["yum"],"title":"部署 YUM 本地仓库","uri":"/posts/yum-repo/#创建-yum-仓库目录"},{"categories":["devops","centos"],"content":" 安装 createrepo 软件 bash yum install createrepo ","date":"2021-04-01","objectID":"/posts/yum-repo/:2:0","series":null,"tags":["yum"],"title":"部署 YUM 本地仓库","uri":"/posts/yum-repo/#安装-createrepo-软件"},{"categories":["devops","centos"],"content":" 初始化 repodata 索引文件 bash createrepo -pdo /data/yum/centos/6/x86_64/ /data/yum/centos/6/x86_64/ createrepo -pdo /data/yum/centos/7/x86_64/ /data/yum/centos/7/x86_64/ ","date":"2021-04-01","objectID":"/posts/yum-repo/:3:0","series":null,"tags":["yum"],"title":"部署 YUM 本地仓库","uri":"/posts/yum-repo/#初始化-repodata-索引文件"},{"categories":["devops","centos"],"content":" 提供 yum 服务提供 yum 服务很简单，只需要使用 nginx 开启目录浏览器功能即可, 测试时可以使用 python 模块实现 bash # python 2.x python2 -m SimpleHTTPServer 80 # python 3.x python3 -m http.server 80 ","date":"2021-04-01","objectID":"/posts/yum-repo/:4:0","series":null,"tags":["yum"],"title":"部署 YUM 本地仓库","uri":"/posts/yum-repo/#提供-yum-服务"},{"categories":["devops","centos"],"content":" 添加新 rpm 包每当添加新的 rpm 包时都需要执行以下命令, 为了方便可以将以下加入计划任务中 bash createrepo --update /data/yum/centos/6/x86_64/ createrepo --update /data/yum/centos/7/x86_64/ ","date":"2021-04-01","objectID":"/posts/yum-repo/:5:0","series":null,"tags":["yum"],"title":"部署 YUM 本地仓库","uri":"/posts/yum-repo/#添加新-rpm-包"},{"categories":["devops","centos"],"content":" 客户端配置客户端需要将 yum 仓库地址写成 yum 源配置文件，并放入 /etc/yum.repos.d 目录中 bash cat \u003e /etc/yum.repos.d/devops.repo \u003c\u003c REPO [devops] name=CentOS-$releasever - DEVOPS baseurl=http://your_domain_name/centos/$releasever/x86_64/ enable=1 gpgcheck=0 REPO 之后就可以使用 yum 安装 devops 仓库中的 rpm 包了 ","date":"2021-04-01","objectID":"/posts/yum-repo/:6:0","series":null,"tags":["yum"],"title":"部署 YUM 本地仓库","uri":"/posts/yum-repo/#客户端配置"},{"categories":["devops"],"content":" 参考文档 - 1 参考文档 - 2 软件编译安装可以很大程序上定制符合实际需求的软件包，但由于编译时间过长依赖关系复杂常常会耽误太多的时间，为了达到快速部署安装的需求我们需要定制符合需求的 rpm 包， rpm 默认是通过 rpmbuild 工具配合 spec 配置文件生成。下面将介绍如何使用 rpmbild 工具生成定制 rpm 包， 以 nginx 为例 推荐使用 fpm 制作 rpm 包，参考 fpm - 简单的包制作工具 ","date":"2021-04-01","objectID":"/posts/rpmbuild/:0:0","series":null,"tags":["rpmbuild"],"title":"使用 rpmbuild 制作 RPM 包","uri":"/posts/rpmbuild/#"},{"categories":["devops"],"content":" 环境准备安装所需工具 bash yum install gcc rpm-build rpm-devel rpmlint make python bash coreutils diffutils patch rpmdevtools 准备制作环境 bash [root@build ~]# useradd -m build [root@build ~]# su - build [build@build ~]# rpmdev-setuptree [build@build ~]# ls -R rpmbuild/ rpmbuild/: BUILD RPMS SOURCES SPECS SRPMS rpmbuild/BUILD: # 源码编译工作目录 rpmbuild/RPMS: # 最终 rpm 包生成目录 rpmbuild/SOURCES: # 源码包及附加文件放置目录 rpmbuild/SPECS: # spec 配置文件目录 rpmbuild/SRPMS: # 最终端 srpm 包生成目录 rpmbuild/BUILDROOT: rpm 打包工作目录 生成 nginx.spec 生成 nginx.spec 配置文件，并根据情况进行修改 bash [build@build ~]# cd rpmbuild/SPECS [build@SPECS ~]# rpmdev-newspec nginx [build@SPECS ~]# cat nginx.spec Name: nginx Version: 1.14.2 Release: 1%{?dist} Summary: A high performance web server and reverse proxy server Group: System Environment/Daemons License: GPLv2 URL: https://nginx.org # 制作 rpm 包所需文件 Source0: nginx-1.14.2.tar.gz Source1: nginx.conf Source2: limit.conf Source3: proxy.conf Source4: pathinfo.conf Source5: enable-php.conf Source6: geoip2.conf Source7: upstream.conf.example Source8: enable-ssl.conf.example Source9: nginx-status.conf.example Source10: nginx.init Source11: nginx.logrotate # 编译时需要的依赖包 BuildRequires: gcc BuildRequires: gcc-c++ BuildRequires: make BuildRequires: libmaxminddb-devel # rpm 安装时需要的依赖包 Requires: libmaxminddb-devel %description Nginx is a web server and a reverse proxy server for HTTP, SMTP, POP3 and IMAP protocols, with a strong focus on high concurrency, performance and low memory usage. # 制作前准备，解包和路径切换工具 %prep %setup -q # 软件包编译过程 %build ./configure --prefix=/usr/local/nginx / --user=www --group=www / --with-http_stub_status_module / --with-http_sub_module / --with-http_ssl_module / --with-http_v2_module / --with-http_realip_module / --with-openssl=./openssl-1.1.1b / --with-pcre=./pcre-8.42 / --with-zlib=./zlib-1.2.11 / --add-module=./nginx-sticky-module-ng-1.2.6/ / --add-module=./nginx-upstream-check-module/ / --add-module=./ngx-http-geoip2-module-3.2/ make %{?_smp_mflags} # 编译完安装软件包至指定目录等待打包 %install rm -rf $RPM_BUILD_ROOT make install DESTDIR=$RPM_BUILD_ROOT %{__install} -p -D -m 0644 %{SOURCE1} %{buildroot}/usr/local/nginx/conf/nginx.conf %{__install} -p -D -m 0644 %{SOURCE2} %{buildroot}/usr/local/nginx/conf/limit.conf %{__install} -p -D -m 0644 %{SOURCE3} %{buildroot}/usr/local/nginx/conf/proxy.conf %{__install} -p -D -m 0644 %{SOURCE4} %{buildroot}/usr/local/nginx/conf/pathinfo.conf %{__install} -p -D -m 0644 %{SOURCE5} %{buildroot}/usr/local/nginx/conf/enable-php.conf %{__install} -p -D -m 0644 %{SOURCE6} %{buildroot}/usr/local/nginx/conf/geoip2.conf %{__install} -p -D -m 0644 %{SOURCE7} %{buildroot}/usr/local/nginx/conf/upstream.conf.example %{__install} -p -D -m 0644 %{SOURCE8} %{buildroot}/usr/local/nginx/conf/enable-ssl.conf.example %{__install} -p -D -m 0644 %{SOURCE9} %{buildroot}/usr/local/nginx/conf/nginx-status.conf.example %{__install} -p -D -m 0755 %{SOURCE10} %{buildroot}/etc/init.d/nginx %{__install} -p -D -m 0644 %{SOURCE11} %{buildroot}/etc/logrotate.d/nginx # 清理工作 %clean rm -rf $RPM_BUILD_ROOT # 安装前执行的命令 %pre if ! id www \u0026\u003e/dev/null; then useradd -r -M -s /sbin/nologin www fi # 安装后 %post /sbin/chkconfig --add %{name} /sbin/chkconfig %{name} on # 卸载前 %preun /etc/init.d/nginx stop /sbin/chkconfig --del %{name} # rpm 打包的文件列表 %files %defattr(-,root,root,-) /usr/local/nginx/ /etc/logrotate.d/nginx %attr(0755,root,root) /etc/init.d/nginx %config(noreplace) /usr/local/nginx/conf/nginx.conf %config(noreplace) /usr/local/nginx/conf/limit.conf %config(noreplace) /usr/local/nginx/conf/geoip2.conf %config(noreplace) /usr/local/nginx/conf/enable-php.conf # 更新日志 %changelog 准备 nginx 源码包及相关文件 bash [build@build ~]$ cd rpmbuild/SOURCES/ [build@build SOURCES]$ ls -l total 12356 -rw-r--r-- 1 build build 207 Mar 17 17:32 enable-php.conf -rw-r--r-- 1 build build 1137 Mar 17 18:11 enable-ssl.conf.example -rw-r--r-- 1 build build 1077 Mar 17 21:05 geoip2.conf -rw-r--r-- 1 build build 1488 Mar 17 17:53 limit.conf -rw-rw-r-- 1 build build 12589977 Mar 17 20:19 nginx-1.14.2.","date":"2021-04-01","objectID":"/posts/rpmbuild/:1:0","series":null,"tags":["rpmbuild"],"title":"使用 rpmbuild 制作 RPM 包","uri":"/posts/rpmbuild/#环境准备"},{"categories":["devops"],"content":" 制作 rpm 包 bash [build@build ~]$ cd rpmbuild/SPECS/ [build@SPECS ~]# rpmbuild -ba nginx.spec rpmbuild -bp nginx.spec # 制作到%prep段 rpmbuild -bc nginx.spec # 制作到%build段 rpmbuild -bi nginx.spec # 执行 spec 文件的 “%install” 阶段 (在执行了 %prep 和 %build 阶段之后)。这通常等价于执行了一次 “make install” rpmbuild -bb nginx.spec # 制作二进制包 rpmbuild -ba nginx.spec # 表示既制作二进制包又制作src格式包 Tips: 更新多选项说明使用 rpmbuild -h ","date":"2021-04-01","objectID":"/posts/rpmbuild/:2:0","series":null,"tags":["rpmbuild"],"title":"使用 rpmbuild 制作 RPM 包","uri":"/posts/rpmbuild/#制作-rpm-包"},{"categories":["devops","command"],"content":"linux 下最受欢迎的多线程归档器是 pigz（而不是gzip）和 pbzip2（而不是bzip2) ","date":"2021-04-01","objectID":"/posts/pigz/:0:0","series":null,"tags":["pigz","pbzip2"],"title":"利用多核 CPU 进行解/压缩","uri":"/posts/pigz/#"},{"categories":["devops","command"],"content":" 开始使用pigz 可以当做是 gzip 高级版，可以执行 gzip 的工作，但是在压缩时会将工作分散到多个处理器和内核上。 pbzip2 可以当做是 bzip2 高级版, 在和 tar 命令一起使用时需要手动使用的压缩程序, 信息如下: bash -I, --use-compress-program=PROG 默认情况系统并没有安装 pigz，pbzip2, 需要手动安装执行下以下命令安装 bash $ yum install -y pigz pbzip2 ","date":"2021-04-01","objectID":"/posts/pigz/:1:0","series":null,"tags":["pigz","pbzip2"],"title":"利用多核 CPU 进行解/压缩","uri":"/posts/pigz/#开始使用"},{"categories":["devops","command"],"content":" 示例 bash $ tar -I pbzip2 -cf OUTPUT_FILE.tar.bz2 paths_to_archive $ tar --use-compress-program=pigz -cf OUTPUT_FILE.tar.gz paths_to_archive Archiver 必须接受 -d 如果替换实用程序没有此参数和/或您需要指定其他参数，则使用管道（如有必要，添加参数）： bash $ tar cf - paths_to_archive | pbzip2 \u003e OUTPUT_FILE.tar.gz $ tar cf - paths_to_archive | pigz \u003e OUTPUT_FILE.tar.gz 解压只需要将 -c 替换为 -x 即可. ","date":"2021-04-01","objectID":"/posts/pigz/:2:0","series":null,"tags":["pigz","pbzip2"],"title":"利用多核 CPU 进行解/压缩","uri":"/posts/pigz/#示例"},{"categories":["nginx"],"content":" 概述在生产环境中一般都会安装根据环境需要定制参数的 nginx , 这就需要通过源码编译安装 nginx 了。 本文将介绍 nginx 源码编译过程 本文使用 Ubuntu 20.04.2 LTS 编译安装. ","date":"2021-04-01","objectID":"/posts/nginx-install/:1:0","series":null,"tags":["nginx"],"title":"nginx - 源码编译安装","uri":"/posts/nginx-install/#概述"},{"categories":["nginx"],"content":" 依赖安装 nginx 编译时所依赖软件包 bash apt install gcc make openssl libssl-dev libpcre3-dev zlib1g-dev ","date":"2021-04-01","objectID":"/posts/nginx-install/:2:0","series":null,"tags":["nginx"],"title":"nginx - 源码编译安装","uri":"/posts/nginx-install/#依赖"},{"categories":["nginx"],"content":" 安装在编译之前需要先下载 nginx 源码包， http://nginx.org/download/ bash wget http://nginx.org/download/nginx-1.18.0.tar.gz 创建 nginx 运行用户 bash useradd -r www 好了，现在可以开始编译安装 nginx 了，开始编译第一步，编译配置（编译前解压好下载好的 nginx 源码包），进入源码包，输入以下命令按 Enter 键开始配置 nginx 编译参数 bash ./configure --prefix=/usr/local/nginx \\ --user=www \\ --group=www \\ --with-threads \\ --with-file-aio \\ --with-http_ssl_module \\ --with-http_v2_module \\ --with-http_realip_module \\ --with-http_addition_module \\ --with-http_sub_module \\ --with-http_gunzip_module \\ --with-http_gzip_static_module \\ --with-http_auth_request_module \\ --with-http_random_index_module \\ --with-http_secure_link_module \\ --with-http_degradation_module \\ --with-http_slice_module \\ --with-http_stub_status_module \\ --with-stream \\ --with-stream_ssl_module \\ --with-stream_realip_module \\ --with-stream_ssl_preread_module 如果没有错误，说明 nginx 编译参数没有问题。好了，现在开始编译 nginx，输入以下命令开始编译： bash make 编译完成，请查看是否有错误，没有就说明编译成功了，可以开始安装了，输入以下命令开始安装： bash make install 注意: nginx 将会安装至 --prefix 参数所指定路径中 ","date":"2021-04-01","objectID":"/posts/nginx-install/:3:0","series":null,"tags":["nginx"],"title":"nginx - 源码编译安装","uri":"/posts/nginx-install/#安装"},{"categories":["nginx"],"content":" systemd源码编译安装的 nginx 是不可以被 systemd 管理，如果需要使用 systemd 管理 nginx 服务，就需要手动编写 systemd 单元文件了。 nginx.service 文件如下: bash [Unit] Description=The NGINX HTTP and reverse proxy server After=syslog.target network.target remote-fs.target nss-lookup.target [Service] Type=forking PIDFile=/usr/local/nginx/logs/nginx.pid ExecStartPre=/usr/local/nginx/sbin/nginx -t ExecStart=/usr/local/nginx/sbin/nginx ExecReload=/usr/local/nginx/sbin/nginx -s reload ExecStop=/bin/kill -s QUIT $MAINPID PrivateTmp=true [Install] WantedBy=multi-user.target 将写好的 nginx.service 文件放入 /usr/lib/systemd/system 路径下即可被 systemd 识别 ","date":"2021-04-01","objectID":"/posts/nginx-install/:4:0","series":null,"tags":["nginx"],"title":"nginx - 源码编译安装","uri":"/posts/nginx-install/#systemd"},{"categories":["redis"],"content":" Redis Replication","date":"2021-03-28","objectID":"/posts/redis-sentinel/:1:0","series":null,"tags":["redis","sentinel"],"title":"Redis Sentinel 高可用","uri":"/posts/redis-sentinel/#redis-replication"},{"categories":["redis"],"content":" Replication 原理 副本库通过 slaveof 127.0.0.1 6380 命令, 连接主库, 并发送 SYNC 给主库 主库收到 SYNC, 会立即触发 BGSAVE, 后台保存 RDB, 发送给副本库 副本库接收后会应用 RDB 快照 主库会陆续将中间产生的新的操作,保存并发送给副本库 到此,我们主复制集就正常工作了 再此以后, 主库只要发生新的操作, 都会以命令传播的形式自动发送给副本库. 所有复制相关信息, 从 info 信息中都可以查到. 即使重启任何节点, 他的主从关系依然都在. 如果发生主从关系断开时,从库数据没有任何损坏, 在下次重连之后, 从库发送 PSYNC 给主库 主库只会将从库缺失部分的数据同步给从库应用, 达到快速恢复主从的目的 使用 slaveof no one 解除主从关系 ","date":"2021-03-28","objectID":"/posts/redis-sentinel/:1:1","series":null,"tags":["redis","sentinel"],"title":"Redis Sentinel 高可用","uri":"/posts/redis-sentinel/#replication-原理"},{"categories":["redis"],"content":" 准备多实例 Redis 服务实验采用单机多实例的方式进行，创建三个实例。端口 6380-6382, 可以使用 redis 源码包中的脚本（install_server.sh）创建 bash [root@localhost utils]# bash install_server.sh Welcome to the redis service installer This script will help you easily set up a running redis server Please select the redis port for this instance: [6379] 6380 Please select the redis config file name [/data/redis/etc/6380.conf] Selected default - /data/redis/etc/6380.conf Please select the redis log file name [/data/redis/log/redis_6380.log] Selected default - /data/redis/log/redis_6380.log Please select the data directory for this instance [/data/redis/6380] Selected default - /data/redis/6380 Please select the redis executable path [/usr/local/bin/redis-server] Selected config: Port : 6380 Config file : /data/redis/etc/6380.conf Log file : /data/redis/log/redis_6380.log Data dir : /data/redis/6380 Executable : /usr/local/bin/redis-server Cli Executable : /usr/local/bin/redis-cli Is this ok? Then press ENTER to go on or Ctrl-C to abort. Copied /tmp/6380.conf =\u003e /etc/init.d/redis_6380 Installing service... Successfully added to chkconfig! Successfully added to runlevels 345! Starting Redis server... Installation successful! [root@localhost utils]# bash install_server.sh Welcome to the redis service installer This script will help you easily set up a running redis server Please select the redis port for this instance: [6379] 6381 Please select the redis config file name [/data/redis/etc/6381.conf] Selected default - /data/redis/etc/6381.conf Please select the redis log file name [/data/redis/log/redis_6381.log] Selected default - /data/redis/log/redis_6381.log Please select the data directory for this instance [/data/redis/6381] Selected default - /data/redis/6381 Please select the redis executable path [/usr/local/bin/redis-server] Selected config: Port : 6381 Config file : /data/redis/etc/6381.conf Log file : /data/redis/log/redis_6381.log Data dir : /data/redis/6381 Executable : /usr/local/bin/redis-server Cli Executable : /usr/local/bin/redis-cli Is this ok? Then press ENTER to go on or Ctrl-C to abort. Copied /tmp/6381.conf =\u003e /etc/init.d/redis_6381 Installing service... Successfully added to chkconfig! Successfully added to runlevels 345! Starting Redis server... Installation successful! [root@localhost utils]# bash install_server.sh Welcome to the redis service installer This script will help you easily set up a running redis server Please select the redis port for this instance: [6379] 6382 Please select the redis config file name [/data/redis/etc/6382.conf] Selected default - /data/redis/etc/6382.conf Please select the redis log file name [/data/redis/log/redis_6382.log] Selected default - /data/redis/log/redis_6382.log Please select the data directory for this instance [/data/redis/6382] Selected default - /data/redis/6382 Please select the redis executable path [/usr/local/bin/redis-server] Selected config: Port : 6382 Config file : /data/redis/etc/6382.conf Log file : /data/redis/log/redis_6382.log Data dir : /data/redis/6382 Executable : /usr/local/bin/redis-server Cli Executable : /usr/local/bin/redis-cli Is this ok? Then press ENTER to go on or Ctrl-C to abort. Copied /tmp/6382.conf =\u003e /etc/init.d/redis_6382 Installing service... Successfully added to chkconfig! Successfully added to runlevels 345! Starting Redis server... Installation successful! 本例为了使用自定义的目录存放 redis 数据及配置文件对 install_server.sh 脚本中的路径做了修改 ","date":"2021-03-28","objectID":"/posts/redis-sentinel/:1:2","series":null,"tags":["redis","sentinel"],"title":"Redis Sentinel 高可用","uri":"/posts/redis-sentinel/#准备多实例-redis-服务"},{"categories":["redis"],"content":" Replication 配置6380 为主库，6381-6382 为从库，配置如下: 主库配置 bash [root@localhost log]# redis-cli -p 6380 127.0.0.1:6381\u003e config set requirepass 123 OK 127.0.0.1:6381\u003e auth 123 OK 127.0.0.1:6381\u003e config set masterauth 123 OK 127.0.0.1:6381\u003e CONFIG REWRITE 从库配置 bash [root@localhost log]# redis-cli -p 6381 127.0.0.1:6381\u003e config set requirepass 123 OK 127.0.0.1:6381\u003e auth 123 OK 127.0.0.1:6381\u003e config set masterauth 123 OK 127.0.0.1:6381\u003e CONFIG REWRITE OK 127.0.0.1:6381\u003e slaveof 127.0.0.1 6380 OK [root@localhost log]# redis-cli -p 6382 127.0.0.1:6381\u003e config set requirepass 123 OK 127.0.0.1:6381\u003e auth 123 OK 127.0.0.1:6381\u003e config set masterauth 123 OK 127.0.0.1:6381\u003e CONFIG REWRITE OK 127.0.0.1:6381\u003e slaveof 127.0.0.1 6380 OK 如果想解除主从关系可以使用 slaveof no one 指令 ","date":"2021-03-28","objectID":"/posts/redis-sentinel/:1:3","series":null,"tags":["redis","sentinel"],"title":"Redis Sentinel 高可用","uri":"/posts/redis-sentinel/#replication-配置"},{"categories":["redis"],"content":" 检查 Replication 状态 bash [root@localhost etc]# redis-cli -p 6380 -a 123 info replication # Replication role:master connected_slaves:2 slave0:ip=127.0.0.1,port=6381,state=online,offset=3442,lag=1 slave1:ip=127.0.0.1,port=6382,state=online,offset=3442,lag=1 master_repl_offset:3575 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:2 repl_backlog_histlen:3574 [root@localhost etc]# redis-cli -p 6381 -a 123 info replication # Replication role:slave master_host:127.0.0.1 master_port:6380 master_link_status:up master_last_io_seconds_ago:0 master_sync_in_progress:0 slave_repl_offset:6291 slave_priority:100 slave_read_only:1 connected_slaves:0 master_repl_offset:0 repl_backlog_active:0 repl_backlog_size:1048576 repl_backlog_first_byte_offset:0 repl_backlog_histlen:0 可以在主库写入数据然后到从库读取测试同步 ","date":"2021-03-28","objectID":"/posts/redis-sentinel/:1:4","series":null,"tags":["redis","sentinel"],"title":"Redis Sentinel 高可用","uri":"/posts/redis-sentinel/#检查-replication-状态"},{"categories":["redis"],"content":" Redis Sentinel 高可用由于 redis replication 默认状态下如果主库宕机，是不会自动切换主从身份的，需要手动干预，这是生产环境下不允许的。为了解决此问题 redis 引入哨兵模式。 redis sentinel 有以下作用： 监控节点 自动选主，切换主从身份 从库自动指向新的主库 对应用透明 自动处理故障节点 ","date":"2021-03-28","objectID":"/posts/redis-sentinel/:2:0","series":null,"tags":["redis","sentinel"],"title":"Redis Sentinel 高可用","uri":"/posts/redis-sentinel/#redis-sentinel-高可用"},{"categories":["redis"],"content":" 配置 sentinel准备 sentinel 配置文件 源码包中有示例配置文件可用，直接复制修改即可 bash mkdir /data/sentinel cat \u003e /data/sentinel/26379.conf \u003c\u003cEOF protected-mode no daemonize yes logfile \"/data/sentinel/26379.log\" port 26379 dir \"/tmp\" sentinel myid 994ea01af0f13692c13eeda116a0668084bb5e68 # mymaster 是一个自定义名称，客户端通过 sentinel 连接 redis 时需要使用 # 127.0.0.1 6380 是主节点的 ip 和 端口号 # 1 是 sentinel failover 投票数，默认为 sentinel 节点数/2 + 1, 1个节点时为1 # 为了能正常投票得出结果 sentinel 节点数得为奇数个 sentinel monitor mymaster 127.0.0.1 6380 1 sentinel down-after-milliseconds mymaster 5000 sentinel auth-pass mymaster 123 sentinel config-epoch mymaster 3 sentinel leader-epoch mymaster 3 sentinel known-slave mymaster 127.0.0.1 6382 sentinel known-slave mymaster 127.0.0.1 6381 sentinel current-epoch 3 EOF 启动 sentinel 服务 bash /usr/local/bin/redis-sentinel /data/sentinel/26379.conf redis-sentinel 是 redis-server 的软链接 ","date":"2021-03-28","objectID":"/posts/redis-sentinel/:2:1","series":null,"tags":["redis","sentinel"],"title":"Redis Sentinel 高可用","uri":"/posts/redis-sentinel/#配置-sentinel"},{"categories":["redis"],"content":" 连接测试 sentinel sentinel 命令sentinel 支持的合法命令如下： PING sentinel 回复 PONG. SENTINEL masters 显示被监控的所有master以及它们的状态. SENTINEL master 显示指定master的信息和状态； SENTINEL slaves \u003cmaster name\u003e 显示指定master的所有slave以及它们的状态； SENTINEL get-master-addr-by-name \u003cmaster name\u003e 返回指定master的ip和端口，如果正在进行failover或者failover已经完成，将会显示被提升为master的slave的ip和端口。 SENTINEL reset \u003cpattern\u003e 重置名字匹配该正则表达式的所有的master的状态信息，清楚其之前的状态信息，以及slaves信息。 SENTINEL failover \u003cmaster name\u003e 强制sentinel执行failover，并且不需要得到其他sentinel的同意。但是failover后会将最新的配置发送给其他sentinel。 动态修改 Sentinel 配置从 redis2.8.4 开始，sentinel 提供了一组 API 用来添加，删除，修改 master 的配置。 需要注意的是，如果你通过 API 修改了一个 sentinel 的配置， sentinel 不会把修改的配置告诉其他 sentinel 。你需要自己手动地对多个 sentinel 发送修改配置的命令。 以下是一些修改 sentinel 配置的命令： SENTINEL MONITOR \u003cname\u003e \u003cip\u003e \u003cport\u003e \u003cquorum\u003e 这个命令告诉 sentinel 去监听一个新的 master SENTINEL REMOVE \u003cname\u003e 命令sentinel放弃对某个master的监听 SENTINEL SET \u003cname\u003e \u003coption\u003e \u003cvalue\u003e 这个命令很像Redis的CONFIG SET命令，用来改变指定master的配置。支持多个 。例如以下实例： SENTINEL SET objects-cache-master down-after-milliseconds 1000 只要是配置文件中存在的配置项，都可以用 SENTINEL SET 命令来设置。这个还可以用来设置 master 的属性，比如说 quorum(票数)，而不需要先删除 master，再重新添加 master。例如： text SENTINEL SET objects-cache-master quorum 5 测试主从切换模拟故障停止主库 bash [root@localhost etc]# redis-cli -p 6380 -a 123 shutdown 查看 sentinel 日志 text 3963:X 28 Mar 15:31:13.864 # +sdown master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.864 # +odown master mymaster 127.0.0.1 6380 #quorum 1/1 3963:X 28 Mar 15:31:13.864 # +new-epoch 6 3963:X 28 Mar 15:31:13.864 # +try-failover master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.864 # +vote-for-leader 994ea01af0f13692c13eeda116a0668084bb5e68 6 3963:X 28 Mar 15:31:13.864 # +elected-leader master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.864 # +failover-state-select-slave master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.948 # +selected-slave slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.948 * +failover-state-send-slaveof-noone slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:14.007 * +failover-state-wait-promotion slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:14.943 # +promoted-slave slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:14.943 # +failover-state-reconf-slaves master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:15.004 * +slave-reconf-sent slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:15.994 * +slave-reconf-inprog slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:15.994 * +slave-reconf-done slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:16.055 # +failover-end master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:16.055 # +switch-master mymaster 127.0.0.1 6380 127.0.0.1 6382 3963:X 28 Mar 15:31:16.055 * +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6382 3963:X 28 Mar 15:31:16.055 * +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6382 3963:X 28 Mar 15:31:21.064 # +sdown slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6382 可以看到 sentinel 检测到主库服务停止，将 6382 选为主库，进行了切换操作， 6381 也自动与 6382 建立主从关系 6380 修复好后，重新启动服务 sentinel 会自动检测到并 6380 加入主从环境中 bash [root@localhost etc]# /etc/init.d/redis_6380 start Starting Redis server... 此时可以从 sentinel 日志中看到以下信息 text 3963:X 28 Mar 15:35:05.234 # -sdown slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6382 3963:X 28 Mar 15:35:15.229 * +convert-to-slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6382 sentinel 会自动在 6380 实例的配置文件最后一行加入一行配置 bash [root@localhost etc]# tail -n 3 6380.conf requirepass \"123\" masterauth \"123\" slaveof 127.0.0.1 6382 配置多节点 sentinel此时 redis 的高可用解决了，但 sentinel 只有一个节点存在单点故障，为了解决这个问题，可以通过部署多个 sentinel 节点解决。 配置多个 sentinel 节点时需要注意节点数据及配置文件中的 sentinel monitor mymaster 127.0.0.1 6380 1 配置项的最后一个值的配置。 客户端连接 redis以 python 客户端为例说明, 参考文档: https://pypi.org/project/redis/ 安装 redis 库 bash pip install redis 连接至单实例 reids python \u003e\u003e\u003e import redis \u003e\u003e\u003e r = redis.Redis(host='","date":"2021-03-28","objectID":"/posts/redis-sentinel/:2:2","series":null,"tags":["redis","sentinel"],"title":"Redis Sentinel 高可用","uri":"/posts/redis-sentinel/#连接测试-sentinel"},{"categories":["redis"],"content":" 连接测试 sentinel sentinel 命令sentinel 支持的合法命令如下： PING sentinel 回复 PONG. SENTINEL masters 显示被监控的所有master以及它们的状态. SENTINEL master 显示指定master的信息和状态； SENTINEL slaves 显示指定master的所有slave以及它们的状态； SENTINEL get-master-addr-by-name 返回指定master的ip和端口，如果正在进行failover或者failover已经完成，将会显示被提升为master的slave的ip和端口。 SENTINEL reset 重置名字匹配该正则表达式的所有的master的状态信息，清楚其之前的状态信息，以及slaves信息。 SENTINEL failover 强制sentinel执行failover，并且不需要得到其他sentinel的同意。但是failover后会将最新的配置发送给其他sentinel。 动态修改 Sentinel 配置从 redis2.8.4 开始，sentinel 提供了一组 API 用来添加，删除，修改 master 的配置。 需要注意的是，如果你通过 API 修改了一个 sentinel 的配置， sentinel 不会把修改的配置告诉其他 sentinel 。你需要自己手动地对多个 sentinel 发送修改配置的命令。 以下是一些修改 sentinel 配置的命令： SENTINEL MONITOR 这个命令告诉 sentinel 去监听一个新的 master SENTINEL REMOVE 命令sentinel放弃对某个master的监听 SENTINEL SET 这个命令很像Redis的CONFIG SET命令，用来改变指定master的配置。支持多个 。例如以下实例： SENTINEL SET objects-cache-master down-after-milliseconds 1000 只要是配置文件中存在的配置项，都可以用 SENTINEL SET 命令来设置。这个还可以用来设置 master 的属性，比如说 quorum(票数)，而不需要先删除 master，再重新添加 master。例如： text SENTINEL SET objects-cache-master quorum 5 测试主从切换模拟故障停止主库 bash [root@localhost etc]# redis-cli -p 6380 -a 123 shutdown 查看 sentinel 日志 text 3963:X 28 Mar 15:31:13.864 # +sdown master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.864 # +odown master mymaster 127.0.0.1 6380 #quorum 1/1 3963:X 28 Mar 15:31:13.864 # +new-epoch 6 3963:X 28 Mar 15:31:13.864 # +try-failover master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.864 # +vote-for-leader 994ea01af0f13692c13eeda116a0668084bb5e68 6 3963:X 28 Mar 15:31:13.864 # +elected-leader master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.864 # +failover-state-select-slave master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.948 # +selected-slave slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.948 * +failover-state-send-slaveof-noone slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:14.007 * +failover-state-wait-promotion slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:14.943 # +promoted-slave slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:14.943 # +failover-state-reconf-slaves master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:15.004 * +slave-reconf-sent slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:15.994 * +slave-reconf-inprog slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:15.994 * +slave-reconf-done slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:16.055 # +failover-end master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:16.055 # +switch-master mymaster 127.0.0.1 6380 127.0.0.1 6382 3963:X 28 Mar 15:31:16.055 * +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6382 3963:X 28 Mar 15:31:16.055 * +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6382 3963:X 28 Mar 15:31:21.064 # +sdown slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6382 可以看到 sentinel 检测到主库服务停止，将 6382 选为主库，进行了切换操作， 6381 也自动与 6382 建立主从关系 6380 修复好后，重新启动服务 sentinel 会自动检测到并 6380 加入主从环境中 bash [root@localhost etc]# /etc/init.d/redis_6380 start Starting Redis server... 此时可以从 sentinel 日志中看到以下信息 text 3963:X 28 Mar 15:35:05.234 # -sdown slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6382 3963:X 28 Mar 15:35:15.229 * +convert-to-slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6382 sentinel 会自动在 6380 实例的配置文件最后一行加入一行配置 bash [root@localhost etc]# tail -n 3 6380.conf requirepass \"123\" masterauth \"123\" slaveof 127.0.0.1 6382 配置多节点 sentinel此时 redis 的高可用解决了，但 sentinel 只有一个节点存在单点故障，为了解决这个问题，可以通过部署多个 sentinel 节点解决。 配置多个 sentinel 节点时需要注意节点数据及配置文件中的 sentinel monitor mymaster 127.0.0.1 6380 1 配置项的最后一个值的配置。 客户端连接 redis以 python 客户端为例说明, 参考文档: https://pypi.org/project/redis/ 安装 redis 库 bash pip install redis 连接至单实例 reids python \u003e\u003e\u003e import redis \u003e\u003e\u003e r = redis.Redis(host='","date":"2021-03-28","objectID":"/posts/redis-sentinel/:2:2","series":null,"tags":["redis","sentinel"],"title":"Redis Sentinel 高可用","uri":"/posts/redis-sentinel/#sentinel-命令"},{"categories":["redis"],"content":" 连接测试 sentinel sentinel 命令sentinel 支持的合法命令如下： PING sentinel 回复 PONG. SENTINEL masters 显示被监控的所有master以及它们的状态. SENTINEL master 显示指定master的信息和状态； SENTINEL slaves 显示指定master的所有slave以及它们的状态； SENTINEL get-master-addr-by-name 返回指定master的ip和端口，如果正在进行failover或者failover已经完成，将会显示被提升为master的slave的ip和端口。 SENTINEL reset 重置名字匹配该正则表达式的所有的master的状态信息，清楚其之前的状态信息，以及slaves信息。 SENTINEL failover 强制sentinel执行failover，并且不需要得到其他sentinel的同意。但是failover后会将最新的配置发送给其他sentinel。 动态修改 Sentinel 配置从 redis2.8.4 开始，sentinel 提供了一组 API 用来添加，删除，修改 master 的配置。 需要注意的是，如果你通过 API 修改了一个 sentinel 的配置， sentinel 不会把修改的配置告诉其他 sentinel 。你需要自己手动地对多个 sentinel 发送修改配置的命令。 以下是一些修改 sentinel 配置的命令： SENTINEL MONITOR 这个命令告诉 sentinel 去监听一个新的 master SENTINEL REMOVE 命令sentinel放弃对某个master的监听 SENTINEL SET 这个命令很像Redis的CONFIG SET命令，用来改变指定master的配置。支持多个 。例如以下实例： SENTINEL SET objects-cache-master down-after-milliseconds 1000 只要是配置文件中存在的配置项，都可以用 SENTINEL SET 命令来设置。这个还可以用来设置 master 的属性，比如说 quorum(票数)，而不需要先删除 master，再重新添加 master。例如： text SENTINEL SET objects-cache-master quorum 5 测试主从切换模拟故障停止主库 bash [root@localhost etc]# redis-cli -p 6380 -a 123 shutdown 查看 sentinel 日志 text 3963:X 28 Mar 15:31:13.864 # +sdown master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.864 # +odown master mymaster 127.0.0.1 6380 #quorum 1/1 3963:X 28 Mar 15:31:13.864 # +new-epoch 6 3963:X 28 Mar 15:31:13.864 # +try-failover master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.864 # +vote-for-leader 994ea01af0f13692c13eeda116a0668084bb5e68 6 3963:X 28 Mar 15:31:13.864 # +elected-leader master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.864 # +failover-state-select-slave master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.948 # +selected-slave slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.948 * +failover-state-send-slaveof-noone slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:14.007 * +failover-state-wait-promotion slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:14.943 # +promoted-slave slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:14.943 # +failover-state-reconf-slaves master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:15.004 * +slave-reconf-sent slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:15.994 * +slave-reconf-inprog slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:15.994 * +slave-reconf-done slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:16.055 # +failover-end master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:16.055 # +switch-master mymaster 127.0.0.1 6380 127.0.0.1 6382 3963:X 28 Mar 15:31:16.055 * +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6382 3963:X 28 Mar 15:31:16.055 * +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6382 3963:X 28 Mar 15:31:21.064 # +sdown slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6382 可以看到 sentinel 检测到主库服务停止，将 6382 选为主库，进行了切换操作， 6381 也自动与 6382 建立主从关系 6380 修复好后，重新启动服务 sentinel 会自动检测到并 6380 加入主从环境中 bash [root@localhost etc]# /etc/init.d/redis_6380 start Starting Redis server... 此时可以从 sentinel 日志中看到以下信息 text 3963:X 28 Mar 15:35:05.234 # -sdown slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6382 3963:X 28 Mar 15:35:15.229 * +convert-to-slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6382 sentinel 会自动在 6380 实例的配置文件最后一行加入一行配置 bash [root@localhost etc]# tail -n 3 6380.conf requirepass \"123\" masterauth \"123\" slaveof 127.0.0.1 6382 配置多节点 sentinel此时 redis 的高可用解决了，但 sentinel 只有一个节点存在单点故障，为了解决这个问题，可以通过部署多个 sentinel 节点解决。 配置多个 sentinel 节点时需要注意节点数据及配置文件中的 sentinel monitor mymaster 127.0.0.1 6380 1 配置项的最后一个值的配置。 客户端连接 redis以 python 客户端为例说明, 参考文档: https://pypi.org/project/redis/ 安装 redis 库 bash pip install redis 连接至单实例 reids python \u003e\u003e\u003e import redis \u003e\u003e\u003e r = redis.Redis(host='","date":"2021-03-28","objectID":"/posts/redis-sentinel/:2:2","series":null,"tags":["redis","sentinel"],"title":"Redis Sentinel 高可用","uri":"/posts/redis-sentinel/#动态修改-sentinel-配置"},{"categories":["redis"],"content":" 连接测试 sentinel sentinel 命令sentinel 支持的合法命令如下： PING sentinel 回复 PONG. SENTINEL masters 显示被监控的所有master以及它们的状态. SENTINEL master 显示指定master的信息和状态； SENTINEL slaves 显示指定master的所有slave以及它们的状态； SENTINEL get-master-addr-by-name 返回指定master的ip和端口，如果正在进行failover或者failover已经完成，将会显示被提升为master的slave的ip和端口。 SENTINEL reset 重置名字匹配该正则表达式的所有的master的状态信息，清楚其之前的状态信息，以及slaves信息。 SENTINEL failover 强制sentinel执行failover，并且不需要得到其他sentinel的同意。但是failover后会将最新的配置发送给其他sentinel。 动态修改 Sentinel 配置从 redis2.8.4 开始，sentinel 提供了一组 API 用来添加，删除，修改 master 的配置。 需要注意的是，如果你通过 API 修改了一个 sentinel 的配置， sentinel 不会把修改的配置告诉其他 sentinel 。你需要自己手动地对多个 sentinel 发送修改配置的命令。 以下是一些修改 sentinel 配置的命令： SENTINEL MONITOR 这个命令告诉 sentinel 去监听一个新的 master SENTINEL REMOVE 命令sentinel放弃对某个master的监听 SENTINEL SET 这个命令很像Redis的CONFIG SET命令，用来改变指定master的配置。支持多个 。例如以下实例： SENTINEL SET objects-cache-master down-after-milliseconds 1000 只要是配置文件中存在的配置项，都可以用 SENTINEL SET 命令来设置。这个还可以用来设置 master 的属性，比如说 quorum(票数)，而不需要先删除 master，再重新添加 master。例如： text SENTINEL SET objects-cache-master quorum 5 测试主从切换模拟故障停止主库 bash [root@localhost etc]# redis-cli -p 6380 -a 123 shutdown 查看 sentinel 日志 text 3963:X 28 Mar 15:31:13.864 # +sdown master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.864 # +odown master mymaster 127.0.0.1 6380 #quorum 1/1 3963:X 28 Mar 15:31:13.864 # +new-epoch 6 3963:X 28 Mar 15:31:13.864 # +try-failover master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.864 # +vote-for-leader 994ea01af0f13692c13eeda116a0668084bb5e68 6 3963:X 28 Mar 15:31:13.864 # +elected-leader master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.864 # +failover-state-select-slave master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.948 # +selected-slave slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.948 * +failover-state-send-slaveof-noone slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:14.007 * +failover-state-wait-promotion slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:14.943 # +promoted-slave slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:14.943 # +failover-state-reconf-slaves master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:15.004 * +slave-reconf-sent slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:15.994 * +slave-reconf-inprog slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:15.994 * +slave-reconf-done slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:16.055 # +failover-end master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:16.055 # +switch-master mymaster 127.0.0.1 6380 127.0.0.1 6382 3963:X 28 Mar 15:31:16.055 * +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6382 3963:X 28 Mar 15:31:16.055 * +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6382 3963:X 28 Mar 15:31:21.064 # +sdown slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6382 可以看到 sentinel 检测到主库服务停止，将 6382 选为主库，进行了切换操作， 6381 也自动与 6382 建立主从关系 6380 修复好后，重新启动服务 sentinel 会自动检测到并 6380 加入主从环境中 bash [root@localhost etc]# /etc/init.d/redis_6380 start Starting Redis server... 此时可以从 sentinel 日志中看到以下信息 text 3963:X 28 Mar 15:35:05.234 # -sdown slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6382 3963:X 28 Mar 15:35:15.229 * +convert-to-slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6382 sentinel 会自动在 6380 实例的配置文件最后一行加入一行配置 bash [root@localhost etc]# tail -n 3 6380.conf requirepass \"123\" masterauth \"123\" slaveof 127.0.0.1 6382 配置多节点 sentinel此时 redis 的高可用解决了，但 sentinel 只有一个节点存在单点故障，为了解决这个问题，可以通过部署多个 sentinel 节点解决。 配置多个 sentinel 节点时需要注意节点数据及配置文件中的 sentinel monitor mymaster 127.0.0.1 6380 1 配置项的最后一个值的配置。 客户端连接 redis以 python 客户端为例说明, 参考文档: https://pypi.org/project/redis/ 安装 redis 库 bash pip install redis 连接至单实例 reids python \u003e\u003e\u003e import redis \u003e\u003e\u003e r = redis.Redis(host='","date":"2021-03-28","objectID":"/posts/redis-sentinel/:2:2","series":null,"tags":["redis","sentinel"],"title":"Redis Sentinel 高可用","uri":"/posts/redis-sentinel/#测试主从切换"},{"categories":["redis"],"content":" 连接测试 sentinel sentinel 命令sentinel 支持的合法命令如下： PING sentinel 回复 PONG. SENTINEL masters 显示被监控的所有master以及它们的状态. SENTINEL master 显示指定master的信息和状态； SENTINEL slaves 显示指定master的所有slave以及它们的状态； SENTINEL get-master-addr-by-name 返回指定master的ip和端口，如果正在进行failover或者failover已经完成，将会显示被提升为master的slave的ip和端口。 SENTINEL reset 重置名字匹配该正则表达式的所有的master的状态信息，清楚其之前的状态信息，以及slaves信息。 SENTINEL failover 强制sentinel执行failover，并且不需要得到其他sentinel的同意。但是failover后会将最新的配置发送给其他sentinel。 动态修改 Sentinel 配置从 redis2.8.4 开始，sentinel 提供了一组 API 用来添加，删除，修改 master 的配置。 需要注意的是，如果你通过 API 修改了一个 sentinel 的配置， sentinel 不会把修改的配置告诉其他 sentinel 。你需要自己手动地对多个 sentinel 发送修改配置的命令。 以下是一些修改 sentinel 配置的命令： SENTINEL MONITOR 这个命令告诉 sentinel 去监听一个新的 master SENTINEL REMOVE 命令sentinel放弃对某个master的监听 SENTINEL SET 这个命令很像Redis的CONFIG SET命令，用来改变指定master的配置。支持多个 。例如以下实例： SENTINEL SET objects-cache-master down-after-milliseconds 1000 只要是配置文件中存在的配置项，都可以用 SENTINEL SET 命令来设置。这个还可以用来设置 master 的属性，比如说 quorum(票数)，而不需要先删除 master，再重新添加 master。例如： text SENTINEL SET objects-cache-master quorum 5 测试主从切换模拟故障停止主库 bash [root@localhost etc]# redis-cli -p 6380 -a 123 shutdown 查看 sentinel 日志 text 3963:X 28 Mar 15:31:13.864 # +sdown master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.864 # +odown master mymaster 127.0.0.1 6380 #quorum 1/1 3963:X 28 Mar 15:31:13.864 # +new-epoch 6 3963:X 28 Mar 15:31:13.864 # +try-failover master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.864 # +vote-for-leader 994ea01af0f13692c13eeda116a0668084bb5e68 6 3963:X 28 Mar 15:31:13.864 # +elected-leader master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.864 # +failover-state-select-slave master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.948 # +selected-slave slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.948 * +failover-state-send-slaveof-noone slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:14.007 * +failover-state-wait-promotion slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:14.943 # +promoted-slave slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:14.943 # +failover-state-reconf-slaves master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:15.004 * +slave-reconf-sent slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:15.994 * +slave-reconf-inprog slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:15.994 * +slave-reconf-done slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:16.055 # +failover-end master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:16.055 # +switch-master mymaster 127.0.0.1 6380 127.0.0.1 6382 3963:X 28 Mar 15:31:16.055 * +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6382 3963:X 28 Mar 15:31:16.055 * +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6382 3963:X 28 Mar 15:31:21.064 # +sdown slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6382 可以看到 sentinel 检测到主库服务停止，将 6382 选为主库，进行了切换操作， 6381 也自动与 6382 建立主从关系 6380 修复好后，重新启动服务 sentinel 会自动检测到并 6380 加入主从环境中 bash [root@localhost etc]# /etc/init.d/redis_6380 start Starting Redis server... 此时可以从 sentinel 日志中看到以下信息 text 3963:X 28 Mar 15:35:05.234 # -sdown slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6382 3963:X 28 Mar 15:35:15.229 * +convert-to-slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6382 sentinel 会自动在 6380 实例的配置文件最后一行加入一行配置 bash [root@localhost etc]# tail -n 3 6380.conf requirepass \"123\" masterauth \"123\" slaveof 127.0.0.1 6382 配置多节点 sentinel此时 redis 的高可用解决了，但 sentinel 只有一个节点存在单点故障，为了解决这个问题，可以通过部署多个 sentinel 节点解决。 配置多个 sentinel 节点时需要注意节点数据及配置文件中的 sentinel monitor mymaster 127.0.0.1 6380 1 配置项的最后一个值的配置。 客户端连接 redis以 python 客户端为例说明, 参考文档: https://pypi.org/project/redis/ 安装 redis 库 bash pip install redis 连接至单实例 reids python \u003e\u003e\u003e import redis \u003e\u003e\u003e r = redis.Redis(host='","date":"2021-03-28","objectID":"/posts/redis-sentinel/:2:2","series":null,"tags":["redis","sentinel"],"title":"Redis Sentinel 高可用","uri":"/posts/redis-sentinel/#配置多节点-sentinel"},{"categories":["redis"],"content":" 连接测试 sentinel sentinel 命令sentinel 支持的合法命令如下： PING sentinel 回复 PONG. SENTINEL masters 显示被监控的所有master以及它们的状态. SENTINEL master 显示指定master的信息和状态； SENTINEL slaves 显示指定master的所有slave以及它们的状态； SENTINEL get-master-addr-by-name 返回指定master的ip和端口，如果正在进行failover或者failover已经完成，将会显示被提升为master的slave的ip和端口。 SENTINEL reset 重置名字匹配该正则表达式的所有的master的状态信息，清楚其之前的状态信息，以及slaves信息。 SENTINEL failover 强制sentinel执行failover，并且不需要得到其他sentinel的同意。但是failover后会将最新的配置发送给其他sentinel。 动态修改 Sentinel 配置从 redis2.8.4 开始，sentinel 提供了一组 API 用来添加，删除，修改 master 的配置。 需要注意的是，如果你通过 API 修改了一个 sentinel 的配置， sentinel 不会把修改的配置告诉其他 sentinel 。你需要自己手动地对多个 sentinel 发送修改配置的命令。 以下是一些修改 sentinel 配置的命令： SENTINEL MONITOR 这个命令告诉 sentinel 去监听一个新的 master SENTINEL REMOVE 命令sentinel放弃对某个master的监听 SENTINEL SET 这个命令很像Redis的CONFIG SET命令，用来改变指定master的配置。支持多个 。例如以下实例： SENTINEL SET objects-cache-master down-after-milliseconds 1000 只要是配置文件中存在的配置项，都可以用 SENTINEL SET 命令来设置。这个还可以用来设置 master 的属性，比如说 quorum(票数)，而不需要先删除 master，再重新添加 master。例如： text SENTINEL SET objects-cache-master quorum 5 测试主从切换模拟故障停止主库 bash [root@localhost etc]# redis-cli -p 6380 -a 123 shutdown 查看 sentinel 日志 text 3963:X 28 Mar 15:31:13.864 # +sdown master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.864 # +odown master mymaster 127.0.0.1 6380 #quorum 1/1 3963:X 28 Mar 15:31:13.864 # +new-epoch 6 3963:X 28 Mar 15:31:13.864 # +try-failover master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.864 # +vote-for-leader 994ea01af0f13692c13eeda116a0668084bb5e68 6 3963:X 28 Mar 15:31:13.864 # +elected-leader master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.864 # +failover-state-select-slave master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.948 # +selected-slave slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:13.948 * +failover-state-send-slaveof-noone slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:14.007 * +failover-state-wait-promotion slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:14.943 # +promoted-slave slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:14.943 # +failover-state-reconf-slaves master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:15.004 * +slave-reconf-sent slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:15.994 * +slave-reconf-inprog slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:15.994 * +slave-reconf-done slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:16.055 # +failover-end master mymaster 127.0.0.1 6380 3963:X 28 Mar 15:31:16.055 # +switch-master mymaster 127.0.0.1 6380 127.0.0.1 6382 3963:X 28 Mar 15:31:16.055 * +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6382 3963:X 28 Mar 15:31:16.055 * +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6382 3963:X 28 Mar 15:31:21.064 # +sdown slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6382 可以看到 sentinel 检测到主库服务停止，将 6382 选为主库，进行了切换操作， 6381 也自动与 6382 建立主从关系 6380 修复好后，重新启动服务 sentinel 会自动检测到并 6380 加入主从环境中 bash [root@localhost etc]# /etc/init.d/redis_6380 start Starting Redis server... 此时可以从 sentinel 日志中看到以下信息 text 3963:X 28 Mar 15:35:05.234 # -sdown slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6382 3963:X 28 Mar 15:35:15.229 * +convert-to-slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6382 sentinel 会自动在 6380 实例的配置文件最后一行加入一行配置 bash [root@localhost etc]# tail -n 3 6380.conf requirepass \"123\" masterauth \"123\" slaveof 127.0.0.1 6382 配置多节点 sentinel此时 redis 的高可用解决了，但 sentinel 只有一个节点存在单点故障，为了解决这个问题，可以通过部署多个 sentinel 节点解决。 配置多个 sentinel 节点时需要注意节点数据及配置文件中的 sentinel monitor mymaster 127.0.0.1 6380 1 配置项的最后一个值的配置。 客户端连接 redis以 python 客户端为例说明, 参考文档: https://pypi.org/project/redis/ 安装 redis 库 bash pip install redis 连接至单实例 reids python \u003e\u003e\u003e import redis \u003e\u003e\u003e r = redis.Redis(host='","date":"2021-03-28","objectID":"/posts/redis-sentinel/:2:2","series":null,"tags":["redis","sentinel"],"title":"Redis Sentinel 高可用","uri":"/posts/redis-sentinel/#客户端连接-redis"},{"categories":["redis"],"content":" Redis 命令","date":"2021-03-28","objectID":"/posts/redis-cli/:1:0","series":null,"tags":["redis"],"title":"Redis 基础操作","uri":"/posts/redis-cli/#redis-命令"},{"categories":["redis"],"content":" 管理命令 info: 查看 Redis 当前状态信息 bash 127.0.0.1:6379\u003e info # Server redis_version:3.2.9 redis_git_sha1:00000000 redis_git_dirty:0 redis_build_id:f0e03a357ae83877 redis_mode:standalone os:Linux 3.10.0-862.el7.x86_64 x86_64 arch_bits:64 multiplexing_api:epoll gcc_version:4.8.5 process_id:2502 run_id:c913615b9c199a0d7ba4454c38e1a65427525c60 tcp_port:6379 uptime_in_seconds:2047 uptime_in_days:0 hz:10 lru_clock:6276784 executable:/usr/local/bin/redis-server config_file:/etc/redis/6379.conf # Clients connected_clients:1 client_longest_output_list:0 client_biggest_input_buf:0 blocked_clients:0 ...(略) # 只查看特定的信息 127.0.0.1:6379\u003e info Memory # Memory used_memory:821088 used_memory_human:801.84K used_memory_rss:7888896 used_memory_rss_human:7.52M used_memory_peak:822064 used_memory_peak_human:802.80K total_system_memory:1021902848 total_system_memory_human:974.56M used_memory_lua:37888 used_memory_lua_human:37.00K maxmemory:128000000 maxmemory_human:122.07M maxmemory_policy:noeviction mem_fragmentation_ratio:9.61 mem_allocator:jemalloc-4.0.3 client list: 查看当前连接的客户端列表 client kill \u003cip:port\u003e: 结束客户端连接 bash 127.0.0.1:6379\u003e CLIENT LIST id=3 addr=127.0.0.1:39676 fd=7 name= age=1340 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=32768 obl=0 oll=0 omem=0 events=r cmd=client # 危险，不要轻易操作 127.0.0.1:6379\u003e CLIENT KILL 127.0.0.1:39676 OK config get/set/rewrite: 在线获取/修改配置信息 config resetstat: 重置统计信息 dbsize: 查看键值对数量 flushall: 清空所有数据，危险操作 flushdb: 清空当前库数据，危险操作 select \u003c序号\u003e: 默认有16个库，切换库 bash 127.0.0.1:6379\u003e select 1 OK 127.0.0.1:6379[1]\u003e select 15 OK monitor: 实时监控操作指令 shutdown: 停止 redis 服务 ","date":"2021-03-28","objectID":"/posts/redis-cli/:1:1","series":null,"tags":["redis"],"title":"Redis 基础操作","uri":"/posts/redis-cli/#管理命令"},{"categories":["redis"],"content":" key 通用操作命令 keys: 查看所有 key bash 127.0.0.1:6379\u003e KEYS * 1) \"user.age\" 2) \"user.email\" 3) \"user.name\" 127.0.0.1:6379\u003e KEYS *n* 1) \"user.name\" 127.0.0.1:6379\u003e KEYS user* 1) \"user.age\" 2) \"user.email\" 3) \"user.name\" 注意: 不建议直接使用 keys * 直接查看，数量多的情况下会影响 redis 性能 type: 查看 key 的类型 bash 127.0.0.1:6379\u003e TYPE user.name string 127.0.0.1:6379\u003e TYPE hbb hash expire/pexpire: 以秒/毫秒设置 key 的存活时间 ttl/pttl: 以秒/毫秒返回 key 的存活时间 persist: 取消生存时间设置 bash 127.0.0.1:6379\u003e set te 123 OK 127.0.0.1:6379\u003e EXPIRE te 20 (integer) 1 127.0.0.1:6379\u003e ttl te (integer) 16 127.0.0.1:6379\u003e persist te (integer) 1 127.0.0.1:6379\u003e ttl te (integer) -1 del: 删除一个 key exists: 检查 key 是否存在 rename: 重命名 key bash 127.0.0.1:6379\u003e exists te (integer) 1 127.0.0.1:6379\u003e del te (integer) 1 127.0.0.1:6379\u003e exists te (integer) 0 127.0.0.1:6379\u003e set te adf OK 127.0.0.1:6379\u003e rename te tem OK 127.0.0.1:6379\u003e get tem \"adf\" 127.0.0.1:6379\u003e exists tem (integer) 1 ","date":"2021-03-28","objectID":"/posts/redis-cli/:1:2","series":null,"tags":["redis"],"title":"Redis 基础操作","uri":"/posts/redis-cli/#key-通用操作命令"},{"categories":["redis"],"content":" Redis 数据类型redis 支持的数据类型如下 String： 字符类型 Hash：字典类型 List：列表 Set：集合 Sorted set：有序集合 ","date":"2021-03-28","objectID":"/posts/redis-cli/:2:0","series":null,"tags":["redis"],"title":"Redis 基础操作","uri":"/posts/redis-cli/#redis-数据类型"},{"categories":["redis"],"content":" string 应用场景: session 共享 计数器：微博数，粉丝数，订阅、礼物 字符串类型操作命令 bash # 设置键的字符串值 127.0.0.1:6379\u003e set mykey 0 OK # 获取键的值 127.0.0.1:6379\u003e get mykey \"0\" # 设置键的字符串值并返回其旧值 127.0.0.1:6379\u003e getset key2 2 (nil) # 设置键的值和有效期(单位秒) 127.0.0.1:6379\u003e setex time 10 10 OK 127.0.0.1:6379\u003e ttl time (integer) 7 # 仅当密钥不存在时设置密钥的值 127.0.0.1:6379\u003e setnx k3 3 (integer) 1 127.0.0.1:6379\u003e get k3 \"3\" # 将键的整数值加1 127.0.0.1:6379\u003e incr sar (integer) 1 # 将键的整数值减1 127.0.0.1:6379\u003e decr sar (integer) 0 # 将键的整数值增加给定的数量 127.0.0.1:6379\u003e incrby sar 100 (integer) 100 # 将键的整数值减少给定的数量 127.0.0.1:6379\u003e decrby sar 15 (integer) 85 # 同时为多个键设置多个值 127.0.0.1:6379\u003e mset k1 1 k2 2 k3 3 OK # 同时获取多个键的值 127.0.0.1:6379\u003e mget k1 k2 k3 1) \"1\" 2) \"2\" 3) \"3\" # 检测键是否存在 127.0.0.1:6379\u003e exists k1 (integer) 1 # 获取键值的长度 127.0.0.1:6379\u003e strlen k2 (integer) 1 ","date":"2021-03-28","objectID":"/posts/redis-cli/:2:1","series":null,"tags":["redis"],"title":"Redis 基础操作","uri":"/posts/redis-cli/#string"},{"categories":["redis"],"content":" hash应用场景: 存储部分变更的数据，如用户信息等, 最接近 mysql 表结构的一种类型,主要是可以做数据库缓存 hash 字典类型操作命令 bash # 设置字典 127.0.0.1:6379\u003e hmset stu id 101 name zhangsan age 20 gender m OK # 获取字典多个字段值 127.0.0.1:6379\u003e hmget stu name age gender 1) \"zhangsan\" 2) \"20\" 3) \"m\" # 获取 stu 键的字段数量 127.0.0.1:6379\u003e hlen stu (integer) 4 # 判断 stu 键中是否存在 name 的字段 127.0.0.1:6379\u003e hexists stu name (integer) 1 # 返回 stu 键的所有字段和值 127.0.0.1:6379\u003e hgetall stu 1) \"id\" 2) \"101\" 3) \"name\" 4) \"zhangsan\" 5) \"age\" 6) \"20\" 7) \"gender\" 8) \"m\" # 获取 stu 所有字段名称 127.0.0.1:6379\u003e hkeys stu 1) \"id\" 2) \"name\" 3) \"age\" 4) \"gender\" # 获取 stu 所有字段的值 127.0.0.1:6379\u003e hvals stu 1) \"101\" 2) \"zhangsan\" 3) \"20\" 4) \"m\" ","date":"2021-03-28","objectID":"/posts/redis-cli/:2:2","series":null,"tags":["redis"],"title":"Redis 基础操作","uri":"/posts/redis-cli/#hash"},{"categories":["redis"],"content":" list应用场景: 消息队列系统，社交类朋友圈 创建一个列表 每次插入的数据都会放在最前面，第一个索引号为 0 bash 127.0.0.1:6379\u003e lpush wechat \"today is nice day !\" (integer) 1 127.0.0.1:6379\u003e lpush wechat \"today is bad day !\" (integer) 2 127.0.0.1:6379\u003e lpush wechat \"today is good day !\" (integer) 3 127.0.0.1:6379\u003e lpush wechat \"today is rainy day !\" (integer) 4 127.0.0.1:6379\u003e lpush wechat \"today is friday day !\" (integer) 5 获取列表中的数据 bash # 取最新1条数据 127.0.0.1:6379\u003e lrange wechat 0 0 1) \"today is friday day !\" # 取所有数据 127.0.0.1:6379\u003e lrange wechat 0 -1 1) \"today is friday day !\" 2) \"today is rainy day !\" 3) \"today is good day !\" 4) \"today is bad day !\" 5) \"today is nice day !\" # 取最新的前3条数据 127.0.0.1:6379\u003e lrange wechat 0 2 1) \"today is friday day !\" 2) \"today is rainy day !\" 3) \"today is good day !\" # 取最后2条数据 127.0.0.1:6379\u003e lrange wechat -2 -1 1) \"today is bad day !\" 2) \"today is nice day !\" 列表的 增、删、改、查 操作命令 text # 增 lpush mykey a b 若key不存在,创建该键及与其关联的List,依次插入a ,b， 若List类型的key存在,则插入value中 lpushx mykey2 e 若key不存在,此命令无效， 若key存在,则插入value中 linsert mykey before a a1 在 a 的前面插入新元素 a1 linsert mykey after e e2 在e 的后面插入新元素 e2 rpush mykey a b 在链表尾部先插入b,在插入a rpushx mykey e 若key存在,在尾部插入e, 若key不存在,则无效 rpoplpush mykey mykey2 将mykey的尾部元素弹出,再插入到mykey2 的头部(原子性的操作) # 删 del mykey 删除已有键 lrem mykey 2 a 从头部开始找,按先后顺序,值为a的元素,删除数量为2个,若存在第3个,则不删除 ltrim mykey 0 2 从头开始,索引为0,1,2的3个元素,其余全部删除 # 改 lset mykey 1 e 从头开始, 将索引为1的元素值,设置为新值 e,若索引越界,则返回错误信息 rpoplpush mykey mykey 将 mykey 中的尾部元素移到其头部 # 查 lrange mykey 0 -1 取链表中的全部元素，其中0表示第一个元素,-1表示最后一个元素。 lrange mykey 0 2 从头开始,取索引为0,1,2的元素 lrange mykey 0 0 从头开始,取第一个元素,从第0个开始,到第0个结束 lpop mykey 获取头部元素,并且弹出头部元素,出栈 lindex mykey 6 从头开始,获取索引为6的元素 若下标越界,则返回nil ","date":"2021-03-28","objectID":"/posts/redis-cli/:2:3","series":null,"tags":["redis"],"title":"Redis 基础操作","uri":"/posts/redis-cli/#list"},{"categories":["redis"],"content":" set案例：在微博应用中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合中。 Redis 还为集合提供了求交集、并集、差集等操作，可以非常方便的实现如共同关注、共同喜好、二度好友等功能， 对上面的所有集合操作，你还可以使用不同的命令选择将结果返回给客户端还是存集到一个新的集合中。 bash 127.0.0.1:6379\u003e sadd lxl pg1 jnl baoqiang gsy alexsb (integer) 5 127.0.0.1:6379\u003e sadd jnl baoqiang ms bbh yf wxg (integer) 5 # 求并集 127.0.0.1:6379\u003e sunion lxl jnl 1) \"bbh\" 2) \"baoqiang\" 3) \"pg1\" 4) \"alexsb\" 5) \"gsy\" 6) \"ms\" 7) \"yf\" 8) \"jnl\" 9) \"wxg\" # 求交集 127.0.0.1:6379\u003e sinter lxl jnl 1) \"baoqiang\" # 求差集 127.0.0.1:6379\u003e sdiff lxl jnl 1) \"alexsb\" 2) \"pg1\" 3) \"gsy\" 4) \"jnl\" 增、删、改、查 text # 增 sadd myset a b c 若 key 不存在, 创建该键及与其关联的 set, 依次插入a ,b, 若key存在, 则插入value中, 若 a 在myset中已经存在,则插入了 d 和 e 两个新成员。 # 删 spop myset 尾部的 b 被移出, 事实上 b 并不是之前插入的第一个或最后一个成员 srem myset a d f 若 f 不存在, 移出 a、d ,并返回2 # 改 smove myset myset2 a 将a从 myset 移到 myset2， # 查 sismember myset a 判断 a 是否已经存在，返回值为 1 表示存在。 smembers myset 查看 set 中的内容 scard myset 获取 set 集合中元素的数量 srandmember myset 随机的返回某一成员 sdiff myset1 myset2 myset3 1和2得到一个结果,拿这个集合和3比较,获得每个独有的值 sdiffstore diffkey myset myset2 myset3 3个集和比较,获取独有的元素,并存入diffkey 关联的Set中 sinter myset myset2 myset3 获得3个集合中都有的元素 sinterstore interkey myset myset2 myset3 把交集存入interkey 关联的Set中 sunion myset myset2 myset3 获取3个集合中的成员的并集 sunionstore unionkey myset myset2 myset3 把并集存入unionkey 关联的Set中 ","date":"2021-03-28","objectID":"/posts/redis-cli/:2:4","series":null,"tags":["redis"],"title":"Redis 基础操作","uri":"/posts/redis-cli/#set"},{"categories":["redis"],"content":" sorted set应用场景： 排行榜应用，取 TOP N 操作 这个需求与上面需求的不同之处在于，前面操作以时间为权重，这个是以某个条件为权重，比如按顶的次数排序， 这时候就需要我们的 sorted set 出马了，将你要排序的值设置成 sorted set 的score，将具体的数据设置成相应的 value，每次只需要执行一条 ZADD 命令即可。 bash 127.0.0.1:6379\u003e zadd topN 0 smlt 0 fskl 0 fshkl 0 lzlsfs 0 wdhbx 0 wxg (integer) 6 127.0.0.1:6379\u003e ZINCRBY topN 100000 smlt \"100000\" 127.0.0.1:6379\u003e ZINCRBY topN 10000 fskl \"10000\" 127.0.0.1:6379\u003e ZINCRBY topN 1000000 fshkl \"1000000\" 127.0.0.1:6379\u003e ZINCRBY topN 100 lzlsfs \"100\" 127.0.0.1:6379\u003e ZINCRBY topN 100000000 wxg \"100000000\" 127.0.0.1:6379\u003e ZREVRANGE topN 0 2 1) \"wxg\" 2) \"fshkl\" 3) \"smlt\" 127.0.0.1:6379\u003e ZREVRANGE topN 0 2 withscores 1) \"wxg\" 2) \"100000000\" 3) \"fshkl\" 4) \"1000000\" 5) \"smlt\" 6) \"100000\" 增、删、改、查 text # 增 zadd myzset 2 \"two\" 3 \"three\" 添加两个分数分别是 2 和 3 的两个成员 # 删 zrem myzset one two 删除多个成员变量,返回删除的数量 # 改 zincrby myzset 2 one 将成员 one 的分数增加 2，并返回该成员更新后的分数 # 查 zrange myzset 0 -1 WITHSCORES 返回所有成员和分数,不加WITHSCORES,只返回成员 zrank myzset one 获取成员one在Sorted-Set中的位置索引值。0表示第一个位置 zcard myzset 获取 myzset 键中成员的数量 zcount myzset 1 2 获取分数满足表达式 1 \u003c= score \u003c= 2 的成员的数量 zscore myzset three 获取成员 three 的分数 zrangebyscore myzset 1 2 获取分数满足表达式 1 \u003c score \u003c= 2 的成员 #-inf 表示第一个成员，+inf最后一个成员 #limit限制关键字 #2 3 是索引号 zrangebyscore myzset -inf +inf limit 2 3 返回索引是2和3的成员 zremrangebyscore myzset 1 2 删除分数 1\u003c= score \u003c= 2 的成员，并返回实际删除的数量 zremrangebyrank myzset 0 1 删除位置索引满足表达式 0 \u003c= rank \u003c= 1 的成员 zrevrange myzset 0 -1 WITHSCORES 按位置索引从高到低,获取所有成员和分数 #原始成员:位置索引从小到大 one 0 two 1 #执行顺序:把索引反转 位置索引:从大到小 one 1 two 0 #输出结果: two one zrevrange myzset 1 3 获取位置索引,为1,2,3的成员 #相反的顺序:从高到低的顺序 zrevrangebyscore myzset 3 0 获取分数 3\u003e=score\u003e=0的成员并以相反的顺序输出 zrevrangebyscore myzset 4 0 limit 1 2 获取索引是1和2的成员,并反转位置索引 ","date":"2021-03-28","objectID":"/posts/redis-cli/:2:5","series":null,"tags":["redis"],"title":"Redis 基础操作","uri":"/posts/redis-cli/#sorted-set"},{"categories":["kubernetes"],"content":" 部署 Prometheus","date":"2021-03-19","objectID":"/posts/kubernetes-prometheus/:1:0","series":null,"tags":["prometheus"],"title":"使用 Prometheus 监控 Kubernetes 集群","uri":"/posts/kubernetes-prometheus/#部署-prometheus"},{"categories":["kubernetes"],"content":" 准备资源配置清单我们将 prometheus.yml 配置文件以 configmap 的形式存储在 kubernetes 集群中。(configmap.yaml) yaml apiVersion: v1 kind: ConfigMap metadata: name: prometheus-cfg namespace: monitor data: prometheus.yml: | global: scrape_interval: 30s scrape_timeout: 30s evaluation_interval: 1m scrape_configs: - job_name: prometheus honor_timestamps: true scrape_interval: 30s scrape_timeout: 30s metrics_path: /metrics scheme: http follow_redirects: true static_configs: - targets: - localhost:9090 - job_name: kubernetes-node-exporter honor_timestamps: true scrape_interval: 30s scrape_timeout: 30s metrics_path: /metrics scheme: http bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt insecure_skip_verify: false follow_redirects: true relabel_configs: - separator: ; regex: __meta_kubernetes_node_label_(.+) replacement: $1 action: labelmap - source_labels: [__meta_kubernetes_role] separator: ; regex: (.*) target_label: kubernetes_role replacement: $1 action: replace - source_labels: [__address__] separator: ; regex: (.*):10250 target_label: __address__ replacement: ${1}:9100 action: replace kubernetes_sd_configs: - role: node follow_redirects: true - job_name: kubernetes-node-kubelet honor_timestamps: true scrape_interval: 30s scrape_timeout: 30s metrics_path: /metrics scheme: https bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt insecure_skip_verify: true follow_redirects: true relabel_configs: - separator: ; regex: __meta_kubernetes_node_label_(.+) replacement: $1 action: labelmap kubernetes_sd_configs: - role: node follow_redirects: true - job_name: traefik honor_timestamps: true scrape_interval: 30s scrape_timeout: 30s metrics_path: /metrics scheme: http follow_redirects: true static_configs: - targets: - traefik.kube-system.svc.cluster.local:8080 - job_name: kubernetes-apiservers kubernetes_sd_configs: - role: endpoints scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token relabel_configs: - action: keep source_labels: - __meta_kubernetes_namespace - __meta_kubernetes_service_name - __meta_kubernetes_endpoint_port_name regex: default;kubernetes;https - job_name: kubernetes-service-endpoints kubernetes_sd_configs: - role: endpoints relabel_configs: - action: keep regex: true source_labels: - __meta_kubernetes_service_annotation_prometheus_io_scrape - action: replace regex: (https?) source_labels: - __meta_kubernetes_service_annotation_prometheus_io_scheme target_label: __scheme__ - action: replace regex: (.+) source_labels: - __meta_kubernetes_service_annotation_prometheus_io_path target_label: __metrics_path__ - action: replace regex: ([^:]+)(?::\\d+)?;(\\d+) replacement: $1:$2 source_labels: - __address__ - __meta_kubernetes_service_annotation_prometheus_io_port target_label: __address__ - action: labelmap regex: __meta_kubernetes_service_label_(.+) - action: replace source_labels: - __meta_kubernetes_namespace target_label: kubernetes_namespace - action: replace source_labels: - __meta_kubernetes_service_name target_label: kubernetes_name # 监控 service - job_name: kubernetes-services kubernetes_sd_configs: - role: service metrics_path: /probe params: module: - http_2xx relabel_configs: - action: keep regex: true source_labels: - __meta_kubernetes_service_annotation_prometheus_io_probe - source_labels: - __address__ target_label: __param_target - replacement: blackbox target_label: __address__ - source_labels: - __param_target target_label: instance - action: labelmap regex: __meta_kubernetes_service_label_(.+) - source_labels: - __meta_kubernetes_namespace target_label: kubernetes_namespace - source_labels: - __meta_kubernetes_service_name target_label: kubernetes_name # 监控 pod - job_name: kubernetes-pods kubernetes_sd_configs: - role: pod relabel_configs: - action: ","date":"2021-03-19","objectID":"/posts/kubernetes-prometheus/:1:1","series":null,"tags":["prometheus"],"title":"使用 Prometheus 监控 Kubernetes 集群","uri":"/posts/kubernetes-prometheus/#准备资源配置清单"},{"categories":["kubernetes"],"content":" 部署 Prometheus 相关资源按顺序应用资源配置清单 bash kubectl apply -f rbac.yaml kubectl apply -f pvc.yaml kubectl apply -f configmap.yaml kubectl apply -f deployment.yaml 使用 traefik 暴露 prometheus 服务: ingress-route.yaml yaml apiVersion: traefik.containo.us/v1alpha1 kind: IngressRoute metadata: name: prometheus namespace: monitor spec: entryPoints: - web routes: - match: Host(`mon.host.com`) kind: Rule services: - name: prometheus port: 9090 应用 bash kubectl apply -f ingress-route.yaml ","date":"2021-03-19","objectID":"/posts/kubernetes-prometheus/:1:2","series":null,"tags":["prometheus"],"title":"使用 Prometheus 监控 Kubernetes 集群","uri":"/posts/kubernetes-prometheus/#部署-prometheus-相关资源"},{"categories":["kubernetes"],"content":" 部署 node-exporter 监控所有节点准备 node-exporter.yaml yaml apiVersion: apps/v1 kind: DaemonSet metadata: labels: app: node-exporter name: node-exporter namespace: monitor spec: selector: matchLabels: app: node-exporter template: metadata: labels: app: node-exporter spec: hostPID: true hostIPC: true hostNetwork: true containers: - name: node-exporter image: prom/node-exporter:v1.1.2 command: - \"/bin/node_exporter\" args: - \"--path.procfs=/host/proc\" - \"--path.sysfs=/host/sys\" - \"--collector.filesystem.ignored-mount-points='^/(dev|proc|sys|host|etc)($|/)'\" ports: - containerPort: 9100 protocol: TCP name: http securityContext: privileged: true volumeMounts: - name: dev mountPath: \"/host/dev\" - name: proc mountPath: \"/host/proc\" - name: sys mountPath: \"/host/sys\" - name: rootfs mountPath: \"/rootfs\" resources: requests: cpu: 100m memory: 128Mi limits: cpu: 100m memory: 128Mi tolerations: - key: \"node-role.kubernetes.io/master\" operator: \"Exists\" effect: \"NoSchedule\" volumes: - name: proc hostPath: path: /proc - name: dev hostPath: path: /dev - name: sys hostPath: path: /sys - name: rootfs hostPath: path: / 由于我们需要监控所有节点包括主节点，所有需要忽略主节点上的污点, 加入 tolerations 配置项，使用 DaemonSet 方式部署 bash kubectl apply -f node-exporter.yaml 查看 Prometheus 监控 Targets 状态 ","date":"2021-03-19","objectID":"/posts/kubernetes-prometheus/:2:0","series":null,"tags":["prometheus"],"title":"使用 Prometheus 监控 Kubernetes 集群","uri":"/posts/kubernetes-prometheus/#部署-node-exporter-监控所有节点"},{"categories":["kubernetes"],"content":" 使用 Grafana 展示 Prometheus 监控数据","date":"2021-03-19","objectID":"/posts/kubernetes-prometheus/:3:0","series":null,"tags":["prometheus"],"title":"使用 Prometheus 监控 Kubernetes 集群","uri":"/posts/kubernetes-prometheus/#使用-grafana-展示-prometheus-监控数据"},{"categories":["kubernetes"],"content":" 部署 Grafanagrafana.yaml yaml --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: grafana namespace: monitor spec: storageClassName: managed-nfs-storage accessModes: - ReadWriteMany resources: requests: storage: 1Gi --- apiVersion: apps/v1 kind: Deployment metadata: name: grafana namespace: monitor labels: app: grafana spec: revisionHistoryLimit: 10 selector: matchLabels: app: grafana template: metadata: labels: app: grafana spec: containers: - name: grafana image: grafana/grafana:7.5.4 imagePullPolicy: IfNotPresent ports: - containerPort: 3000 name: grafana env: - name: GF_SECURITY_ADMIN_USER value: admin - name: GF_SECURITY_ADMIN_PASSWORD value: admin321 readinessProbe: failureThreshold: 10 httpGet: path: /api/health port: 3000 scheme: HTTP initialDelaySeconds: 60 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 30 livenessProbe: failureThreshold: 3 httpGet: path: /api/health port: 3000 scheme: HTTP periodSeconds: 10 successThreshold: 1 timeoutSeconds: 1 resources: limits: cpu: 100m memory: 256Mi requests: cpu: 100m memory: 256Mi volumeMounts: - mountPath: /var/lib/grafana subPath: grafana name: storage securityContext: runAsUser: 0 volumes: - name: storage persistentVolumeClaim: claimName: grafana --- apiVersion: v1 kind: Service metadata: labels: app: grafana name: grafana namespace: monitor spec: ports: - name: \"http\" port: 3000 protocol: TCP targetPort: 3000 selector: app: grafana type: ClusterIP --- apiVersion: traefik.containo.us/v1alpha1 kind: IngressRoute metadata: name: grafana namespace: monitor spec: entryPoints: - web routes: - match: Host(`grafana.host.com`) kind: Rule services: - name: grafana port: 3000 应用 grafana.yaml bash kubectl apply -f grafana.yml ","date":"2021-03-19","objectID":"/posts/kubernetes-prometheus/:3:1","series":null,"tags":["prometheus"],"title":"使用 Prometheus 监控 Kubernetes 集群","uri":"/posts/kubernetes-prometheus/#部署-grafana"},{"categories":["kubernetes"],"content":" 安装 Grafana 插件插件安装有两种方式： 进入 Container 中，执行 grafana-cli plugins install $plugin_name 手动下载插件zip包，访问 https://grafana.com/grafana/plugins/ 下载 zip 包解压到 /var/lib/grafana/plugins 目录中 插件安装完毕后，需要重启 Grafana 的 Pod 进入容器运行如下命令安装插件 bash grafana-cli plugins install grafana-kubernetes-app grafana-cli plugins install grafana-clock-panel grafana-cli plugins install grafana-piechart-panel grafana-cli plugins install briangann-gauge-panel grafana-cli plugins install natel-discrete-panel 配置 prometheus 数据源 浏览器打开 grafana.host.com 使用用户名: admin, 密码: admin321 登录，进入 Configuration -\u003e Data Sources -\u003e Add Data Source 选择 Prometheus Url 为 http://prometheus:9090 Access: Server(default) 其他均为默认。 配置 kubernetes 插件 进入插件管理页面，先启用 kubernetes 插件 配置 kubernetes 插件 ","date":"2021-03-19","objectID":"/posts/kubernetes-prometheus/:3:2","series":null,"tags":["prometheus"],"title":"使用 Prometheus 监控 Kubernetes 集群","uri":"/posts/kubernetes-prometheus/#安装-grafana-插件"},{"categories":["kubernetes"],"content":" Traefik 灰度发布概述Traefik2.0 的一个更强大的功能就是灰度发布，灰度发布我们有时候也会称为金丝雀发布（Canary），主要就是让一部分测试的服务也参与到线上去，经过测试观察看是否符号上线要求 ","date":"2021-03-10","objectID":"/posts/kubernetes-traefik-canary/:1:0","series":null,"tags":["traefik"],"title":"使用 Traefik-2.4 进行灰度发布","uri":"/posts/kubernetes-traefik-canary/#traefik-灰度发布概述"},{"categories":["kubernetes"],"content":" 测试灰度发布比如现在我们有两个名为 appv1 和 appv2 的服务，我们希望通过 Traefik 来控制我们的流量，将 3⁄4 的流量路由到 appv1，1/4 的流量路由到 appv2 去，这个时候就可以利用 Traefik2.0 中提供的带权重的轮询（WRR）来实现该功能，首先在 Kubernetes 集群中部署上面的两个服务。为了对比结果我们这里提供的两个服务一个是 whoami，一个是 nginx，方便测试。 appv1 服务的资源清单如下所示：（appv1.yaml） yaml apiVersion: apps/v1 kind: Deployment metadata: name: appv1 spec: selector: matchLabels: app: appv1 template: metadata: labels: use: test app: appv1 spec: containers: - name: whoami image: traefik/whoami ports: - containerPort: 80 name: portv1 --- apiVersion: v1 kind: Service metadata: name: appv1 spec: selector: app: appv1 ports: - name: http port: 80 targetPort: portv1 appv2 服务的资源清单如下所示：（appv2.yaml） yaml apiVersion: apps/v1 kind: Deployment metadata: name: appv2 spec: selector: matchLabels: app: appv2 template: metadata: labels: use: test app: appv2 spec: containers: - name: nginx image: nginx ports: - containerPort: 80 name: portv2 --- apiVersion: v1 kind: Service metadata: name: appv2 spec: selector: app: appv2 ports: - name: http port: 80 targetPort: portv2 直接创建上面两个服务： bash kubectl apply -f appv1.yaml kubectl apply -f appv2.yaml 在 Traefik 2.1 中新增了一个 TraefikService 的 CRD 资源，我们可以直接利用这个对象来配置 WRR，之前的版本需要通过 File Provider，比较麻烦，新建一个描述 WRR 的资源清单：(wrr.yaml) yaml apiVersion: traefik.containo.us/v1alpha1 kind: TraefikService metadata: name: app-wrr spec: weighted: services: - name: appv1 weight: 3 # 定义权重 port: 80 kind: Service # 可选，默认就是 Service - name: appv2 weight: 1 port: 80 然后为我们的灰度发布的服务创建一个 IngressRoute 资源对象：(ingressroute.yaml) yaml apiVersion: traefik.containo.us/v1alpha1 kind: IngressRoute metadata: name: wrringressroute namespace: default spec: entryPoints: - web routes: - match: Host(`wrr.wglee.cn`) kind: Rule services: - name: app-wrr kind: TraefikService 不过需要注意的是现在我们配置的 Service 不再是直接的 Kubernetes 对象了，而是上面我们定义的 TraefikService 对象，直接创建上面的两个资源对象，这个时候我们对域名 wrr.wglee.cn 做上解析，去浏览器中连续访问 4 次，我们可以观察到 appv1 这应用会收到 3 次请求，而 appv2 这个应用只收到 1 次请求，符合上面我们的 3:1 的权重配置。 ","date":"2021-03-10","objectID":"/posts/kubernetes-traefik-canary/:2:0","series":null,"tags":["traefik"],"title":"使用 Traefik-2.4 进行灰度发布","uri":"/posts/kubernetes-traefik-canary/#测试灰度发布"},{"categories":["kubernetes"],"content":" 简单 TCP 服务首先部署一个普通的 mongo 服务，资源清单文件如下所示：（mongo.yaml） yaml apiVersion: apps/v1 kind: Deployment metadata: name: mongo-traefik labels: app: mongo-traefik spec: selector: matchLabels: app: mongo-traefik template: metadata: labels: app: mongo-traefik spec: containers: - name: mongo image: mongo:4.0 ports: - containerPort: 27017 --- apiVersion: v1 kind: Service metadata: name: mongo-traefik spec: selector: app: mongo-traefik ports: - port: 27017 直接创建 mongo 应用： bash kubectl apply -f mongo.yaml ","date":"2021-03-10","objectID":"/posts/kubernetes-traefik-tcp/:1:0","series":null,"tags":["traefik"],"title":"使用 Traefik-2.4 暴露 Kubernetes 内部 TCP 协议","uri":"/posts/kubernetes-traefik-tcp/#简单-tcp-服务"},{"categories":["kubernetes"],"content":" ingressroute-tcp创建成功后就可以来为 mongo 服务配置一个路由了。由于 Traefik 中使用 TCP 路由配置需要 SNI，而 SNI 又是依赖 TLS 的，所以我们需要配置证书才行，如果没有证书的话，我们可以使用通配符 * 进行配置，我们这里创建一个 IngressRouteTCP 类型的 CRD 对象（前面我们就已经安装了对应的 CRD 资源）：(mongo-ingressroute-tcp.yaml) yaml apiVersion: traefik.containo.us/v1alpha1 kind: IngressRouteTCP metadata: name: mongo-traefik-tcp spec: entryPoints: - tcpep routes: - match: HostSNI(`*`) services: - name: mongo-traefik port: 27017 要注意的是这里的 entryPoints 部分，是根据我们启动的 Traefik 的静态配置中的 entryPoints 来决定的，我们当然可以使用前面我们定义得 80 和 443 这两个入口点，但是也可以可以自己添加一个用于 mongo 服务的专门入口点, 这里我们使用 tcpep 这个入口 关于 entryPoints 入口点的更多信息，可以查看文档 entrypoints 了解更多信息。 然后更新 Traefik 后我们就可以直接创建上面的资源对象： bash kubectl apply -f mongo-ingressroute-tcp.yaml 创建完成后，同样我们可以去 Traefik 的 Dashboard 页面上查看是否生效, 然后我们配置一个域名 mongo.local 解析到 Traefik 所在的节点，然后通过 8000 端口来连接 mongo 服务： bash mongo --host mongo.local --port 8000 mongo(75243,0x1075295c0) malloc: *** malloc_zone_unregister() failed for 0x7fffa56f4000 MongoDB shell version: 2.6.1 connecting to: mongo.local:8000/test \u003e show dbs admin 0.000GB config 0.000GB local 0.000GB ","date":"2021-03-10","objectID":"/posts/kubernetes-traefik-tcp/:2:0","series":null,"tags":["traefik"],"title":"使用 Traefik-2.4 暴露 Kubernetes 内部 TCP 协议","uri":"/posts/kubernetes-traefik-tcp/#ingressroute-tcp"},{"categories":["kubernetes"],"content":" 部署测试 web 应用使用 Deployment 部署 nginx， 启动两个 pod 实例， 资源配置清单 nginx.yaml 如下： yaml apiVersion: apps/v1 kind: Deployment metadata: labels: app: nginx name: nginx namespace: default spec: replicas: 2 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:stable-alpine --- apiVersion: v1 kind: Service metadata: labels: app: nginx name: nginx namespace: default spec: ports: - name: \"http\" port: 80 protocol: TCP targetPort: 80 selector: app: nginx type: ClusterIP 在集群中应用 nginx.yaml bash kubectl apply -f nginx.yaml ","date":"2021-03-10","objectID":"/posts/kubernetes-traefik-web/:1:0","series":null,"tags":["traefik"],"title":"使用 Traefik-2.4 暴露 Kubernetes 内部 Web 服务","uri":"/posts/kubernetes-traefik-web/#部署测试-web-应用"},{"categories":["kubernetes"],"content":" 配置 traefik IngressRouteingress-route.yaml yaml apiVersion: traefik.containo.us/v1alpha1 # 使用 ingress route kind: IngressRoute metadata: name: nginx namespace: default spec: # 指定使用的入口，由于是 http 流量，我们使用 web 入口（入口在 traefik 命令行配置参数自行配置） entryPoints: - web routes: # 指定匹配规则 - match: Host(`www.host.com`) kind: Rule services: - name: nginx port: 80 在集群中应用 ingress-route.yaml bash kubectl apply -f ingress-route.yaml 在内部使用 http 可以减少管理证书的麻烦及简化配置的步骤，我们只要在最外围的反代上配置成 https 即可。 如果需要使用 traefik 暴露 https 流量，可以下面步骤操作 1.使用 cfssl 命令自签 www.host.com 域名证书，参考 使用 cfssl 自签证书 2.将自签证书存入 k8s 集群中，以 secret 资源存储 bash kubectl create secret tls host-com-tls --cert=host.pem --key=host-key.pem 要注意证书文件名称必须是 tls.crt 和 tls.key 3.配置 IngressRoute 的 entryPoints 为 websecure, 并启用 tls 配置 yaml apiVersion: traefik.containo.us/v1alpha1 # 使用 ingress route kind: IngressRoute metadata: name: nginx namespace: default spec: # 指定使用的入口，由于是 http 流量，我们使用 web 入口（入口在 traefik 命令行配置参数自行配置） entryPoints: - websecure routes: # 指定匹配规则 - match: Host(`www.host.com`) kind: Rule services: - name: nginx port: 80 tls: secretName: host-com-tls 在配置 nginx 反向代理时后端 web 服务的端口此时就成了 443 了，协议为 https ","date":"2021-03-10","objectID":"/posts/kubernetes-traefik-web/:2:0","series":null,"tags":["traefik"],"title":"使用 Traefik-2.4 暴露 Kubernetes 内部 Web 服务","uri":"/posts/kubernetes-traefik-web/#配置-traefik-ingressroute"},{"categories":["kubernetes"],"content":" 配置负载均衡反向代理我们把只要是 www.host.com 这个域名的流量（配置中使用通配符）统一反代到 traefik 的 web 入口 bash upstream k8s_services { server 10.7.50.17; server 10.7.149.184; } server { listen 80; server_name *.host.com; location / { proxy_pass http://k8s_services; include proxy.conf; } } ","date":"2021-03-10","objectID":"/posts/kubernetes-traefik-web/:3:0","series":null,"tags":["traefik"],"title":"使用 Traefik-2.4 暴露 Kubernetes 内部 Web 服务","uri":"/posts/kubernetes-traefik-web/#配置负载均衡反向代理"},{"categories":["kubernetes"],"content":" 查看及测试打开 traefik-dashboard 页面，查看配置的规则是否生效，使用域名访问此 web 服务。 ","date":"2021-03-10","objectID":"/posts/kubernetes-traefik-web/:4:0","series":null,"tags":["traefik"],"title":"使用 Traefik-2.4 暴露 Kubernetes 内部 Web 服务","uri":"/posts/kubernetes-traefik-web/#查看及测试"},{"categories":["kubernetes"],"content":" 部署 Metrics Server在 kubernetes 中 HPA 自动伸缩指标依据，kubectl top 命令的资源使用率，可以通过 metrics-server 来获取。 dashboard 也会引用 metrics-server 展示资源负载情况图表。但是官方明确表示，该指标不应该用于监控指标采集。 官方主页: https://github.com/kubernetes-sigs/metrics-server 在大部分情况下，使用 deployment 部署一个副本即可，最多支持5000个 node，每个 node 消耗 3m CPU 和 3M 内存 可以从官方主页获取资源配置清单文件，也可以直接使用下面的配置文件。 metrics-server 配置参数 text - args: - --cert-dir=/tmp - --secure-port=4443 - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname - --kubelet-use-node-status-port - --kubelet-insecure-tls 部署 metrics-server bash kubectl apply -f metrics-server.yaml 由于国内环境导致无法下载 metrics-server 镜像，在网上也没有找到可用的代理的服务器。请自行解决此问题。 ","date":"2021-03-09","objectID":"/posts/kubernetes-metricsserver/:1:0","series":null,"tags":["metrics-server"],"title":"使用 metrics-server 采集 Kubernetes 集群性能指标","uri":"/posts/kubernetes-metricsserver/#部署-metrics-server"},{"categories":["kubernetes"],"content":" Dashboard 页面效果展示metrics-server 安装完成后可以在 dashboard 页面中看到效果 dashboard metrics ","date":"2021-03-09","objectID":"/posts/kubernetes-metricsserver/:1:1","series":null,"tags":["metrics-server"],"title":"使用 metrics-server 采集 Kubernetes 集群性能指标","uri":"/posts/kubernetes-metricsserver/#dashboard-页面效果展示"},{"categories":["kubernetes"],"content":" Dashboard 介绍Kubernetes Dashboard 是 Kubernetes 集群的基于 Web 的通用 UI。 它允许用户管理群集中运行的应用程序并对其进行故障排除，以及管理群集本身。 Dashboard 的 Github 主页：https://github.com/kubernetes/dashboard ","date":"2021-03-09","objectID":"/posts/kubernetes-dashboard/:1:0","series":null,"tags":["dashboard"],"title":"使用 Dashborad 管理 Kubernetes 集群","uri":"/posts/kubernetes-dashboard/#dashboard-介绍"},{"categories":["kubernetes"],"content":" 部署 DashboardDashboard 默认的 YAML 配置文件中是采用 HTTPS 方式访问，本实验中前端 SLB 采用 HTTP 与后端集群中 Ingress 通信，因此需要对该 YAML 文件进行改造，否则会出现以客户端 HTTP 方式请求 HTTPS 接口的报错。 由于 Dashboard 使用自签发的证书, 在连接及配置反向代理多有不便，建议将其改为 HTTP 方式，然后在 nginx 反代处加证书。 从官网下载 Dashboard YAML 配置文件，进行修改，配置如下: yaml # Copyright 2017 The Kubernetes Authors. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. apiVersion: v1 kind: Namespace metadata: name: kubernetes-dashboard --- apiVersion: v1 kind: ServiceAccount metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard --- kind: Service apiVersion: v1 metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard spec: ports: # 配置关联 HTTP 服务端口 - port: 80 targetPort: 8080 #- port: 443 # targetPort: 8443 selector: k8s-app: kubernetes-dashboard --- apiVersion: v1 kind: Secret metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard-certs namespace: kubernetes-dashboard type: Opaque --- apiVersion: v1 kind: Secret metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard-csrf namespace: kubernetes-dashboard type: Opaque data: csrf: \"a36ff54b93460ed9c987ca71a618659e\" --- apiVersion: v1 kind: Secret metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard-key-holder namespace: kubernetes-dashboard type: Opaque --- kind: ConfigMap apiVersion: v1 metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard-settings namespace: kubernetes-dashboard --- kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard rules: # Allow Dashboard to get, update and delete Dashboard exclusive secrets. - apiGroups: [\"\"] resources: [\"secrets\"] resourceNames: [\"kubernetes-dashboard-key-holder\", \"kubernetes-dashboard-certs\", \"kubernetes-dashboard-csrf\"] verbs: [\"get\", \"update\", \"delete\"] # Allow Dashboard to get and update 'kubernetes-dashboard-settings' config map. - apiGroups: [\"\"] resources: [\"configmaps\"] resourceNames: [\"kubernetes-dashboard-settings\"] verbs: [\"get\", \"update\"] # Allow Dashboard to get metrics. - apiGroups: [\"\"] resources: [\"services\"] resourceNames: [\"heapster\", \"dashboard-metrics-scraper\"] verbs: [\"proxy\"] - apiGroups: [\"\"] resources: [\"services/proxy\"] resourceNames: [\"heapster\", \"http:heapster:\", \"https:heapster:\", \"dashboard-metrics-scraper\", \"http:dashboard-metrics-scraper\"] verbs: [\"get\"] --- kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1 metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard rules: # Allow Metrics Scraper to get metrics from the Metrics server - apiGroups: [\"metrics.k8s.io\"] resources: [\"pods\", \"nodes\"] verbs: [\"get\", \"list\", \"watch\"] --- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard roleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: kubernetes-dashboard subjects: - kind: ServiceAccount name: kubernetes-dashboard namespace: kubernetes-dashboard --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: kubernetes-dashboard roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: kubernetes-dashboard subjects: - kind: ServiceAccount name: kubernetes-dashboard namespace: kubernetes-dashboard --- kind: Deployment apiVersion: apps/v1 metadata: labels: k8s-app: kubernetes-dashboard name: kube","date":"2021-03-09","objectID":"/posts/kubernetes-dashboard/:2:0","series":null,"tags":["dashboard"],"title":"使用 Dashborad 管理 Kubernetes 集群","uri":"/posts/kubernetes-dashboard/#部署-dashboard"},{"categories":["kubernetes"],"content":" 使用 Ingress 暴露 Dashboard 服务使用 traefik 2.x 版本实现 Ingress 功能，准备 ingressroute.yaml 资源配置清单 yaml apiVersion: traefik.containo.us/v1alpha1 kind: IngressRoute metadata: name: dashboard-ingress namespace: kubernetes-dashboard spec: entryPoints: - web routes: - match: Host(`dashboard.host.com`) kind: Rule services: - name: kubernetes-dashboard port: 80 ","date":"2021-03-09","objectID":"/posts/kubernetes-dashboard/:3:0","series":null,"tags":["dashboard"],"title":"使用 Dashborad 管理 Kubernetes 集群","uri":"/posts/kubernetes-dashboard/#使用-ingress-暴露-dashboard-服务"},{"categories":["kubernetes"],"content":" 配置 nginx 反代由于 dashboard 不允许使用 http 登录，所以需要在 nginx 反向代理配置文件中配置 tls 证书 bash upstream www_pools { server 10.7.50.17; server 10.7.149.184; } server { listen 443 ssl; server_name dashboard.host.com; ssl_certificate ssl/wglee.cn.crt; ssl_certificate_key ssl/wglee.cn.key; ssl_ciphers \"TLS13-AES-256-GCM-SHA384:TLS13-CHACHA20-POLY1305-SHA256:TLS13-AES-128-GCM-SHA256:TLS13-AES-128-CCM-8-SHA256:TLS13-AES-128-CCM-SHA256:EECDH+CHACHA20:EECDH+CHACHA20-draft:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5\"; ssl_session_cache builtin:1000 shared:SSL:10m; location / { proxy_pass http://www_pools; include proxy.conf; } } server { listen 80; server_name dashboard.host.com; access_log off; return 301 https://$host$request_uri; } 此时我们可以通过域名访问 kubernetes-dashboard 页面 ","date":"2021-03-09","objectID":"/posts/kubernetes-dashboard/:4:0","series":null,"tags":["dashboard"],"title":"使用 Dashborad 管理 Kubernetes 集群","uri":"/posts/kubernetes-dashboard/#配置-nginx-反代"},{"categories":["kubernetes"],"content":" 创建集群管理员账号由于 kubernetes-dashboard 需要使用集群用户验证，我们先准备集群管理员账号配置清单 admin-user.yaml yaml --- apiVersion: v1 kind: ServiceAccount metadata: name: admin namespace: kubernetes-dashboard --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: admin roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: admin namespace: kubernetes-dashboard 应用 admin-user.yaml 配置，在 kubernetes-dashboard 名称空间里创建集群管理员账号。 获取 admin 管理员用户的 token bash kubectl -n kubernetes-dashboard get secret $(kubectl -n kubernetes-dashboard get sa/admin -o jsonpath=\"{.secrets[0].name}\") -o go-template=\"{{.data.token | base64decode}}\" 使用 admin 管理员 token 登录 dashboard 管理页面 ","date":"2021-03-09","objectID":"/posts/kubernetes-dashboard/:5:0","series":null,"tags":["dashboard"],"title":"使用 Dashborad 管理 Kubernetes 集群","uri":"/posts/kubernetes-dashboard/#创建集群管理员账号"},{"categories":["kubernetes"],"content":" Traefik 简介 Traefik 是一个开源的可以使服务发布变得轻松有趣的边缘路由器。它负责接收你系统的请求，然后使用合适的组件来对这些请求进行处理。 除了众多的功能之外，Traefik 的与众不同之处还在于它会自动发现适合你服务的配置。当 Traefik 在检查你的服务时，会找到服务的相关信息并找到合适的服务来满足对应的请求。 Traefik 兼容所有主流的集群技术，比如 Kubernetes，Docker，Docker Swarm，AWS，Mesos，Marathon，等等；并且可以同时处理多种方式。（甚至可以用于在裸机上运行的比较旧的软件。） 使用 Traefik，不需要维护或者同步一个独立的配置文件：因为一切都会自动配置，实时操作的（无需重新启动，不会中断连接）。使用 Traefik，你可以花更多的时间在系统的开发和新功能上面，而不是在配置和维护工作状态上面花费大量时间。 官方文档 – https://doc.traefik.io/traefik/ ","date":"2021-03-09","objectID":"/posts/kubernetes-traefik/:1:0","series":null,"tags":["traefik"],"title":"部署 Traefik 2.4","uri":"/posts/kubernetes-traefik/#traefik-简介"},{"categories":["kubernetes"],"content":" 核心概念 Traefik 是一个边缘路由器，是你整个平台的大门，拦截并路由每个传入的请求：它知道所有的逻辑和规则，这些规则确定哪些服务处理哪些请求；传统的反向代理需要一个配置文件，其中包含路由到你服务的所有可能路由，而 Traefik 会实时检测服务并自动更新路由规则，可以自动服务发现。 首先，当启动 Traefik 时，需要定义 entrypoints（入口点），然后，根据连接到这些 entrypoints 的路由来分析传入的请求，来查看他们是否与一组规则相匹配，如果匹配，则路由可能会将请求通过一系列中间件转换过后再转发到你的服务上去。在了解 Traefik 之前有几个核心概念我们必须要了解： Providers 用来自动发现平台上的服务，可以是编排工具、容器引擎或者 key-value 存储等，比如 Docker、Kubernetes、File Entrypoints 监听传入的流量（端口等…），是网络入口点，它们定义了接收请求的端口（HTTP 或者 TCP）。 Routers 分析请求（host, path, headers, SSL, …），负责将传入请求连接到可以处理这些请求的服务上去。 Services 将请求转发给你的应用（load balancing, …），负责配置如何获取最终将处理传入请求的实际服务。 Middlewares 中间件，用来修改请求或者根据请求来做出一些判断（authentication, rate limiting, headers, …），中间件被附件到路由上，是一种在请求发送到你的服务之前（或者在服务的响应发送到客户端之前）调整请求的一种方法。 ","date":"2021-03-09","objectID":"/posts/kubernetes-traefik/:2:0","series":null,"tags":["traefik"],"title":"部署 Traefik 2.4","uri":"/posts/kubernetes-traefik/#核心概念"},{"categories":["kubernetes"],"content":" 安装 Traefik 2.4由于 Traefik 2.x 版本和之前的 1.x 版本不兼容，我们这里选择功能更加强大的 2.x 版本来和大家进行讲解，我们这里使用的镜像是 traefik:2.4。 在 Traefik 中的配置可以使用两种不同的方式： 动态配置：完全动态的路由配置 静态配置：启动配置 静态配置中的元素（这些元素不会经常更改）连接到 providers 并定义 Treafik 将要监听的 entrypoints。 在 Traefik 中有三种方式定义静态配置：在配置文件中、在命令行参数中、通过环境变量传递 动态配置包含定义系统如何处理请求的所有配置内容，这些配置是可以改变的，而且是无缝热更新的，没有任何请求中断或连接损耗。 安装 Traefik 到 Kubernetes 集群中的资源清单文件可以到官方文档中找到，链接: https://doc.traefik.io/traefik/routing/providers/kubernetes-crd/ 将配置资源清单保存到本地，资源清单文件我这里准备好了（做了些修改，traefik 容器网络模式改为与共用宿主机网络，详细查看配置文件），通过以下命令应用。 请根据自己的需求修改资源配置清单 bash kubectl apply -f https://liwanggui.com/files/k8s/traefik2/crd.yaml kubectl apply -f https://liwanggui.com/files/k8s/traefik2/rbac.yaml kubectl apply -f https://liwanggui.com/files/k8s/traefik2/traefik.yaml kubectl apply -f https://liwanggui.com/files/k8s/traefik2/traefik-ui.yaml 其中 traefik.yaml 使用的是 DaemonSet 部署方式，如果你需要修改可以下载下来做相应的修改即可。我们这里是通过命令行参数来做的静态配置： text args: - --log.level=INFO - --accesslog - --api=true # 开启 api/dashboard 会创建一个名为 api@internal 的特殊 service，在 dashboard 中可以直接使用这个 service 来访问 - --api.insecure - --metrics.prometheus=true - --metrics.prometheus.addentrypointslabels - --metrics.prometheus.addserviceslabels - --entrypoints.web.address=:80 # 定义名为 web 的入口 - --entryPoints.websecure.address=:443 # 定义名为 websecure 的入口 - --entrypoints.tcpep.address=:8000 # 定义名为 tcpep 的入口 - --entrypoints.web.forwardedheaders.insecure # 信任 web 入口 所有转发的 header 头信息，可以用于获取客户端真实 IP 地址 - --entrypoints.websecure.forwardedheaders.insecure # 信任 websecure 入口 所有转发的 header 头信息，可以用于获取客户端真实 IP 地址 - --providers.kubernetescrd - --providers.kubernetesingress traefik-ui.yaml 中定义的是访问 traefik WEB UI 的资源配置清单，可以根据自己的实际情况修改。 bash $ kubectl get pods -n kube-system -l app=traefik NAME READY STATUS RESTARTS AGE traefik-7s6wk 1/1 Running 0 7m27s traefik-bx6m8 1/1 Running 0 7m27s 部署完成后我们可以通过域名 traefik.host.cn 访问 Traefik 的 Dashboard 页面了 资源参考 https://www.qikqiak.com/post/traefik-2.1-101/ ","date":"2021-03-09","objectID":"/posts/kubernetes-traefik/:3:0","series":null,"tags":["traefik"],"title":"部署 Traefik 2.4","uri":"/posts/kubernetes-traefik/#安装-traefik-24"},{"categories":["kubernetes"],"content":" 主机环境本示例中的 Kubernetes 集群部署将基于以下环境进行。 OS: Ubuntu 18.04.5 Kubernetes：v1.18.1 Container Runtime: Docker CE 19.03.15 ","date":"2021-03-09","objectID":"/posts/kubernetes-install/:1:0","series":null,"tags":["kubeadm"],"title":"使用 Kubeadm 快速部署 Kubernetes 集群","uri":"/posts/kubernetes-install/#主机环境"},{"categories":["kubernetes"],"content":" 环境说明测试使用的 kubernetes 集群可由一个 master 主机及一个以上（建议至少两个）node 主机组成，这些主机可以是物理服务器，也可以运行于 vmware、virtualbox 或 kvm 等虚拟化平台上的虚拟机，甚至是公有云上的 VPS 主机。 本测试环境将由 master1.host.com、node1.host.com、node2.host.com 3个独立的主机组成，它们分别拥有 4 核心的 CPU 及 8G 的内存资源，操作系统环境均为最小化部署的 Ubuntu Server 18.04.5 LTS，启用了 SSH 服务，域名为 host.com。此外，各主机需要预设的系统环境如下： 借助于 chronyd 服务（程序包名称 chrony）设定各节点时间精确同步； 通过 DNS 完成各节点的主机名称解析； 各节点禁用所有的 Swap 设备； 各节点禁用默认配置的 iptables 防火墙服务； 注意：为了便于操作，后面将在各节点直接以系统管理员 root 用户进行操作。若用户使用了普通用户，建议将如下各命令以 sudo 方式运行。 ","date":"2021-03-09","objectID":"/posts/kubernetes-install/:2:0","series":null,"tags":["kubeadm"],"title":"使用 Kubeadm 快速部署 Kubernetes 集群","uri":"/posts/kubernetes-install/#环境说明"},{"categories":["kubernetes"],"content":" 网络规划Kubernetes 网络分为三类: Pod 网络：172.16.0.0/16 Service 网络: 192.168.0.0/16 Node 网络: 10.7.0.0/16 注意: 请按照实际情况进行网络规划。 ","date":"2021-03-09","objectID":"/posts/kubernetes-install/:3:0","series":null,"tags":["kubeadm"],"title":"使用 Kubeadm 快速部署 Kubernetes 集群","uri":"/posts/kubernetes-install/#网络规划"},{"categories":["kubernetes"],"content":" 设定时钟同步若节点可直接访问互联网，安装 chrony 程序包后，可直接启动 chronyd 系统服务，并设定其随系统引导而启动。随后，chronyd 服务即能够从默认的时间服务器同步时间。 bash apt install chrony systemctl start chronyd.service 不过，建议用户配置使用本地的的时间服务器，在节点数量众多时尤其如此。存在可用的本地时间服务器时，修改节点的 /etc/chrony/chrony.conf 配置文件，并将时间服务器指向相应的主机即可，配置格式如下： text server CHRONY-SERVER-NAME-OR-IP iburst ","date":"2021-03-09","objectID":"/posts/kubernetes-install/:4:0","series":null,"tags":["kubeadm"],"title":"使用 Kubeadm 快速部署 Kubernetes 集群","uri":"/posts/kubernetes-install/#设定时钟同步"},{"categories":["kubernetes"],"content":" 主机名称解析（可选）使用 bind9 提供 dns 服务, 本环境直接在主节点安装 bind9 bash apt install bind9 更新多详细配置参考 Ubuntu Server 安装配置 bind9 host.com zone 配置文件示例 bash ; ; BIND data file for local loopback interface ; $TTL 604800 @ IN SOA host.com. root.host.com. ( 2 ; Serial 604800 ; Refresh 86400 ; Retry 2419200 ; Expire 604800 ) ; Negative Cache TTL ; @ IN NS ns.host.com. @ IN A 10.7.79.148 ns IN A 10.7.79.148 master1 IN A 10.7.79.148 node1 IN A 10.7.50.17 node2 IN A 10.7.149.184 apiserver IN A 10.7.79.148 由于本实验中使用的机器较小，使用 hosts 文件实现本地域名解析 ","date":"2021-03-09","objectID":"/posts/kubernetes-install/:5:0","series":null,"tags":["kubeadm"],"title":"使用 Kubeadm 快速部署 Kubernetes 集群","uri":"/posts/kubernetes-install/#主机名称解析可选"},{"categories":["kubernetes"],"content":" 禁用 Swap 设备部署集群时，kubeadm 默认会预先检查当前主机是否禁用了 Swap 设备，并在未禁用时强制终止部署过程。因此，在主机内存资源充裕的条件下，需要禁用所有的 Swap 设备，否则，就需要在后文的 kubeadm init 及 kubeadm join 命令执行时额外使用相关的选项忽略检查错误。 关闭 Swap 设备，需要分两步完成。首先是关闭当前已启用的所有 Swap 设备： bash swapoff -a 而后编辑 /etc/fstab 配置文件，注释用于挂载 Swap 设备的所有行。 另外，若确需在节点上使用 Swap 设备，也可选择让 kubeam 忽略 Swap 设备的相关设定。我们编辑 kubelet 的配置文件 /etc/default/kubelet，设置其忽略 Swap 启用的状态错误即可，文件内容如下： text KUBELET_EXTRA_ARGS=\"--fail-swap-on=false\" ","date":"2021-03-09","objectID":"/posts/kubernetes-install/:6:0","series":null,"tags":["kubeadm"],"title":"使用 Kubeadm 快速部署 Kubernetes 集群","uri":"/posts/kubernetes-install/#禁用-swap-设备"},{"categories":["kubernetes"],"content":" 禁用默认的防火墙服务Ubuntu 和 Debian 等 Linux 发行版默认使用 ufw（Uncomplicated FireWall）作为前端来简化 iptables 的使用，处于启用状态时，它默认会生成一些规则以加强系统安全。出于降低配置复杂度之目的，本文选择直接将其禁用。 bash ufw disable ufw status ","date":"2021-03-09","objectID":"/posts/kubernetes-install/:7:0","series":null,"tags":["kubeadm"],"title":"使用 Kubeadm 快速部署 Kubernetes 集群","uri":"/posts/kubernetes-install/#禁用默认的防火墙服务"},{"categories":["kubernetes"],"content":" 安装程序包 提示：以下操作需要在本示例中的所有三台主机上分别进行 ","date":"2021-03-09","objectID":"/posts/kubernetes-install/:8:0","series":null,"tags":["kubeadm"],"title":"使用 Kubeadm 快速部署 Kubernetes 集群","uri":"/posts/kubernetes-install/#安装程序包"},{"categories":["kubernetes"],"content":" 安装 docker此时我们需要安装指定版本的 docker，docker 安装请参考 Docker 快速安装 kubelet 需要让 docker 容器引擎使用 systemd 作为 CGroup 的驱动，其默认值为 cgroupfs，因而，我们还需要编辑 docker 的配置文件 /etc/docker/daemon.json，添加如下内容 json { \"registry-mirrors\": [\"https://docker.mirrors.ustc.edu.cn\", \"http://hub-mirror.c.163.com\"], # 镜像加速器 \"insecure-registries\":[\"harbor.host.com\"], # 第三方仓库或自建仓库地址，可以配置为 http \"data-root\": \"/data/docker\", # docker 数据存储目录 \"exec-opts\": [\"native.cgroupdriver=systemd\"], # 额外参数,部署 k8s 时需要指定此选项 \"log-driver\": \"json-file\", \"log-opts\": { \"max-size\": \"100m\"}, \"live-restore\": true } 配置完成后即可启动 docker 服务，并将其设置为随系统启动而自动引导： bash systemctl daemon-reload systemctl start docker.service systemctl enable docker.service ","date":"2021-03-09","objectID":"/posts/kubernetes-install/:8:1","series":null,"tags":["kubeadm"],"title":"使用 Kubeadm 快速部署 Kubernetes 集群","uri":"/posts/kubernetes-install/#安装-docker"},{"categories":["kubernetes"],"content":" 安装配置 kubelet 和 kubeadm首先，在各主机上生成 kubelet 和 kubeadm 等相关程序包的仓库，这里以阿里云的镜像服务为例： bash apt update \u0026\u0026 apt install -y apt-transport-https curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - cat \u003e/etc/apt/sources.list.d/kubernetes.list\u003c\u003cEOF deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main EOF apt update 接着，在各主机安装 kubelet、kubeadm 和 kubectl 程序包，并将其设置为随系统启动而自动引导： bash apt install -y kubelet=1.18.1-00 kubeadm=1.18.1-00 kubectl=1.18.1-00 systemctl enable kubelet 安装完成后，要确保 kubeadm 等程序文件的版本，这将也是后面初始化 Kubernetes 集群时需要明确指定的版本号 ","date":"2021-03-09","objectID":"/posts/kubernetes-install/:8:2","series":null,"tags":["kubeadm"],"title":"使用 Kubeadm 快速部署 Kubernetes 集群","uri":"/posts/kubernetes-install/#安装配置-kubelet-和-kubeadm"},{"categories":["kubernetes"],"content":" 初始化第一个主节点该步骤开始尝试构建 Kubernetes 集群的 master 节点，配置完成后，各 worker 节点直接加入到集群中的即可。需要特别说明的是，由 kubeadm 部署的 Kubernetes 集群上，集群核心组件 kube-apiserver、kube-controller-manager、kube-scheduler 和 etcd 等均会以静态 Pod 的形式运行，它们所依赖的镜像文件默认来自于 gcr.io 这一 Registry 服务之上。但我们无法直接访问该服务，常用的解决办法有如下两种，本示例将选择使用更易于使用的后一种方式。 使用能够到达该服务的代理服务；使用国内的镜像服务器上的服务，例如 gcr.azk8s.cn/google_containers 和 registry.aliyuncs.com/google_containers 等。 ","date":"2021-03-09","objectID":"/posts/kubernetes-install/:9:0","series":null,"tags":["kubeadm"],"title":"使用 Kubeadm 快速部署 Kubernetes 集群","uri":"/posts/kubernetes-install/#初始化第一个主节点"},{"categories":["kubernetes"],"content":" 初始化 master 节点在 master1.host.com 上完成如下操作 在运行初始化命令之前先运行如下命令单独获取相关的镜像文件，而后再运行后面的 kubeadm init 命令，以便于观察到镜像文件的下载过程。 bash # 查看镜像列表 kubeadm config images list --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.18.1 # 获取镜像文件至本地 kubeadm config images pull --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.18.1 而后即可进行 master 节点初始化。kubeadm init 命令支持两种初始化方式，一是通过命令行选项传递关键的部署设定，另一个是基于 yaml 格式的专用配置文件，后一种允许用户自定义各个部署参数。下面分别给出了两种实现方式的配置步骤，建议采用第二种方式进行。 初始化方式一 运行如下命令完成 master 节点的初始化： bash kubeadm init \\ --image-repository registry.aliyuncs.com/google_containers \\ --control-plane-endpoint apiserver.host.com \\ --kubernetes-version v1.18.1 \\ --apiserver-advertise-address 10.7.79.148 \\ --service-cidr 192.168.0.0/16 \\ --pod-network-cidr 172.16.0.0/16 \\ --token-ttl 0 \\ --upload-certs 命令中的各选项简单说明如下： --image-repository： 指定要使用的镜像仓库，默认为 gcr.io； --kubernetes-version：kubernetes 程序组件的版本号，它必须要与安装的 kubelet 程序包的版本号相同； --control-plane-endpoint：控制平面的固定访问端点，可以是 IP 地址或 DNS 名称，会被用于集群管理员及集群组件的 kubeconfig 配置文件的 API Server 的访问地址；单控制平面部署时可以不使用该选项； --pod-network-cidr：Pod 网络的地址范围，其值为 CIDR 格式的网络地址，通常，Flannel 网络插件的默认为 10.244.0.0/16, Calico 插件的默认值为 192.168.0.0/16； --service-cidr：Service 的网络地址范围，其值为 CIDR 格式的网络地址，默认为 10.96.0.0/12；通常，仅 Flannel一类的网络插件需要手动指定该地址； --apiserver-advertise-address：apiserver 通告给其他组件的IP地址，一般应该为 Master 节点的用于集群内部通信的IP地址，0.0.0.0 表示节点上所有可用地址； --upload-certs: 将控制平面证书上传到 kubeadm-certs secret。 --token-ttl：共享令牌（token）的过期时长，默认为 24小时，0 表示永不过期；为防止不安全存储等原因导致的令牌泄露危及集群安全，建议为其设定过期时长。未设定该选项时，在 token 过期后，若期望再向集群中加入其它节点，可以使用如下命令重新创建 token，并生成节点加入命令。 bash kubeadm token create --print-join-command 需要注意的是，若各节点未禁用Swap设备，还需要附加选项 “–ignore-preflight-errors=Swap”，从而让 kubeadm 忽略该错误设定。 初始化方式二 kubeadm 也可通过配置文件加载配置，以定制更丰富的部署选项。以下是个符合前述命令设定方式的使用示例，不过，它明确定义了 kubeProxy 的模式为 ipvs，并支持通过修改 imageRepository 的值修改获取系统镜像时使用的镜像仓库。 默认配置可以通过 kubeadm config print init-defaults 获取 yaml --- apiVersion: kubeadm.k8s.io/v1beta2 bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token ttl: 24h0m0s usages: - signing - authentication kind: InitConfiguration localAPIEndpoint: # 这里的地址即为初始化的控制平面第一个节点的IP地址； advertiseAddress: 192.168.31.11 bindPort: 6443 nodeRegistration: criSocket: /var/run/dockershim.sock # 第一个控制平面节点的主机名称； name: master1.host.com taints: - effect: NoSchedule key: node-role.kubernetes.io/master --- apiServer: timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta2 # 控制平面的接入端点，我们这里选择适配到 apiserver.host.com 这一域名上 controlPlaneEndpoint: \"apiserver.host.com:6443\" certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controllerManager: {} dns: type: CoreDNS etcd: local: # 配置 etcd 数据存储路径 dataDir: /data/etcd # 配置镜像拉取站点 imageRepository: registry.aliyuncs.com/google_containers kind: ClusterConfiguration # 版本号要与部署的目标版本保持一致 kubernetesVersion: v1.18.1 networking: # 要使用的集群域名，默认为 cluster.local dnsDomain: cluster.local # Pod 的网络地址段 podSubnet: 172.16.0.0/16 # Service 的网络地址段 serviceSubnet: 192.168.0.0/16 scheduler: {} --- apiVersion: kubeproxy.config.k8s.io/v1alpha1 kind: KubeProxyConfiguration # 用于配置 kube-proxy 上为 Service 指定的代理模式，默认为 iptables mode: \"ipvs\" ipvs: scheduler: \"nq\" 将上面的内容保存于配置文件中，例如 kubeadm-config.yaml，而后执行如下命令即能实现类似前一种初始化方式中的集群初始配置，但这里将 Service 的代理模式设定为了 ipvs。 初始化命令 bash kubeadm init --config kubeadm-config.yaml kubeadm init 命令完整参考指南请移步官方文档，地址为 https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-init/ ","date":"2021-03-09","objectID":"/posts/kubernetes-install/:9:1","series":null,"tags":["kubeadm"],"title":"使用 Kubeadm 快速部署 Kubernetes 集群","uri":"/posts/kubernetes-install/#初始化-master-节点"},{"categories":["kubernetes"],"content":" 初始化完成后的操作步骤 注意：对于 Kubernetes 系统的新用户来说，无论使用上述哪种方法，命令运行结束后，请记录最后的 kubeadm join 命令输出的最后提示的操作步骤。下面的内容是需要用户记录的一个命令输出示例，它提示了后续需要的操作步骤： W0309 [init] Using Kubernetes version: v1.18.1 [preflight] Running pre-flight checks [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using 'kubeadm config images pull' [kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\" [kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\" [kubelet-start] Starting the kubelet [certs] Using certificateDir folder \"/etc/kubernetes/pki\" [certs] Generating \"ca\" certificate and key [certs] Generating \"apiserver\" certificate and key [certs] apiserver serving cert is signed for DNS names [master1.host.com kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local apiserver.host.com] and IPs [10.10.0.1 192.168.31.11] [certs] Generating \"apiserver-kubelet-client\" certificate and key [certs] Generating \"front-proxy-ca\" certificate and key [certs] Generating \"front-proxy-client\" certificate and key [certs] Generating \"etcd/ca\" certificate and key [certs] Generating \"etcd/server\" certificate and key [certs] etcd/server serving cert is signed for DNS names [master1.host.com localhost] and IPs [192.168.31.11 127.0.0.1 ::1] [certs] Generating \"etcd/peer\" certificate and key [certs] etcd/peer serving cert is signed for DNS names [master1.host.com localhost] and IPs [192.168.31.11 127.0.0.1 ::1] [certs] Generating \"etcd/healthcheck-client\" certificate and key [certs] Generating \"apiserver-etcd-client\" certificate and key [certs] Generating \"sa\" key and public key [kubeconfig] Using kubeconfig folder \"/etc/kubernetes\" [kubeconfig] Writing \"admin.conf\" kubeconfig file [kubeconfig] Writing \"kubelet.conf\" kubeconfig file [kubeconfig] Writing \"controller-manager.conf\" kubeconfig file [kubeconfig] Writing \"scheduler.conf\" kubeconfig file [control-plane] Using manifest folder \"/etc/kubernetes/manifests\" [control-plane] Creating static Pod manifest for \"kube-apiserver\" [control-plane] Creating static Pod manifest for \"kube-controller-manager\" W0309 06:48:52.172442 48909 manifests.go:225] the default kube-apiserver authorization-mode is \"Node,RBAC\"; using \"Node,RBAC\" [control-plane] Creating static Pod manifest for \"kube-scheduler\" W0309 06:48:52.173496 48909 manifests.go:225] the default kube-apiserver authorization-mode is \"Node,RBAC\"; using \"Node,RBAC\" [etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\" [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s [apiclient] All control plane components are healthy after 26.002622 seconds [upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace [kubelet] Creating a ConfigMap \"kubelet-config-1.18\" in namespace kube-system with the configuration for the kubelets in the cluster [upload-certs] Skipping phase. Please see --upload-certs [mark-control-plane] Marking the node master1.host.com as control-plane by adding the label \"node-role.kubernetes.io/master=''\" [mark-control-plane] Marking the node master1.host.com as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule] [bootstrap-token] Using token: x3oo6y.ytmywnftdx6khuh5 [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Toke","date":"2021-03-09","objectID":"/posts/kubernetes-install/:9:2","series":null,"tags":["kubeadm"],"title":"使用 Kubeadm 快速部署 Kubernetes 集群","uri":"/posts/kubernetes-install/#初始化完成后的操作步骤"},{"categories":["kubernetes"],"content":" 初始化完成后的操作步骤 注意：对于 Kubernetes 系统的新用户来说，无论使用上述哪种方法，命令运行结束后，请记录最后的 kubeadm join 命令输出的最后提示的操作步骤。下面的内容是需要用户记录的一个命令输出示例，它提示了后续需要的操作步骤： W0309 [init] Using Kubernetes version: v1.18.1 [preflight] Running pre-flight checks [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using 'kubeadm config images pull' [kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\" [kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\" [kubelet-start] Starting the kubelet [certs] Using certificateDir folder \"/etc/kubernetes/pki\" [certs] Generating \"ca\" certificate and key [certs] Generating \"apiserver\" certificate and key [certs] apiserver serving cert is signed for DNS names [master1.host.com kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local apiserver.host.com] and IPs [10.10.0.1 192.168.31.11] [certs] Generating \"apiserver-kubelet-client\" certificate and key [certs] Generating \"front-proxy-ca\" certificate and key [certs] Generating \"front-proxy-client\" certificate and key [certs] Generating \"etcd/ca\" certificate and key [certs] Generating \"etcd/server\" certificate and key [certs] etcd/server serving cert is signed for DNS names [master1.host.com localhost] and IPs [192.168.31.11 127.0.0.1 ::1] [certs] Generating \"etcd/peer\" certificate and key [certs] etcd/peer serving cert is signed for DNS names [master1.host.com localhost] and IPs [192.168.31.11 127.0.0.1 ::1] [certs] Generating \"etcd/healthcheck-client\" certificate and key [certs] Generating \"apiserver-etcd-client\" certificate and key [certs] Generating \"sa\" key and public key [kubeconfig] Using kubeconfig folder \"/etc/kubernetes\" [kubeconfig] Writing \"admin.conf\" kubeconfig file [kubeconfig] Writing \"kubelet.conf\" kubeconfig file [kubeconfig] Writing \"controller-manager.conf\" kubeconfig file [kubeconfig] Writing \"scheduler.conf\" kubeconfig file [control-plane] Using manifest folder \"/etc/kubernetes/manifests\" [control-plane] Creating static Pod manifest for \"kube-apiserver\" [control-plane] Creating static Pod manifest for \"kube-controller-manager\" W0309 06:48:52.172442 48909 manifests.go:225] the default kube-apiserver authorization-mode is \"Node,RBAC\"; using \"Node,RBAC\" [control-plane] Creating static Pod manifest for \"kube-scheduler\" W0309 06:48:52.173496 48909 manifests.go:225] the default kube-apiserver authorization-mode is \"Node,RBAC\"; using \"Node,RBAC\" [etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\" [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s [apiclient] All control plane components are healthy after 26.002622 seconds [upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace [kubelet] Creating a ConfigMap \"kubelet-config-1.18\" in namespace kube-system with the configuration for the kubelets in the cluster [upload-certs] Skipping phase. Please see --upload-certs [mark-control-plane] Marking the node master1.host.com as control-plane by adding the label \"node-role.kubernetes.io/master=''\" [mark-control-plane] Marking the node master1.host.com as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule] [bootstrap-token] Using token: x3oo6y.ytmywnftdx6khuh5 [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Toke","date":"2021-03-09","objectID":"/posts/kubernetes-install/:9:2","series":null,"tags":["kubeadm"],"title":"使用 Kubeadm 快速部署 Kubernetes 集群","uri":"/posts/kubernetes-install/#配置-kubectl"},{"categories":["kubernetes"],"content":" 初始化完成后的操作步骤 注意：对于 Kubernetes 系统的新用户来说，无论使用上述哪种方法，命令运行结束后，请记录最后的 kubeadm join 命令输出的最后提示的操作步骤。下面的内容是需要用户记录的一个命令输出示例，它提示了后续需要的操作步骤： W0309 [init] Using Kubernetes version: v1.18.1 [preflight] Running pre-flight checks [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using 'kubeadm config images pull' [kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\" [kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\" [kubelet-start] Starting the kubelet [certs] Using certificateDir folder \"/etc/kubernetes/pki\" [certs] Generating \"ca\" certificate and key [certs] Generating \"apiserver\" certificate and key [certs] apiserver serving cert is signed for DNS names [master1.host.com kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local apiserver.host.com] and IPs [10.10.0.1 192.168.31.11] [certs] Generating \"apiserver-kubelet-client\" certificate and key [certs] Generating \"front-proxy-ca\" certificate and key [certs] Generating \"front-proxy-client\" certificate and key [certs] Generating \"etcd/ca\" certificate and key [certs] Generating \"etcd/server\" certificate and key [certs] etcd/server serving cert is signed for DNS names [master1.host.com localhost] and IPs [192.168.31.11 127.0.0.1 ::1] [certs] Generating \"etcd/peer\" certificate and key [certs] etcd/peer serving cert is signed for DNS names [master1.host.com localhost] and IPs [192.168.31.11 127.0.0.1 ::1] [certs] Generating \"etcd/healthcheck-client\" certificate and key [certs] Generating \"apiserver-etcd-client\" certificate and key [certs] Generating \"sa\" key and public key [kubeconfig] Using kubeconfig folder \"/etc/kubernetes\" [kubeconfig] Writing \"admin.conf\" kubeconfig file [kubeconfig] Writing \"kubelet.conf\" kubeconfig file [kubeconfig] Writing \"controller-manager.conf\" kubeconfig file [kubeconfig] Writing \"scheduler.conf\" kubeconfig file [control-plane] Using manifest folder \"/etc/kubernetes/manifests\" [control-plane] Creating static Pod manifest for \"kube-apiserver\" [control-plane] Creating static Pod manifest for \"kube-controller-manager\" W0309 06:48:52.172442 48909 manifests.go:225] the default kube-apiserver authorization-mode is \"Node,RBAC\"; using \"Node,RBAC\" [control-plane] Creating static Pod manifest for \"kube-scheduler\" W0309 06:48:52.173496 48909 manifests.go:225] the default kube-apiserver authorization-mode is \"Node,RBAC\"; using \"Node,RBAC\" [etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\" [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s [apiclient] All control plane components are healthy after 26.002622 seconds [upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace [kubelet] Creating a ConfigMap \"kubelet-config-1.18\" in namespace kube-system with the configuration for the kubelets in the cluster [upload-certs] Skipping phase. Please see --upload-certs [mark-control-plane] Marking the node master1.host.com as control-plane by adding the label \"node-role.kubernetes.io/master=''\" [mark-control-plane] Marking the node master1.host.com as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule] [bootstrap-token] Using token: x3oo6y.ytmywnftdx6khuh5 [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Toke","date":"2021-03-09","objectID":"/posts/kubernetes-install/:9:2","series":null,"tags":["kubeadm"],"title":"使用 Kubeadm 快速部署 Kubernetes 集群","uri":"/posts/kubernetes-install/#部署网络插件"},{"categories":["kubernetes"],"content":" 初始化完成后的操作步骤 注意：对于 Kubernetes 系统的新用户来说，无论使用上述哪种方法，命令运行结束后，请记录最后的 kubeadm join 命令输出的最后提示的操作步骤。下面的内容是需要用户记录的一个命令输出示例，它提示了后续需要的操作步骤： W0309 [init] Using Kubernetes version: v1.18.1 [preflight] Running pre-flight checks [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using 'kubeadm config images pull' [kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\" [kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\" [kubelet-start] Starting the kubelet [certs] Using certificateDir folder \"/etc/kubernetes/pki\" [certs] Generating \"ca\" certificate and key [certs] Generating \"apiserver\" certificate and key [certs] apiserver serving cert is signed for DNS names [master1.host.com kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local apiserver.host.com] and IPs [10.10.0.1 192.168.31.11] [certs] Generating \"apiserver-kubelet-client\" certificate and key [certs] Generating \"front-proxy-ca\" certificate and key [certs] Generating \"front-proxy-client\" certificate and key [certs] Generating \"etcd/ca\" certificate and key [certs] Generating \"etcd/server\" certificate and key [certs] etcd/server serving cert is signed for DNS names [master1.host.com localhost] and IPs [192.168.31.11 127.0.0.1 ::1] [certs] Generating \"etcd/peer\" certificate and key [certs] etcd/peer serving cert is signed for DNS names [master1.host.com localhost] and IPs [192.168.31.11 127.0.0.1 ::1] [certs] Generating \"etcd/healthcheck-client\" certificate and key [certs] Generating \"apiserver-etcd-client\" certificate and key [certs] Generating \"sa\" key and public key [kubeconfig] Using kubeconfig folder \"/etc/kubernetes\" [kubeconfig] Writing \"admin.conf\" kubeconfig file [kubeconfig] Writing \"kubelet.conf\" kubeconfig file [kubeconfig] Writing \"controller-manager.conf\" kubeconfig file [kubeconfig] Writing \"scheduler.conf\" kubeconfig file [control-plane] Using manifest folder \"/etc/kubernetes/manifests\" [control-plane] Creating static Pod manifest for \"kube-apiserver\" [control-plane] Creating static Pod manifest for \"kube-controller-manager\" W0309 06:48:52.172442 48909 manifests.go:225] the default kube-apiserver authorization-mode is \"Node,RBAC\"; using \"Node,RBAC\" [control-plane] Creating static Pod manifest for \"kube-scheduler\" W0309 06:48:52.173496 48909 manifests.go:225] the default kube-apiserver authorization-mode is \"Node,RBAC\"; using \"Node,RBAC\" [etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\" [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s [apiclient] All control plane components are healthy after 26.002622 seconds [upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace [kubelet] Creating a ConfigMap \"kubelet-config-1.18\" in namespace kube-system with the configuration for the kubelets in the cluster [upload-certs] Skipping phase. Please see --upload-certs [mark-control-plane] Marking the node master1.host.com as control-plane by adding the label \"node-role.kubernetes.io/master=''\" [mark-control-plane] Marking the node master1.host.com as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule] [bootstrap-token] Using token: x3oo6y.ytmywnftdx6khuh5 [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Toke","date":"2021-03-09","objectID":"/posts/kubernetes-install/:9:2","series":null,"tags":["kubeadm"],"title":"使用 Kubeadm 快速部署 Kubernetes 集群","uri":"/posts/kubernetes-install/#验证-master-节点已经就绪"},{"categories":["kubernetes"],"content":" 向集群添加额外的控制平面节点在添加额外主节点之前我们需要将集群证书上传到集群中以便向其它主节点共享证书并生成证书密钥，使用此密钥可以解密由 init 上载的证书。 使用如下命令命令完成。 bash kubeadm init phase upload-certs --upload-certs I0309 07:16:31.594295 62834 version.go:252] remote version is much newer: v1.20.4; falling back to: stable-1.18 W0309 07:16:35.449971 62834 configset.go:202] WARNING: kubeadm cannot validate component configs for API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io] [upload-certs] Storing the certificates in Secret \"kubeadm-certs\" in the \"kube-system\" Namespace [upload-certs] Using certificate key: 7c3c34ac69d980bdaf28eb42e38186c71245cef7c5926d0fb252b7200aad05bf 也可以直接拷贝 /etc/kubernetes/pki 至另一台主节点上的 /etc/kubernetes 目录下 集群添加额外的主节点，使用如下命令完成。 bash kubeadm join apiserver.host.com:6443 --token x3oo6y.ytmywnftdx6khuh5 \\ --discovery-token-ca-cert-hash sha256:7708b5166572b6f33094b27d3c457d080213ec3bd701161d4d648367c53f1013 \\ --control-plane --certificate-key 7c3c34ac69d980bdaf28eb42e38186c71245cef7c5926d0fb252b7200aad05bf 本次实验由于资源有限只部署一台主节点，实际生产环境中建议部署多台，避免单点故障。 ","date":"2021-03-09","objectID":"/posts/kubernetes-install/:10:0","series":null,"tags":["kubeadm"],"title":"使用 Kubeadm 快速部署 Kubernetes 集群","uri":"/posts/kubernetes-install/#向集群添加额外的控制平面节点"},{"categories":["kubernetes"],"content":" 添加节点到集群中下面的两个步骤，需要分别在 node1.host.com 和 node2.host.com 上完成。 1、若未禁用 Swap 设备，编辑 kubelet 的配置文件 /etc/default/kubelet，设置其忽略 Swap 启用的状态错误，内容如下： text KUBELET_EXTRA_ARGS=\"--fail-swap-on=false\" 2、将节点加入 master 的集群中，要使用主节点初始化过程中记录的 kubeadm join 命令，并且在未禁用 Swap 设备的情况下，额外附加 “--ignore-preflight-errors=Swap” 选项； bash kubeadm join apiserver.host.com:6443 --token x3oo6y.ytmywnftdx6khuh5 \\ --discovery-token-ca-cert-hash sha256:7708b5166572b6f33094b27d3c457d080213ec3bd701161d4d648367c53f1013 ","date":"2021-03-09","objectID":"/posts/kubernetes-install/:11:0","series":null,"tags":["kubeadm"],"title":"使用 Kubeadm 快速部署 Kubernetes 集群","uri":"/posts/kubernetes-install/#添加节点到集群中"},{"categories":["kubernetes"],"content":" 验证节点添加结果在每个节点添加完成后，即可通过 kubectl 验正添加结果。下面的命令及其输出是在 node1 和 node2 均添加完成后运行的，其输出结果表明两个 Node 已经准备就绪。 bash kubectl get nodes NAME STATUS ROLES AGE VERSION master1.host.com Ready master 41m v1.18.1 node1.host.com Ready \u003cnone\u003e 51s v1.18.1 node2.host.com Ready \u003cnone\u003e 43s v1.18.1 ","date":"2021-03-09","objectID":"/posts/kubernetes-install/:11:1","series":null,"tags":["kubeadm"],"title":"使用 Kubeadm 快速部署 Kubernetes 集群","uri":"/posts/kubernetes-install/#验证节点添加结果"},{"categories":["kubernetes"],"content":" 测试应用编排及服务访问到此为止，一个 master，并附带有二个 node 的 kubernetes 集群基础设施已经部署完成，用户随后即可测试其核心功能。例如，下面的命令可将 demoapp 以 Pod 的形式编排运行于集群之上，并通过在集群外部进行访问： bash kubectl create deployment demoapp --image=ikubernetes/demoapp:v1.0 kubectl scale deployment/demoapp --replicas=2 kubectl create service nodeport demoapp --tcp=80:80 而后，使用如下命令了解 Service 对象 demoapp 使用的 NodePort，以便于在集群外部进行访问 text kubectl get svc -l app=demoapp NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE demoapp NodePort 10.10.149.76 \u003cnone\u003e 80:32002/TCP 10s demoapp 是一个 web 应用，因此，用户可以于集群外部通过 http://NodeIP:32002 这个 URL 访问 demoapp 上的应用，例如于集群外通过浏览器访问 http://10.7.50.17:32002。 ","date":"2021-03-09","objectID":"/posts/kubernetes-install/:12:0","series":null,"tags":["kubeadm"],"title":"使用 Kubeadm 快速部署 Kubernetes 集群","uri":"/posts/kubernetes-install/#测试应用编排及服务访问"},{"categories":["container"],"content":" docker 安装请参考: – Docker 快速安装 ","date":"2021-03-06","objectID":"/posts/docker-cli/:0:0","series":null,"tags":["docker"],"title":"docker - 基本操作","uri":"/posts/docker-cli/#"},{"categories":["container"],"content":" 镜像管理","date":"2021-03-06","objectID":"/posts/docker-cli/:1:0","series":null,"tags":["docker"],"title":"docker - 基本操作","uri":"/posts/docker-cli/#镜像管理"},{"categories":["container"],"content":" 1. 获取镜像 bash # 默认从 dockerhub 拉取最新版本镜像 [root@localhost ~]# docker pull busybox Using default tag: latest latest: Pulling from library/busybox add3ddb21ede: Pull complete Digest: sha256:b82b5740006c1ab823596d2c07f081084ecdb32fd258072707b99f52a3cb8692 Status: Downloaded newer image for busybox:latest # 拉取指定版本的镜像 [root@localhost ~]# docker pull ubuntu:14.04 14.04: Pulling from library/ubuntu 48f0413f904d: Downloading [======\u003e ] 8.925MB/67.12MB 2bd2b2e92c5f: Download complete 06ed1e3efabb: Download complete a220dbf88993: Waiting 57c164185602: Waiting ","date":"2021-03-06","objectID":"/posts/docker-cli/:1:1","series":null,"tags":["docker"],"title":"docker - 基本操作","uri":"/posts/docker-cli/#1-获取镜像"},{"categories":["container"],"content":" 2. 列出镜像 bash [root@localhost ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE busybox latest d20ae45477cb 2 weeks ago 1.13MB ubuntu latest ccc7a11d65b1 4 weeks ago 120MB ubuntu 14.04 c69811d4e993 4 weeks ago 188MB ","date":"2021-03-06","objectID":"/posts/docker-cli/:1:2","series":null,"tags":["docker"],"title":"docker - 基本操作","uri":"/posts/docker-cli/#2-列出镜像"},{"categories":["container"],"content":" 3. 删除镜像 bash [root@localhost ~]# docker rmi ubuntu:14.04 Untagged: ubuntu:14.04 Untagged: ubuntu@sha256:6a3e01207b899a347115f3859cf8a6031fdbebb6ffedea6c2097be40a298c85d Deleted: sha256:c69811d4e9931740c0a490f74fafb566bb520b945f6e62cab96f6faecd750b95 Deleted: sha256:5294610fabc319f443fc036f7bf5c02299f2614d4b0f79c87529bb9aef46ce4e Deleted: sha256:a783f54895fb2d76726d8b4fbbb263bcffc0cbb7fe858450a39d21b7f4de1df6 Deleted: sha256:e11129e7baf41455394f83970e3e232fa7c33a87948b76ca1c121942c4f0403f Deleted: sha256:38c3fb0ca70b3e0444085376821508b758e4f30b290a0016c4b044b9f46bddf8 Deleted: sha256:826fc2344fbbc40cf9f2714c831a0d3ff88596e471f71c33b1055f3913d829d4 ","date":"2021-03-06","objectID":"/posts/docker-cli/:1:3","series":null,"tags":["docker"],"title":"docker - 基本操作","uri":"/posts/docker-cli/#3-删除镜像"},{"categories":["container"],"content":" 4. 保存镜像 bash [root@localhost ~]# docker save ubuntu:latest -o ubuntu-latest.tar [root@localhost ~]# ls -lh total 44M -rw-r--r-- 1 root root 72.9M Sep 9 19:20 ubuntu-latest.tar 保存并压缩 bash [root@localhost ~]# docker save ubuntu:latest | gzip \u003e ubuntu-latest.tar.gz [root@localhost ~]# ls -lh total 44M -rw-r--r-- 1 root root 44M Sep 9 19:20 ubuntu-latest.tar.gz ","date":"2021-03-06","objectID":"/posts/docker-cli/:1:4","series":null,"tags":["docker"],"title":"docker - 基本操作","uri":"/posts/docker-cli/#4-保存镜像"},{"categories":["container"],"content":" 5. 载入镜像 bash [root@localhost ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE busybox latest d20ae45477cb 2 weeks ago 1.13MB [root@localhost ~]# docker load -i ubuntu-latest.tar.gz 8aa4fcad5eeb: Loading layer [==================================================\u003e] 124.1MB/124.1MB 25e0901a71b8: Loading layer [==================================================\u003e] 15.87kB/15.87kB 625c7a2a783b: Loading layer [==================================================\u003e] 11.78kB/11.78kB 9c42c2077cde: Loading layer [==================================================\u003e] 5.632kB/5.632kB a09947e71dc0: Loading layer [==================================================\u003e] 3.072kB/3.072kB Loaded image: ubuntu:latest [root@localhost ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE busybox latest d20ae45477cb 2 weeks ago 1.13MB ubuntu latest ccc7a11d65b1 4 weeks ago 120MB PS: 结合以上命令可以使用 shell 命令完成镜像迁移工作 docker save \u003c镜像名\u003e | bzip2 | pv | ssh \u003c用户名\u003e@\u003c主机名\u003e 'cat | docker load' ","date":"2021-03-06","objectID":"/posts/docker-cli/:1:5","series":null,"tags":["docker"],"title":"docker - 基本操作","uri":"/posts/docker-cli/#5-载入镜像"},{"categories":["container"],"content":" 使用容器","date":"2021-03-06","objectID":"/posts/docker-cli/:2:0","series":null,"tags":["docker"],"title":"docker - 基本操作","uri":"/posts/docker-cli/#使用容器"},{"categories":["container"],"content":" 1. 启动/停止/重启容器 bash # -d 参数表示守护进程方式运行 [root@localhost ~]# docker container ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 727dbeacc1f5 ubuntu:latest \"/bin/bash\" 3 seconds ago Up 2 seconds inspiring_goldberg # 停止容器，重启，启动指令为 restart, start [root@localhost ~]# docker container stop inspiring_goldberg inspiring_goldberg [root@localhost ~]# docker container ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 727dbeacc1f5 ubuntu:latest \"/bin/bash\" About a minute ago Exited (0) 1 second ago inspiring_goldberg ","date":"2021-03-06","objectID":"/posts/docker-cli/:2:1","series":null,"tags":["docker"],"title":"docker - 基本操作","uri":"/posts/docker-cli/#1-启动停止重启容器"},{"categories":["container"],"content":" 2. 删除容器 bash [root@localhost ~]# docker container rm 727dbeacc1f5 727dbeacc1f5 [root@localhost ~]# docker container ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 容器删除前需要先停止 ","date":"2021-03-06","objectID":"/posts/docker-cli/:2:2","series":null,"tags":["docker"],"title":"docker - 基本操作","uri":"/posts/docker-cli/#2-删除容器"},{"categories":["container"],"content":" 3. 导出容器 bash [root@localhost ~]# docker container export 84bc66973544 \u003e ubuntu-latest.tar ","date":"2021-03-06","objectID":"/posts/docker-cli/:2:3","series":null,"tags":["docker"],"title":"docker - 基本操作","uri":"/posts/docker-cli/#3-导出容器"},{"categories":["container"],"content":" 4. 导入容器为镜像 bash [root@localhost ~]# cat ubuntu-latest.tar | docker import - test/ubuntu:latest sha256:389b10ce91abd80cc9b306cbc02cfc74b5089ba60766d8fd66af48691ab9d6fc [root@localhost ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE test/ubuntu latest 389b10ce91ab 5 seconds ago 97.9MB busybox latest d20ae45477cb 2 weeks ago 1.13MB ubuntu latest ccc7a11d65b1 4 weeks ago 120MB 注：用户既可以使用 docker load 来导入镜像存储文件到本地镜像库，也可以 使用 docker import 来导入一个容器快照到本地镜像库。这两者的区别在于容 器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状 态），而镜像存储文件将保存完整记录，体积也要大。此外，从容器快照文件导入 时可以重新指定标签等元数据信息。 ","date":"2021-03-06","objectID":"/posts/docker-cli/:2:4","series":null,"tags":["docker"],"title":"docker - 基本操作","uri":"/posts/docker-cli/#4-导入容器为镜像"},{"categories":["container"],"content":" 5. 进入容器 bash [root@localhost ~]# docker container ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 84bc66973544 ubuntu:latest \"/bin/bash\" 12 minutes ago Up 12 minutes hungry_bartik [root@localhost ~]# docker exec -ti 84bc66973544 bash root@84bc66973544:/# cat /etc/os-release NAME=\"Ubuntu\" VERSION=\"16.04.3 LTS (Xenial Xerus)\" ID=ubuntu ID_LIKE=debian PRETTY_NAME=\"Ubuntu 16.04.3 LTS\" VERSION_ID=\"16.04\" HOME_URL=\"http://www.ubuntu.com/\" SUPPORT_URL=\"http://help.ubuntu.com/\" BUG_REPORT_URL=\"http://bugs.launchpad.net/ubuntu/\" VERSION_CODENAME=xenial UBUNTU_CODENAME=xenial ","date":"2021-03-06","objectID":"/posts/docker-cli/:2:5","series":null,"tags":["docker"],"title":"docker - 基本操作","uri":"/posts/docker-cli/#5-进入容器"},{"categories":["container"],"content":"harbor 使用 docker 容器的方式部署，所以在部署 harbor 前需要安装好 docker 及单机编排工具 docker-compose ","date":"2021-03-06","objectID":"/posts/docker-harbor/:0:0","series":null,"tags":["docker","harbor"],"title":"docker - 私有仓库部署 (harbor)","uri":"/posts/docker-harbor/#"},{"categories":["container"],"content":" 下载 harbor 离线安装包harbor 托管于 Github，在 Github 上有提供完整的离线安装直接下载即可。 Github 地址 bash root@ops:/opt# wget https://github.com/goharbor/harbor/releases/download/v2.1.0/harbor-offline-installer-v2.1.0.tgz ","date":"2021-03-06","objectID":"/posts/docker-harbor/:1:0","series":null,"tags":["docker","harbor"],"title":"docker - 私有仓库部署 (harbor)","uri":"/posts/docker-harbor/#下载-harbor-离线安装包"},{"categories":["container"],"content":" 安装 docker-compose由于 harbor 依赖于 docker-compose 完成单机编排工作，需要先安装好 bash root@ops:/opt# curl -L \"https://github.com/docker/compose/releases/download/1.27.4/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose root@ops:/opt# chmod +x /usr/local/bin/docker-compose ","date":"2021-03-06","objectID":"/posts/docker-harbor/:2:0","series":null,"tags":["docker","harbor"],"title":"docker - 私有仓库部署 (harbor)","uri":"/posts/docker-harbor/#安装-docker-compose"},{"categories":["container"],"content":" 部署 harbor bash root@ops:/opt# tar xzf harbor-offline-installer-v2.1.0.tgz root@ops:/opt# cd harbor # 复制一份harbor配置文件 root@ops:/opt/harbor# cp harbor.yml.tmpl harbor.yml root@ops:/opt/harbor# egrep -v '^$|#' harbor.yml hostname: harbor.host.com # harbor 站点域名 http: port: 801 # 修改端口 harbor_admin_password: Harbor12345 # harbor 管理员默认密码 database: password: root123 max_idle_conns: 50 max_open_conns: 100 data_volume: /data/harbor # harbor 数据存储路径 clair: updaters_interval: 12 trivy: ignore_unfixed: false skip_update: false insecure: false jobservice: max_job_workers: 10 notification: webhook_job_max_retry: 10 chart: absolute_url: disabled log: level: info local: rotate_count: 50 rotate_size: 200M location: /data/harbor/logs # harbor 日志文件路径 _version: 2.0.0 proxy: http_proxy: https_proxy: no_proxy: components: - core - jobservice - clair - trivy root@ops:/opt/harbor# ./install # 开始部署 harbor ","date":"2021-03-06","objectID":"/posts/docker-harbor/:3:0","series":null,"tags":["docker","harbor"],"title":"docker - 私有仓库部署 (harbor)","uri":"/posts/docker-harbor/#部署-harbor"},{"categories":["container"],"content":" 配置 nginx 反代 部署完成后可以配置 nginx 反代对外提供服务，nginx 配置注意加大 client_max_body_size 参数值. nginx server { listen 80; server_name harbor.wfugui.com; # 注意此项配置 client_max_body_size 2000m; location / { proxy_pass https://localhost:801; include proxy.conf; } } 注意: 最新版本的 harbor 如果不启用证书验证连接(https) 在 push 镜像时会不成功 ","date":"2021-03-06","objectID":"/posts/docker-harbor/:4:0","series":null,"tags":["docker","harbor"],"title":"docker - 私有仓库部署 (harbor)","uri":"/posts/docker-harbor/#配置-nginx-反代"},{"categories":["container"],"content":" Dockerfile 是一个文本格式的配置文件，用户可以使用 Dockerfile 快速创建自定义的镜像。 Dockerfile 由一行行命令语句组成，并且支持以 # 开头注释行。 Dockerfile 一般分为四部分： 基础镜像信息，维护者信息、镜像操作指令和容器启动时执行指令。 ","date":"2021-03-06","objectID":"/posts/docker-dockerfile/:0:0","series":null,"tags":["docker","dockerfile"],"title":"docker - Dockerfile 相关指令","uri":"/posts/docker-dockerfile/#"},{"categories":["container"],"content":" 指令","date":"2021-03-06","objectID":"/posts/docker-dockerfile/:1:0","series":null,"tags":["docker","dockerfile"],"title":"docker - Dockerfile 相关指令","uri":"/posts/docker-dockerfile/#指令"},{"categories":["container"],"content":" FROM格式: FROM \u003cimage\u003e 或者 FROM \u003cimage\u003e:\u003ctag\u003e Dockerfile 的第一条指令必须是 FROM ","date":"2021-03-06","objectID":"/posts/docker-dockerfile/:1:1","series":null,"tags":["docker","dockerfile"],"title":"docker - Dockerfile 相关指令","uri":"/posts/docker-dockerfile/#from"},{"categories":["container"],"content":" MAINTAINER - 弃用格式: MAINTAINER \u003cname\u003e，指定维护者信息 推荐使用 LABEL maintainer=\"SvenDowideit@home.org.au\" ","date":"2021-03-06","objectID":"/posts/docker-dockerfile/:1:2","series":null,"tags":["docker","dockerfile"],"title":"docker - Dockerfile 相关指令","uri":"/posts/docker-dockerfile/#maintainer---弃用"},{"categories":["container"],"content":" LABLE格式: LABEL \u003ckey\u003e=\u003cvalue\u003e \u003ckey\u003e=\u003cvalue\u003e \u003ckey\u003e=\u003cvalue\u003e ... 该指令将元数据添加到 docker 镜像中 text LABEL \"com.example.vendor\"=\"ACME Incorporated\" LABEL com.example.label-with-value=\"foo\" LABEL version=\"1.0\" LABEL description=\"This text illustrates \\ that label-values can span multiple lines.\" ","date":"2021-03-06","objectID":"/posts/docker-dockerfile/:1:3","series":null,"tags":["docker","dockerfile"],"title":"docker - Dockerfile 相关指令","uri":"/posts/docker-dockerfile/#lable"},{"categories":["container"],"content":" USER格式: USER \u003cusername\u003e 指定容器内进程使用的用户名或 UID, 当服务不需要管理员权限时，可以通过该命令指定运行用户。并且可以在之前创建所需要的用户。 ","date":"2021-03-06","objectID":"/posts/docker-dockerfile/:1:4","series":null,"tags":["docker","dockerfile"],"title":"docker - Dockerfile 相关指令","uri":"/posts/docker-dockerfile/#user"},{"categories":["container"],"content":" WORKDIR格式: WORKDIR /path/to/workdir 指定容器的当前工作路径，为后续的 RUN、CMD、ENTRYPINT 指令配置工作路径 ","date":"2021-03-06","objectID":"/posts/docker-dockerfile/:1:5","series":null,"tags":["docker","dockerfile"],"title":"docker - Dockerfile 相关指令","uri":"/posts/docker-dockerfile/#workdir"},{"categories":["container"],"content":" ENV格式: ENV \u003ckey\u003e \u003cvalue\u003e 指定一个环境变量，可以被 RUN 指令使用，并在容器运行时保持存在 ENV \u003ckey1\u003e=\u003cvalue1\u003e \u003ckey2\u003e=\u003cvalue2\u003e... 可以同时指定多个变量，推荐使用这种方式 text ENV PG_MAJOR=9.3 PG_VERSION=9.3.4 RUN curl -SL http://example.com/postgres-${PG_VERSION}.tar.gz | tar -xzC /usr/src \u0026\u0026 ... ENV PATH=/usr/local/postgres-$PG_MAJOR/bin:$PATH ","date":"2021-03-06","objectID":"/posts/docker-dockerfile/:1:6","series":null,"tags":["docker","dockerfile"],"title":"docker - Dockerfile 相关指令","uri":"/posts/docker-dockerfile/#env"},{"categories":["container"],"content":" ARG格式: ARG \u003ckey\u003e=\u003cvalue\u003e ... 该指令定义了一个变量，只在构建镜像时生效。可以只定义变量名(或者默认值)，然后使用命令 docker build --build-arg 参数, 传递变量值的给构建者。 如果用户指定了Dockerfile中未定义的构建参数，则该构建会输出警告。ARGdocker build--build-arg \u003cvarname\u003e=\u003cvalue\u003e ","date":"2021-03-06","objectID":"/posts/docker-dockerfile/:1:7","series":null,"tags":["docker","dockerfile"],"title":"docker - Dockerfile 相关指令","uri":"/posts/docker-dockerfile/#arg"},{"categories":["container"],"content":" ADD格式: ADD \u003csrc\u003e \u003cdest\u003e 该指令将复制指定的 \u003csrc\u003e 到容器中的 \u003cdest\u003e. 其中 \u003csrc\u003e 可以是 Dockerfile 所在目录的一个相对路径(文件和目录)； 也可以是一个 url；还可以是一个 tar 文件（自动解压为目录） text ADD hom* /mydir/ ADD hom?.txt /mydir/ ADD --chown=55:mygroup files* /somedir/ ADD --chown=bin files* /somedir/ ADD --chown=1 files* /somedir/ ADD --chown=10:11 files* /somedir/ ADD --chmod=755 entrypoint.sh /usr/bin ","date":"2021-03-06","objectID":"/posts/docker-dockerfile/:1:8","series":null,"tags":["docker","dockerfile"],"title":"docker - Dockerfile 相关指令","uri":"/posts/docker-dockerfile/#add"},{"categories":["container"],"content":" COPY格式: COPY [--chown=\u003cuser\u003e:\u003cgroup\u003e] \u003csrc\u003e... \u003cdest\u003e COPY [--chown=\u003cuser\u003e:\u003cgroup\u003e] [\"\u003csrc\u003e\",... \"\u003cdest\u003e\"] 该指令复制文件或目录，并将它们添加到容器的文件系统路径中; 可以指定多个资源，但文件和目录的路径将基于构建路径。 text COPY hom* /mydir/ COPY hom?.txt /mydir/ COPY --chown=55:mygroup files* /somedir/ COPY --chown=bin files* /somedir/ COPY --chown=1 files* /somedir/ COPY --chown=10:11 files* /somedir/ ","date":"2021-03-06","objectID":"/posts/docker-dockerfile/:1:9","series":null,"tags":["docker","dockerfile"],"title":"docker - Dockerfile 相关指令","uri":"/posts/docker-dockerfile/#copy"},{"categories":["container"],"content":" RUN格式: RUN \u003ccommand\u003e 或者 RUN [\"executable\", \"param1\", \"param2\"] 每条 RUN 指令将在当前镜像的基础上执行指定的命令，并提交为新镜像。当命令过长时可以使用 \\ 换行。 ","date":"2021-03-06","objectID":"/posts/docker-dockerfile/:1:10","series":null,"tags":["docker","dockerfile"],"title":"docker - Dockerfile 相关指令","uri":"/posts/docker-dockerfile/#run"},{"categories":["container"],"content":" EXPOSE格式: EXPOSE \u003cport\u003e [\u003cport\u003e ...] 示例: text EXPOSE 22 80 443 EXPOSE 指令用于暴露容器端口。在启动容器时需要通过 -P, Docker 服务会随机分配一个端口转发到指定的端口； 使用 -p, 可以手动指定具体本地的端口与容器端口映射。 ","date":"2021-03-06","objectID":"/posts/docker-dockerfile/:1:11","series":null,"tags":["docker","dockerfile"],"title":"docker - Dockerfile 相关指令","uri":"/posts/docker-dockerfile/#expose"},{"categories":["container"],"content":" VOLUME格式: VOLUME [\"/data\"] 创建一个可以从本地主机或其他容器挂载的挂载点，一般用来存放需要持久化的数据等。 ","date":"2021-03-06","objectID":"/posts/docker-dockerfile/:1:12","series":null,"tags":["docker","dockerfile"],"title":"docker - Dockerfile 相关指令","uri":"/posts/docker-dockerfile/#volume"},{"categories":["container"],"content":" CMD格式: CMD [\"executable\", \"param1\", \"param2\"] 使用 exec 执行，推荐方式 CMD command param1 param2 ,在 /bin/sh 中执行 CMD [\"param1\", \"param2\"] 提供给 ENTRYPOINT 的默认参数 指定启动容器时执行的命令，每个 Dockerfile 只能有一条 CMD 指令。如果指定多条，只有最后一条生效被执行。 如果在启动容器时指定了运行的命令，会覆盖掉 CMD 指定的命令。 ","date":"2021-03-06","objectID":"/posts/docker-dockerfile/:1:13","series":null,"tags":["docker","dockerfile"],"title":"docker - Dockerfile 相关指令","uri":"/posts/docker-dockerfile/#cmd"},{"categories":["container"],"content":" ENTRYPOINT格式: ENTRYPOINT [\"executable\", \"param1\", \"param2\"] ENTRYPOINT command param1 param2 配置容器启动后执行的命令，并且不可被 docker run 提供的参数覆盖. 每个 Dockerfile 中只能有一个 ENTRYPOINT，指定多个 ENTRYPOINT 时，只有最一个有效。 entrypoint 命令列表必须使用双引号，单引号会出错(实测) ","date":"2021-03-06","objectID":"/posts/docker-dockerfile/:1:14","series":null,"tags":["docker","dockerfile"],"title":"docker - Dockerfile 相关指令","uri":"/posts/docker-dockerfile/#entrypoint"},{"categories":["container"],"content":"完整的配置项参考: https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file ","date":"2021-03-06","objectID":"/posts/docker-config/:0:0","series":null,"tags":["docker"],"title":"docker - 基本配置项","uri":"/posts/docker-config/#"},{"categories":["container"],"content":" docker 常用的配置项 docker 默认配置文件路径为: /etc/docker/daemon.json bash { \"registry-mirrors\": [\"https://docker.mirrors.ustc.edu.cn\", \"http://hub-mirror.c.163.com\"], # 镜像加速器 \"insecure-registries\":[\"harbor.host.com\"], # 第三方仓库或自建仓库地址，可以配置为 http \"data-root\": \"/data/docker\", # docker 数据存储目录 \"exec-opts\": [\"native.cgroupdriver=systemd\"], # 额外参数,部署 k8s 时需要指定此选项 \"bip\": \"10.10.0.1/16\", # 配置 docker 网桥 ip \"log-driver\": \"json-file\", \"log-opts\": { \"max-size\": \"100m\"}, \"live-restore\": true } ","date":"2021-03-06","objectID":"/posts/docker-config/:1:0","series":null,"tags":["docker"],"title":"docker - 基本配置项","uri":"/posts/docker-config/#docker-常用的配置项"},{"categories":["container"],"content":" 一键安装 dockerDocker 官方提供了一键安装 docker 脚本工具: https://github.com/docker/docker-install ","date":"2021-03-06","objectID":"/posts/docker-install/:1:0","series":null,"tags":["docker"],"title":"docker - 快速安装","uri":"/posts/docker-install/#一键安装-docker"},{"categories":["container"],"content":" 安装 docker bash curl -fsSL https://get.docker.com | bash 默认下载源是 docker 官方境外的源，在国内下载很慢 ","date":"2021-03-06","objectID":"/posts/docker-install/:1:1","series":null,"tags":["docker"],"title":"docker - 快速安装","uri":"/posts/docker-install/#安装-docker"},{"categories":["container"],"content":" 指定阿里源安装 docker bash curl -fsSL https://get.docker.com | bash -s -- --mirror=Aliyun 通过传递 VERSION=20.10.5 变量，可以安装指定版本的 docker ","date":"2021-03-06","objectID":"/posts/docker-install/:1:2","series":null,"tags":["docker"],"title":"docker - 快速安装","uri":"/posts/docker-install/#指定阿里源安装-docker"},{"categories":["container"],"content":" 配置阿里源安装 docker bash # step 1: 安装必要的一些系统工具 sudo apt-get update sudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common # step 2: 安装GPG证书 curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - # Step 3: 写入软件源信息 sudo add-apt-repository \"deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\" # Step 4: 更新并安装Docker-CE sudo apt-get -y update sudo apt-get -y install docker-ce ","date":"2021-03-06","objectID":"/posts/docker-install/:2:0","series":null,"tags":["docker"],"title":"docker - 快速安装","uri":"/posts/docker-install/#配置阿里源安装-docker"},{"categories":["container"],"content":" 安装指定版本的Docker-CE1: 查找 Docker-CE的版本: bash root@ops:~# apt-cache madison docker-ce docker-ce | 5:20.10.5~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages docker-ce | 5:20.10.4~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages docker-ce | 5:20.10.3~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages docker-ce | 5:20.10.2~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages docker-ce | 5:20.10.1~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages docker-ce | 5:20.10.0~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages docker-ce | 5:19.03.15~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages docker-ce | 5:19.03.14~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages docker-ce | 5:19.03.13~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages docker-ce | 5:19.03.12~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages docker-ce | 5:19.03.11~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages docker-ce | 5:19.03.10~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages docker-ce | 5:19.03.9~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages docker-ce | 5:19.03.8~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages docker-ce | 5:19.03.7~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages ... 2: 安装指定版本的 Docker-CE: (VERSION 例如上面的 5:19.03.15~3-0~ubuntu-bionic) bash root@ops:~# apt-get -y install docker-ce=5:19.03.15~3-0~ubuntu-bionic 注意: 如果部署 kubernetes 集群，就是需要安装经过 kubernetes 验证过的 docker 版本 ","date":"2021-03-06","objectID":"/posts/docker-install/:2:1","series":null,"tags":["docker"],"title":"docker - 快速安装","uri":"/posts/docker-install/#安装指定版本的docker-ce"},{"categories":["container"],"content":" 配置 docker 命令自动补全配置前需要先安装 bash-completion 工具包 bash curl -o /etc/bash_completion.d/docker -fsSL https://raw.githubusercontent.com/docker/cli/master/contrib/completion/bash/docker source /etc/profile ","date":"2021-03-06","objectID":"/posts/docker-install/:2:2","series":null,"tags":["docker"],"title":"docker - 快速安装","uri":"/posts/docker-install/#配置-docker-命令自动补全"},{"categories":["devops","ubuntu"],"content":"如果你没有在 Linux 下安装和运行 Systemd-Resolved、DNSMasq、Nscd 缓存服务，那就没有操作系统级的 DNS 缓存，不同的 Linux 发行版在刷新 DNS 缓存上方法是不同的。 以下操作在 Ubuntu 18.04 操作系统下进行 ","date":"2021-03-04","objectID":"/posts/ubuntu-flushdns/:0:0","series":null,"tags":["ubuntu","dns"],"title":"Ubuntu 刷新/删除 DNS 缓存","uri":"/posts/ubuntu-flushdns/#"},{"categories":["devops","ubuntu"],"content":" 刷新 Systemd Resolved 缓存Ubuntu 18.04 系统是使用 Systemd Resolved 服务来缓存 DNS 的，所以可以运行以下命令确定该服务是否运行： bash sudo systemctl is-active systemd-resolved.service 如果服务运行，则会看到返回的活动状态信息，否则只会看到非活动状态。 删除 Systemd Resolved DNS 缓存的方法，运行以下命令： bash sudo systemd-resolve --flush-caches ","date":"2021-03-04","objectID":"/posts/ubuntu-flushdns/:1:0","series":null,"tags":["ubuntu","dns"],"title":"Ubuntu 刷新/删除 DNS 缓存","uri":"/posts/ubuntu-flushdns/#刷新-systemd-resolved-缓存"},{"categories":["devops","ubuntu"],"content":" 刷新 DNSMasq 缓存如果你在 Ubuntu 18.04 下使用 DNSMasq 作为缓存服务器，要删除 DNS 缓存，请运行以下命令： bash sudo systemctl restart dnsmasq.service ","date":"2021-03-04","objectID":"/posts/ubuntu-flushdns/:2:0","series":null,"tags":["ubuntu","dns"],"title":"Ubuntu 刷新/删除 DNS 缓存","uri":"/posts/ubuntu-flushdns/#刷新-dnsmasq-缓存"},{"categories":["devops","ubuntu"],"content":" 刷新 Nscd 缓存如果使用了 Nscd，删除 DNS 缓存只需要运行以下命令： bash sudo systemctl restart nscd.service 或者运行： bash sudo service nscd restart ","date":"2021-03-04","objectID":"/posts/ubuntu-flushdns/:3:0","series":null,"tags":["ubuntu","dns"],"title":"Ubuntu 刷新/删除 DNS 缓存","uri":"/posts/ubuntu-flushdns/#刷新-nscd-缓存"},{"categories":["devops","ubuntu"],"content":"域名服务（DNS）是一种Internet服务，可将IP地址和标准域名（FQDN）相互映射。这样，DNS减轻了记住IP地址的需要。运行DNS的计算机称为名称服务器。Ubuntu附带了BIND (Berkley Internet Naming Daemon)，BIND是用于在Linux上维护名称服务器的最常用程序。 ","date":"2021-03-04","objectID":"/posts/ubuntu-bind/:0:0","series":null,"tags":["ubuntu","bind","dns"],"title":"Ubuntu Server 安装配置 bind9","uri":"/posts/ubuntu-bind/#"},{"categories":["devops","ubuntu"],"content":" 安装在终端提示符下，输入以下命令安装 dns: bash sudo apt install bind9 dnsutils 软件包是测试和解决 DNS 问题非常有用的。 这些工具通常已经安装，但是要检查或安装 dnsutils，请输入以下内容： bash sudo apt install dnsutils ","date":"2021-03-04","objectID":"/posts/ubuntu-bind/:1:0","series":null,"tags":["ubuntu","bind","dns"],"title":"Ubuntu Server 安装配置 bind9","uri":"/posts/ubuntu-bind/#安装"},{"categories":["devops","ubuntu"],"content":" 配置角色有许多方法可以配置BIND9。一些最常见的配置是缓存名称服务器，主服务器和辅助服务器。 当配置为缓存名称服务器时，BIND9将找到名称查询的答案，并在再次查询域时记住答案。 作为主要服务器，BIND9从其主机上的文件中读取区域的数据，并且对该区域具有权威性。 作为辅助服务器，BIND9从另一个对该区域具有权威性的名称服务器获取区域数据。 ","date":"2021-03-04","objectID":"/posts/ubuntu-bind/:2:0","series":null,"tags":["ubuntu","bind","dns"],"title":"Ubuntu Server 安装配置 bind9","uri":"/posts/ubuntu-bind/#配置角色"},{"categories":["devops","ubuntu"],"content":" 配置文件概览DNS配置文件存储在 /etc/bind 目录中。主要配置文件是 /etc/bind/named.conf ，在软件包提供的布局中仅包括这些文件。 /etc/bind/named.conf.options：DNS 全局选项配置文件 /etc/bind/named.conf.local：自定义区域配置文件 /etc/bind/named.conf.default-zones：默认区域，例如localhost，其反向和根提示 根名称服务器曾经在文件中描述过 /etc/bind/db.root 。 现在由软件包 /usr/share/dns/root.hints 附带的文件提供了此功能 dns-root-data，并且在 named.conf.default-zones 上面的配置文件中对此进行了引用。 可以将同一服务器配置为缓存名称服务器，主要和辅助名称服务器：这都取决于它所服务的区域。服务器可以是一个区域的授权开始（SOA），同时为另一区域提供辅助服务。同时为本地LAN上的主机提供缓存服务。 ","date":"2021-03-04","objectID":"/posts/ubuntu-bind/:3:0","series":null,"tags":["ubuntu","bind","dns"],"title":"Ubuntu Server 安装配置 bind9","uri":"/posts/ubuntu-bind/#配置文件概览"},{"categories":["devops","ubuntu"],"content":" 缓存名称服务器默认配置充当缓存服务器。只需取消注释并编辑 /etc/bind/named.conf.options 即可设置ISP的DNS服务器的IP地址： text forwarders { 1.2.3.4; 5.6.7.8; }; 注意: 用实际 DNS 服务器的IP地址替换 1.2.3.4 和 5.6.7.8。 要启用新配置，请重新启动DNS服务器。在终端提示下： bash sudo systemctl restart bind9.service ","date":"2021-03-04","objectID":"/posts/ubuntu-bind/:4:0","series":null,"tags":["ubuntu","bind","dns"],"title":"Ubuntu Server 安装配置 bind9","uri":"/posts/ubuntu-bind/#缓存名称服务器"},{"categories":["devops","ubuntu"],"content":" 主服务器在本节中，将BIND9配置为域的主服务器 example.com。只需 example.com 用您的FQDN（完全合格的域名）替换即可。 ","date":"2021-03-04","objectID":"/posts/ubuntu-bind/:5:0","series":null,"tags":["ubuntu","bind","dns"],"title":"Ubuntu Server 安装配置 bind9","uri":"/posts/ubuntu-bind/#主服务器"},{"categories":["devops","ubuntu"],"content":" 转发区域文件要将DNS区域添加到BIND9，将BIND9变成主服务器，请首先编辑 /etc/bind/named.conf.local： text zone \"example.com\" { type master; file \"/etc/bind/db.example.com\"; }; 注意 如果bind将像使用DDNS一样接收文件的自动更新，请在此处以及下面的复制命令中使用 /var/lib/bind/db.example.com 而不是 /etc/bind/db.example.com。 现在，使用现有的区域文件作为模板来创建 /etc/bind/db.example.com 文件： bash sudo cp /etc/bind/db.local /etc/bind/db.example.com 编辑新的区域文件，/etc/bind/db.example.com 然后更改 localhost.为服务器的FQDN，.在末尾保留其他文件。更改 127.0.0.1 为名称服务器的IP地址和 root.localhost 有效的电子邮件地址，但用.代替通常的@符号，并再次.在末尾保留。更改注释以指示此文件所针对的域。 为基本域创建A记录example.com。此外，创建一个A记录的ns.example.com，在这个例子中，域名服务器： text ; ; BIND data file for example.com ; $TTL 604800 @ IN SOA example.com. root.example.com. ( 2 ; Serial 604800 ; Refresh 86400 ; Retry 2419200 ; Expire 604800 ) ; Negative Cache TTL @ IN NS ns.example.com. @ IN A 192.168.1.10 @ IN AAAA ::1 ns IN A 192.168.1.10 每次更改区域文件时，都必须增加序列号(Serial)。如果在重新启动BIND9之前进行了多次更改，只需增加一次串行。 现在，您可以将DNS记录添加到区域文件的底部。有关详细信息，请参阅公共记录类型。 注意，许多管理员喜欢使用最后编辑的日期作为区域的序列号(Serial)，例如2020012100，它是yyyymmddss(其中ss是序列号) 对区域文件进行了更改之后，需要重新启动BIND9以使更改生效 bash sudo systemctl restart bind9.service ","date":"2021-03-04","objectID":"/posts/ubuntu-bind/:5:1","series":null,"tags":["ubuntu","bind","dns"],"title":"Ubuntu Server 安装配置 bind9","uri":"/posts/ubuntu-bind/#转发区域文件"},{"categories":["devops","ubuntu"],"content":" 反向区域文件现在已经设置了区域并将名称解析为IP地址，现在需要添加反向区域以允许DNS将地址解析为名称。 编辑 /etc/bind/named.conf.local 并添加以下内容： text zone \"1.168.192.in-addr.arpa\" { type master; file \"/etc/bind/db.192\"; }; 注意: 将 1.168.192 替换为所用网络的前三个八位位组。 另外，适当命名区域文件 /etc/bind/db.192。 它应与网络的第一个八位位组匹配。 现在创建 /etc/bind/db.192 文件: bash sudo cp /etc/bind/db.127 /etc/bind/db.192 接下来编辑 /etc/bind/db.192，更改与/etc/bind/db.example.com相同的选项： text ; ; BIND reverse data file for local 192.168.1.XXX net ; $TTL 604800 @ IN SOA ns.example.com. root.example.com. ( 2 ; Serial 604800 ; Refresh 86400 ; Retry 2419200 ; Expire 604800 ) ; Negative Cache TTL ; @ IN NS ns. 10 IN PTR ns.example.com. 每次更改时，“反向”区域中的序列号也需要增加。 对于您在/etc/bind/db.example.com中配置的每个A记录（即针对另一个地址），您需要在/etc/bind/db.192中创建一个PTR记录。 创建反向区域文件后，重新启动BIND9 bash sudo systemctl restart bind9.service ","date":"2021-03-04","objectID":"/posts/ubuntu-bind/:5:2","series":null,"tags":["ubuntu","bind","dns"],"title":"Ubuntu Server 安装配置 bind9","uri":"/posts/ubuntu-bind/#反向区域文件"},{"categories":["devops","ubuntu"],"content":" 辅助服务器一旦配置了主服务器，强烈建议使用辅助服务器，以在主服务器不可用时维持域的可用性。 首先，在主服务器上，需要允许区域传输。将 allow-transfer 选项添加到示例正向和反向区域定义中 /etc/bind/named.conf.local： text zone \"example.com\" { type master; file \"/etc/bind/db.example.com\"; allow-transfer { 192.168.1.11; }; }; zone \"1.168.192.in-addr.arpa\" { type master; file \"/etc/bind/db.192\"; allow-transfer { 192.168.1.11; }; }; 注意 替换192.168.1.11为辅助名称服务器的IP地址。 在主服务器上重新启动BIND9： text sudo systemctl restart bind9.service 接下来，在辅助服务器上，以与主服务器相同的方式安装bind9软件包。然后编辑，/etc/bind/named.conf.local 并为正向和反向区域添加以下声明： text zone \"example.com\" { type slave; file \"db.example.com\"; masters { 192.168.1.10; }; }; zone \"1.168.192.in-addr.arpa\" { type slave; file \"db.192\"; masters { 192.168.1.10; }; }; 注意 替换192.168.1.10为您的主要名称服务器的IP地址。 在辅助服务器上重新启动BIND9： bash sudo systemctl restart bind9.service 在其中，/var/log/syslog 您应该看到类似以下内容的内容（为了适应本文档的格式，对某些行进行了拆分）： text client 192.168.1.10#39448: received notify for zone '1.168.192.in-addr.arpa' zone 1.168.192.in-addr.arpa/IN: Transfer started. transfer of '100.18.172.in-addr.arpa/IN' from 192.168.1.10#53: connected using 192.168.1.11#37531 zone 1.168.192.in-addr.arpa/IN: transferred serial 5 transfer of '100.18.172.in-addr.arpa/IN' from 192.168.1.10#53: Transfer completed: 1 messages, 6 records, 212 bytes, 0.002 secs (106000 bytes/sec) zone 1.168.192.in-addr.arpa/IN: sending notifies (serial 5) client 192.168.1.10#20329: received notify for zone 'example.com' zone example.com/IN: Transfer started. transfer of 'example.com/IN' from 192.168.1.10#53: connected using 192.168.1.11#38577 zone example.com/IN: transferred serial 5 transfer of 'example.com/IN' from 192.168.1.10#53: Transfer completed: 1 messages, 8 records, 225 bytes, 0.002 secs (112500 bytes/sec) 注意：仅当主服务器上的序列号大于辅助服务器上的序列号时，才会传输区域。如果要让您的主DNS通知其他辅助DNS服务器区域更改，则可以将其添加also-notify { ipaddress; };到/etc/bind/named.conf.local以下示例中： text zone \"example.com\" { type master; file \"/etc/bind/db.example.com\"; allow-transfer { 192.168.1.11; }; also-notify { 192.168.1.11; }; }; zone \"1.168.192.in-addr.arpa\" { type master; file \"/etc/bind/db.192\"; allow-transfer { 192.168.1.11; }; also-notify { 192.168.1.11; }; }; 注意 非权威区域文件的默认目录为/var/cache/bind/。该目录还在AppArmor中配置为允许命名守护程序向其写入。有关AppArmor的更多信息，请参见Security-AppArmor。 ","date":"2021-03-04","objectID":"/posts/ubuntu-bind/:6:0","series":null,"tags":["ubuntu","bind","dns"],"title":"Ubuntu Server 安装配置 bind9","uri":"/posts/ubuntu-bind/#辅助服务器"},{"categories":["devops","ubuntu"],"content":" 测试","date":"2021-03-04","objectID":"/posts/ubuntu-bind/:7:0","series":null,"tags":["ubuntu","bind","dns"],"title":"Ubuntu Server 安装配置 bind9","uri":"/posts/ubuntu-bind/#测试"},{"categories":["devops","ubuntu"],"content":" resolv.conf测试BIND9的第一步是将名称服务器的IP地址添加到主机解析器。应该配置主要名称服务器以及另一个主机，以仔细检查。有关将名称服务器地址添加到网络客户端的详细信息，请参阅DNS客户端配置。最后，您的nameserver一行/etc/resolv.conf应指向，127.0.0.53并且您应该search为您的域指定一个参数。像这样： text nameserver 127.0.0.53 search example.com 要检查您的本地解析器正在使用哪个DNS服务器，请运行： text systemd-resolve --status 注意 如果主要服务器不可用，您还应该将辅助名称服务器的IP地址添加到客户端配置中。 ","date":"2021-03-04","objectID":"/posts/ubuntu-bind/:7:1","series":null,"tags":["ubuntu","bind","dns"],"title":"Ubuntu Server 安装配置 bind9","uri":"/posts/ubuntu-bind/#resolvconf"},{"categories":["devops","ubuntu"],"content":" dig如果安装了dnsutils软件包，则可以使用DNS查找实用程序dig测试设置： 安装完BIND9之后，请对环回接口使用dig来确保它正在侦听端口53。从终端提示符下： text dig -x 127.0.0.1 您应该在命令输出中看到类似于以下内容的行： text ;; Query time: 1 msec ;; SERVER: 192.168.1.10#53(192.168.1.10) 如果您已将BIND9配置为缓存名称服务器，则“挖掘”外部域以检查查询时间： text dig ubuntu.com 注意查询时间接近命令输出的末尾： text ;; Query time: 49 msec 经过第二次挖掘后，应该有所改进： text ;; Query time: 1 msec ","date":"2021-03-04","objectID":"/posts/ubuntu-bind/:7:2","series":null,"tags":["ubuntu","bind","dns"],"title":"Ubuntu Server 安装配置 bind9","uri":"/posts/ubuntu-bind/#dig"},{"categories":["devops","ubuntu"],"content":" ping现在演示应用程序如何使用DNS解析主机名，使用ping实用程序发送ICMP回显请求： text ping example.com 这测试名称服务器是否可以将名称解析为ns.example.com IP 地址。 命令输出应类似于： text PING ns.example.com (192.168.1.10) 56(84) bytes of data. 64 bytes from 192.168.1.10: icmp_seq=1 ttl=64 time=0.800 ms 64 bytes from 192.168.1.10: icmp_seq=2 ttl=64 time=0.813 ms ","date":"2021-03-04","objectID":"/posts/ubuntu-bind/:7:3","series":null,"tags":["ubuntu","bind","dns"],"title":"Ubuntu Server 安装配置 bind9","uri":"/posts/ubuntu-bind/#ping"},{"categories":["devops","ubuntu"],"content":" named-checkzone测试区域文件的一种好方法是使用 named-checkzone 与bind9软件包一起安装的实用程序。使用此实用程序，可以在重新启动BIND9并使更改生效之前确保配置正确。 要测试我们的示例正向区域文件，请从命令提示符处输入以下内容： text named-checkzone example.com /etc/bind/db.example.com 如果一切配置正确，您应该会看到类似以下的输出： text zone example.com/IN: loaded serial 6 OK 同样，要测试反向区域文件，请输入以下内容： text named-checkzone 1.168.192.in-addr.arpa /etc/bind/db.192 输出应类似于： text zone 1.168.192.in-addr.arpa/IN: loaded serial 3 OK ","date":"2021-03-04","objectID":"/posts/ubuntu-bind/:7:4","series":null,"tags":["ubuntu","bind","dns"],"title":"Ubuntu Server 安装配置 bind9","uri":"/posts/ubuntu-bind/#named-checkzone"},{"categories":["devops","ubuntu"],"content":" 日志BIND9有多种可用的日志记录配置选项，但是两个主要的选项是channel和category，它们分别配置日志的去向和要记录的信息。 如果未配置任何日志记录选项，则默认配置为： text logging { category default { default_syslog; default_debug; }; category unmatched { null; }; }; 让我们将BIND9配置为将与DNS查询相关的调试消息发送到单独的文件。 我们需要配置一个通道以指定要将消息发送到的文件，以及一个category。在此示例中，类别将记录所有查询。编辑/etc/bind/named.conf.local并添加以下内容： text logging { channel query.log { file \"/var/log/named/query.log\"; severity debug 3; }; category queries { query.log; }; }; 注意 该调试选项可以从1设置为3。如果没有指定级别，1级是默认的。 由于命名守护程序以绑定用户身份运行，因此/var/log/named必须创建目录并更改所有权： text sudo mkdir /var/log/named sudo chown bind:bind /var/log/named 现在重新启动BIND9，以使更改生效： text sudo systemctl restart bind9.service 您应该看到文件中/var/log/named/query.log填充了查询信息。这是BIND9日志记录选项的简单示例。 注意 您的区域文件的序列号可能会有所不同。 ","date":"2021-03-04","objectID":"/posts/ubuntu-bind/:8:0","series":null,"tags":["ubuntu","bind","dns"],"title":"Ubuntu Server 安装配置 bind9","uri":"/posts/ubuntu-bind/#日志"},{"categories":["devops","ubuntu"],"content":" 临时IP地址分配对于临时网络配置，可以使用在大多数其他 GNU/Linux 操作系统上也可以找到的ip命令。ip 命令允许您配置立即生效的设置，但是这些设置不是永久性的，并且在重新启动后会丢失。 要临时配置IP地址，可以按以下方式使用ip命令。修改IP地址和子网掩码以符合您的网络要求。 bash sudo ip addr add 10.102.66.200/24 dev enp0s25 然后可以使用ip来设置链接的打开或关闭。 bash ip link set dev enp0s25 up ip link set dev enp0s25 down 要验证 enp0s25 的 IP 地址配置，可以按以下方式使用 ip 命令。 bash ip address show dev enp0s25 10: enp0s25: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 00:16:3e:e2:52:42 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 10.102.66.200/24 brd 10.102.66.255 scope global dynamic eth0 valid_lft 2857sec preferred_lft 2857sec inet6 fe80::216:3eff:fee2:5242/64 scope link valid_lft forever preferred_lft forever6 要配置默认网关，可以按以下方式使用ip命令。修改默认网关地址以符合您的网络要求。 bash sudo ip route add default via 10.102.66.1 要验证默认网关配置，可以按以下方式使用ip命令。 bash ip route show default via 10.102.66.1 dev eth0 proto dhcp src 10.102.66.200 metric 100 10.102.66.0/24 dev eth0 proto kernel scope link src 10.102.66.200 10.102.66.1 dev eth0 proto dhcp scope link src 10.102.66.200 metric 100 如果您需要DNS进行临时网络配置，则可以在文件中添加DNS服务器IP地址 /etc/resolv.conf。通常，/etc/resolv.conf不建议直接进行编辑，但这是一个临时且非持久的配置。下面的示例显示如何在中输入两个DNS服务器/etc/resolv.conf，应将其更改为适合您的网络的服务器。下一节将更详细地说明进行DNS客户端配置的正确的持久方法。 bash nameserver 8.8.8.8 nameserver 8.8.4.4 如果您不再需要此配置，并且希望从接口清除所有IP配置，则可以将ip命令与flush选项一起使用，如下所示。 bash ip addr flush eth0 使用ip命令刷新IP配置不会清除的内容 /etc/resolv.conf。您必须手动删除或修改这些条目，或者重新引导，这也将导致重新写入/etc/resolv.conf，这是到的符号链接/run/systemd/resolve/stub-resolv.conf ","date":"2021-03-04","objectID":"/posts/ubuntu-network/:1:0","series":null,"tags":["ubuntu","netplan"],"title":"Ubuntu Server 网络配置","uri":"/posts/ubuntu-network/#临时ip地址分配"},{"categories":["devops","ubuntu"],"content":" 静态IP地址分配要将系统配置为使用静态地址分配，请在文件中创建一个netplan配置 /etc/netplan/99_config.yaml。下面的示例假定您正在配置标识为eth0的第一个以太网接口。更改地址，gateway4和名称服务器值，以满足您的网络要求。 yaml network: version: 2 renderer: networkd ethernets: eth0: addresses: - 10.10.10.2/24 gateway4: 10.10.10.1 nameservers: search: - mydomain - otherdomain addresses: - 10.10.10.1 - 1.1.1.1 然后可以使用 netplan 命令应用该配置。 bash sudo netplan apply ","date":"2021-03-04","objectID":"/posts/ubuntu-network/:2:0","series":null,"tags":["ubuntu","netplan"],"title":"Ubuntu Server 网络配置","uri":"/posts/ubuntu-network/#静态ip地址分配"},{"categories":["devops","ubuntu"],"content":" 名称解析与IP网络相关的名称解析是将IP地址映射到主机名的过程，从而更容易识别网络上的资源。下一节将说明如何使用DNS和静态主机名记录正确配置系统以进行名称解析。 DNS客户端配置 传统上，该文件/etc/resolv.conf是静态配置文件，很少需要通过DCHP客户端挂接进行更改或自动更改。Systemd 解析处理名称服务器配置，并且应该通过systemd-resolve命令与之交互。Netplan配置systemd-resolved以生成要放入的名称服务器和域的列表/etc/resolv.conf，这是一个符号链接： /etc/resolv.conf -\u003e ../run/systemd/resolve/stub-resolv.conf 要配置解析器，请将适合您的网络的名称服务器的IP地址添加到netplan配置文件中。您还可以添加可选的DNS后缀搜索列表以匹配您的网络域名。生成的文件可能如下所示： yaml network: version: 2 renderer: networkd ethernets: enp0s25: addresses: - 192.168.0.100/24 gateway4: 192.168.0.1 nameservers: search: [mydomain, otherdomain] addresses: [1.1.1.1, 8.8.8.8, 4.4.4.4] 该搜索选项也可以用多个域名使用，使得DNS查询将按照它们的输入顺序追加。例如，您的网络可能有多个子域可供搜索；的父域example.com和两个子域，sales.example.com以及dev.example.com。 如果您要搜索多个域，则配置可能如下所示： yaml network: version: 2 renderer: networkd ethernets: enp0s25: addresses: - 192.168.0.100/24 gateway4: 192.168.0.1 nameservers: search: [example.com, sales.example.com, dev.example.com] addresses: [1.1.1.1, 8.8.8.8, 4.4.4.4] 如果您尝试对名称为server1的主机执行ping操作，系统将按以下顺序自动查询DNS的完全合格域名（FQDN）： server1.example.com server1.sales.example.com server1.dev.example.com 如果找不到匹配项，则DNS服务器将提供notfound的结果，并且DNS查询将失败。 ","date":"2021-03-04","objectID":"/posts/ubuntu-network/:3:0","series":null,"tags":["ubuntu","netplan"],"title":"Ubuntu Server 网络配置","uri":"/posts/ubuntu-network/#名称解析"},{"categories":["devops","ubuntu"],"content":" 静态路由例如，如果你要添加到目标为 192.168.1.0/24 的网络，网关为 192.168.0.2 的路由，可以将以下行添加到配置文件中： yaml network: version: 2 renderer: networkd ethernets: enp0s25: addresses: - 192.168.0.100/24 nameservers: search: [example.com, sales.example.com, dev.example.com] addresses: [1.1.1.1, 8.8.8.8, 4.4.4.4] routes: - to: default via: 192.168.0.1 - to: 192.168.1.0/24 via: 192.168.0.2 注意: 临时静态路由可以使用 ip route 命令添加删除 ","date":"2021-03-04","objectID":"/posts/ubuntu-network/:4:0","series":null,"tags":["ubuntu","netplan"],"title":"Ubuntu Server 网络配置","uri":"/posts/ubuntu-network/#静态路由"},{"categories":["devops","command"],"content":" awk 文本处理awk 是一种很棒的语言，它适合文本处理和报表生成，其语法较为常见，借鉴了某些语言的一些精华，如 C 语言等。 在 linux 系统日常处理工作中，发挥很重要的作用，掌握了 awk 将会使你的工作变的高大上。 awk 是三剑客的老大，利剑出鞘，必会不同凡响。 ","date":"2021-03-03","objectID":"/posts/awk/:1:0","series":null,"tags":["awk"],"title":"Linux 文本三剑客: awk","uri":"/posts/awk/#awk-文本处理"},{"categories":["devops","command"],"content":" awk 内置变量 $0 匹配当前记录整行数据 $1-$n 匹配当前记录的第n个字段（列） FS 输入字段分隔符，默认是空格或制表符(tab) RS 输入记录分隔符，默认为换行符 NF 当前记录的字段个数，就是有多个列 NR 记录所有行数，就是行号，从1开始 OFS 输出字段分隔符，默认也是空格 ORS 输入的记录分隔符，默认为换行符 内置变量很多，更多参数自行查询 ","date":"2021-03-03","objectID":"/posts/awk/:1:1","series":null,"tags":["awk"],"title":"Linux 文本三剑客: awk","uri":"/posts/awk/#awk-内置变量"},{"categories":["devops","command"],"content":" awk 使用示例 1. 统计 linux 系统下 tcp 协议所有网络状态条数 bash root@ops:~# ss -ant | awk '{++d[$1]} END {for (k in d){print k \": \" d[k]}}' | grep -v State LISTEN: 10 ESTAB: 1 语法解析 bash { # 定义一个数组 d, 键为 $1 (状态名), ++ 表示数组中键名相同时值自动加 1 ++d[$1] } END { # awk 在处理了输入文件中的所有行之后执行这个块 # 输入数组中所有数据，k 是键名，通过键名取数据 for (k in d){ print k \": \" d[k] } } 2. 求和并排序文本有两列字段，用户名，充值金额。 在数据中用户可能会重复出现，现在需要统计出所有用户的金额总值并按降序排列 bash root@ops:~# cat b.txt 1234 100 1344 13 1242 783 1234 234 4563 21 4562 145 root@ops:~# awk '{d[$1]+=$2} END { for (n in d){print n \": \" d[n]}}' b.txt | sort -nr -k 2 1242: 783 1234: 334 4562: 145 4563: 21 1344: 13 awk 语法解析 bash { # 定义一个数据，key 为用户名，value 为 充值金额， # 由于用户名会重复出现金额需要累加，所以使用 += 表达式进行赋值 d[$1]+=$2 } END { # 输入数据中所有值 for (n in d){ print n \": \" d[n] } } 3. 列出占用 80 端口进程的 pid 并结束它 bash root@ops:~# lsof -i:80 | awk '{ if ($2 ~ /[0-9]/) {print $2}}' | xargs kill 30213 30232 30233 也可以使用: ss -antp | grep ':80 ' | egrep -o 'pid=[0-9]{,5}' | tr -d 'pid=' | xargs kill ","date":"2021-03-03","objectID":"/posts/awk/:1:2","series":null,"tags":["awk"],"title":"Linux 文本三剑客: awk","uri":"/posts/awk/#awk-使用示例"},{"categories":["devops","command"],"content":" awk 使用示例 1. 统计 linux 系统下 tcp 协议所有网络状态条数 bash root@ops:~# ss -ant | awk '{++d[$1]} END {for (k in d){print k \": \" d[k]}}' | grep -v State LISTEN: 10 ESTAB: 1 语法解析 bash { # 定义一个数组 d, 键为 $1 (状态名), ++ 表示数组中键名相同时值自动加 1 ++d[$1] } END { # awk 在处理了输入文件中的所有行之后执行这个块 # 输入数组中所有数据，k 是键名，通过键名取数据 for (k in d){ print k \": \" d[k] } } 2. 求和并排序文本有两列字段，用户名，充值金额。 在数据中用户可能会重复出现，现在需要统计出所有用户的金额总值并按降序排列 bash root@ops:~# cat b.txt 1234 100 1344 13 1242 783 1234 234 4563 21 4562 145 root@ops:~# awk '{d[$1]+=$2} END { for (n in d){print n \": \" d[n]}}' b.txt | sort -nr -k 2 1242: 783 1234: 334 4562: 145 4563: 21 1344: 13 awk 语法解析 bash { # 定义一个数据，key 为用户名，value 为 充值金额， # 由于用户名会重复出现金额需要累加，所以使用 += 表达式进行赋值 d[$1]+=$2 } END { # 输入数据中所有值 for (n in d){ print n \": \" d[n] } } 3. 列出占用 80 端口进程的 pid 并结束它 bash root@ops:~# lsof -i:80 | awk '{ if ($2 ~ /[0-9]/) {print $2}}' | xargs kill 30213 30232 30233 也可以使用: ss -antp | grep ':80 ' | egrep -o 'pid=[0-9]{,5}' | tr -d 'pid=' | xargs kill ","date":"2021-03-03","objectID":"/posts/awk/:1:2","series":null,"tags":["awk"],"title":"Linux 文本三剑客: awk","uri":"/posts/awk/#1-统计-linux-系统下-tcp-协议所有网络状态条数"},{"categories":["devops","command"],"content":" awk 使用示例 1. 统计 linux 系统下 tcp 协议所有网络状态条数 bash root@ops:~# ss -ant | awk '{++d[$1]} END {for (k in d){print k \": \" d[k]}}' | grep -v State LISTEN: 10 ESTAB: 1 语法解析 bash { # 定义一个数组 d, 键为 $1 (状态名), ++ 表示数组中键名相同时值自动加 1 ++d[$1] } END { # awk 在处理了输入文件中的所有行之后执行这个块 # 输入数组中所有数据，k 是键名，通过键名取数据 for (k in d){ print k \": \" d[k] } } 2. 求和并排序文本有两列字段，用户名，充值金额。 在数据中用户可能会重复出现，现在需要统计出所有用户的金额总值并按降序排列 bash root@ops:~# cat b.txt 1234 100 1344 13 1242 783 1234 234 4563 21 4562 145 root@ops:~# awk '{d[$1]+=$2} END { for (n in d){print n \": \" d[n]}}' b.txt | sort -nr -k 2 1242: 783 1234: 334 4562: 145 4563: 21 1344: 13 awk 语法解析 bash { # 定义一个数据，key 为用户名，value 为 充值金额， # 由于用户名会重复出现金额需要累加，所以使用 += 表达式进行赋值 d[$1]+=$2 } END { # 输入数据中所有值 for (n in d){ print n \": \" d[n] } } 3. 列出占用 80 端口进程的 pid 并结束它 bash root@ops:~# lsof -i:80 | awk '{ if ($2 ~ /[0-9]/) {print $2}}' | xargs kill 30213 30232 30233 也可以使用: ss -antp | grep ':80 ' | egrep -o 'pid=[0-9]{,5}' | tr -d 'pid=' | xargs kill ","date":"2021-03-03","objectID":"/posts/awk/:1:2","series":null,"tags":["awk"],"title":"Linux 文本三剑客: awk","uri":"/posts/awk/#2-求和并排序"},{"categories":["devops","command"],"content":" awk 使用示例 1. 统计 linux 系统下 tcp 协议所有网络状态条数 bash root@ops:~# ss -ant | awk '{++d[$1]} END {for (k in d){print k \": \" d[k]}}' | grep -v State LISTEN: 10 ESTAB: 1 语法解析 bash { # 定义一个数组 d, 键为 $1 (状态名), ++ 表示数组中键名相同时值自动加 1 ++d[$1] } END { # awk 在处理了输入文件中的所有行之后执行这个块 # 输入数组中所有数据，k 是键名，通过键名取数据 for (k in d){ print k \": \" d[k] } } 2. 求和并排序文本有两列字段，用户名，充值金额。 在数据中用户可能会重复出现，现在需要统计出所有用户的金额总值并按降序排列 bash root@ops:~# cat b.txt 1234 100 1344 13 1242 783 1234 234 4563 21 4562 145 root@ops:~# awk '{d[$1]+=$2} END { for (n in d){print n \": \" d[n]}}' b.txt | sort -nr -k 2 1242: 783 1234: 334 4562: 145 4563: 21 1344: 13 awk 语法解析 bash { # 定义一个数据，key 为用户名，value 为 充值金额， # 由于用户名会重复出现金额需要累加，所以使用 += 表达式进行赋值 d[$1]+=$2 } END { # 输入数据中所有值 for (n in d){ print n \": \" d[n] } } 3. 列出占用 80 端口进程的 pid 并结束它 bash root@ops:~# lsof -i:80 | awk '{ if ($2 ~ /[0-9]/) {print $2}}' | xargs kill 30213 30232 30233 也可以使用: ss -antp | grep ':80 ' | egrep -o 'pid=[0-9]{,5}' | tr -d 'pid=' | xargs kill ","date":"2021-03-03","objectID":"/posts/awk/:1:2","series":null,"tags":["awk"],"title":"Linux 文本三剑客: awk","uri":"/posts/awk/#3-列出占用-80-端口进程的-pid-并结束它"},{"categories":["devops","haproxy"],"content":" HAPrxoy 介绍HAProxy 是一个使用 C 语言编写的自由及开放源代码软件，其提供高可用性、负载均衡，以及基于 tcp 和 http 的应用程序代理。 mode http：七层反向代理，受端口数量限制 mode tcp：四层反向代理，不受套接字文件数量限制 HAProxy 特别适用于那些负载特大的 web 站点，这些站点通常又需要会话保持或七层处理。HAProxy 运行在当前的硬件上，完全可以支持数以万计的并发连接。并且它的运行模式使得它可以很简单安全的整合进您当前的架构中，同时可以保护你的 web 服务器不被暴露到网络上。 更多内容请查看 官方网站 – 官方文档 ","date":"2021-02-22","objectID":"/posts/haproxy-install/:1:0","series":null,"tags":["haproxy"],"title":"HAPrxoy 的简单使用","uri":"/posts/haproxy-install/#haprxoy-介绍"},{"categories":["devops","haproxy"],"content":" 安装 HAProxy以 Ubuntu Server 18.04 操作系统为例, 官方教程 您需要使用以下命令启用专用的PPA： bash root@lb-01:~# apt-get install --no-install-recommends software-properties-common root@lb-01:~# add-apt-repository ppa:vbernat/haproxy-2.2 然后，使用以下命令： bash root@lb-01:~# apt-get install haproxy=2.2.\\* 您将获得最新版本的 HAProxy 2.2（并坚持使用此分支）。 ","date":"2021-02-22","objectID":"/posts/haproxy-install/:2:0","series":null,"tags":["haproxy"],"title":"HAPrxoy 的简单使用","uri":"/posts/haproxy-install/#安装-haproxy"},{"categories":["devops","haproxy"],"content":" HAProxy 服务配置","date":"2021-02-22","objectID":"/posts/haproxy-install/:3:0","series":null,"tags":["haproxy"],"title":"HAPrxoy 的简单使用","uri":"/posts/haproxy-install/#haproxy-服务配置"},{"categories":["devops","haproxy"],"content":" 程序环境 主程序：/usr/sbin/haproxy 主配置文件：/etc/haproxy/haproxy.cfg systemd 服务配置文件：/lib/systemd/system/haproxy.service ","date":"2021-02-22","objectID":"/posts/haproxy-install/:3:1","series":null,"tags":["haproxy"],"title":"HAPrxoy 的简单使用","uri":"/posts/haproxy-install/#程序环境"},{"categories":["devops","haproxy"],"content":" 配置文件说明 bash root@lb-01:/etc/haproxy# cat haproxy.cfg # 全局配置段 global log /dev/log local0 log /dev/log local1 notice # 指定最大连接数 maxconn 200000 # 限制 haproxy 根路径 chroot /var/lib/haproxy # 指定 haproxy 管理 socket 文件并与指定的进程绑定(process) stats socket /run/haproxy/admin1.sock mode 660 level admin expose-fd listeners process 1 stats socket /run/haproxy/admin2.sock mode 660 level admin expose-fd listeners process 2 stats timeout 30s # 指定 haproxy 运行的用户和组 user haproxy group haproxy # 开启守护进程 daemon # 避免对于后端检测同时并发造成的问题，设置错开时间比，范围0到50，一般设置2-5较好 spread-checks 5 # 开启多进程 nbproc 2 # 设定进程与 CPU 绑定 cpu-map 1 0 cpu-map 2 1 # 默认参数配置段， 为 frontend, listen, backend 提供默认配置 defaults log global # 使用 http 模式 mode http # 日志类别 http 日志格式 option httplog # 对应的服务器挂掉后,强制定向到其他健康的服务器 option redispatch # 不记录健康检查的日志信息 option dontlognull # 开启 ip 透传，向后端服务发送真实客户端地址 option forwardfor # 开启 http 长连接 option http-keep-alive # 长连接超时时间设置 timeout http-keep-alive 120s # 连接超时时间设置 timeout connect 60s # 与后端服务器连接超时时间设置 timeout server 600s # 与客户端连接超时时间设置 timeout client 600s # check 检测超时时间设置 timeout check 5s # 配置默认 http 错误响应码对应的页面文件 errorfile 400 /etc/haproxy/errors/400.http errorfile 403 /etc/haproxy/errors/403.http errorfile 408 /etc/haproxy/errors/408.http errorfile 500 /etc/haproxy/errors/500.http errorfile 502 /etc/haproxy/errors/502.http errorfile 503 /etc/haproxy/errors/503.http errorfile 504 /etc/haproxy/errors/504.http # 开启状态页 listen stauts mode http bind :9999 stats enable # 指定状态面的 uri 路径 stats uri /haproxy-status # 配置状态页的用户名和密码 stats auth haproxy:liwg # 配置 http 代理 listen http # 代理监控端口 bind *:80 # 使用的负载均衡调度算法 balance roundrobin # 在后端启用基于 cookie 的持久性 cookie SRVID insert indirect nocache # 后端服务器配置列表, cookie: 指定 cookie值， check: 启用健康检测 # inter 检测间隔， fall 检测失败次数， rise 重试次数 server server1 192.168.31.31:80 cookie 31 check inter 3s fall 3 rise 5 server server2 192.168.31.32:80 cookie 32 check inter 3s fall 3 rise 5 当使用 haproxy 负载均衡集群时，监听的地址为 vip 时，服务会无法启动， 这是因为 Linux 绑定了一个网卡上没有配置的 ip 地址导致的， 此时可以通过修改 Linux 内核 net.ipv4.ip_nonlocal_bind = 1 参数解决 ","date":"2021-02-22","objectID":"/posts/haproxy-install/:3:2","series":null,"tags":["haproxy"],"title":"HAPrxoy 的简单使用","uri":"/posts/haproxy-install/#配置文件说明"},{"categories":["devops","haproxy"],"content":" 启动 HAProxy 服务并测试","date":"2021-02-22","objectID":"/posts/haproxy-install/:4:0","series":null,"tags":["haproxy"],"title":"HAPrxoy 的简单使用","uri":"/posts/haproxy-install/#启动-haproxy-服务并测试"},{"categories":["devops","haproxy"],"content":" 启动 HAProxy 服务 bash root@lb-01:/etc/haproxy# systemctl start haproxy.service root@lb-01:/etc/haproxy# ss -anptl | grep haproxy LISTEN 0 128 0.0.0.0:9999 0.0.0.0:* users:((\"haproxy\",pid=26699,fd=12),(\"haproxy\",pid=26697,fd=12)) LISTEN 0 128 0.0.0.0:80 0.0.0.0:* users:((\"haproxy\",pid=26699,fd=14),(\"haproxy\",pid=26697,fd=14)) root@lb-01:/etc/haproxy# ps -ef | grep haproxy root 26690 1 0 14:32 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -S /run/haproxy-master.sock haproxy 26697 26690 0 14:32 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -S /run/haproxy-master.sock haproxy 26699 26690 0 14:32 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -S /run/haproxy-master.sock 端口 9999 是 haproxy 状态页，端口 80 用于后端服务器负载均衡， 通过 ps 命令， 可以看到 haproxy 开启了多进程 ","date":"2021-02-22","objectID":"/posts/haproxy-install/:4:1","series":null,"tags":["haproxy"],"title":"HAPrxoy 的简单使用","uri":"/posts/haproxy-install/#启动-haproxy-服务"},{"categories":["devops","haproxy"],"content":" 动态下线/上线后端服务器动态下线后端服务器 bash root@lb-01:/etc/haproxy# echo 'disable server http/server2' | socat stdio /run/haproxy/admin1.sock root@lb-01:/etc/haproxy# echo 'disable server http/server2' | socat stdio /run/haproxy/admin2.sock 注意： 当输入软下线的命令时 haproxy 依旧可以将用户的请求调度到后端已经下线的服务器上，这是因为 haproxy 的 socket 文件的关系，一个 socket 文件对应一个进程，当 haproxy 处于多进程的模式下时，就需要有多个 socket 文件，并将其和进程进行绑定，对后端服务器进行软下线时需要对所有的 socket 文件下达软下线的指令。 可以通过 http://haproxy_ipaddress:9999/haproxy-status 查看后端服务器状态 动态上线后端服务器 bash root@lb-01:/etc/haproxy# echo 'enable server http/server2' | socat stdio /run/haproxy/admin1.sock root@lb-01:/etc/haproxy# echo 'enable server http/server2' | socat stdio /run/haproxy/admin2.sock ","date":"2021-02-22","objectID":"/posts/haproxy-install/:4:2","series":null,"tags":["haproxy"],"title":"HAPrxoy 的简单使用","uri":"/posts/haproxy-install/#动态下线上线后端服务器"},{"categories":["devops","tomcat"],"content":" 配置优化","date":"2021-02-22","objectID":"/posts/tomcat-optimization/:1:0","series":null,"tags":["tomcat"],"title":"Tomcat 配置及运行权限优化","uri":"/posts/tomcat-optimization/#配置优化"},{"categories":["devops","tomcat"],"content":" 修改 Server 节点 shutdown 属性值为长随机数 xml \u003cServer port=\"8005\" shutdown=\"d41d8cd98f00b204e9800998ecf8427e\"\u003e ","date":"2021-02-22","objectID":"/posts/tomcat-optimization/:1:1","series":null,"tags":["tomcat"],"title":"Tomcat 配置及运行权限优化","uri":"/posts/tomcat-optimization/#修改-server-节点-shutdown-属性值为长随机数"},{"categories":["devops","tomcat"],"content":" 启用 tomcat 线程池使用线程池，用较少的线程处理较多的访问，可以提高tomcat处理请求的能力。使用方式： 打开 conf/server.xml，增加 xml \u003cExecutorname=\"tomcatThreadPool\" namePrefix=\"catalina-exec-\" maxThreads=\"500\" minSpareThreads=\"20\" maxIdleTime=\"60000\" prestartminSpareThreads=\"true\" maxQueueSize=\"100\"/\u003e 属性说明 name: 线程名称 namePrefix: 线程前缀 maxThreads : 最大并发连接数，不配置时默认200，一般建议设置500~ 800 ，要根据自己的硬件设施条件和实际业务需求而定。 minSpareThreads：Tomcat 启动初始化的线程数，默认值25 prestartminSpareThreads：在 Tomcat 初始化的时候就初始化 minSpareThreads 的值 maxQueueSize: 最大的等待队列数，超过则拒绝请求 maxIdleTime：线程最大空闲时间60秒 然后，修改 Connector 节点，增加 executor 属性，如: xml \u003cConnector port=\"8080\" protocol=\"org.apache.coyote.http11.Http11NioProtocol\" executor=\"tomcatThreadPool\" connectionTimeout=\"20000\" enableLookups=\"false\" redirectPort=\"8443\" maxPostSize=\"20971520\" acceptCount=\"2000\" acceptorThreadCount=\"2\" disableUploadTimeout=\"true\" URIEncoding=\"utf-8\"/\u003e 属性说明 port ：连接端口。 protocol：连接器使用的传输方式。 executor： 连接器使用的线程池名称 enableLookups：禁用DNS 查询 acceptCount：指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理，默认设置 100 。 maxPostSize：限制以 FORM URL 参数方式的POST请求的内容大小，单位字节，默认是 2097152(2M)，10485760 为 10M。如果要禁用限制，则可以设置为 -1。 acceptorThreadCount： 用于接收连接的线程的数量，默认值是1。一般这个指需要改动的时候是因为该服务器是一个多核CPU，如果是多核 CPU 一般配置为 2。 disableUploadTimeout：上传时是否使用超时机制，以是 servlet 有较长时间来完成它的执行，默认值为 false； URIEncoding: 指定 Url 字符编码，防止出现乱码 ","date":"2021-02-22","objectID":"/posts/tomcat-optimization/:1:2","series":null,"tags":["tomcat"],"title":"Tomcat 配置及运行权限优化","uri":"/posts/tomcat-optimization/#启用-tomcat-线程池"},{"categories":["devops","tomcat"],"content":" 运行权限优化默认情况下 Tomcat 服务是以 root 用户运行的，为了减少安全隐患需要更改为普通用户运行 Tomcat 服务 bash [root@10-7-171-239 apache-tomcat-9.0.43]# cd bin/ [root@10-7-171-239 bin]# tar xzf commons-daemon-native.tar.gz [root@10-7-171-239 bin]# cd commons-daemon-1.2.4-native-src/unix/ [root@10-7-171-239 unix]# ./configure [root@10-7-171-239 unix]# make [root@10-7-171-239 unix]# mv jsvc /usr/local/apache-tomcat-9.0.43/bin [root@10-7-171-239 unix]# cd /usr/local/apache-tomcat-9.0.43/bin [root@10-7-171-239 bin]# cat \u003e setenv.sh \u003c\u003cEOF #!/bin/bash JAVA_HOME=/usr/local/jdk TOMCAT_USER=tomcat JSVC_OPTS='-jvm server' JAVA_OPTS=\"-server -Xms3072m -Xmx3072m -Djava.security.egd=file:/dev/./urandom\" # 开启监控配置 #CATALINA_OPTS=\"${CATALINA_OPTS} -Dcom.sun.management.jmxremote.port=\u003c监听端口\u003e -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=\u003c本机ip地址\u003e -Dcom.sun.management.jmxremote\" EOF [root@10-7-171-239 bin]# useradd -r tomcat [root@10-7-171-239 apache-tomcat-9.0.43]# chown -R tomcat.tomcat /usr/local/apache-tomcat-9.0.43/ 注意 setenv.sh 配置文件中的 jvm 内存大小，请根据实际情况进行配置。 此时就可以使用 daemon.sh 脚本对 Tomcat 服务进行启停操作了 bash [root@10-7-171-239 apache-tomcat-9.0.43]# ./bin/daemon.sh start [root@10-7-171-239 apache-tomcat-9.0.43]# ps -ef | grep tomcat root 31610 1 0 11:54 ? 00:00:00 jsvc.exec -jvm server -java-home /usr/local/jdk -user tomcat -pidfile /usr/local/apache-tomcat-9.0.43/logs/catalina-daemon.pid -wait 10 -umask 0027 -outfile /usr/local/apache-tomcat-9.0.43/logs/catalina-daemon.out -errfile \u00261 -classpath /usr/local/apache-tomcat-9.0.43/bin/bootstrap.jar:/usr/local/apache-tomcat-9.0.43/bin/commons-daemon.jar:/usr/local/apache-tomcat-9.0.43/bin/tomcat-juli.jar -Djava.util.logging.config.file=/usr/local/apache-tomcat-9.0.43/conf/logging.properties -server -Xms512m -Xmx512m -Djava.security.egd=file:/dev/./urandom -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Dignore.endorsed.dirs= -Dcatalina.base=/usr/local/apache-tomcat-9.0.43 -Dcatalina.home=/usr/local/apache-tomcat-9.0.43 -Djava.io.tmpdir=/usr/local/apache-tomcat-9.0.43/temp org.apache.catalina.startup.Bootstrap tomcat 31611 31610 30 11:54 ? 00:00:03 jsvc.exec -jvm server -java-home /usr/local/jdk -user tomcat -pidfile /usr/local/apache-tomcat-9.0.43/logs/catalina-daemon.pid -wait 10 -umask 0027 -outfile /usr/local/apache-tomcat-9.0.43/logs/catalina-daemon.out -errfile \u00261 -classpath /usr/local/apache-tomcat-9.0.43/bin/bootstrap.jar:/usr/local/apache-tomcat-9.0.43/bin/commons-daemon.jar:/usr/local/apache-tomcat-9.0.43/bin/tomcat-juli.jar -Djava.util.logging.config.file=/usr/local/apache-tomcat-9.0.43/conf/logging.properties -server -Xms512m -Xmx512m -Djava.security.egd=file:/dev/./urandom -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Dignore.endorsed.dirs= -Dcatalina.base=/usr/local/apache-tomcat-9.0.43 -Dcatalina.home=/usr/local/apache-tomcat-9.0.43 -Djava.io.tmpdir=/usr/local/apache-tomcat-9.0.43/temp org.apache.catalina.startup.Bootstrap root 31645 29718 0 11:54 pts/0 00:00:00 grep --color=auto tomcat 从上面的进程信息可以看到 Tomcat 服务的进程，现在已经是使用的 tomcat 用户运行了。 ","date":"2021-02-22","objectID":"/posts/tomcat-optimization/:2:0","series":null,"tags":["tomcat"],"title":"Tomcat 配置及运行权限优化","uri":"/posts/tomcat-optimization/#运行权限优化"},{"categories":["devops","tomcat"],"content":" Tomcat 介绍Tomcat 是 Apache 软件基金会（Apache Software Foundation）项目中的一个核心项目，由 Apache、Sun 和其他一些公司及个人共同开发而成。 Tomcat 服务器是一个免费的开放源代码的 Web 应用服务器，属于轻量级应用服务器，在中小型系统和并发访问用户不是很多的场合下被普遍使用，是开发和调试 JSP 程序的首选。 实际生产环境中建议和 nginx 配合一起使用，nginx 处理静态，tomcat 处理动态程序 ","date":"2021-02-22","objectID":"/posts/tomcat-install/:1:0","series":null,"tags":["tomcat"],"title":"Tomcat 的简单使用","uri":"/posts/tomcat-install/#tomcat-介绍"},{"categories":["devops","tomcat"],"content":" 开始安装安装 tomcat 前需先安装 JDK 工具包。 JDK 是 java 语言的软件开发工具包，它包含了 java 的运行环境（jvm + java 系统类库）和 java 工具。 ","date":"2021-02-22","objectID":"/posts/tomcat-install/:2:0","series":null,"tags":["tomcat"],"title":"Tomcat 的简单使用","uri":"/posts/tomcat-install/#开始安装"},{"categories":["devops","tomcat"],"content":" 安装 JDK JDK 下载地址: https://www.oracle.com/java/technologies/javase-downloads.html 这里我们选择安装 JDK 8 bash [root@10-7-171-239 src]# wget https://download.oracle.com/otn/java/jdk/8u281-b09/89d678f2be164786b292527658ca1605/jdk-8u281-linux-x64.tar.gz?AuthParam=1614219040_36465185941d2c06fb1457b5fc724aee -O jdk-8u281-linux-x64.tar.gz [root@10-7-171-239 src]# tar xzf jdk-8u281-linux-x64.tar.gz -C /usr/local [root@10-7-171-239 src]# cd /usr/local/ [root@10-7-171-239 local]# ln -s jdk1.8.0_281/ jdk 配置 JDK 环境变量 bash [root@10-7-171-239 local]# cat \u003e /etc/profile.d/jdk.sh \u003c\u003c EOF \u003e export JAVA_HOME=/usr/local/jdk \u003e export PATH=\\$JAVA_HOME/bin:\\$PATH \u003e EOF [root@10-7-171-239 local]# source /etc/profile [root@10-7-171-239 local]# java -version java version \"1.8.0_281\" Java(TM) SE Runtime Environment (build 1.8.0_281-b09) Java HotSpot(TM) 64-Bit Server VM (build 25.281-b09, mixed mode) ","date":"2021-02-22","objectID":"/posts/tomcat-install/:2:1","series":null,"tags":["tomcat"],"title":"Tomcat 的简单使用","uri":"/posts/tomcat-install/#安装-jdk"},{"categories":["devops","tomcat"],"content":" 安装 Tomcat Tomcat 下载地址: https://tomcat.apache.org/download-90.cgi bash [root@10-7-171-239 src]# wget https://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-9/v9.0.43/bin/apache-tomcat-9.0.43.tar.gz [root@10-7-171-239 src]# tar xzf apache-tomcat-9.0.43.tar.gz -C /usr/local/ Tomcat 的安装很简单，只要下载解压即可开始使用 ","date":"2021-02-22","objectID":"/posts/tomcat-install/:2:2","series":null,"tags":["tomcat"],"title":"Tomcat 的简单使用","uri":"/posts/tomcat-install/#安装-tomcat"},{"categories":["devops","tomcat"],"content":" Tomcat 服务启停介绍默认 Tomcat 启动可以直接执行 bin 目录的 startup.sh 脚本，停止使用 shutdown.sh 脚本，如果你查看这两个脚本文件中的内容会发现它们都是通过调用 catalina.sh 脚本并传递相应的参数进行启动的。 所以我们可以直接使用 .catalina.sh 脚本进行 Tomcat 服务的启动与停止. catalina.sh 脚本帮助信息 bash [root@10-7-171-239 bin]# ./catalina.sh Using CATALINA_BASE: /usr/local/apache-tomcat-9.0.43 Using CATALINA_HOME: /usr/local/apache-tomcat-9.0.43 Using CATALINA_TMPDIR: /usr/local/apache-tomcat-9.0.43/temp Using JRE_HOME: /usr/local/jdk Using CLASSPATH: /usr/local/apache-tomcat-9.0.43/bin/bootstrap.jar:/usr/local/apache-tomcat-9.0.43/bin/tomcat-juli.jar Using CATALINA_OPTS: Usage: catalina.sh ( commands ... ) commands: debug Start Catalina in a debugger debug -security Debug Catalina with a security manager jpda start Start Catalina under JPDA debugger run Start Catalina in the current window run -security Start in the current window with security manager start Start Catalina in a separate window start -security Start in a separate window with security manager stop Stop Catalina, waiting up to 5 seconds for the process to end stop n Stop Catalina, waiting up to n seconds for the process to end stop -force Stop Catalina, wait up to 5 seconds and then use kill -KILL if still running stop n -force Stop Catalina, wait up to n seconds and then use kill -KILL if still running configtest Run a basic syntax check on server.xml - check exit code for result version What version of tomcat are you running? Note: Waiting for the process to end and use of the -force option require that $CATALINA_PID is defined ","date":"2021-02-22","objectID":"/posts/tomcat-install/:2:3","series":null,"tags":["tomcat"],"title":"Tomcat 的简单使用","uri":"/posts/tomcat-install/#tomcat-服务启停介绍"},{"categories":["devops","tomcat"],"content":" 启动 Tomcat 服务 bash [root@10-7-171-239 apache-tomcat-9.0.43]# /usr/local/apache-tomcat-9.0.43/bin/startup.sh Using CATALINA_BASE: /usr/local/apache-tomcat-9.0.43 Using CATALINA_HOME: /usr/local/apache-tomcat-9.0.43 Using CATALINA_TMPDIR: /usr/local/apache-tomcat-9.0.43/temp Using JRE_HOME: /usr/local/jdk Using CLASSPATH: /usr/local/apache-tomcat-9.0.43/bin/bootstrap.jar:/usr/local/apache-tomcat-9.0.43/bin/tomcat-juli.jar Using CATALINA_OPTS: Tomcat started. [root@10-7-171-239 apache-tomcat-9.0.43]# ss -anptl | grep java LISTEN 0 1 ::ffff:127.0.0.1:8005 :::* users:((\"java\",pid=30004,fd=68)) LISTEN 0 100 :::8080 :::* users:((\"java\",pid=30004,fd=57)) Tomcat 默认监听于 8080 端口，直接在浏览器上访问 http://\u003cyour_server_ipaddress\u003e:8080 bash [root@10-7-171-239 apache-tomcat-9.0.43]# ps -ef | grep tomcat root 30004 1 8 10:23 pts/0 00:00:02 /usr/local/jdk/bin/java -Djava.util.logging.config.file=/usr/local/apache-tomcat-9.0.43/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -Dorg.apache.catalina.security.SecurityListener.UMASK=0027 -Dignore.endorsed.dirs= -classpath /usr/local/apache-tomcat-9.0.43/bin/bootstrap.jar:/usr/local/apache-tomcat-9.0.43/bin/tomcat-juli.jar -Dcatalina.base=/usr/local/apache-tomcat-9.0.43 -Dcatalina.home=/usr/local/apache-tomcat-9.0.43 -Djava.io.tmpdir=/usr/local/apache-tomcat-9.0.43/temp org.apache.catalina.startup.Bootstrap start root 30038 29718 0 10:24 pts/0 00:00:00 grep --color=auto tomcat 通过查看 tomcat 进程可以看到 tomcat 默认使用 root 用户启动，这会存在安全风险，那该如何使用普通用户启动呢？ ","date":"2021-02-22","objectID":"/posts/tomcat-install/:2:4","series":null,"tags":["tomcat"],"title":"Tomcat 的简单使用","uri":"/posts/tomcat-install/#启动-tomcat-服务"},{"categories":["devops","tomcat"],"content":" Tomcat 目录结构 bash [root@10-7-171-239 apache-tomcat-9.0.43]# tree -L 1 -d . ├── bin # 管理脚本存放路径 ├── conf # 配置文件目录 ├── lib # 公共程序库目录 ├── logs # 日志目录 ├── temp ├── webapps # 默认 web 应用程序目录 └── work ","date":"2021-02-22","objectID":"/posts/tomcat-install/:3:0","series":null,"tags":["tomcat"],"title":"Tomcat 的简单使用","uri":"/posts/tomcat-install/#tomcat-目录结构"},{"categories":["devops","tomcat"],"content":" webapps 目录webapps 目录存放都是 web 应用，每个目录都是单独的应用。其中 ROOT 比较特殊，ROOT 目录中的应用是打开网页可以直接访问到的，例如 http://localhost:8080 访问的是 ROOT 目录中的应用，如果需要访问 docs 应用需要在 url 上加上 http://localhost:8080/docs/ 路径。 bash [root@10-7-171-239 apache-tomcat-9.0.43]# tree webapps -L 1 -d webapps ├── docs ├── examples ├── host-manager ├── manager └── ROOT 默认 webapps 中有 Tomcat 自带管理应用，不用可以移除。 ","date":"2021-02-22","objectID":"/posts/tomcat-install/:3:1","series":null,"tags":["tomcat"],"title":"Tomcat 的简单使用","uri":"/posts/tomcat-install/#webapps-目录"},{"categories":["devops","tomcat"],"content":" 配置 Tomcat","date":"2021-02-22","objectID":"/posts/tomcat-install/:4:0","series":null,"tags":["tomcat"],"title":"Tomcat 的简单使用","uri":"/posts/tomcat-install/#配置-tomcat"},{"categories":["devops","tomcat"],"content":" 配置介绍Tomcat 的配置文件存放在 conf 目录中，其中 server.xml 为主配置文件。默认配置信息如下 xml \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!-- port: tomcat 服务管理端口， shutdown: 服务停止字符，如果从服务管理端口接收到此字符 tomcat 服务将会停止， 有安全风险，建议更改为更复杂的字符串。 可以使用 cat /dev/urandom | head -n 1 | md5sum 生成 --\u003e \u003cServer port=\"8005\" shutdown=\"SHUTDOWN\"\u003e \u003cListener className=\"org.apache.catalina.startup.VersionLoggerListener\" /\u003e \u003cListener className=\"org.apache.catalina.core.AprLifecycleListener\" SSLEngine=\"on\" /\u003e \u003cListener className=\"org.apache.catalina.core.JreMemoryLeakPreventionListener\" /\u003e \u003cListener className=\"org.apache.catalina.mbeans.GlobalResourcesLifecycleListener\" /\u003e \u003cListener className=\"org.apache.catalina.core.ThreadLocalLeakPreventionListener\" /\u003e \u003cGlobalNamingResources\u003e \u003cResource name=\"UserDatabase\" auth=\"Container\" type=\"org.apache.catalina.UserDatabase\" description=\"User database that can be updated and saved\" factory=\"org.apache.catalina.users.MemoryUserDatabaseFactory\" pathname=\"conf/tomcat-users.xml\" /\u003e \u003c/GlobalNamingResources\u003e \u003cService name=\"Catalina\"\u003e \u003c!-- HTTP 服务监听的端口 --\u003e \u003cConnector port=\"8080\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" /\u003e \u003c!-- defaultHost: 定义缺省处理请求的虚拟主机域名 --\u003e \u003cEngine name=\"Catalina\" defaultHost=\"localhost\"\u003e \u003cRealm className=\"org.apache.catalina.realm.LockOutRealm\"\u003e \u003cRealm className=\"org.apache.catalina.realm.UserDatabaseRealm\" resourceName=\"UserDatabase\"/\u003e \u003c/Realm\u003e \u003c!-- 虚拟主机定义, name: 域名， appBase: WEB 应用程序路径 --\u003e \u003cHost name=\"localhost\" appBase=\"webapps\" unpackWARs=\"true\" autoDeploy=\"true\"\u003e \u003cValve className=\"org.apache.catalina.valves.AccessLogValve\" directory=\"logs\" prefix=\"localhost_access_log\" suffix=\".txt\" pattern=\"%h %l %u %t \u0026quot;%r\u0026quot; %s %b\" /\u003e \u003c/Host\u003e \u003c/Engine\u003e \u003c/Service\u003e \u003c/Server\u003e ","date":"2021-02-22","objectID":"/posts/tomcat-install/:4:1","series":null,"tags":["tomcat"],"title":"Tomcat 的简单使用","uri":"/posts/tomcat-install/#配置介绍"},{"categories":["devops","tomcat"],"content":" Tomcat url 路径配置如果想让 Tomcat 的根指向为 webapps 中的 test 应用该如何配置？？ 准备测试数据 bash [root@10-7-171-239 webapps]# mkdir test [root@10-7-171-239 webapps]# echo 'hello test file' \u003e test/index.html 修改 server.xml 配置文件, 在 Host 节点加入 Context 配置项，具体内容如下 xml \u003cContext path=\"/\" docBase=\"test/\" reloadable=\"false\" debug=\"0\" /\u003e path: 指定 url 路径，如果是 / 可以忽略不写 docBase: 用于指定 WEB 应用路径，可以是相当路径（相对于 Host 的 appBase 属性的值），也可以是绝对路径 reloadable: 是否自动重载，建议\b值设置为 false，此属性会影响服务性能 重启服务，测试 bash [root@10-7-171-239 apache-tomcat-9.0.43]# ./bin/shutdown.sh [root@10-7-171-239 apache-tomcat-9.0.43]# ./bin/startup.sh [root@10-7-171-239 apache-tomcat-9.0.43]# curl localhost:8080 hello test file ","date":"2021-02-22","objectID":"/posts/tomcat-install/:4:2","series":null,"tags":["tomcat"],"title":"Tomcat 的简单使用","uri":"/posts/tomcat-install/#tomcat-url-路径配置"},{"categories":["devops","keepalived","lvs"],"content":" 环境准备两台调度服务器: 安装 keepalived + ipvsadm 两台真实服务器: 安装 nginx 提供 Web 服务 web-01: 192.168.31.31/24 web-02: 192.168.31.32/24 lb-01: 192.168.31.33/24 lb-02: 192.168.31.34/24 vip: 192.168.31.30 ","date":"2021-02-21","objectID":"/posts/keepalived-lvs-dr/:1:0","series":null,"tags":["keepalived","lvs","ipvsadm"],"title":"Keepalived 实现 LVS 高可用负载均衡群集","uri":"/posts/keepalived-lvs-dr/#环境准备"},{"categories":["devops","keepalived","lvs"],"content":" 配置 Real Server 服务器安装 nginx 来提供一个简单 Web 页面用来测试 web-01 bash root@web-01:~# apt install nginx root@web-01:~# echo '\u003ch1\u003eWelcome to nginx 11111111111!\u003c/h1\u003e' \u003e /var/www/html/index.nginx-debian.html root@web-01:~# systemctl start nginx root@web-01:~# curl localhost \u003ch1\u003eWelcome to nginx 11111111111!\u003c/h1\u003e web-02 bash root@web-02:~# apt install nginx root@web-02:~# echo '\u003ch1\u003eWelcome to nginx 22222222!\u003c/h1\u003e' \u003e /var/www/html/index.nginx-debian.html root@web-02:~# systemctl start nginx root@web-02:~# curl localhost \u003ch1\u003eWelcome to nginx 22222222!\u003c/h1\u003e ","date":"2021-02-21","objectID":"/posts/keepalived-lvs-dr/:2:0","series":null,"tags":["keepalived","lvs","ipvsadm"],"title":"Keepalived 实现 LVS 高可用负载均衡群集","uri":"/posts/keepalived-lvs-dr/#配置-real-server-服务器"},{"categories":["devops","keepalived","lvs"],"content":" 配置 lvs 调用可用集群","date":"2021-02-21","objectID":"/posts/keepalived-lvs-dr/:3:0","series":null,"tags":["keepalived","lvs","ipvsadm"],"title":"Keepalived 实现 LVS 高可用负载均衡群集","uri":"/posts/keepalived-lvs-dr/#配置-lvs-调用可用集群"},{"categories":["devops","keepalived","lvs"],"content":" 安装 keepalived 与 ipvs 管理工具 bash root@lb-01:~# apt install keepalived ipvsadm ","date":"2021-02-21","objectID":"/posts/keepalived-lvs-dr/:3:1","series":null,"tags":["keepalived","lvs","ipvsadm"],"title":"Keepalived 实现 LVS 高可用负载均衡群集","uri":"/posts/keepalived-lvs-dr/#安装-keepalived-与-ipvs-管理工具"},{"categories":["devops","keepalived","lvs"],"content":" 配置 keepalived配置主节点 /etc/keepalived/keepalived.conf config ! Configuration File for keepalived global_defs { router_id LVS_DEVEL } vrrp_instance VI_1 { state MASTER interface ens32 virtual_router_id 50 priority 100 advert_int 1 nopreempt authentication { auth_type PASS auth_pass 11111 } virtual_ipaddress { 192.168.31.30 } } virtual_server 192.168.31.31 80 { delay_loop 6 ! 使用 rr 调度算法 lb_algo rr ! 使用 DR 直接路由工作方式 lb_kind DR ! 会话保持时间，单位是秒。这个选项对动态网页是非常有用的，为集群系统中的 SEEION 共享 ! 提供了一个很好的解决方案。有了这个会话保持功能，用户的请求会一直分发到同一个服务节点， ! 直到超过这个会话的保持时间。 注意: 这个会话保持时间是最大无响应超时时间。如果用户一直 ! 在操作动态页面，是不受这个时间限制的。 persistence_timeout 50 ! 使用转发的协议类型， 也可以是 UDP protocol TCP ! 真实提供服务器的机器 real_server 192.168.31.31 80 { ! 定义权重 weight 3 ! real_server 状态检测，单位为秒 TCP_CHECK { ! 表示3秒无响应超时 connect_timeout 3 ! 表示重试次数 nb_get_retry 3 ! 重试间隔 delay_before_retry 3 } } real_server 192.168.31.32 80 { weight 3 TCP_CHECK { connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } } } 配置备用节点 /etc/keepalived/keepalived.conf config ! Configuration File for keepalived global_defs { router_id LVS_DEVEL } vrrp_instance VI_1 { state BACKUP interface ens32 virtual_router_id 50 priority 90 advert_int 1 authentication { auth_type PASS auth_pass 11111 } virtual_ipaddress { 192.168.31.30 } } virtual_server 192.168.31.31 80 { delay_loop 6 lb_algo rr lb_kind DR persistence_timeout 50 protocol TCP real_server 192.168.31.31 80 { weight 3 TCP_CHECK { connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } } real_server 192.168.31.32 80 { weight 3 TCP_CHECK { connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } } } ","date":"2021-02-21","objectID":"/posts/keepalived-lvs-dr/:3:2","series":null,"tags":["keepalived","lvs","ipvsadm"],"title":"Keepalived 实现 LVS 高可用负载均衡群集","uri":"/posts/keepalived-lvs-dr/#配置-keepalived"},{"categories":["devops","keepalived","lvs"],"content":" 启动 keepalivd 服务启动 keepalived 服务并查看 ipvs 规则， vip 配置情况 bash root@lb-01:/etc/keepalived# systemctl start keepalived.service root@lb-01:/etc/keepalived# ipvsadm -Ln IP Virtual Server version 1.2.1 (size=4096) Prot LocalAddress:Port Scheduler Flags -\u003e RemoteAddress:Port Forward Weight ActiveConn InActConn TCP 192.168.31.30:80 rr persistent 50 -\u003e 192.168.31.31:80 Route 3 0 0 -\u003e 192.168.31.32:80 Route 3 0 0 root@lb-01:/etc/keepalived# ip addr show ens32 2: ens32: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 00:0c:29:af:9c:1f brd ff:ff:ff:ff:ff:ff inet 192.168.31.33/24 brd 192.168.31.255 scope global ens32 valid_lft forever preferred_lft forever inet 192.168.31.30/32 scope global ens32 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:feaf:9c1f/64 scope link valid_lft forever preferred_lft forever 备用节点的 keepalived 服务也启动起来 ","date":"2021-02-21","objectID":"/posts/keepalived-lvs-dr/:3:3","series":null,"tags":["keepalived","lvs","ipvsadm"],"title":"Keepalived 实现 LVS 高可用负载均衡群集","uri":"/posts/keepalived-lvs-dr/#启动-keepalivd-服务"},{"categories":["devops","keepalived","lvs"],"content":" 配置 RealServer由于 lvs 的 DR 方式，需要在两台 Real Server 上也配置 vip 地址，并且还需要抑制 arp 广播。 使用以下脚本完成。 bash #!/bin/bash # # filename: lvs-vip.sh # VIP=192.168.31.30 INTERFACE=lo case $1 in start) echo 1 \u003e /proc/sys/net/ipv4/conf/all/arp_ignore echo 1 \u003e /proc/sys/net/ipv4/conf/lo/arp_ignore echo 2 \u003e /proc/sys/net/ipv4/conf/all/arp_announce echo 2 \u003e /proc/sys/net/ipv4/conf/lo/arp_announce ip addr add ${VIP}/32 brd ${VIP} dev $INTERFACE echo \"The RS Server is Ready!\" ;; stop) ip addr del ${VIP}/32 brd ${VIP} dev $INTERFACE echo 0 \u003e /proc/sys/net/ipv4/conf/all/arp_ignore echo 0 \u003e /proc/sys/net/ipv4/conf/lo/arp_ignore echo 0 \u003e /proc/sys/net/ipv4/conf/all/arp_announce echo 0 \u003e /proc/sys/net/ipv4/conf/lo/arp_announce echo \"The RS Server is Canceled!\" ;; *) echo $\"Usage: $0 {start|stop|restart}\" exit 1 ;; esac 启用 vip bash root@web-01:~# mv lvs-vip.sh /usr/local/bin/ root@web-01:~# chmod +x /usr/local/bin/lvs-vip.sh root@web-01:~# lvs-vip.sh start The RS Server is Ready! ","date":"2021-02-21","objectID":"/posts/keepalived-lvs-dr/:3:4","series":null,"tags":["keepalived","lvs","ipvsadm"],"title":"Keepalived 实现 LVS 高可用负载均衡群集","uri":"/posts/keepalived-lvs-dr/#配置-realserver"},{"categories":["devops","keepalived","lvs"],"content":" 测试 lvs 高可用集群测试过程略，请自行测试… 可以将主 lvs 服务器宕机，然后查看服务是否会中断， 备用 lvs 服务器是否能接手，并正确配置 vip 提供调度服务。 ","date":"2021-02-21","objectID":"/posts/keepalived-lvs-dr/:4:0","series":null,"tags":["keepalived","lvs","ipvsadm"],"title":"Keepalived 实现 LVS 高可用负载均衡群集","uri":"/posts/keepalived-lvs-dr/#测试-lvs-高可用集群"},{"categories":["devops","keepalived"],"content":" Keepalived 介绍Keepalived 是一个基于 VRRP 协议来实现的 WEB 服务高可用方案，可以利用其来避免单点故障。使用多台节点安装keepalived。其他的节点用来提供真实的服务（RealServer），同样的，他们对外表现一个虚拟的IP（vip）。主服务器宕机的时候，备份服务器就会接管虚拟IP，继续提供服务，从而保证了高可用性。 ","date":"2021-02-21","objectID":"/posts/keepalived/:1:0","series":null,"tags":["keepalived"],"title":"Keepalived 高可用简单入门","uri":"/posts/keepalived/#keepalived-介绍"},{"categories":["devops","keepalived"],"content":" Keepalived 简单应用 拓扑图 ","date":"2021-02-21","objectID":"/posts/keepalived/:2:0","series":null,"tags":["keepalived"],"title":"Keepalived 高可用简单入门","uri":"/posts/keepalived/#keepalived-简单应用"},{"categories":["devops","keepalived"],"content":" 环境准备本次实验需要准备2台后端 Web 服务器，用于提供真实服务，最前端挂2台 nginx 反向代理并安装 keepalived 实现高可用。 总共4台机器。 实现的目的 当用户请求 web 服务器时，请求先到 keeplived 主服务器，然后 keepalived 主服务器根据 nginx 的负载均衡配置规则 选择 1台后端的 web 服务器将用户的请求转发给它，keepalived 主服务器拿到相应的数据后在响应给用户。如果keepalived 主服务器的 nginx 服务挂了，将由备份 keepalived 服务器接手为用户提供服务。 nginx：反向代理、负载均衡配置参考 nginx 文档 ","date":"2021-02-21","objectID":"/posts/keepalived/:2:1","series":null,"tags":["keepalived"],"title":"Keepalived 高可用简单入门","uri":"/posts/keepalived/#环境准备"},{"categories":["devops","keepalived"],"content":" 安装配置 keepalived","date":"2021-02-21","objectID":"/posts/keepalived/:3:0","series":null,"tags":["keepalived"],"title":"Keepalived 高可用简单入门","uri":"/posts/keepalived/#安装配置-keepalived"},{"categories":["devops","keepalived"],"content":" 安装 keepalived bash root@lb-01:~# apt install keepalived # 复制一份示例配置文件 root@lb-01:~# cp /usr/share/doc/keepalived/samples/keepalived.conf.sample /etc/keepalived/keepalived.conf ","date":"2021-02-21","objectID":"/posts/keepalived/:3:1","series":null,"tags":["keepalived"],"title":"Keepalived 高可用简单入门","uri":"/posts/keepalived/#安装-keepalived"},{"categories":["devops","keepalived"],"content":" keepalived 高可用配置keepalived 的配置文件默认位于：/etc/keepalived/keepalived.conf config ! Configuration File for keepalived global_defs { ! 运行Keepalived服务器的一个标识，发邮件时显示在邮件主题中。 router_id LVS_DEVEL } ! 定义 nginx 服务检测脚本 vrrp_script check_nginx { script \"/bin/bash /etc/keepalived/chk_ngx.sh\" ! 检查时间间隔，2秒 interval 2 } ! 定义高可用实例 vrrp_instance VI_1 { ! 指明当前服务的角色，备用为 BACKUP state MASTER ! 指定监测的网络接口 interface ens32 ! 虚拟路由标识，同一个实例使用唯一的标识，master与backup必须是一致的 virtual_router_id 50 ! 定义节点的优先级，数字越大，优先级越高。 priority 100 ! 主从主机之间同步检查的时间间隔 advert_int 1 ! 不抢占，恢复后不进行切换，主挂了再起来不会抢回身份。防止 vip 飘来飘去影响稳定性 nopreempt ! 用于设置节点间通信验证类型和密码 authentication { auth_type PASS auth_pass 11111 } ! 设置虚拟 ip 地址 virtual_ipaddress { 192.168.31.30 } ! 检查条件 track_script { check_nginx } } /etc/keepalived/chk_ngx.sh bash #!/bin/bash /bin/pidof nginx \u0026\u003e /dev/null ## 也可使用 killall -0 nginx 探测服务状态 if [[ $? -ne 0 ]]; then echo 'nginx is stop' exit 1 fi 将 keepalived.conf 和 chk_ngx.sh 复制到备份主机上，修改 keepalived.conf 文件 state BACKUP, priority 90, 删除 nopreempt 即可。 ","date":"2021-02-21","objectID":"/posts/keepalived/:3:2","series":null,"tags":["keepalived"],"title":"Keepalived 高可用简单入门","uri":"/posts/keepalived/#keepalived-高可用配置"},{"categories":["devops","keepalived"],"content":" 安装反代和Web服务","date":"2021-02-21","objectID":"/posts/keepalived/:4:0","series":null,"tags":["keepalived"],"title":"Keepalived 高可用简单入门","uri":"/posts/keepalived/#安装反代和web服务"},{"categories":["devops","keepalived"],"content":" 安装 Web 服务这里使用 nginx 来提供一个简单 Web 页面用来测试 web-01 bash root@web-01:~# apt install nginx root@web-01:~# echo '\u003ch1\u003eWelcome to nginx 11111111111!\u003c/h1\u003e' \u003e /var/www/html/index.nginx-debian.html root@web-01:~# systemctl start nginx root@web-01:~# curl localhost \u003ch1\u003eWelcome to nginx 11111111111!\u003c/h1\u003e web-02 bash root@web-02:~# apt install nginx root@web-02:~# echo '\u003ch1\u003eWelcome to nginx 22222222!\u003c/h1\u003e' \u003e /var/www/html/index.nginx-debian.html root@web-02:~# systemctl start nginx root@web-02:~# curl localhost \u003ch1\u003eWelcome to nginx 22222222!\u003c/h1\u003e ","date":"2021-02-21","objectID":"/posts/keepalived/:4:1","series":null,"tags":["keepalived"],"title":"Keepalived 高可用简单入门","uri":"/posts/keepalived/#安装-web-服务"},{"categories":["devops","keepalived"],"content":" 安装配置 nginx 反向代理在两台 keepalived 机器上安装 nginx 并配置反向代理到后端两台 Web 服务器, 两台机的配置是一样的。 bash root@lb-01:~# apt install nginx root@lb-01:~# cat /etc/nginx/sites-available/default upstream web { server 192.168.31.31; server 192.168.31.32; } server { listen 80 default_server; listen [::]:80 default_server; root /var/www/html; index index.html index.htm index.nginx-debian.html; server_name _; location / { proxy_pass http://web; } } root@lb-01:~# systemctl restart nginx ","date":"2021-02-21","objectID":"/posts/keepalived/:4:2","series":null,"tags":["keepalived"],"title":"Keepalived 高可用简单入门","uri":"/posts/keepalived/#安装配置-nginx-反向代理"},{"categories":["devops","keepalived"],"content":" 测试 keepalived 高可用","date":"2021-02-21","objectID":"/posts/keepalived/:5:0","series":null,"tags":["keepalived"],"title":"Keepalived 高可用简单入门","uri":"/posts/keepalived/#测试-keepalived-高可用"},{"categories":["devops","keepalived"],"content":" 启用 keepalived 服务 bash root@lb-01:~# systemctl start keepalived.service root@lb-01:~# ip addr 1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens32: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 00:0c:29:af:9c:1f brd ff:ff:ff:ff:ff:ff inet 192.168.31.33/24 brd 192.168.31.255 scope global ens32 valid_lft forever preferred_lft forever inet 192.168.31.30/32 scope global ens32 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:feaf:9c1f/64 scope link valid_lft forever preferred_lft forever 日志信息 text Feb 27 08:10:46 lb-01 systemd[1]: Starting Keepalive Daemon (LVS and VRRP)... Feb 27 08:10:46 lb-01 Keepalived[8259]: Starting Keepalived v1.3.9 (10/21,2017) Feb 27 08:10:46 lb-01 Keepalived[8259]: Opening file '/etc/keepalived/keepalived.conf'. Feb 27 08:10:46 lb-01 systemd[1]: Started Keepalive Daemon (LVS and VRRP). Feb 27 08:10:46 lb-01 Keepalived[8275]: Starting Healthcheck child process, pid=8276 Feb 27 08:10:46 lb-01 Keepalived[8275]: Starting VRRP child process, pid=8277 Feb 27 08:10:46 lb-01 Keepalived_healthcheckers[8276]: Opening file '/etc/keepalived/keepalived.conf'. Feb 27 08:10:46 lb-01 Keepalived_vrrp[8277]: Registering Kernel netlink reflector Feb 27 08:10:46 lb-01 Keepalived_vrrp[8277]: Registering Kernel netlink command channel Feb 27 08:10:46 lb-01 Keepalived_vrrp[8277]: Registering gratuitous ARP shared channel Feb 27 08:10:46 lb-01 Keepalived_vrrp[8277]: Opening file '/etc/keepalived/keepalived.conf'. Feb 27 08:10:46 lb-01 Keepalived_vrrp[8277]: WARNING - default user 'keepalived_script' for script execution does not exist - please create. Feb 27 08:10:46 lb-01 Keepalived_vrrp[8277]: (VI_1): Warning - nopreempt will not work with initial state MASTER Feb 27 08:10:46 lb-01 Keepalived_vrrp[8277]: SECURITY VIOLATION - scripts are being executed but script_security not enabled. Feb 27 08:10:46 lb-01 Keepalived_vrrp[8277]: Using LinkWatch kernel netlink reflector... Feb 27 08:10:46 lb-01 Keepalived_vrrp[8277]: VRRP_Script(check_nginx) succeeded Feb 27 08:10:47 lb-01 Keepalived_vrrp[8277]: VRRP_Instance(VI_1) Transition to MASTER STATE Feb 27 08:10:48 lb-01 Keepalived_vrrp[8277]: VRRP_Instance(VI_1) Entering MASTER STATE 从上面的信息可以看到， keepalived 自动为 ens32 网卡添加一个 vip，服务角色为 master 开启备份节点服务 bash root@lb-02:/etc/keepalived# systemctl start keepalived.service ","date":"2021-02-21","objectID":"/posts/keepalived/:5:1","series":null,"tags":["keepalived"],"title":"Keepalived 高可用简单入门","uri":"/posts/keepalived/#启用-keepalived-服务"},{"categories":["devops","keepalived"],"content":" 测试测试使用 vip 访问 Web 服务 bash root@web-01:~# while :; do curl 192.168.31.30; sleep .5; done \u003ch1\u003eWelcome to nginx 22222222!\u003c/h1\u003e \u003ch1\u003eWelcome to nginx 11111111111!\u003c/h1\u003e \u003ch1\u003eWelcome to nginx 22222222!\u003c/h1\u003e \u003ch1\u003eWelcome to nginx 11111111111!\u003c/h1\u003e \u003ch1\u003eWelcome to nginx 22222222!\u003c/h1\u003e \u003ch1\u003eWelcome to nginx 11111111111!\u003c/h1\u003e 停止 keepalived 主服务的 nginx 服务，查看 vip 是否转移。Web 服务是否可用。 bash root@lb-01:~# systemctl stop nginx 主节点日志信息 text Feb 27 08:17:15 lb-01 systemd[1]: Stopping A high performance web server and a reverse proxy server... Feb 27 08:17:15 lb-01 systemd[1]: Stopped A high performance web server and a reverse proxy server. Feb 27 08:17:17 lb-01 Keepalived_vrrp[8277]: /bin/bash /etc/keepalived/chk_ngx.sh exited with status 1 Feb 27 08:17:17 lb-01 Keepalived_vrrp[8277]: VRRP_Script(check_nginx) failed Feb 27 08:17:18 lb-01 Keepalived_vrrp[8277]: VRRP_Instance(VI_1) Entering FAULT STATE Feb 27 08:17:18 lb-01 Keepalived_vrrp[8277]: VRRP_Instance(VI_1) Now in FAULT state Feb 27 08:17:19 lb-01 Keepalived_vrrp[8277]: /bin/bash /etc/keepalived/chk_ngx.sh exited with status 1 日志信息表明，检测到 nginx 服务停止，检测失败，keepalived 进入 FAULT 状态。 查看备用节点的日志和网卡信息 tail root@lb-02:/etc/keepalived# systemctl start keepalived.service root@lb-02:/etc/keepalived# tail /var/log/syslog Feb 27 08:14:08 ubuntu Keepalived_vrrp[10287]: Registering gratuitous ARP shared channel Feb 27 08:14:08 ubuntu Keepalived_vrrp[10287]: Opening file '/etc/keepalived/keepalived.conf'. Feb 27 08:14:08 ubuntu Keepalived_vrrp[10287]: WARNING - default user 'keepalived_script' for script execution does not exist - please create. Feb 27 08:14:08 ubuntu Keepalived_vrrp[10287]: SECURITY VIOLATION - scripts are being executed but script_security not enabled. Feb 27 08:14:08 ubuntu Keepalived_vrrp[10287]: Using LinkWatch kernel netlink reflector... Feb 27 08:14:08 ubuntu Keepalived_vrrp[10287]: VRRP_Instance(VI_1) Entering BACKUP STATE Feb 27 08:14:08 ubuntu Keepalived_vrrp[10287]: VRRP_Script(check_nginx) succeeded Feb 27 08:17:01 ubuntu CRON[10641]: (root) CMD ( cd / \u0026\u0026 run-parts --report /etc/cron.hourly) Feb 27 08:17:18 ubuntu Keepalived_vrrp[10287]: VRRP_Instance(VI_1) Transition to MASTER STATE Feb 27 08:17:19 ubuntu Keepalived_vrrp[10287]: VRRP_Instance(VI_1) Entering MASTER STATE root@lb-02:/etc/keepalived# ip addr 1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens32: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 00:0c:29:0c:ee:46 brd ff:ff:ff:ff:ff:ff inet 192.168.31.34/24 brd 192.168.31.255 scope global ens32 valid_lft forever preferred_lft forever inet 192.168.31.30/32 scope global ens32 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:fe0c:ee46/64 scope link valid_lft forever preferred_lft forever 从日志和网卡信息可以看出，备用节点接替了主节点的 vip ，并将自己提升为主节点 客户端请求测试信息 text \u003ch1\u003eWelcome to nginx 22222222!\u003c/h1\u003e \u003ch1\u003eWelcome to nginx 11111111111!\u003c/h1\u003e curl: (7) Failed to connect to 192.168.31.30 port 80: Connection refused curl: (7) Failed to connect to 192.168.31.30 port 80: Connection refused curl: (7) Failed to connect to 192.168.31.30 port 80: Connection refused curl: (7) Failed to connect to 192.168.31.30 port 80: Connection refused curl: (7) Failed to connect to 192.168.31.30 port 80: Connection refused \u003ch1\u003eWelcome to nginx 22222222!\u003c/h1\u003e \u003ch1\u003eWelcome to nginx 11111111111!\u003c/h1\u003e \u003ch1\u003eWelcome to nginx 22222222!\u003c/h1\u003e 可以看到在 vip 切换时，有一些无法响应的请求，之后又立即恢复了 ","date":"2021-02-21","objectID":"/posts/keepalived/:5:2","series":null,"tags":["keepalived"],"title":"Keepalived 高可用简单入门","uri":"/posts/keepalived/#测试"},{"categories":["devops","lvs"],"content":" 环境准备 Director Server: 192.168.31.33/24 Real Server 1: 192.168.31.31/24 Real Server 2: 192.168.31.32/24 VIP: 192.168.31.30/32 ","date":"2021-02-20","objectID":"/posts/lvs-configure/:1:0","series":null,"tags":["lvs","ipvsadm"],"title":"配置 LVS DR 负载均衡","uri":"/posts/lvs-configure/#环境准备"},{"categories":["devops","lvs"],"content":" 安装配置 ipvs","date":"2021-02-20","objectID":"/posts/lvs-configure/:2:0","series":null,"tags":["lvs","ipvsadm"],"title":"配置 LVS DR 负载均衡","uri":"/posts/lvs-configure/#安装配置-ipvs"},{"categories":["devops","lvs"],"content":" 安装 ipvs 管理软件在 Director Server 上安装 ipvsadm bash root@lb-01:~# apt install ipvsadm ","date":"2021-02-20","objectID":"/posts/lvs-configure/:2:1","series":null,"tags":["lvs","ipvsadm"],"title":"配置 LVS DR 负载均衡","uri":"/posts/lvs-configure/#安装-ipvs-管理软件"},{"categories":["devops","lvs"],"content":" 配置 ipvs配置 vip bash root@lb-01:~# ip addr add 192.168.31.30/32 brd 192.168.31.30 dev ens32 root@lb-01:~# ip addr show ens32 2: ens32: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 00:0c:29:af:9c:1f brd ff:ff:ff:ff:ff:ff inet 192.168.31.33/24 brd 192.168.31.255 scope global ens32 valid_lft forever preferred_lft forever inet 192.168.31.30/32 brd 192.168.31.30 scope global ens32 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:feaf:9c1f/64 scope link valid_lft forever preferred_lft forever 配置 ipvs 规则 bash # 清空 ipvsadm 配置表 root@lb-01:~# ipvsadm -C # 设置连接超时值 root@lb-01:~# ipvsadm --set 30 5 60 # 添加虚拟服务器 root@lb-01:~# ipvsadm -A -t 192.168.31.30:80 -s rr -p 20 # 向虚拟服务器添加 RealServer root@lb-01:~# ipvsadm -a -t 192.168.31.30:80 -r 192.168.31.31:80 -g -w 1 root@lb-01:~# ipvsadm -a -t 192.168.31.30:80 -r 192.168.31.32:80 -g -w 1 # 查看 lvs 状态 root@lb-01:~# ipvsadm -L -n --stats IP Virtual Server version 1.2.1 (size=4096) Prot LocalAddress:Port Conns InPkts OutPkts InBytes OutBytes -\u003e RemoteAddress:Port TCP 192.168.31.30:80 0 0 0 0 0 -\u003e 192.168.31.31:80 0 0 0 0 0 -\u003e 192.168.31.32:80 0 0 0 0 0 参数说明 -C: 清空 ipvs 所有规则 -A: 添加虚拟服务器 -t: 使用 tcp 协议, 后接虚拟服务器的 ip 地址和端口 -s: 使用的调度算法 -p: 定义持久时间，能够实现将来自同一个地址的请求始终发往同一个 RealServer -a: 添加 RealServer -r: 指定 RealServer 地址和端口 -g: 使用的 DR 实现方式 -w: RealServer 服务器的权重 ","date":"2021-02-20","objectID":"/posts/lvs-configure/:2:2","series":null,"tags":["lvs","ipvsadm"],"title":"配置 LVS DR 负载均衡","uri":"/posts/lvs-configure/#配置-ipvs"},{"categories":["devops","lvs"],"content":" RealServer 服务器配置","date":"2021-02-20","objectID":"/posts/lvs-configure/:3:0","series":null,"tags":["lvs","ipvsadm"],"title":"配置 LVS DR 负载均衡","uri":"/posts/lvs-configure/#realserver-服务器配置"},{"categories":["devops","lvs"],"content":" 向回环接口（lo）添加 vip bash root@web-01:~# ip addr add 192.168.31.30/32 brd 192.168.31.30 dev lo ","date":"2021-02-20","objectID":"/posts/lvs-configure/:3:1","series":null,"tags":["lvs","ipvsadm"],"title":"配置 LVS DR 负载均衡","uri":"/posts/lvs-configure/#向回环接口lo添加-vip"},{"categories":["devops","lvs"],"content":" 抑制 arp 广播禁止发送 arp 广播，由于 vip 在多台机器上配置了，如果不抑制广播会造成 ip 地址冲突。 bash root@web-01:~# echo 1 \u003e /proc/sys/net/ipv4/conf/all/arp_ignore root@web-01:~# echo 1 \u003e /proc/sys/net/ipv4/conf/lo/arp_ignore root@web-01:~# echo 2 \u003e /proc/sys/net/ipv4/conf/all/arp_announce root@web-01:~# echo 2 \u003e /proc/sys/net/ipv4/conf/lo/arp_announce ","date":"2021-02-20","objectID":"/posts/lvs-configure/:3:2","series":null,"tags":["lvs","ipvsadm"],"title":"配置 LVS DR 负载均衡","uri":"/posts/lvs-configure/#抑制-arp-广播"},{"categories":["devops","lvs"],"content":" 在客户机测试 LVS 负载群集 bash curl 192.168.31.30 注意: 至此 lvs 负载均衡集群配置完成，由于 lvs 服务器本身不支持高可用，存在单点故障， 可以配合 keepalived 一起使用 ","date":"2021-02-20","objectID":"/posts/lvs-configure/:4:0","series":null,"tags":["lvs","ipvsadm"],"title":"配置 LVS DR 负载均衡","uri":"/posts/lvs-configure/#在客户机测试-lvs-负载群集"},{"categories":["devops","lvs"],"content":" 服务脚本lvs 的配置是终端上配置的，机器重启后会丢失，那么该如何管理配置呢？ 有两种方法: ipvsadm 包自带配置信息管理工具，ipvsadm-save, ipvsadm-restore 开发脚本管理 ipvsadm-save: 用于导出 lvs 配置 ipvsadm-restore: 用于从文件中恢复 lvs 配置 也可以使用 ipvsadm 包中的脚本管理 /etc/init.d/ipvsadm ","date":"2021-02-20","objectID":"/posts/lvs-configure/:5:0","series":null,"tags":["lvs","ipvsadm"],"title":"配置 LVS DR 负载均衡","uri":"/posts/lvs-configure/#服务脚本"},{"categories":["devops","lvs"],"content":" lvs 配置管理 bash root@lb-01:~# ipvsadm-save \u003e /etc/ipvsadm.rules # 等价于 /etc/init.d/ipvsadm save root@lb-01:~# ipvsadm-restore \u003c /etc/ipvsadm.rules # 等价于 /etc/init.d/ipvsadm load root@lb-01:~# ipvsadm -Ln IP Virtual Server version 1.2.1 (size=4096) Prot LocalAddress:Port Scheduler Flags -\u003e RemoteAddress:Port Forward Weight ActiveConn InActConn TCP 192.168.31.30:80 rr persistent 20 -\u003e 192.168.31.31:80 Route 1 0 0 -\u003e 192.168.31.32:80 Route 1 0 0 ","date":"2021-02-20","objectID":"/posts/lvs-configure/:5:1","series":null,"tags":["lvs","ipvsadm"],"title":"配置 LVS DR 负载均衡","uri":"/posts/lvs-configure/#lvs-配置管理"},{"categories":["devops","lvs"],"content":" lvs 服务器配置脚本 bash #!/bin/bash INTERFACE=ens32 PORT=80 VIP=192.168.31.30 RIP=( 192.168.31.31 192.168.31.32 ) IPVSADM=/usr/sbin/ipvsadm start() { ip addr add ${VIP}/32 brd ${VIP} dev $INTERFACE $IPVSADM -C $IPVSADM --set 30 5 60 $IPVSADM -A -t ${VIP}:${PORT} -s rr -p 20 for (( i = 0; i \u003c echo ${#RIP[*]}; i++ )); do $IPVSADM -a -t ${VIP}:${PORT} -r ${RIP[$i]}:${PORT} -g -w 1 done echo \"The lvs Server is start!\" } stop() { $IPVSADM -C ip addr del ${VIP}/32 brd ${VIP} dev $INTERFACE echo \"The lvs Server is stop!\" } status() { $IPVSADM -L -n --stats } case $1 in start) start ;; stop) stop ;; restart) stop sleep 1 start ;; status) status ;; *) echo $\"Usage: $0 {start|stop|status|restart}\" exit 2 ;; esac ","date":"2021-02-20","objectID":"/posts/lvs-configure/:5:2","series":null,"tags":["lvs","ipvsadm"],"title":"配置 LVS DR 负载均衡","uri":"/posts/lvs-configure/#lvs-服务器配置脚本"},{"categories":["devops","lvs"],"content":" RealServer 服务器配置脚本 bash #!/bin/bash VIP=192.168.31.30 INTERFACE=lo case $1 in start) echo 1 \u003e /proc/sys/net/ipv4/conf/all/arp_ignore echo 1 \u003e /proc/sys/net/ipv4/conf/lo/arp_ignore echo 2 \u003e /proc/sys/net/ipv4/conf/all/arp_announce echo 2 \u003e /proc/sys/net/ipv4/conf/lo/arp_announce ip addr add ${VIP}/32 brd ${VIP} dev $INTERFACE echo \"The RS Server is Ready!\" ;; stop) ip addr del ${VIP}/32 brd ${VIP} dev $INTERFACE echo 0 \u003e /proc/sys/net/ipv4/conf/all/arp_ignore echo 0 \u003e /proc/sys/net/ipv4/conf/lo/arp_ignore echo 0 \u003e /proc/sys/net/ipv4/conf/all/arp_announce echo 0 \u003e /proc/sys/net/ipv4/conf/lo/arp_announce echo \"The RS Server is Canceled!\" ;; *) echo $\"Usage: $0 {start|stop|restart}\" exit 1 ;; esac ","date":"2021-02-20","objectID":"/posts/lvs-configure/:5:3","series":null,"tags":["lvs","ipvsadm"],"title":"配置 LVS DR 负载均衡","uri":"/posts/lvs-configure/#realserver-服务器配置脚本"},{"categories":["devops","lvs"],"content":" LVS 介绍Linux 虚拟服务器（Linux Virtual Server, LVS），是一个由章文嵩开发的一款自由软件。利用 LVS 可以实现高可用、可伸缩的 Web、Mail、Cache 等网络服务。 LVS 具有很好的可伸缩性、可靠性和可管性，通过 LVS 要实现的最终目标是：利用 Linux 操作系统和 LVS 集群软件实现一个高可用、高性能、低成本的服务器应用集群。 常用的实现负载均衡集群的开源软件有: LVS、haproxy、Nginx 等 LVS 工作于 OSI模型的传输层, 也可以称为4层负载。Nginx 与 Haproxy 即可以工作在 4 层（传输层）也可以工作于 7 层 （应用层）。 LVM 集群架构由2部分组成：最前端是负载均衡层（Load Balancer），后端是服务器群组 (一般称其为 Real Server) 负载均衡层: 由于一台或多台负载调度器(Director Server)组成。 LVS 核心模板 IPVS 就安装在 Director Server 上，而 Director 的主要作用类似于一个路由器，它含有为完成 LVS 功能所设定的路由表，通过这些路由表把用户的请求分发给服务器群组的应用服务器（Real Server）。 同时，在 Director Server 上还要安装对 Real Server 的监控模块 Ldirectord, 此模块用于监测各个 Real Server 服务健康状况。 在 Real Server 不可用时可以将其从 LVS 路由表中删除，在恢复时加入。 服务器群组层：由一组实际提供服务的机器组成，Real Server 可以在同一个网络中，也可以在不同网络中或者不同物理位置。 Linux 内核原生内转了 LVS 的各个模块，不用任何设置就可以支持 LVS 功能。 ","date":"2021-02-20","objectID":"/posts/lvs-introduction/:1:0","series":null,"tags":["lvs"],"title":"LVS 负载均衡，介绍","uri":"/posts/lvs-introduction/#lvs-介绍"},{"categories":["devops","lvs"],"content":" IPVS 负载均衡实现方式IPVS 实现负载均衡的方式有3种，分别是 NAT, TUN 和 DR。 ","date":"2021-02-20","objectID":"/posts/lvs-introduction/:2:0","series":null,"tags":["lvs"],"title":"LVS 负载均衡，介绍","uri":"/posts/lvs-introduction/#ipvs-负载均衡实现方式"},{"categories":["devops","lvs"],"content":" VS/NAT (Virtual Server via Network Address Translation)VS/NAT 方式使用网络地址翻译技术实现虚拟服务器。当用户请求到达调度器时，调度器将请求报文的目标地址(即虚拟IP地址)改写成选定的 RealServer 地址，同时将报文的目标端口也改成选定的 RealServer 的相应端口，最后将报文发送到选定的RealServer。 在服务器得到数据后， RealServer 将数据返回给用户时，需要再次经过负载均衡调度器将报文的源地址和源端口改成虚拟IP地址和相应的端口，然后把数据发送给用户，完成整个负载调度过程。 可以看出，在 NAT 方式下，用户请求和响应的报文都需要经过负载均衡调度器重写，当请求越来越多时，调度器的处理能力将成为瓶颈。 ","date":"2021-02-20","objectID":"/posts/lvs-introduction/:2:1","series":null,"tags":["lvs"],"title":"LVS 负载均衡，介绍","uri":"/posts/lvs-introduction/#vsnat-virtual-server-via-network-address-translation"},{"categories":["devops","lvs"],"content":" VS/TUN (Virtual Server via IP Tunneling)VS/TUN 方式是通过 IP 隧道技术实现虚拟服务器。这种方式的连接调度和管理与 VS/NAT 方式一样，只是报文转发方法不同。 在 VS/TUN 方式中，调度器采用 IP 隧道技术将用户的请求转发到某个 RealServer，而这个 RealServer 将直接响应用户的请求，不再经过前端调度器。 此外，对 RealServer 的地域位置没有要求。 因为在 TUN 方式中，调度器将只处理用户请求的报文，从而使集群系统的吞吐量大大提高。 ","date":"2021-02-20","objectID":"/posts/lvs-introduction/:2:2","series":null,"tags":["lvs"],"title":"LVS 负载均衡，介绍","uri":"/posts/lvs-introduction/#vstun-virtual-server-via-ip-tunneling"},{"categories":["devops","lvs"],"content":" VS/DR (Virtual Server via Direct Routing)VS/DR 就是直接路由技术实现虚拟服务器，这种方式的连接调度和管理与前两种一样，但它的报文转发方法又有所不同，VS/DR 通过改写请求报文的 MAC 地址，将请求发送到 RealServer， 而 RealServer 将响应直接返回给用户，免去了 VS/TUN的 IP 隧道开销。 这种方式是3咱负载调度方式中性能最好的，但是要求 Director Server 与 RealServer 必须由一块网卡连在同一物理网段上。 ","date":"2021-02-20","objectID":"/posts/lvs-introduction/:2:3","series":null,"tags":["lvs"],"title":"LVS 负载均衡，介绍","uri":"/posts/lvs-introduction/#vsdr-virtual-server-via-direct-routing"},{"categories":["devops","lvs"],"content":" 负载调度算法根据前面的介绍，我们了解了LVS的三种工作模式，但不管实际环境中采用的是哪种模式，调度算法进行调度的策略与算法都是LVS的核心技术，LVS在内核中主要实现了一下十种调度算法。 ","date":"2021-02-20","objectID":"/posts/lvs-introduction/:3:0","series":null,"tags":["lvs"],"title":"LVS 负载均衡，介绍","uri":"/posts/lvs-introduction/#负载调度算法"},{"categories":["devops","lvs"],"content":" 1.轮询调度轮询调度（Round Robin 简称’RR’）算法就是按依次循环的方式将请求调度到不同的服务器上，该算法最大的特点就是实现简单。轮询算法假设所有的服务器处理请求的能力都一样的，调度器会将所有的请求平均分配给每个真实服务器。 ","date":"2021-02-20","objectID":"/posts/lvs-introduction/:3:1","series":null,"tags":["lvs"],"title":"LVS 负载均衡，介绍","uri":"/posts/lvs-introduction/#1轮询调度"},{"categories":["devops","lvs"],"content":" 2.加权轮询调度加权轮询（Weight Round Robin 简称’WRR’）算法主要是对轮询算法的一种优化与补充，LVS会考虑每台服务器的性能，并给每台服务器添加一个权值，如果服务器A的权值为1，服务器B的权值为2，则调度器调度到服务器B的请求会是服务器A的两倍。权值越高的服务器，处理的请求越多。 ","date":"2021-02-20","objectID":"/posts/lvs-introduction/:3:2","series":null,"tags":["lvs"],"title":"LVS 负载均衡，介绍","uri":"/posts/lvs-introduction/#2加权轮询调度"},{"categories":["devops","lvs"],"content":" 3.最小连接调度最小连接调度（Least Connections 简称’LC’）算法是把新的连接请求分配到当前连接数最小的服务器。最小连接调度是一种动态的调度算法，它通过服务器当前活跃的连接数来估计服务器的情况。调度器需要记录各个服务器已建立连接的数目，当一个请求被调度到某台服务器，其连接数加1；当连接中断或者超时，其连接数减1。 （集群系统的真实服务器具有相近的系统性能，采用最小连接调度算法可以比较好地均衡负载。) ","date":"2021-02-20","objectID":"/posts/lvs-introduction/:3:3","series":null,"tags":["lvs"],"title":"LVS 负载均衡，介绍","uri":"/posts/lvs-introduction/#3最小连接调度"},{"categories":["devops","lvs"],"content":" 4.加权最小连接调度加权最少连接（Weight Least Connections 简称’WLC’）算法是最小连接调度的超集，各个服务器相应的权值表示其处理性能。服务器的缺省权值为1，系统管理员可以动态地设置服务器的权值。加权最小连接调度在调度新连接时尽可能使服务器的已建立连接数和其权值成比例。调度器可以自动问询真实服务器的负载情况，并动态地调整其权值。 ","date":"2021-02-20","objectID":"/posts/lvs-introduction/:3:4","series":null,"tags":["lvs"],"title":"LVS 负载均衡，介绍","uri":"/posts/lvs-introduction/#4加权最小连接调度"},{"categories":["devops","lvs"],"content":" 5.基于局部的最少连接基于局部的最少连接调度（Locality-Based Least Connections 简称’LBLC’）算法是针对请求报文的目标IP地址的 负载均衡调度，目前主要用于Cache集群系统，因为在Cache集群客户请求报文的目标IP地址是变化的。这里假设任何后端服务器都可以处理任一请求，算法的设计目标是在服务器的负载基本平衡情况下，将相同目标IP地址的请求调度到同一台服务器，来提高各台服务器的访问局部性和Cache命中率，从而提升整个集群系统的处理能力。LBLC调度算法先根据请求的目标IP地址找出该目标IP地址最近使用的服务器，若该服务器是可用的且没有超载，将请求发送到该服务器；若服务器不存在，或者该服务器超载且有服务器处于一半的工作负载，则使用’最少连接’的原则选出一个可用的服务器，将请求发送到服务器。 ","date":"2021-02-20","objectID":"/posts/lvs-introduction/:3:5","series":null,"tags":["lvs"],"title":"LVS 负载均衡，介绍","uri":"/posts/lvs-introduction/#5基于局部的最少连接"},{"categories":["devops","lvs"],"content":" 6.带复制的基于局部性的最少连接带复制的基于局部性的最少连接（Locality-Based Least Connections with Replication 简称’LBLCR’）算法也是针对目标IP地址的负载均衡，目前主要用于Cache集群系统，它与LBLC算法不同之处是它要维护从一个目标IP地址到一组服务器的映射，而LBLC算法维护从一个目标IP地址到一台服务器的映射。按’最小连接’原则从该服务器组中选出一一台服务器，若服务器没有超载，将请求发送到该服务器；若服务器超载，则按’最小连接’原则从整个集群中选出一台服务器，将该服务器加入到这个服务器组中，将请求发送到该服务器。同时，当该服务器组有一段时间没有被修改，将最忙的服务器从服务器组中删除，以降低复制的程度。 ","date":"2021-02-20","objectID":"/posts/lvs-introduction/:3:6","series":null,"tags":["lvs"],"title":"LVS 负载均衡，介绍","uri":"/posts/lvs-introduction/#6带复制的基于局部性的最少连接"},{"categories":["devops","lvs"],"content":" 7.目标地址散列调度目标地址散列调度（Destination Hashing 简称’DH’）算法先根据请求的目标IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且并未超载，将请求发送到该服务器，否则返回空。 ","date":"2021-02-20","objectID":"/posts/lvs-introduction/:3:7","series":null,"tags":["lvs"],"title":"LVS 负载均衡，介绍","uri":"/posts/lvs-introduction/#7目标地址散列调度"},{"categories":["devops","lvs"],"content":" 8.源地址散列调度源地址散列调度（Source Hashing 简称’SH’）算法先根据请求的源IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且并未超载，将请求发送到该服务器，否则返回空。它采用的散列函数与目标地址散列调度算法的相同，它的算法流程与目标地址散列调度算法的基本相似。 ","date":"2021-02-20","objectID":"/posts/lvs-introduction/:3:8","series":null,"tags":["lvs"],"title":"LVS 负载均衡，介绍","uri":"/posts/lvs-introduction/#8源地址散列调度"},{"categories":["devops","lvs"],"content":" 9.最短的期望的延迟最短的期望的延迟调度（Shortest Expected Delay 简称’SED’）算法基于WLC算法。举个例子吧，ABC三台服务器的权重分别为1、2、3 。那么如果使用WLC算法的话一个新请求进入时它可能会分给ABC中的任意一个。使用SED算法后会进行一个运算 A：（1+1）/1=2 B：（1+2）/2=3/2 C：（1+3）/3=4/3 就把请求交给得出运算结果最小的服务器。 ","date":"2021-02-20","objectID":"/posts/lvs-introduction/:3:9","series":null,"tags":["lvs"],"title":"LVS 负载均衡，介绍","uri":"/posts/lvs-introduction/#9最短的期望的延迟"},{"categories":["devops","lvs"],"content":" 10.最少队列调度最少队列调度（Never Queue 简称’NQ’）算法，无需队列。如果有realserver的连接数等于0就直接分配过去，不需要在进行SED运算。 ","date":"2021-02-20","objectID":"/posts/lvs-introduction/:3:10","series":null,"tags":["lvs"],"title":"LVS 负载均衡，介绍","uri":"/posts/lvs-introduction/#10最少队列调度"},{"categories":["redis"],"content":" 使用场景介绍Memcached：多核的缓存服务，更加适合于多用户并发访问次数较少的应用场景 Redis：单核的缓存服务，单节点情况下，更加适合于少量用户，多次访问的应用场景。 redis 一般是单机多实例架构，配合 redis 集群出现。 ","date":"2021-02-12","objectID":"/posts/redis-install/:1:0","series":null,"tags":["redis"],"title":"Redis 的简单安装与使用","uri":"/posts/redis-install/#使用场景介绍"},{"categories":["redis"],"content":" 安装 Reis","date":"2021-02-12","objectID":"/posts/redis-install/:2:0","series":null,"tags":["redis"],"title":"Redis 的简单安装与使用","uri":"/posts/redis-install/#安装-reis"},{"categories":["redis"],"content":" 源码编译安装 Redisredis 3.x bash cd /usr/local/src wget http://download.redis.io/releases/redis-3.2.12.tar.gz tar xzf redis-3.2.12.tar.gz yum -y install gcc automake autoconf libtool make cd /usr/local/src/redis-3.2.12 make make install redis 6.x bash wget https://download.redis.io/releases/redis-6.2.5.tar.gz tar xzf redis-6.2.5.tar.gz cd redis-6.2.5 # 编译 redis 所需依赖, 不编译时可能会无法编译下去 cd deps make hdr_histogram hiredis jemalloc linenoise lua # 编译 redis cd .. make make install ","date":"2021-02-12","objectID":"/posts/redis-install/:2:1","series":null,"tags":["redis"],"title":"Redis 的简单安装与使用","uri":"/posts/redis-install/#源码编译安装-redis"},{"categories":["redis"],"content":" 安装 Redis 服务使用源码包中的 install_server.sh 脚本工具，安装 redis 服务 bash [root@10-7-171-239 redis-3.2.12]# cd utils [root@10-7-171-239 utils]# bash install_server.sh Welcome to the redis service installer This script will help you easily set up a running redis server Please select the redis port for this instance: [6379] Selecting default: 6379 Please select the redis config file name [/etc/redis/6379.conf] Selected default - /etc/redis/6379.conf Please select the redis log file name [/var/log/redis_6379.log] Selected default - /var/log/redis_6379.log Please select the data directory for this instance [/var/lib/redis/6379] Selected default - /var/lib/redis/6379 Please select the redis executable path [/usr/local/bin/redis-server] Selected config: Port : 6379 Config file : /etc/redis/6379.conf Log file : /var/log/redis_6379.log Data dir : /var/lib/redis/6379 Executable : /usr/local/bin/redis-server Cli Executable : /usr/local/bin/redis-cli Is this ok? Then press ENTER to go on or Ctrl-C to abort. Copied /tmp/6379.conf =\u003e /etc/init.d/redis_6379 Installing service... Successfully added to chkconfig! Successfully added to runlevels 345! Starting Redis server... Installation successful! ","date":"2021-02-12","objectID":"/posts/redis-install/:2:2","series":null,"tags":["redis"],"title":"Redis 的简单安装与使用","uri":"/posts/redis-install/#安装-redis-服务"},{"categories":["redis"],"content":" 配置 Redis","date":"2021-02-12","objectID":"/posts/redis-install/:3:0","series":null,"tags":["redis"],"title":"Redis 的简单安装与使用","uri":"/posts/redis-install/#配置-redis"},{"categories":["redis"],"content":" 连接测试 Redisredis 默认配置文件中监听的地址和端口是 127.0.0.1:6379，无密码验证(requirepass) 可以直接使用 redis-cli 命令连接 bash [root@localhost ~]# /etc/init.d/redis_6379 status Redis is running (1446) [root@localhost ~]# redis-cli 127.0.0.1:6379\u003e ping PONG 输入 ping 指令，redis 回复 PONG w代表连接成功，可以正常与 redis-server 通信 ","date":"2021-02-12","objectID":"/posts/redis-install/:3:1","series":null,"tags":["redis"],"title":"Redis 的简单安装与使用","uri":"/posts/redis-install/#连接测试-redis"},{"categories":["redis"],"content":" 配置 redis配置文件基础项说明 bash $ egrep -v '^#|^$' /etc/redis/6379.conf # 绑定的 ip 地址， 只绑定 127.0.0.1 地址是无法对外提供服务的 # 生产环境中建议配置此项 bind 127.0.0.1 10.7.171.239 # 是否启用保护模式 # 在未指定绑定地址，未向客户端请求认证密码。 在此模式下，仅从环回接口接受连接。 # 如果要从外部计算机连接到 Redis 可以使用以下方法 # 1. 关闭保护模式, 通过在线修改 (CONFIG SET protected-mode no) 或者 修改配置文件 # 2. 启动服务时加入 '--protected-mode no' 参数 # 3. 配置 bind 地址或身份验证密码 # 注意：您只需要执行上述操作之一，服务器就可以开始接受来自外部的连接。 protected-mode yes # 连接时验证的密码 requirepass S4Ea0lFLwJjehB91 # 服务监听端口 port 6379 # 是否后台运行 daemonize yes # pidfile 存放路径 pidfile /var/run/redis_6379.pid # 日志 存放路径 logfile /var/log/redis_6379.log # 日志级别 loglevel notice ## RDB 持久化配置 ## # RDB 持久化数据文件, 存储在 dir 选项配置的目录下 dbfilename dump.rdb # 数据持久化存储路径 dir /var/lib/redis/6379 # 900 秒内如果累积 1 个变更就持久化一次 save 900 1 save 300 10 save 60 10000 stop-writes-on-bgsave-error yes rdbcompression yes rdbchecksum yes # 最大使用内存大小 maxmemory 512m slave-serve-stale-data yes slave-read-only yes repl-diskless-sync no repl-diskless-sync-delay 5 repl-disable-tcp-nodelay no slave-priority 100 ## AOF 持久化配置，如果用于缓存用途可以不开启 ## appendonly no appendfilename \"appendonly.aof\" appendfsync everysec ","date":"2021-02-12","objectID":"/posts/redis-install/:3:2","series":null,"tags":["redis"],"title":"Redis 的简单安装与使用","uri":"/posts/redis-install/#配置-redis-1"},{"categories":["redis"],"content":" 在线查看和修改 redis 配置 在线查看配置项 bash # 查看所有配置项 127.0.0.1:6379\u003e config get * 1) \"dbfilename\" 2) \"dump.rdb\" 3) \"requirepass\" 4) \"123\" 5) \"masterauth\" 6) \"\" 7) \"unixsocket\" 8) \"\" 9) \"logfile\" .... # 查看验证密码 127.0.0.1:6379\u003e config get maxmemory 1) \"maxmemory\" 2) \"0\" # 模糊查看配置项 127.0.0.1:6379\u003e config get maxm* 1) \"maxmemory\" 2) \"128000000\" 3) \"maxmemory-samples\" 4) \"5\" 5) \"maxmemory-policy\" 6) \"noeviction\" 在线调整配置项 bash # 配置最大使用内存量 127.0.0.1:6379\u003e config set maxmemory 128m OK # 配置连接验证密码 127.0.0.1:6379\u003e config set requirepass 123 OK # 连接验证 127.0.0.1:6379\u003e auth 123 OK # 查看配置 127.0.0.1:6379\u003e config get maxmemory 1) \"maxmemory\" 2) \"128000000\" 127.0.0.1:6379\u003e config get requirepass 1) \"requirepass\" 2) \"123\" # 将修改的配置修改写入配置文件中 127.0.0.1:6379\u003e config rewrite OK ","date":"2021-02-12","objectID":"/posts/redis-install/:3:3","series":null,"tags":["redis"],"title":"Redis 的简单安装与使用","uri":"/posts/redis-install/#在线查看和修改-redis-配置"},{"categories":["redis"],"content":" 在线查看和修改 redis 配置 在线查看配置项 bash # 查看所有配置项 127.0.0.1:6379\u003e config get * 1) \"dbfilename\" 2) \"dump.rdb\" 3) \"requirepass\" 4) \"123\" 5) \"masterauth\" 6) \"\" 7) \"unixsocket\" 8) \"\" 9) \"logfile\" .... # 查看验证密码 127.0.0.1:6379\u003e config get maxmemory 1) \"maxmemory\" 2) \"0\" # 模糊查看配置项 127.0.0.1:6379\u003e config get maxm* 1) \"maxmemory\" 2) \"128000000\" 3) \"maxmemory-samples\" 4) \"5\" 5) \"maxmemory-policy\" 6) \"noeviction\" 在线调整配置项 bash # 配置最大使用内存量 127.0.0.1:6379\u003e config set maxmemory 128m OK # 配置连接验证密码 127.0.0.1:6379\u003e config set requirepass 123 OK # 连接验证 127.0.0.1:6379\u003e auth 123 OK # 查看配置 127.0.0.1:6379\u003e config get maxmemory 1) \"maxmemory\" 2) \"128000000\" 127.0.0.1:6379\u003e config get requirepass 1) \"requirepass\" 2) \"123\" # 将修改的配置修改写入配置文件中 127.0.0.1:6379\u003e config rewrite OK ","date":"2021-02-12","objectID":"/posts/redis-install/:3:3","series":null,"tags":["redis"],"title":"Redis 的简单安装与使用","uri":"/posts/redis-install/#在线查看配置项"},{"categories":["redis"],"content":" 在线查看和修改 redis 配置 在线查看配置项 bash # 查看所有配置项 127.0.0.1:6379\u003e config get * 1) \"dbfilename\" 2) \"dump.rdb\" 3) \"requirepass\" 4) \"123\" 5) \"masterauth\" 6) \"\" 7) \"unixsocket\" 8) \"\" 9) \"logfile\" .... # 查看验证密码 127.0.0.1:6379\u003e config get maxmemory 1) \"maxmemory\" 2) \"0\" # 模糊查看配置项 127.0.0.1:6379\u003e config get maxm* 1) \"maxmemory\" 2) \"128000000\" 3) \"maxmemory-samples\" 4) \"5\" 5) \"maxmemory-policy\" 6) \"noeviction\" 在线调整配置项 bash # 配置最大使用内存量 127.0.0.1:6379\u003e config set maxmemory 128m OK # 配置连接验证密码 127.0.0.1:6379\u003e config set requirepass 123 OK # 连接验证 127.0.0.1:6379\u003e auth 123 OK # 查看配置 127.0.0.1:6379\u003e config get maxmemory 1) \"maxmemory\" 2) \"128000000\" 127.0.0.1:6379\u003e config get requirepass 1) \"requirepass\" 2) \"123\" # 将修改的配置修改写入配置文件中 127.0.0.1:6379\u003e config rewrite OK ","date":"2021-02-12","objectID":"/posts/redis-install/:3:3","series":null,"tags":["redis"],"title":"Redis 的简单安装与使用","uri":"/posts/redis-install/#在线调整配置项"},{"categories":["mongodb"],"content":" 备份工具介绍MongoDB 自带两种备份工具, 以备份出的文件区分为文本备份工具与二进制备份工具，各有不同的适用场景。 ","date":"2021-02-09","objectID":"/posts/mongodb-backup/:1:0","series":null,"tags":["mongodb","mongoexport","mongoimport","mongodump","mongorestore"],"title":"Mongodb 数据备份与恢复","uri":"/posts/mongodb-backup/#备份工具介绍"},{"categories":["mongodb"],"content":" 文本备份工具使用此工具备份出的文件是可读的，备份格式可选为 json 或 csv。 适用场景 异构平台: 当我们需要迁移 mysql 数据至 mongodb 时就可以选用此工具了(相反亦可)。 同平台，跨大版本升级：mongodb2 –\u003e mongodb3 mongoexport: 以 CSV 或 JSON 格式从 MongoDB 导出数据 mongoimport: 将 CSV，TSV 或 JSON 数据导入 MongoDB。 如果未提供文件，则 mongoimport 从 stdin 中读取。 在 test 库中生成测试数据 javascript ues test for (var i=1; i\u003c=10000; i++){ db.rands.insert({id: i, date: new Date()}) } mongoexportjson 格式 mongoexport 默认导入数据为 json 格式 bash $ mongoexport -u root -p root123 --authenticationDatabase admin -d test -c rands -o rands.json 2021-02-24T10:38:15.398+0800 connected to: localhost 2021-02-24T10:38:15.557+0800 exported 10000 records csv 格式 导出 csv 格式需要加上 --type 选项并指定要导出的键名使用 -f 选项 bash $ mongoexport -u root -p root123 --authenticationDatabase admin -d test -c rands --type=csv -f id,date -o rands.csv 2021-02-24T10:44:01.075+0800 connected to: localhost 2021-02-24T10:44:01.144+0800 exported 10000 records mongoimport导入 json 数据 bash $ mongoimport -u root -p root123 --authenticationDatabase admin -d test -c rands --file rands.json 2021-02-24T10:52:55.845+0800 connected to: localhost 2021-02-24T10:52:55.935+0800 imported 10000 documents 导入 csv 数据 如果 csv 文件首行是为列名，需要加入 --headerline 选项，如果不是需要使用 -f 选项指定列名. --headerline: 指明第一行是列名，不需要导入 bash mongoimport -u root -p root123 --authenticationDatabase admin -d test -c rands --type=csv --headerline --file rands.csv 2021-02-24T10:55:23.714+0800 connected to: localhost 2021-02-24T10:55:23.776+0800 imported 10000 documents 注意: 数据导入是追加导入，所以不重复导入以免数据重复 ","date":"2021-02-09","objectID":"/posts/mongodb-backup/:1:1","series":null,"tags":["mongodb","mongoexport","mongoimport","mongodump","mongorestore"],"title":"Mongodb 数据备份与恢复","uri":"/posts/mongodb-backup/#文本备份工具"},{"categories":["mongodb"],"content":" 文本备份工具使用此工具备份出的文件是可读的，备份格式可选为 json 或 csv。 适用场景 异构平台: 当我们需要迁移 mysql 数据至 mongodb 时就可以选用此工具了(相反亦可)。 同平台，跨大版本升级：mongodb2 –\u003e mongodb3 mongoexport: 以 CSV 或 JSON 格式从 MongoDB 导出数据 mongoimport: 将 CSV，TSV 或 JSON 数据导入 MongoDB。 如果未提供文件，则 mongoimport 从 stdin 中读取。 在 test 库中生成测试数据 javascript ues test for (var i=1; i\u003c=10000; i++){ db.rands.insert({id: i, date: new Date()}) } mongoexportjson 格式 mongoexport 默认导入数据为 json 格式 bash $ mongoexport -u root -p root123 --authenticationDatabase admin -d test -c rands -o rands.json 2021-02-24T10:38:15.398+0800 connected to: localhost 2021-02-24T10:38:15.557+0800 exported 10000 records csv 格式 导出 csv 格式需要加上 --type 选项并指定要导出的键名使用 -f 选项 bash $ mongoexport -u root -p root123 --authenticationDatabase admin -d test -c rands --type=csv -f id,date -o rands.csv 2021-02-24T10:44:01.075+0800 connected to: localhost 2021-02-24T10:44:01.144+0800 exported 10000 records mongoimport导入 json 数据 bash $ mongoimport -u root -p root123 --authenticationDatabase admin -d test -c rands --file rands.json 2021-02-24T10:52:55.845+0800 connected to: localhost 2021-02-24T10:52:55.935+0800 imported 10000 documents 导入 csv 数据 如果 csv 文件首行是为列名，需要加入 --headerline 选项，如果不是需要使用 -f 选项指定列名. --headerline: 指明第一行是列名，不需要导入 bash mongoimport -u root -p root123 --authenticationDatabase admin -d test -c rands --type=csv --headerline --file rands.csv 2021-02-24T10:55:23.714+0800 connected to: localhost 2021-02-24T10:55:23.776+0800 imported 10000 documents 注意: 数据导入是追加导入，所以不重复导入以免数据重复 ","date":"2021-02-09","objectID":"/posts/mongodb-backup/:1:1","series":null,"tags":["mongodb","mongoexport","mongoimport","mongodump","mongorestore"],"title":"Mongodb 数据备份与恢复","uri":"/posts/mongodb-backup/#mongoexport"},{"categories":["mongodb"],"content":" 文本备份工具使用此工具备份出的文件是可读的，备份格式可选为 json 或 csv。 适用场景 异构平台: 当我们需要迁移 mysql 数据至 mongodb 时就可以选用此工具了(相反亦可)。 同平台，跨大版本升级：mongodb2 –\u003e mongodb3 mongoexport: 以 CSV 或 JSON 格式从 MongoDB 导出数据 mongoimport: 将 CSV，TSV 或 JSON 数据导入 MongoDB。 如果未提供文件，则 mongoimport 从 stdin 中读取。 在 test 库中生成测试数据 javascript ues test for (var i=1; i\u003c=10000; i++){ db.rands.insert({id: i, date: new Date()}) } mongoexportjson 格式 mongoexport 默认导入数据为 json 格式 bash $ mongoexport -u root -p root123 --authenticationDatabase admin -d test -c rands -o rands.json 2021-02-24T10:38:15.398+0800 connected to: localhost 2021-02-24T10:38:15.557+0800 exported 10000 records csv 格式 导出 csv 格式需要加上 --type 选项并指定要导出的键名使用 -f 选项 bash $ mongoexport -u root -p root123 --authenticationDatabase admin -d test -c rands --type=csv -f id,date -o rands.csv 2021-02-24T10:44:01.075+0800 connected to: localhost 2021-02-24T10:44:01.144+0800 exported 10000 records mongoimport导入 json 数据 bash $ mongoimport -u root -p root123 --authenticationDatabase admin -d test -c rands --file rands.json 2021-02-24T10:52:55.845+0800 connected to: localhost 2021-02-24T10:52:55.935+0800 imported 10000 documents 导入 csv 数据 如果 csv 文件首行是为列名，需要加入 --headerline 选项，如果不是需要使用 -f 选项指定列名. --headerline: 指明第一行是列名，不需要导入 bash mongoimport -u root -p root123 --authenticationDatabase admin -d test -c rands --type=csv --headerline --file rands.csv 2021-02-24T10:55:23.714+0800 connected to: localhost 2021-02-24T10:55:23.776+0800 imported 10000 documents 注意: 数据导入是追加导入，所以不重复导入以免数据重复 ","date":"2021-02-09","objectID":"/posts/mongodb-backup/:1:1","series":null,"tags":["mongodb","mongoexport","mongoimport","mongodump","mongorestore"],"title":"Mongodb 数据备份与恢复","uri":"/posts/mongodb-backup/#mongoimport"},{"categories":["mongodb"],"content":" 二进制备份工具日常备份恢复推荐使用此工具 mongodump 能够在 Mongodb 运行时进行备份，它的工作原理是对运行的 Mongodb 做查询，然后将所有查到的文档写入磁盘。 但是存在的问题时使用 mongodump 产生的备份不一定是数据库的实时快照，如果我们在备份时对数据库进行了写入操作， 则备份出来的文件可能不完全和 Mongodb 实时数据相等。另外在备份时可能会对其它客户端性能产生不利的影响。 mongodump参数说明 -h: 指明数据库宿主机的 IP -u: 指明数据库的用户名 -p: 指明数据库的密码 --authenticationDatabase: 指明验证库名 -d: 指明数据库的名字 -c: 指明 collection 的名字 -o: 指明到要导出到的路径名 -q: 指明导出数据的过滤条件 -j, --numParallelCollections: 并行转储的集合数（默认为4个） --oplog: 备份的同时备份 oplog 全库备份不指定 -d 和 -c 选项时备份全库 bash $ mongodump -u root -p root123 --authenticationDatabase admin -o ./full 2021-02-24T11:13:12.997+0800 writing admin.system.users to 2021-02-24T11:13:12.997+0800 done dumping admin.system.users (1 document) 2021-02-24T11:13:12.997+0800 writing admin.system.version to 2021-02-24T11:13:12.998+0800 done dumping admin.system.version (2 documents) 2021-02-24T11:13:12.998+0800 writing test.rands to 2021-02-24T11:13:13.035+0800 done dumping test.rands (20000 documents) mongodump 备份的是 bson 格式的二进制文件, 备份目录不存在自动创建，目录结构按库名分 备份 test 库 bash $ mongodump -u root -p root123 --authenticationDatabase admin -d test -o /backup 2021-02-24T11:28:11.957+0800 writing test.rands to 2021-02-24T11:28:12.045+0800 done dumping test.rands (20000 documents) mongorestore恢复 test 库 bash $ mongorestore -u root -p root123 --authenticationDatabase admin -d test /backup/test 2021-02-24T11:34:47.061+0800 the --db and --collection args should only be used when restoring from a BSON file. Other uses are deprecated and will not exist in the future; use --nsInclude instead 2021-02-24T11:34:47.061+0800 building a list of collections to restore from test dir 2021-02-24T11:34:47.062+0800 reading metadata for test.rands from test/rands.metadata.json.gz 2021-02-24T11:34:47.067+0800 restoring test.rands from test/rands.bson.gz 2021-02-24T11:34:47.153+0800 no indexes to restore 2021-02-24T11:34:47.153+0800 finished restoring test.rands (20000 documents) 2021-02-24T11:34:47.153+0800 done 当我们恢复数据库出现这样的错误信息 - E11000 duplicate key error collection: test.rands index: _id_ dup key: { : ObjectId('6035c17ea0af461fd150f74c') } 时，是因为数据重复无法写入此可以加入 --drop 选项解决, 但不建议使用 --drop 选项，此操作危险，可能会有数据丢失的风险。 ","date":"2021-02-09","objectID":"/posts/mongodb-backup/:1:2","series":null,"tags":["mongodb","mongoexport","mongoimport","mongodump","mongorestore"],"title":"Mongodb 数据备份与恢复","uri":"/posts/mongodb-backup/#二进制备份工具"},{"categories":["mongodb"],"content":" 二进制备份工具日常备份恢复推荐使用此工具 mongodump 能够在 Mongodb 运行时进行备份，它的工作原理是对运行的 Mongodb 做查询，然后将所有查到的文档写入磁盘。 但是存在的问题时使用 mongodump 产生的备份不一定是数据库的实时快照，如果我们在备份时对数据库进行了写入操作， 则备份出来的文件可能不完全和 Mongodb 实时数据相等。另外在备份时可能会对其它客户端性能产生不利的影响。 mongodump参数说明 -h: 指明数据库宿主机的 IP -u: 指明数据库的用户名 -p: 指明数据库的密码 --authenticationDatabase: 指明验证库名 -d: 指明数据库的名字 -c: 指明 collection 的名字 -o: 指明到要导出到的路径名 -q: 指明导出数据的过滤条件 -j, --numParallelCollections: 并行转储的集合数（默认为4个） --oplog: 备份的同时备份 oplog 全库备份不指定 -d 和 -c 选项时备份全库 bash $ mongodump -u root -p root123 --authenticationDatabase admin -o ./full 2021-02-24T11:13:12.997+0800 writing admin.system.users to 2021-02-24T11:13:12.997+0800 done dumping admin.system.users (1 document) 2021-02-24T11:13:12.997+0800 writing admin.system.version to 2021-02-24T11:13:12.998+0800 done dumping admin.system.version (2 documents) 2021-02-24T11:13:12.998+0800 writing test.rands to 2021-02-24T11:13:13.035+0800 done dumping test.rands (20000 documents) mongodump 备份的是 bson 格式的二进制文件, 备份目录不存在自动创建，目录结构按库名分 备份 test 库 bash $ mongodump -u root -p root123 --authenticationDatabase admin -d test -o /backup 2021-02-24T11:28:11.957+0800 writing test.rands to 2021-02-24T11:28:12.045+0800 done dumping test.rands (20000 documents) mongorestore恢复 test 库 bash $ mongorestore -u root -p root123 --authenticationDatabase admin -d test /backup/test 2021-02-24T11:34:47.061+0800 the --db and --collection args should only be used when restoring from a BSON file. Other uses are deprecated and will not exist in the future; use --nsInclude instead 2021-02-24T11:34:47.061+0800 building a list of collections to restore from test dir 2021-02-24T11:34:47.062+0800 reading metadata for test.rands from test/rands.metadata.json.gz 2021-02-24T11:34:47.067+0800 restoring test.rands from test/rands.bson.gz 2021-02-24T11:34:47.153+0800 no indexes to restore 2021-02-24T11:34:47.153+0800 finished restoring test.rands (20000 documents) 2021-02-24T11:34:47.153+0800 done 当我们恢复数据库出现这样的错误信息 - E11000 duplicate key error collection: test.rands index: _id_ dup key: { : ObjectId('6035c17ea0af461fd150f74c') } 时，是因为数据重复无法写入此可以加入 --drop 选项解决, 但不建议使用 --drop 选项，此操作危险，可能会有数据丢失的风险。 ","date":"2021-02-09","objectID":"/posts/mongodb-backup/:1:2","series":null,"tags":["mongodb","mongoexport","mongoimport","mongodump","mongorestore"],"title":"Mongodb 数据备份与恢复","uri":"/posts/mongodb-backup/#mongodump"},{"categories":["mongodb"],"content":" 二进制备份工具日常备份恢复推荐使用此工具 mongodump 能够在 Mongodb 运行时进行备份，它的工作原理是对运行的 Mongodb 做查询，然后将所有查到的文档写入磁盘。 但是存在的问题时使用 mongodump 产生的备份不一定是数据库的实时快照，如果我们在备份时对数据库进行了写入操作， 则备份出来的文件可能不完全和 Mongodb 实时数据相等。另外在备份时可能会对其它客户端性能产生不利的影响。 mongodump参数说明 -h: 指明数据库宿主机的 IP -u: 指明数据库的用户名 -p: 指明数据库的密码 --authenticationDatabase: 指明验证库名 -d: 指明数据库的名字 -c: 指明 collection 的名字 -o: 指明到要导出到的路径名 -q: 指明导出数据的过滤条件 -j, --numParallelCollections: 并行转储的集合数（默认为4个） --oplog: 备份的同时备份 oplog 全库备份不指定 -d 和 -c 选项时备份全库 bash $ mongodump -u root -p root123 --authenticationDatabase admin -o ./full 2021-02-24T11:13:12.997+0800 writing admin.system.users to 2021-02-24T11:13:12.997+0800 done dumping admin.system.users (1 document) 2021-02-24T11:13:12.997+0800 writing admin.system.version to 2021-02-24T11:13:12.998+0800 done dumping admin.system.version (2 documents) 2021-02-24T11:13:12.998+0800 writing test.rands to 2021-02-24T11:13:13.035+0800 done dumping test.rands (20000 documents) mongodump 备份的是 bson 格式的二进制文件, 备份目录不存在自动创建，目录结构按库名分 备份 test 库 bash $ mongodump -u root -p root123 --authenticationDatabase admin -d test -o /backup 2021-02-24T11:28:11.957+0800 writing test.rands to 2021-02-24T11:28:12.045+0800 done dumping test.rands (20000 documents) mongorestore恢复 test 库 bash $ mongorestore -u root -p root123 --authenticationDatabase admin -d test /backup/test 2021-02-24T11:34:47.061+0800 the --db and --collection args should only be used when restoring from a BSON file. Other uses are deprecated and will not exist in the future; use --nsInclude instead 2021-02-24T11:34:47.061+0800 building a list of collections to restore from test dir 2021-02-24T11:34:47.062+0800 reading metadata for test.rands from test/rands.metadata.json.gz 2021-02-24T11:34:47.067+0800 restoring test.rands from test/rands.bson.gz 2021-02-24T11:34:47.153+0800 no indexes to restore 2021-02-24T11:34:47.153+0800 finished restoring test.rands (20000 documents) 2021-02-24T11:34:47.153+0800 done 当我们恢复数据库出现这样的错误信息 - E11000 duplicate key error collection: test.rands index: _id_ dup key: { : ObjectId('6035c17ea0af461fd150f74c') } 时，是因为数据重复无法写入此可以加入 --drop 选项解决, 但不建议使用 --drop 选项，此操作危险，可能会有数据丢失的风险。 ","date":"2021-02-09","objectID":"/posts/mongodb-backup/:1:2","series":null,"tags":["mongodb","mongoexport","mongoimport","mongodump","mongorestore"],"title":"Mongodb 数据备份与恢复","uri":"/posts/mongodb-backup/#全库备份"},{"categories":["mongodb"],"content":" 二进制备份工具日常备份恢复推荐使用此工具 mongodump 能够在 Mongodb 运行时进行备份，它的工作原理是对运行的 Mongodb 做查询，然后将所有查到的文档写入磁盘。 但是存在的问题时使用 mongodump 产生的备份不一定是数据库的实时快照，如果我们在备份时对数据库进行了写入操作， 则备份出来的文件可能不完全和 Mongodb 实时数据相等。另外在备份时可能会对其它客户端性能产生不利的影响。 mongodump参数说明 -h: 指明数据库宿主机的 IP -u: 指明数据库的用户名 -p: 指明数据库的密码 --authenticationDatabase: 指明验证库名 -d: 指明数据库的名字 -c: 指明 collection 的名字 -o: 指明到要导出到的路径名 -q: 指明导出数据的过滤条件 -j, --numParallelCollections: 并行转储的集合数（默认为4个） --oplog: 备份的同时备份 oplog 全库备份不指定 -d 和 -c 选项时备份全库 bash $ mongodump -u root -p root123 --authenticationDatabase admin -o ./full 2021-02-24T11:13:12.997+0800 writing admin.system.users to 2021-02-24T11:13:12.997+0800 done dumping admin.system.users (1 document) 2021-02-24T11:13:12.997+0800 writing admin.system.version to 2021-02-24T11:13:12.998+0800 done dumping admin.system.version (2 documents) 2021-02-24T11:13:12.998+0800 writing test.rands to 2021-02-24T11:13:13.035+0800 done dumping test.rands (20000 documents) mongodump 备份的是 bson 格式的二进制文件, 备份目录不存在自动创建，目录结构按库名分 备份 test 库 bash $ mongodump -u root -p root123 --authenticationDatabase admin -d test -o /backup 2021-02-24T11:28:11.957+0800 writing test.rands to 2021-02-24T11:28:12.045+0800 done dumping test.rands (20000 documents) mongorestore恢复 test 库 bash $ mongorestore -u root -p root123 --authenticationDatabase admin -d test /backup/test 2021-02-24T11:34:47.061+0800 the --db and --collection args should only be used when restoring from a BSON file. Other uses are deprecated and will not exist in the future; use --nsInclude instead 2021-02-24T11:34:47.061+0800 building a list of collections to restore from test dir 2021-02-24T11:34:47.062+0800 reading metadata for test.rands from test/rands.metadata.json.gz 2021-02-24T11:34:47.067+0800 restoring test.rands from test/rands.bson.gz 2021-02-24T11:34:47.153+0800 no indexes to restore 2021-02-24T11:34:47.153+0800 finished restoring test.rands (20000 documents) 2021-02-24T11:34:47.153+0800 done 当我们恢复数据库出现这样的错误信息 - E11000 duplicate key error collection: test.rands index: _id_ dup key: { : ObjectId('6035c17ea0af461fd150f74c') } 时，是因为数据重复无法写入此可以加入 --drop 选项解决, 但不建议使用 --drop 选项，此操作危险，可能会有数据丢失的风险。 ","date":"2021-02-09","objectID":"/posts/mongodb-backup/:1:2","series":null,"tags":["mongodb","mongoexport","mongoimport","mongodump","mongorestore"],"title":"Mongodb 数据备份与恢复","uri":"/posts/mongodb-backup/#mongorestore"},{"categories":["mongodb"],"content":" Replication Set 基本原理MongoDB 复制集的基本构成是一主两从的结构，自带互相监控投标机制，使用 Raft 协议保证数据一致性，（MySQL MGR 用的是 Paxos 变种） 如果发生主库宕机，复制集内部会进行投票选举，选择一个新的主库替代原有主库对外提供服务。同时复制集会自动通知 客户端程序，主库已经发生切换了。应用就会连接到新的主库。 ","date":"2021-02-08","objectID":"/posts/mongodb-repliset/:1:0","series":null,"tags":["mongodb","mongodb-replication"],"title":"Mongodb RepliSet 部署","uri":"/posts/mongodb-repliset/#replication-set-基本原理"},{"categories":["mongodb"],"content":" Replication Set 配置过程","date":"2021-02-08","objectID":"/posts/mongodb-repliset/:2:0","series":null,"tags":["mongodb","mongodb-replication"],"title":"Mongodb RepliSet 部署","uri":"/posts/mongodb-repliset/#replication-set-配置过程"},{"categories":["mongodb"],"content":" 多实例复制集环境规划三个以上的 mongodb 节点或多实例, 这里使用多实例。 多实例端口: 28017、28018、28019 多实例配置目录: /data/mongodb/{28017,28018,28019}/etc 多实例配置目录: /data/mongodb/{28017,28018,28019}/logs 多实例数据目录: /data/mongodb/{28017,28018,28019}/data ","date":"2021-02-08","objectID":"/posts/mongodb-repliset/:2:1","series":null,"tags":["mongodb","mongodb-replication"],"title":"Mongodb RepliSet 部署","uri":"/posts/mongodb-repliset/#多实例复制集环境规划"},{"categories":["mongodb"],"content":" 创建多实例环境使用以下脚本创建 MongoDB 多实例 bash #!/bin/bash # # filename: mongodb-instances.sh # for port in {28017..28019}; do # 创建多实例目录 mkdir -p /data/mongodb/$port/etc mkdir -p /data/mongodb/$port/logs mkdir -p /data/mongodb/$port/data chown -R mongod.mongod /data/mongodb/$port # 生成配置文件 cat \u003e /data/mongodb/$port/etc/mongod.conf \u003c\u003cEOF systemLog: destination: file path: /data/mongodb/$port/logs/mongodb.log logAppend: true storage: journal: enabled: true dbPath: /data/mongodb/$port/data directoryPerDB: true #engine: wiredTiger wiredTiger: engineConfig: cacheSizeGB: 1 directoryForIndexes: true collectionConfig: blockCompressor: zlib indexConfig: prefixCompression: true processManagement: fork: true net: bindIp: 127.0.0.1,10.7.171.239 port: $port replication: oplogSizeMB: 2048 replSetName: my_repl EOF echo \"start mongodb $port instance\" echo \"/usr/local/mongodb/bin/mongod -f /data/mongodb/$port/etc/mongod.conf\" done 执行脚本 bash $ bash mongodb-instances.sh start mongodb 28017 instance /usr/local/mongodb/bin/mongod -f /data/mongodb/28017/etc/mongod.conf start mongodb 28018 instance /usr/local/mongodb/bin/mongod -f /data/mongodb/28018/etc/mongod.conf start mongodb 28019 instance /usr/local/mongodb/bin/mongod -f /data/mongodb/28019/etc/mongod.conf 启用 mongodb 多实例服务 bash ## 使用 mongod 用户启动 mongodb 多实例服务 # su - mongod $ /usr/local/mongodb/bin/mongod -f /data/mongodb/28017/etc/mongod.conf about to fork child process, waiting until server is ready for connections. forked process: 15702 child process started successfully, parent exiting $ /usr/local/mongodb/bin/mongod -f /data/mongodb/28018/etc/mongod.conf about to fork child process, waiting until server is ready for connections. forked process: 15731 child process started successfully, parent exiting $ /usr/local/mongodb/bin/mongod -f /data/mongodb/28019/etc/mongod.conf about to fork child process, waiting until server is ready for connections. forked process: 15760 child process started successfully, parent exiting ## 查看服务启动状态 $ ss -anptl | grep mongo LISTEN 0 128 10.7.171.239:28017 *:* users:((\"mongod\",pid=15702,fd=12)) LISTEN 0 128 127.0.0.1:28017 *:* users:((\"mongod\",pid=15702,fd=11)) LISTEN 0 128 10.7.171.239:28018 *:* users:((\"mongod\",pid=15731,fd=12)) LISTEN 0 128 127.0.0.1:28018 *:* users:((\"mongod\",pid=15731,fd=11)) LISTEN 0 128 10.7.171.239:28019 *:* users:((\"mongod\",pid=15760,fd=12)) LISTEN 0 128 127.0.0.1:28019 *:* users:((\"mongod\",pid=15760,fd=11)) ","date":"2021-02-08","objectID":"/posts/mongodb-repliset/:2:2","series":null,"tags":["mongodb","mongodb-replication"],"title":"Mongodb RepliSet 部署","uri":"/posts/mongodb-repliset/#创建多实例环境"},{"categories":["mongodb"],"content":" 配置普通复制集配置一主两从，从库为两普通从库 ","date":"2021-02-08","objectID":"/posts/mongodb-repliset/:3:0","series":null,"tags":["mongodb","mongodb-replication"],"title":"Mongodb RepliSet 部署","uri":"/posts/mongodb-repliset/#配置普通复制集"},{"categories":["mongodb"],"content":" 初始化复制集 bash $ mongo --port 28017 admin ## 定义初始化信息 \u003e config = {_id: 'my_repl', members: [ {_id: 0, host: '10.7.171.239:28017'}, {_id: 1, host: '10.7.171.239:28018'}, {_id: 2, host: '10.7.171.239:28019'}] } ## 初始化复制集 \u003e rs.initiate(config) { \"ok\" : 1, \"operationTime\" : Timestamp(1614066863, 1), \"$clusterTime\" : { \"clusterTime\" : Timestamp(1614066863, 1), \"signature\" : { \"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"), \"keyId\" : NumberLong(0) } } } ","date":"2021-02-08","objectID":"/posts/mongodb-repliset/:3:1","series":null,"tags":["mongodb","mongodb-replication"],"title":"Mongodb RepliSet 部署","uri":"/posts/mongodb-repliset/#初始化复制集"},{"categories":["mongodb"],"content":" 查询复制集状态 bash my_repl:PRIMARY\u003e rs.status() { \"set\" : \"my_repl\", \"date\" : ISODate(\"2021-02-23T07:56:10.466Z\"), \"myState\" : 1, \"term\" : NumberLong(1), \"syncingTo\" : \"\", \"syncSourceHost\" : \"\", \"syncSourceId\" : -1, \"heartbeatIntervalMillis\" : NumberLong(2000), \"optimes\" : { \"lastCommittedOpTime\" : { \"ts\" : Timestamp(1614066965, 1), \"t\" : NumberLong(1) }, \"readConcernMajorityOpTime\" : { \"ts\" : Timestamp(1614066965, 1), \"t\" : NumberLong(1) }, \"appliedOpTime\" : { \"ts\" : Timestamp(1614066965, 1), \"t\" : NumberLong(1) }, \"durableOpTime\" : { \"ts\" : Timestamp(1614066965, 1), \"t\" : NumberLong(1) } }, \"members\" : [ ## 这里记录集群中所有实例的信息及其状态 { \"_id\" : 0, \"name\" : \"10.7.171.239:28017\", \"health\" : 1, \"state\" : 1, \"stateStr\" : \"PRIMARY\", \"uptime\" : 421, \"optime\" : { \"ts\" : Timestamp(1614066965, 1), \"t\" : NumberLong(1) }, \"optimeDate\" : ISODate(\"2021-02-23T07:56:05Z\"), \"syncingTo\" : \"\", \"syncSourceHost\" : \"\", \"syncSourceId\" : -1, \"infoMessage\" : \"could not find member to sync from\", \"electionTime\" : Timestamp(1614066874, 1), \"electionDate\" : ISODate(\"2021-02-23T07:54:34Z\"), \"configVersion\" : 1, \"self\" : true, \"lastHeartbeatMessage\" : \"\" }, { \"_id\" : 1, \"name\" : \"10.7.171.239:28018\", \"health\" : 1, \"state\" : 2, \"stateStr\" : \"SECONDARY\", \"uptime\" : 106, \"optime\" : { \"ts\" : Timestamp(1614066965, 1), \"t\" : NumberLong(1) }, \"optimeDurable\" : { \"ts\" : Timestamp(1614066965, 1), \"t\" : NumberLong(1) }, \"optimeDate\" : ISODate(\"2021-02-23T07:56:05Z\"), \"optimeDurableDate\" : ISODate(\"2021-02-23T07:56:05Z\"), \"lastHeartbeat\" : ISODate(\"2021-02-23T07:56:10.130Z\"), \"lastHeartbeatRecv\" : ISODate(\"2021-02-23T07:56:08.582Z\"), \"pingMs\" : NumberLong(0), \"lastHeartbeatMessage\" : \"\", \"syncingTo\" : \"10.7.171.239:28017\", \"syncSourceHost\" : \"10.7.171.239:28017\", \"syncSourceId\" : 0, \"infoMessage\" : \"\", \"configVersion\" : 1 }, { \"_id\" : 2, \"name\" : \"10.7.171.239:28019\", \"health\" : 1, \"state\" : 2, \"stateStr\" : \"SECONDARY\", \"uptime\" : 106, \"optime\" : { \"ts\" : Timestamp(1614066965, 1), \"t\" : NumberLong(1) }, \"optimeDurable\" : { \"ts\" : Timestamp(1614066965, 1), \"t\" : NumberLong(1) }, \"optimeDate\" : ISODate(\"2021-02-23T07:56:05Z\"), \"optimeDurableDate\" : ISODate(\"2021-02-23T07:56:05Z\"), \"lastHeartbeat\" : ISODate(\"2021-02-23T07:56:10.130Z\"), \"lastHeartbeatRecv\" : ISODate(\"2021-02-23T07:56:08.581Z\"), \"pingMs\" : NumberLong(0), \"lastHeartbeatMessage\" : \"\", \"syncingTo\" : \"10.7.171.239:28017\", \"syncSourceHost\" : \"10.7.171.239:28017\", \"syncSourceId\" : 0, \"infoMessage\" : \"\", \"configVersion\" : 1 } ], \"ok\" : 1, \"operationTime\" : Timestamp(1614066965, 1), \"$clusterTime\" : { \"clusterTime\" : Timestamp(1614066965, 1), \"signature\" : { \"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"), \"keyId\" : NumberLong(0) } } } ","date":"2021-02-08","objectID":"/posts/mongodb-repliset/:3:2","series":null,"tags":["mongodb","mongodb-replication"],"title":"Mongodb RepliSet 部署","uri":"/posts/mongodb-repliset/#查询复制集状态"},{"categories":["mongodb"],"content":" 特殊从节点 (arbiter)arbiter 节点，翻译过来就是仲裁节点的意义，arbiter 主要负责选主过程中的投票，但是不存储任何数据，也不提供任何服务。 当我们想搭建一主一从的 MongoDB 复制集时就需要配置 arbiter 节点了。 搭建过程和搭建普通复制集基本是一样的，就是初始化配置多加一个配置。 ","date":"2021-02-08","objectID":"/posts/mongodb-repliset/:4:0","series":null,"tags":["mongodb","mongodb-replication"],"title":"Mongodb RepliSet 部署","uri":"/posts/mongodb-repliset/#特殊从节点-arbiter"},{"categories":["mongodb"],"content":" arbiter 复制集 bash $ mongo --port 28017 admin ## 定义初始化信息 \u003e config = {_id: 'my_repl', members: [ {_id: 0, host: '10.7.171.239:28017'}, {_id: 1, host: '10.7.171.239:28018'}, {_id: 2, host: '10.7.171.239:28019', \"arbiterOnly\": true }] } ## 初始化复制集 \u003e rs.initiate(config) ","date":"2021-02-08","objectID":"/posts/mongodb-repliset/:4:1","series":null,"tags":["mongodb","mongodb-replication"],"title":"Mongodb RepliSet 部署","uri":"/posts/mongodb-repliset/#arbiter-复制集"},{"categories":["mongodb"],"content":" 将普通复制集更改为含有 arbiter 节点复制集要想将普通节点改为 arbiter 节点，需要先移除，再添加为 arbiter 节点。 此例我们将 10.7.171.239:28019 节点更改为 arbiter 节点 bash ## 移除 10.7.171.239:28019 节点 my_repl:PRIMARY\u003e rs.remove('10.7.171.239:28019') { \"ok\" : 1, \"operationTime\" : Timestamp(1614069229, 1), \"$clusterTime\" : { \"clusterTime\" : Timestamp(1614069229, 1), \"signature\" : { \"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"), \"keyId\" : NumberLong(0) } } } ## 添加为 arbiter 节点 my_repl:PRIMARY\u003e rs.addArb('10.7.171.239:28019') { \"ok\" : 1, \"operationTime\" : Timestamp(1614069241, 1), \"$clusterTime\" : { \"clusterTime\" : Timestamp(1614069241, 1), \"signature\" : { \"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"), \"keyId\" : NumberLong(0) } } } 复制集中的节点被移除时服务会自动停止，需要手动开启服务 ","date":"2021-02-08","objectID":"/posts/mongodb-repliset/:4:2","series":null,"tags":["mongodb","mongodb-replication"],"title":"Mongodb RepliSet 部署","uri":"/posts/mongodb-repliset/#将普通复制集更改为含有-arbiter-节点复制集"},{"categories":["mongodb"],"content":" 查看 arbiter 复制集 bash my_repl:PRIMARY\u003e rs.status() { \"set\" : \"my_repl\", \"date\" : ISODate(\"2021-02-23T08:38:56.291Z\"), \"myState\" : 1, \"term\" : NumberLong(1), \"syncingTo\" : \"\", \"syncSourceHost\" : \"\", \"syncSourceId\" : -1, \"heartbeatIntervalMillis\" : NumberLong(2000), \"optimes\" : { \"lastCommittedOpTime\" : { \"ts\" : Timestamp(1614069535, 1), \"t\" : NumberLong(1) }, \"readConcernMajorityOpTime\" : { \"ts\" : Timestamp(1614069535, 1), \"t\" : NumberLong(1) }, \"appliedOpTime\" : { \"ts\" : Timestamp(1614069535, 1), \"t\" : NumberLong(1) }, \"durableOpTime\" : { \"ts\" : Timestamp(1614069535, 1), \"t\" : NumberLong(1) } }, \"members\" : [ { \"_id\" : 0, \"name\" : \"10.7.171.239:28017\", \"health\" : 1, \"state\" : 1, \"stateStr\" : \"PRIMARY\", \"uptime\" : 2987, \"optime\" : { \"ts\" : Timestamp(1614069535, 1), \"t\" : NumberLong(1) }, \"optimeDate\" : ISODate(\"2021-02-23T08:38:55Z\"), \"syncingTo\" : \"\", \"syncSourceHost\" : \"\", \"syncSourceId\" : -1, \"infoMessage\" : \"\", \"electionTime\" : Timestamp(1614066874, 1), \"electionDate\" : ISODate(\"2021-02-23T07:54:34Z\"), \"configVersion\" : 3, \"self\" : true, \"lastHeartbeatMessage\" : \"\" }, { \"_id\" : 1, \"name\" : \"10.7.171.239:28018\", \"health\" : 1, \"state\" : 2, \"stateStr\" : \"SECONDARY\", \"uptime\" : 2672, \"optime\" : { \"ts\" : Timestamp(1614069535, 1), \"t\" : NumberLong(1) }, \"optimeDurable\" : { \"ts\" : Timestamp(1614069535, 1), \"t\" : NumberLong(1) }, \"optimeDate\" : ISODate(\"2021-02-23T08:38:55Z\"), \"optimeDurableDate\" : ISODate(\"2021-02-23T08:38:55Z\"), \"lastHeartbeat\" : ISODate(\"2021-02-23T08:38:56.010Z\"), \"lastHeartbeatRecv\" : ISODate(\"2021-02-23T08:38:56.015Z\"), \"pingMs\" : NumberLong(0), \"lastHeartbeatMessage\" : \"\", \"syncingTo\" : \"10.7.171.239:28017\", \"syncSourceHost\" : \"10.7.171.239:28017\", \"syncSourceId\" : 0, \"infoMessage\" : \"\", \"configVersion\" : 3 }, { \"_id\" : 2, \"name\" : \"10.7.171.239:28019\", \"health\" : 1, \"state\" : 7, \"stateStr\" : \"ARBITER\", \"uptime\" : 174, \"lastHeartbeat\" : ISODate(\"2021-02-23T08:38:56.047Z\"), \"lastHeartbeatRecv\" : ISODate(\"2021-02-23T08:38:55.204Z\"), \"pingMs\" : NumberLong(0), \"lastHeartbeatMessage\" : \"\", \"syncingTo\" : \"\", \"syncSourceHost\" : \"\", \"syncSourceId\" : -1, \"infoMessage\" : \"\", \"configVersion\" : 3 } ], \"ok\" : 1, \"operationTime\" : Timestamp(1614069535, 1), \"$clusterTime\" : { \"clusterTime\" : Timestamp(1614069535, 1), \"signature\" : { \"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"), \"keyId\" : NumberLong(0) } } } 注意 “10.7.171.239:28019” 节点 “stateStr” 字段的值，此为 “ARBITER”， 说明 arbiter 节点配置成功 ","date":"2021-02-08","objectID":"/posts/mongodb-repliset/:4:3","series":null,"tags":["mongodb","mongodb-replication"],"title":"Mongodb RepliSet 部署","uri":"/posts/mongodb-repliset/#查看-arbiter-复制集"},{"categories":["mongodb"],"content":" 复制集管理操作","date":"2021-02-08","objectID":"/posts/mongodb-repliset/:5:0","series":null,"tags":["mongodb","mongodb-replication"],"title":"Mongodb RepliSet 部署","uri":"/posts/mongodb-repliset/#复制集管理操作"},{"categories":["mongodb"],"content":" 查看复制集状态信息 bash \u003e rs.status(); //查看整体复制集状态 \u003e rs.isMaster(); // 查看当前是否是主节点 \u003e rs.conf()； //查看复制集配置信息 ","date":"2021-02-08","objectID":"/posts/mongodb-repliset/:5:1","series":null,"tags":["mongodb","mongodb-replication"],"title":"Mongodb RepliSet 部署","uri":"/posts/mongodb-repliset/#查看复制集状态信息"},{"categories":["mongodb"],"content":" 添加删除节点 bash \u003e rs.remove(\"ip:port\"); // 删除一个节点 \u003e rs.add(\"ip:port\"); // 新增从节点 \u003e rs.addArb(\"ip:port\"); // 新增仲裁节点 注意: 以下操作需要在主节点上进行 ","date":"2021-02-08","objectID":"/posts/mongodb-repliset/:5:2","series":null,"tags":["mongodb","mongodb-replication"],"title":"Mongodb RepliSet 部署","uri":"/posts/mongodb-repliset/#添加删除节点"},{"categories":["mongodb"],"content":" 什么是验证库？验证库是建立用户时 use 到的库，在使用用户时，要加上验证库才能登陆。 对于管理员用户, 必须在 admin 下创建(先 use admin，再创建管理员用户)。 需要注意点 建用户时, use 到的库, 就是此用户的验证库 登录时,必须明确指定验证库才能登录 通常,管理员用的验证库是 admin, 普通用户的验证库一般是所管理的库设置为验证库 如果直接登录到数据库,不进行 use, 默认的验证库是 test, 不是我们生产建议的. 从 3.6 版本开始，不添加 bindIp 参数，默认不让远程登录，只能本地管理员登录。 ","date":"2021-02-05","objectID":"/posts/mongodb-auth/:1:0","series":null,"tags":["mongodb"],"title":"Mongodb 用户和权限管理","uri":"/posts/mongodb-auth/#什么是验证库"},{"categories":["mongodb"],"content":" 创建用户并赋于权限创建管理员用户 bash \u003e use admin \u003e db.createUser( { user: \"root\", pwd: \"root123\", roles: [ { role: \"root\", db: \"admin\" } ] }) 基本语法说明 user: 用户名 pwd: 用户密码 roles: role: 角色名，常用角色名(root, readWrite,read) db: 作用的库对象 查看所有 roles 指令 javascript use admin show roles ","date":"2021-02-05","objectID":"/posts/mongodb-auth/:2:0","series":null,"tags":["mongodb"],"title":"Mongodb 用户和权限管理","uri":"/posts/mongodb-auth/#创建用户并赋于权限"},{"categories":["mongodb"],"content":" 启用 mongodb 用户验证在 /etc/mongod.conf 配置文件中加入以下配置以启用用户验证功能, 然后重启 MongoDB 服务 yaml security: authorization: enabled 测试连接 bash mongo -u root -p root123 127.0.0.1/admin 查看用户信息 bash \u003e use admin # 先 use 到验证库 switched to db admin \u003e db.system.users.find().pretty() { \"_id\" : \"admin.root\", \"userId\" : UUID(\"6bf7b26e-e41b-46a3-8d28-fb6b793ba1b7\"), \"user\" : \"root\", \"db\" : \"admin\", \"credentials\" : { \"SCRAM-SHA-1\" : { \"iterationCount\" : 10000, \"salt\" : \"aViob5trN+4saa+6/5Uiow==\", \"storedKey\" : \"6tAnFjGMtn5hamEbrioIS3eTydY=\", \"serverKey\" : \"iORLUz6Ay2alLzz6Z7YevOJzdIs=\" } }, \"roles\" : [ { \"role\" : \"root\", \"db\" : \"admin\" } ] } ","date":"2021-02-05","objectID":"/posts/mongodb-auth/:3:0","series":null,"tags":["mongodb"],"title":"Mongodb 用户和权限管理","uri":"/posts/mongodb-auth/#启用-mongodb-用户验证"},{"categories":["mongodb"],"content":" 删除用户","date":"2021-02-05","objectID":"/posts/mongodb-auth/:4:0","series":null,"tags":["mongodb"],"title":"Mongodb 用户和权限管理","uri":"/posts/mongodb-auth/#删除用户"},{"categories":["mongodb"],"content":" 创建测试用户 bash \u003e use test switched to db test \u003e db.createUser({user: \"test\",pwd: \"test123\",roles: [ { role: \"readWrite\" , db: \"test\" }]}) Successfully added user: { \"user\" : \"test\", \"roles\" : [ { \"role\" : \"readWrite\", \"db\" : \"test\" } ] } ","date":"2021-02-05","objectID":"/posts/mongodb-auth/:4:1","series":null,"tags":["mongodb"],"title":"Mongodb 用户和权限管理","uri":"/posts/mongodb-auth/#创建测试用户"},{"categories":["mongodb"],"content":" 删除用户查看所有用户 bash \u003e use admin switched to db admin \u003e db.system.users.find().pretty() { \"_id\" : \"admin.root\", \"userId\" : UUID(\"6bf7b26e-e41b-46a3-8d28-fb6b793ba1b7\"), \"user\" : \"root\", \"db\" : \"admin\", \"credentials\" : { \"SCRAM-SHA-1\" : { \"iterationCount\" : 10000, \"salt\" : \"aViob5trN+4saa+6/5Uiow==\", \"storedKey\" : \"6tAnFjGMtn5hamEbrioIS3eTydY=\", \"serverKey\" : \"iORLUz6Ay2alLzz6Z7YevOJzdIs=\" } }, \"roles\" : [ { \"role\" : \"root\", \"db\" : \"admin\" } ] } { \"_id\" : \"test.test\", \"userId\" : UUID(\"505db884-397e-4eee-a050-2dab9a6dc500\"), \"user\" : \"test\", \"db\" : \"test\", \"credentials\" : { \"SCRAM-SHA-1\" : { \"iterationCount\" : 10000, \"salt\" : \"P0mVJ7NqhnXkzzXyWEfQFw==\", \"storedKey\" : \"JOjf0Xya+cOKTKuGCki7J7f7GNI=\", \"serverKey\" : \"TQLjC7FQabHjrZOtWuxIFv8kfZg=\" } }, \"roles\" : [ { \"role\" : \"readWrite\", \"db\" : \"test\" } ] } 删除用户 删除用户时需要先 use 到此用户的验证库，再执行删除命令 bash # 切换到 test 用户的验证库 test 库，删除 test 用户 \u003e use test; switched to db test \u003e db.dropUser('test') true # 切换到 admin 库查看所有用户 \u003e use admin; switched to db admin \u003e db.system.users.find() { \"_id\" : \"admin.root\", \"userId\" : UUID(\"6bf7b26e-e41b-46a3-8d28-fb6b793ba1b7\"), \"user\" : \"root\", \"db\" : \"admin\", \"credentials\" : { \"SCRAM-SHA-1\" : { \"iterationCount\" : 10000, \"salt\" : \"aViob5trN+4saa+6/5Uiow==\", \"storedKey\" : \"6tAnFjGMtn5hamEbrioIS3eTydY=\", \"serverKey\" : \"iORLUz6Ay2alLzz6Z7YevOJzdIs=\" } }, \"roles\" : [ { \"role\" : \"root\", \"db\" : \"admin\" } ] } ","date":"2021-02-05","objectID":"/posts/mongodb-auth/:4:2","series":null,"tags":["mongodb"],"title":"Mongodb 用户和权限管理","uri":"/posts/mongodb-auth/#删除用户-1"},{"categories":["mongodb"],"content":" 下载 mongodb MongoDB 社区版下载地址 bash wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel62-3.6.20.tgz ","date":"2021-01-21","objectID":"/posts/mongodb-install/:1:0","series":null,"tags":["mongodb"],"title":"Mongodb 3.6 安装","uri":"/posts/mongodb-install/#下载-mongodb"},{"categories":["mongodb"],"content":" 配置 mongodb将下载的 tar 包解压至 /usr/local 路径下，创建软链接并配置好环境变量 bash cd /usr/local/src tar xzf mongodb-linux-x86_64-rhel62-3.6.20.tgz -C /usr/local/ cd /usr/local/ ln -s /usr/local/mongodb-linux-x86_64-rhel62-3.6.20 /usr/local/mongodb # 加入环境变量 echo 'export PATH=/usr/local/mongodb/bin:$PATH' \u003e /etc/profile.d/mongo.sh source /etc/profile 创建配置文件 /etc/mongod.conf, 配置如下 yaml # mongod.conf # for documentation of all options, see: # http://docs.mongodb.org/manual/reference/configuration-options/ # where to write logging data. systemLog: destination: file logAppend: true path: /var/log/mongodb/mongod.log # Where and how to store data. storage: dbPath: /data/mongo journal: enabled: true # engine: # mmapv1: # wiredTiger: # how the process runs processManagement: fork: true # fork and run in background pidFilePath: /var/run/mongodb/mongod.pid # location of pidfile timeZoneInfo: /usr/share/zoneinfo # network interfaces net: port: 27017 bindIp: 127.0.0.1 # Listen to local interface only, comment to listen on all interfaces. #security: # authorization: enabled # 是否打开用户名和密码验证 #operationProfiling: #replication: #sharding: 创建数据目录并授权 bash useradd -r -s /bin/false mongod mkdir -p /data/mongo chown mongod:mongod /data/mongo ","date":"2021-01-21","objectID":"/posts/mongodb-install/:2:0","series":null,"tags":["mongodb"],"title":"Mongodb 3.6 安装","uri":"/posts/mongodb-install/#配置-mongodb"},{"categories":["mongodb"],"content":" 管理 mongodb 服务为 mongodb 编写 systemd unit 文件 /usr/lib/systemd/system/mongod.service bash [Unit] Description=MongoDB Database Server Documentation=https://docs.mongodb.org/manual After=network.target [Service] User=mongod Group=mongod Environment=\"OPTIONS=-f /etc/mongod.conf\" ExecStart=/usr/local/mongodb/bin/mongod $OPTIONS ExecStartPre=/usr/bin/mkdir -p /var/run/mongodb ExecStartPre=/usr/bin/chown mongod:mongod /var/run/mongodb ExecStartPre=/usr/bin/chmod 0755 /var/run/mongodb Restart=on-failure PermissionsStartOnly=true PIDFile=/var/run/mongodb/mongod.pid Type=forking # file size LimitFSIZE=infinity # cpu time LimitCPU=infinity # virtual memory size LimitAS=infinity # open files LimitNOFILE=64000 # processes/threads LimitNPROC=64000 # locked memory LimitMEMLOCK=infinity # total threads (user+kernel) TasksMax=infinity TasksAccounting=false # Recommended limits for for mongod as specified in # http://docs.mongodb.org/manual/reference/ulimit/#recommended-settings [Install] WantedBy=multi-user.target EOF 启动 MongoDB 服务, 并设置为开机自启 bash systemctl enable --now mongod.service ","date":"2021-01-21","objectID":"/posts/mongodb-install/:3:0","series":null,"tags":["mongodb"],"title":"Mongodb 3.6 安装","uri":"/posts/mongodb-install/#管理-mongodb-服务"},{"categories":["mongodb"],"content":" 连接 mongodb使用以下命令连接至 mongodb bash mongo # 或 mongo localhost:27017/admin ","date":"2021-01-21","objectID":"/posts/mongodb-install/:4:0","series":null,"tags":["mongodb"],"title":"Mongodb 3.6 安装","uri":"/posts/mongodb-install/#连接-mongodb"},{"categories":["mysql"],"content":" 参考资料: DBAplus 社区 ","date":"2021-01-14","objectID":"/posts/mysql-maxscale-readwrite-separation/:0:0","series":null,"tags":["maxscale"],"title":"MaxScale：实现MySQL读写分离与负载均衡的中间件利器","uri":"/posts/mysql-maxscale-readwrite-separation/#"},{"categories":["mysql"],"content":" 搭建主从集群参考 MySQL GTID 主从复制配置 ","date":"2021-01-14","objectID":"/posts/mysql-maxscale-readwrite-separation/:1:0","series":null,"tags":["maxscale"],"title":"MaxScale：实现MySQL读写分离与负载均衡的中间件利器","uri":"/posts/mysql-maxscale-readwrite-separation/#搭建主从集群"},{"categories":["mysql"],"content":" 安装 MaxScale MaxScale Github 地址 MaxScale 下载地址 bash yum install https://downloads.mariadb.com/MaxScale/2.5.6/centos/7/x86_64/maxscale-2.5.6-1.rhel.7.x86_64.rpm ","date":"2021-01-14","objectID":"/posts/mysql-maxscale-readwrite-separation/:2:0","series":null,"tags":["maxscale"],"title":"MaxScale：实现MySQL读写分离与负载均衡的中间件利器","uri":"/posts/mysql-maxscale-readwrite-separation/#安装-maxscale"},{"categories":["mysql"],"content":" 配置 MaxScale在主库创建监控用户，路由用户 sql # 监控账号 create user scalemon@'%' identified by \"123456\"; grant replication slave, replication client on *.* to scalemon@'%'; # 路由用户 create user maxscale@'%' identified by \"123456\"; grant select on mysql.* to maxscale@'%'; grant show databases on *.* to maxscale@'%'; 从库会自动同步账号 开始配置 由于我们只使用 Read-Write-Service，不需要 Read-Only-Service，将其注释即可。 Read-Only-Listener 也需要同时注释 bash [root@db-proxy ~]# cat /etc/maxscale.cnf # MaxScale documentation: # https://mariadb.com/kb/en/mariadb-maxscale-24/ # Global parameters # # Complete list of configuration options: # https://mariadb.com/kb/en/mariadb-maxscale-24-mariadb-maxscale-configuration-guide/ [maxscale] threads=auto log_info=1 logdir=/tmp/ admin_host=0.0.0.0 admin_secure_gui=false # Server definitions # # Set the address of the server to the network # address of a MariaDB server. # [server1] type=server address=10.10.1.11 port=3306 protocol=MariaDBBackend [server2] type=server address=10.10.1.12 port=3306 protocol=MariaDBBackend [server3] type=server address=10.10.1.13 port=3306 protocol=MariaDBBackend # Monitor for the servers # # This will keep MaxScale aware of the state of the servers. # MariaDB Monitor documentation: # https://mariadb.com/kb/en/mariadb-maxscale-24-mariadb-monitor/ [MariaDB-Monitor] type=monitor module=mariadbmon servers=server1,server2,server3 user=scalemon password=123456 monitor_interval=2000 # Service definitions # # Service Definition for a read-only service and # a read/write splitting service. # # ReadConnRoute documentation: # https://mariadb.com/kb/en/mariadb-maxscale-24-readconnroute/ #[Read-Only-Service] #type=service #router=readconnroute #servers=server1,server2,server3 #user=maxscale #password=123456 #router_options=slave # ReadWriteSplit documentation: # https://mariadb.com/kb/en/mariadb-maxscale-24-readwritesplit/ [Read-Write-Service] type=service router=readwritesplit servers=server1,server2,server3 user=maxscale password=123456 # Listener definitions for the services # # These listeners represent the ports the # services will listen on. # #[Read-Only-Listener] #type=listener #service=Read-Only-Service #protocol=MariaDBClient #port=4008 [Read-Write-Listener] type=listener service=Read-Write-Service protocol=MariaDBClient port=4006 启动检查状态 bash [root@db-proxy ~]# systemctl start maxscale.service [root@MHA_Maxscale ~]# netstat -anptl | grep maxscale [root@db-proxy ~]# ss -anptl | grep maxscale LISTEN 0 128 *:8989 *:* users:((\"maxscale\",pid=1498,fd=23)) LISTEN 0 128 :::4006 :::* users:((\"maxscale\",pid=1498,fd=28)) 4006: 是 MaxScale 实现 MySQL 读写分离时连接使用的端口 8989: 是 MaxScale web 管理页面端口 使用 maxctrl 命令查看数据库连接状态 bash [root@db-proxy ~]# maxctrl list services ┌────────────────────┬────────────────┬─────────────┬───────────────────┬───────────────────────────┐ │ Service │ Router │ Connections │ Total Connections │ Servers │ ├────────────────────┼────────────────┼─────────────┼───────────────────┼───────────────────────────┤ │ Read-Write-Service │ readwritesplit │ 0 │ 0 │ server1, server3, server2 │ └────────────────────┴────────────────┴─────────────┴───────────────────┴───────────────────────────┘ [root@db-proxy ~]# maxctrl list servers ┌─────────┬────────────┬──────┬─────────────┬─────────────────┬──────┐ │ Server │ Address │ Port │ Connections │ State │ GTID │ ├─────────┼────────────┼──────┼─────────────┼─────────────────┼──────┤ │ server2 │ 10.10.1.12 │ 3306 │ 0 │ Slave, Running │ │ ├─────────┼────────────┼──────┼─────────────┼─────────────────┼──────┤ │ server1 │ 10.10.1.11 │ 3306 │ 0 │ Master, Running │ │ ├─────────┼────────────┼──────┼─────────────┼─────────────────┼──────┤ │ server3 │ 10.10.1.13 │ 3306 │ 0 │ Slave, Running │ │ └─────────┴────────────┴──────┴─────────────┴─────────────────┴──────┘ 也可以登录 Web 页面查看，地址: http://maxscale_server_ip:8989, 默认的用户名和密码是 admin/mariadb ","date":"2021-01-14","objectID":"/posts/mysql-maxscale-readwrite-separation/:3:0","series":null,"tags":["maxscale"],"title":"MaxScale：实现MySQL读写分离与负载均衡的中间件利器","uri":"/posts/mysql-maxscale-readwrite-separation/#配置-maxscale"},{"categories":["mysql"],"content":" 测试读写分离使用 mysql 命令连接 maxscale 4006 端口进行测试，应用端也是使用此地址和端口进行连接数据库 bash [root@db-proxy ~]# mysql -h 10.10.1.10 -P 4006 -u lwg -p123456 Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MySQL connection id is 1 Server version: 5.7.28-log MySQL Community Server (GPL) Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MySQL [(none)]\u003e select @@hostname; # 默认读操作会发送至从库，重复多次执行可以看到两台从库轮询的效果 +------------+ | @@hostname | +------------+ | db2 | +------------+ 1 row in set (0.01 sec) MySQL [(none)]\u003e begin; select @@hostname; rollback; # 使用开启事务方式，模拟写操作，可以看到写操作被发送到主库 Query OK, 0 rows affected (0.01 sec) +------------+ | @@hostname | +------------+ | db1 | +------------+ 1 row in set (0.00 sec) Query OK, 0 rows affected (0.00 sec) ","date":"2021-01-14","objectID":"/posts/mysql-maxscale-readwrite-separation/:4:0","series":null,"tags":["maxscale"],"title":"MaxScale：实现MySQL读写分离与负载均衡的中间件利器","uri":"/posts/mysql-maxscale-readwrite-separation/#测试读写分离"},{"categories":["mysql"],"content":" MySQL MHA 架构介绍官方文档: https://github.com/yoshinorim/mha4mysql-manager/wiki MHA（Master High Availability）目前在MySQL高可用方面是一个相对成熟的解决方案，它由日本 DeNA 公司 youshimaton（现就职于Facebook公司）开发，是一套优秀的作为 MySQL 高可用性环境下故障切换和主从提升的高可用软件。 在MySQL故障切换过程中，MHA能做到在0~30秒之内自动完成数据库的故障切换操作，并且在进行故障切换的过程中，MHA能在最大程度上保证数据的一致性，以达到真正意义上的高可用。 该软件由两部分组成：MHA Manager（管理节点）和MHA Node（数据节点）。 MHA Manager 可以单独部署在一台独立的机器上管理多个 master-slave 集群，也可以部署在一台 slave 节点上。 MHA Node 运行在每台 MySQL 服务器上，MHA Manager 会定时探测集群中的 master 节点，当 master 出现故障时，它可以自动将最新数据的 slave 提升为新的 master，然后将所有其他的 slave 重新指向新的 master。整个故障转移过程对应用程序完全透明（配合 vip）。 在 MHA 自动故障切换过程中，MHA 试图从宕机的主服务器上保存二进制日志，最大程度的保证数据的不丢失，但这并不总是可行的。例如，如果主服务器硬件故障或无法通过 ssh 访问，MHA 没法保存二进制日志，只进行故障转移而丢失了最新的数据。使用 binlog-server 可以最大程度减少日志的缺失，大大降低数据丢失的风险。MHA 可以 binlog-server 结合起来。如果只有一个 slave已经收到了最新的二进制日志，MHA 可以将最新的二进制日志应用于其他所有的 slave 服务器上，因此可以保证所有节点的数据一致性。 目前 MHA 主要支持一主多从的架构，要搭建 MHA,要求一个复制集群中必须最少有三台数据库服务器，一主二从，即一台充当 master，一台充当备用 master，另外一台充当从库，因为至少需要三台服务器，出于机器成本的考虑，淘宝也在该基础上进行了改造，目前淘宝TMHA已经支持一主一从。 注: MHA 是一次性高可用，Failover 后, Manager 会自动退出 ","date":"2021-01-14","objectID":"/posts/mysql-mha/:1:0","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#mysql-mha-架构介绍"},{"categories":["mysql"],"content":" MHA 工作原理可以将 MHA 工作原理总结如下 从宕机崩溃的 master 保存二进制日志事件（binlog events）; 识别含有最新更新的 slave； 应用差异的中继日志（relay log）到其他的 slave； 应用从 master 保存的二进制日志事件（binlog events）； 提升一个 slave 为新的 master； 使其他的 slave 连接新的 master 进行复制； ","date":"2021-01-14","objectID":"/posts/mysql-mha/:2:0","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#mha-工作原理"},{"categories":["mysql"],"content":" MHA 软件说明MHA 软件由两部分组成，Manager 工具包和 Node 工具包，具体的说明如下。 Manager 工具包主要包括以下几个工具： masterha_check_ssh: 检查MHA的SSH配置状况 masterha_check_repl: 检查MySQL复制状况 masterha_manger: 启动MHA masterha_check_status: 检测当前MHA运行状态 masterha_master_monitor: 检测master是否宕机 masterha_master_switch: 控制故障转移（自动或者手动） masterha_conf_host: 添加或删除配置的server信息 Node工具包（这些工具通常由MHA Manager的脚本触发，无需人为操作）主要包括以下几个工具： save_binary_logs: 保存和复制master的二进制日志 apply_diff_relay_logs: 识别差异的中继日志事件并将其差异的事件应用于其他的 slave filter_mysqlbinlog: 去除不必要的 ROLLBACK 事件（MHA 已不再使用这个工具） purge_relay_logs: 清除中继日志（不会阻塞 SQL 线程） ","date":"2021-01-14","objectID":"/posts/mysql-mha/:3:0","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#mha-软件说明"},{"categories":["mysql"],"content":" 环境准备环境说明: 服务器数量: 3台，一主两从（使用 GTID 模式搭建主从环境，搭建过程略） 操作系统: Ubuntu 18.04 server, MySQL 版本: 5.7.28 注意: 如果需要使用 MHA 的 VIP 功能，三台机的网卡名必须一致 Master: ip: 10.10.1.2/24 vip: 10.10.1.10/24 (应用连接主库使用的 ip 地址) server_id: 2 mha_role: node Slave1: ip: 10.10.1.3/24 server_id: 3 mha_role: node Slave2: ip: 10.10.1.4/24 server_id: 4 mha_role: node, manager 创建 mha 管理 mysql 用户， 在主库执行 sql create user mha@'10.10.1.%' identified by 'YMhHZawmFAFBEf6T'; grant all privileges on *.* to 'mha'@'10.10.1.%'; 配置 mysql, mysqlbinlog 软链接 bash ln -s /usr/local/mysql/bin/mysql /usr/bin/ ln -s /usr/local/mysql/bin/mysqlbinlog /usr/bin/ ","date":"2021-01-14","objectID":"/posts/mysql-mha/:4:0","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#环境准备"},{"categories":["mysql"],"content":" 配置 SSH 互信MHA Manager 在内部通过 SSH 连接到 MySQL 服务器。最新从站上的 MHA 节点还通过 SSH（scp）在内部将中继日志文件发送到其他从站。为了使这些过程自动化，通常建议在不使用口令的情况下启用SSH公钥身份验证。您可以使用 MHA Manager 中包含的 masterha_check_ssh 命令来检查SSH连接是否正常工作。 slave2 机器上操作 bash ssh-keygen -t rsa ...（略） ssh-copy -i /root/.ssh/id_rsa.pub 10.10.1.4 rsync -arvP /root/.ssh/ 10.10.1.2:/root./ssh rsync -arvP /root/.ssh/ 10.10.1.3:/root./ssh ","date":"2021-01-14","objectID":"/posts/mysql-mha/:4:1","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#配置-ssh-互信"},{"categories":["mysql"],"content":" 安装 MHAMHA 下载地址: mha4mysql-node: https://github.com/yoshinorim/mha4mysql-node/releases mha4mysql-manager: https://github.com/yoshinorim/mha4mysql-manager/releases ","date":"2021-01-14","objectID":"/posts/mysql-mha/:5:0","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#安装-mha"},{"categories":["mysql"],"content":" 安装 mha4mysql-node在三台机器执行安装 bash dpkg -i mha4mysql-node_0.58-0_all.deb apt install -f 修复 mha4mysql-node bug mha4mysql-node-0.58 版本中 /usr/share/perl5/MHA/NodeUtil.pm 文件在执行 masterha_check_repl 命令时会提示错误，修复方法: 直接从 mha4mysql-node 存储库下载最新的 NodeUtil.pm 覆盖即可 ","date":"2021-01-14","objectID":"/posts/mysql-mha/:5:1","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#安装-mha4mysql-node"},{"categories":["mysql"],"content":" 安装 mha4mysql-manager在 slave2 机器上安装 mha4mysql-manager bash dpkg -i mha4mysql-manager_0.58-0_all.deb ","date":"2021-01-14","objectID":"/posts/mysql-mha/:5:2","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#安装-mha4mysql-manager"},{"categories":["mysql"],"content":" 配置 MHA","date":"2021-01-14","objectID":"/posts/mysql-mha/:6:0","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#配置-mha"},{"categories":["mysql"],"content":" 生成 MHA 配置文件 bash # 创建配置目录 mkdir /etc/mha # 配置 mha 配置文件 cat \u003e /etc/mha/app1.conf \u003c\u003cEOF [server default] # mha 的工作目录 manager_workdir=/var/log/masterha # mha-manager 的日志文件 manager_log=/var/log/masterha/app1.log # 主库的 BINLOG 日志存储路径 master_binlog_dir=/data/mysql/3306 # MHA管理器 ping 主库主机的频率 ping_interval=2 # mha 管理 mysql 的用户名和密码 user=mha password=123456 # mysql replication username and password repl_user=repl repl_password=123456 # ssh 连接其他服务器的用户名 ssh_user=root # 主库故障切换时 VIP 漂移脚本文件，需要自定义 master_ip_failover_script=/usr/local/bin/master_ip_failover # 故障切换时发送邮箱提示, 自定义脚本(可以调用通讯工具的 api 发送消息, 例如: 微信) report_script=/usr/local/bin/alarm.sh [server1] hostname=10.10.1.2 port=3306 [server2] hostname=10.10.1.3 port=3306 # 配置为备选主，但是如果日志量落后 master 太多话也可能不会选为新主 # 此时需要配合 check_repl_delay = 0 参数 candidate_master=1 # 不检查日志落后量 check_repl_delay=0 [server3] hostname=10.10.1.4 port=3306 [binlog1] # 不参与选主 no_master=1 hostname=10.10.1.4 # 注意此参数必须与 [server default] 下配置值不同 master_binlog_dir=/data/mysql/binlog EOF binlogserver 配置：找一台额外的机器，必须要有 MySQL 5.6 以上的版本，支持 gtid 并开启 注意: mha 配置文件名是可以自己随意指定，建议和业务有关。mha 可以管理多套主从高可用 ","date":"2021-01-14","objectID":"/posts/mysql-mha/:6:1","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#生成-mha-配置文件"},{"categories":["mysql"],"content":" 配置 vip vip 配置项 ini [server default] master_ip_failover_script=/usr/local/bin/master_ip_failover 注意: 需要先在主库手动配置上 vip 地址，本例是: 10.10.1.10/24 vip 切换脚本注意: 使用 mha vip 功能需要保证所有机器的网卡名是一致的 脚本内容修改说明: 根据实际情况修改脚本 vip 变量: $vip, $ssh_start_vip, $ssh_stop_vip perl #!/usr/bin/env perl # Copyright (C) 2011 DeNA Co.,Ltd. # # This program is free software; you can redistribute it and/or modify # it under the terms of the GNU General Public License as published by # the Free Software Foundation; either version 2 of the License, or # (at your option) any later version. # # This program is distributed in the hope that it will be useful, # but WITHOUT ANY WARRANTY; without even the implied warranty of # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the # GNU General Public License for more details. # # You should have received a copy of the GNU General Public License # along with this program; if not, write to the Free Software # Foundation, Inc., # 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA ## Note: This is a sample script and is not complete. Modify the script based on your environment. use strict; use warnings FATAL =\u003e 'all'; use Getopt::Long; use MHA::DBHelper; my ( $command, $ssh_user, $orig_master_host, $orig_master_ip, $orig_master_port, $new_master_host, $new_master_ip, $new_master_port, $new_master_user, $new_master_password ); # vip 变量配置处 my $vip = '10.10.1.10/24'; my $ssh_start_vip = \"/sbin/ip addr add $vip dev ens33\"; my $ssh_stop_vip = \"/sbin/ip addr del $vip dev ens33\"; GetOptions( 'command=s' =\u003e \\$command, 'ssh_user=s' =\u003e \\$ssh_user, 'orig_master_host=s' =\u003e \\$orig_master_host, 'orig_master_ip=s' =\u003e \\$orig_master_ip, 'orig_master_port=i' =\u003e \\$orig_master_port, 'new_master_host=s' =\u003e \\$new_master_host, 'new_master_ip=s' =\u003e \\$new_master_ip, 'new_master_port=i' =\u003e \\$new_master_port, 'new_master_user=s' =\u003e \\$new_master_user, 'new_master_password=s' =\u003e \\$new_master_password, ); exit \u0026main(); sub main { if ( $command eq \"stop\" || $command eq \"stopssh\" ) { # $orig_master_host, $orig_master_ip, $orig_master_port are passed. # If you manage master ip address at global catalog database, # invalidate orig_master_ip here. my $exit_code = 1; eval { # updating global catalog, etc $exit_code = 0; }; if ($@) { warn \"Got Error: $@\\n\"; exit $exit_code; } exit $exit_code; } elsif ( $command eq \"start\" ) { # all arguments are passed. # If you manage master ip address at global catalog database, # activate new_master_ip here. # You can also grant write access (create user, set read_only=0, etc) here. my $exit_code = 10; eval { print \"Enabling the VIP - $vip on the new master - $new_master_host \\n\"; \u0026start_vip(); \u0026stop_vip(); $exit_code = 0; }; if ($@) { warn $@; exit $exit_code; } exit $exit_code; } elsif ( $command eq \"status\" ) { print \"Checking the Status of the script.. OK \\n\"; `ssh $ssh_user\\@$orig_master_host \\\" $ssh_start_vip \\\"`; exit 0; } else { \u0026usage(); exit 1; } } sub start_vip() { `ssh $ssh_user\\@$new_master_host \\\" $ssh_start_vip \\\"`; } # A simple system call that disable the VIP on the old_master sub stop_vip() { `ssh $ssh_user\\@$orig_master_host \\\" $ssh_stop_vip \\\"`; } sub usage { print \"Usage: master_ip_failover --command=start|stop|stopssh|status --orig_master_host=host --orig_master_ip=ip --orig_master_port=port --new_master_host=host --new_master_ip=ip --new_master_port=port\\n\"; } ","date":"2021-01-14","objectID":"/posts/mysql-mha/:6:2","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#配置-vip"},{"categories":["mysql"],"content":" 配置 vip vip 配置项 ini [server default] master_ip_failover_script=/usr/local/bin/master_ip_failover 注意: 需要先在主库手动配置上 vip 地址，本例是: 10.10.1.10/24 vip 切换脚本注意: 使用 mha vip 功能需要保证所有机器的网卡名是一致的 脚本内容修改说明: 根据实际情况修改脚本 vip 变量: $vip, $ssh_start_vip, $ssh_stop_vip perl #!/usr/bin/env perl # Copyright (C) 2011 DeNA Co.,Ltd. # # This program is free software; you can redistribute it and/or modify # it under the terms of the GNU General Public License as published by # the Free Software Foundation; either version 2 of the License, or # (at your option) any later version. # # This program is distributed in the hope that it will be useful, # but WITHOUT ANY WARRANTY; without even the implied warranty of # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the # GNU General Public License for more details. # # You should have received a copy of the GNU General Public License # along with this program; if not, write to the Free Software # Foundation, Inc., # 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA ## Note: This is a sample script and is not complete. Modify the script based on your environment. use strict; use warnings FATAL =\u003e 'all'; use Getopt::Long; use MHA::DBHelper; my ( $command, $ssh_user, $orig_master_host, $orig_master_ip, $orig_master_port, $new_master_host, $new_master_ip, $new_master_port, $new_master_user, $new_master_password ); # vip 变量配置处 my $vip = '10.10.1.10/24'; my $ssh_start_vip = \"/sbin/ip addr add $vip dev ens33\"; my $ssh_stop_vip = \"/sbin/ip addr del $vip dev ens33\"; GetOptions( 'command=s' =\u003e \\$command, 'ssh_user=s' =\u003e \\$ssh_user, 'orig_master_host=s' =\u003e \\$orig_master_host, 'orig_master_ip=s' =\u003e \\$orig_master_ip, 'orig_master_port=i' =\u003e \\$orig_master_port, 'new_master_host=s' =\u003e \\$new_master_host, 'new_master_ip=s' =\u003e \\$new_master_ip, 'new_master_port=i' =\u003e \\$new_master_port, 'new_master_user=s' =\u003e \\$new_master_user, 'new_master_password=s' =\u003e \\$new_master_password, ); exit \u0026main(); sub main { if ( $command eq \"stop\" || $command eq \"stopssh\" ) { # $orig_master_host, $orig_master_ip, $orig_master_port are passed. # If you manage master ip address at global catalog database, # invalidate orig_master_ip here. my $exit_code = 1; eval { # updating global catalog, etc $exit_code = 0; }; if ($@) { warn \"Got Error: $@\\n\"; exit $exit_code; } exit $exit_code; } elsif ( $command eq \"start\" ) { # all arguments are passed. # If you manage master ip address at global catalog database, # activate new_master_ip here. # You can also grant write access (create user, set read_only=0, etc) here. my $exit_code = 10; eval { print \"Enabling the VIP - $vip on the new master - $new_master_host \\n\"; \u0026start_vip(); \u0026stop_vip(); $exit_code = 0; }; if ($@) { warn $@; exit $exit_code; } exit $exit_code; } elsif ( $command eq \"status\" ) { print \"Checking the Status of the script.. OK \\n\"; `ssh $ssh_user\\@$orig_master_host \\\" $ssh_start_vip \\\"`; exit 0; } else { \u0026usage(); exit 1; } } sub start_vip() { `ssh $ssh_user\\@$new_master_host \\\" $ssh_start_vip \\\"`; } # A simple system call that disable the VIP on the old_master sub stop_vip() { `ssh $ssh_user\\@$orig_master_host \\\" $ssh_stop_vip \\\"`; } sub usage { print \"Usage: master_ip_failover --command=start|stop|stopssh|status --orig_master_host=host --orig_master_ip=ip --orig_master_port=port --new_master_host=host --new_master_ip=ip --new_master_port=port\\n\"; } ","date":"2021-01-14","objectID":"/posts/mysql-mha/:6:2","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#vip-配置项"},{"categories":["mysql"],"content":" 配置 vip vip 配置项 ini [server default] master_ip_failover_script=/usr/local/bin/master_ip_failover 注意: 需要先在主库手动配置上 vip 地址，本例是: 10.10.1.10/24 vip 切换脚本注意: 使用 mha vip 功能需要保证所有机器的网卡名是一致的 脚本内容修改说明: 根据实际情况修改脚本 vip 变量: $vip, $ssh_start_vip, $ssh_stop_vip perl #!/usr/bin/env perl # Copyright (C) 2011 DeNA Co.,Ltd. # # This program is free software; you can redistribute it and/or modify # it under the terms of the GNU General Public License as published by # the Free Software Foundation; either version 2 of the License, or # (at your option) any later version. # # This program is distributed in the hope that it will be useful, # but WITHOUT ANY WARRANTY; without even the implied warranty of # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the # GNU General Public License for more details. # # You should have received a copy of the GNU General Public License # along with this program; if not, write to the Free Software # Foundation, Inc., # 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA ## Note: This is a sample script and is not complete. Modify the script based on your environment. use strict; use warnings FATAL =\u003e 'all'; use Getopt::Long; use MHA::DBHelper; my ( $command, $ssh_user, $orig_master_host, $orig_master_ip, $orig_master_port, $new_master_host, $new_master_ip, $new_master_port, $new_master_user, $new_master_password ); # vip 变量配置处 my $vip = '10.10.1.10/24'; my $ssh_start_vip = \"/sbin/ip addr add $vip dev ens33\"; my $ssh_stop_vip = \"/sbin/ip addr del $vip dev ens33\"; GetOptions( 'command=s' =\u003e \\$command, 'ssh_user=s' =\u003e \\$ssh_user, 'orig_master_host=s' =\u003e \\$orig_master_host, 'orig_master_ip=s' =\u003e \\$orig_master_ip, 'orig_master_port=i' =\u003e \\$orig_master_port, 'new_master_host=s' =\u003e \\$new_master_host, 'new_master_ip=s' =\u003e \\$new_master_ip, 'new_master_port=i' =\u003e \\$new_master_port, 'new_master_user=s' =\u003e \\$new_master_user, 'new_master_password=s' =\u003e \\$new_master_password, ); exit \u0026main(); sub main { if ( $command eq \"stop\" || $command eq \"stopssh\" ) { # $orig_master_host, $orig_master_ip, $orig_master_port are passed. # If you manage master ip address at global catalog database, # invalidate orig_master_ip here. my $exit_code = 1; eval { # updating global catalog, etc $exit_code = 0; }; if ($@) { warn \"Got Error: $@\\n\"; exit $exit_code; } exit $exit_code; } elsif ( $command eq \"start\" ) { # all arguments are passed. # If you manage master ip address at global catalog database, # activate new_master_ip here. # You can also grant write access (create user, set read_only=0, etc) here. my $exit_code = 10; eval { print \"Enabling the VIP - $vip on the new master - $new_master_host \\n\"; \u0026start_vip(); \u0026stop_vip(); $exit_code = 0; }; if ($@) { warn $@; exit $exit_code; } exit $exit_code; } elsif ( $command eq \"status\" ) { print \"Checking the Status of the script.. OK \\n\"; `ssh $ssh_user\\@$orig_master_host \\\" $ssh_start_vip \\\"`; exit 0; } else { \u0026usage(); exit 1; } } sub start_vip() { `ssh $ssh_user\\@$new_master_host \\\" $ssh_start_vip \\\"`; } # A simple system call that disable the VIP on the old_master sub stop_vip() { `ssh $ssh_user\\@$orig_master_host \\\" $ssh_stop_vip \\\"`; } sub usage { print \"Usage: master_ip_failover --command=start|stop|stopssh|status --orig_master_host=host --orig_master_ip=ip --orig_master_port=port --new_master_host=host --new_master_ip=ip --new_master_port=port\\n\"; } ","date":"2021-01-14","objectID":"/posts/mysql-mha/:6:2","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#vip-切换脚本"},{"categories":["mysql"],"content":" 配置故障切换告警故障切换告警脚本需自行开发，可以调用通讯应用的 api 接口发送信息，例如: 微信，叮叮等 ini [server default] report_script=/usr/local/bin/alarm.sh ","date":"2021-01-14","objectID":"/posts/mysql-mha/:6:3","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#配置故障切换告警"},{"categories":["mysql"],"content":" 配置 binlogserver mha 的 binlogserver 配置项 ini [binlog1] no_master=1 hostname=10.10.1.4 # 注意此参数须与 [server default] 下配置值不同 master_binlog_dir=/data/mysql/binlog 启动 binlogserver 服务 bash # 必须进入到自己创建好的目录 cd /data/mysql/binlog mysqlbinlog -R --host=10.10.1.10 --user=mha --password=mha --raw --stop-never mysql-bin.000001 \u0026 --host=10.10.1.10: 从主库拉取二进制日志 mysql-bin.000001: 拉取二进制日志的起始日志文件名，可以在从库 show slave status\\G 查看获取 注意： 拉取日志的起点, 需要按照目前从库的已经获取到的二进制日志点为起点 binlogserver 服务可以使用 supervisor 程序管理 ","date":"2021-01-14","objectID":"/posts/mysql-mha/:6:4","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#配置-binlogserver"},{"categories":["mysql"],"content":" 配置 binlogserver mha 的 binlogserver 配置项 ini [binlog1] no_master=1 hostname=10.10.1.4 # 注意此参数须与 [server default] 下配置值不同 master_binlog_dir=/data/mysql/binlog 启动 binlogserver 服务 bash # 必须进入到自己创建好的目录 cd /data/mysql/binlog mysqlbinlog -R --host=10.10.1.10 --user=mha --password=mha --raw --stop-never mysql-bin.000001 \u0026 --host=10.10.1.10: 从主库拉取二进制日志 mysql-bin.000001: 拉取二进制日志的起始日志文件名，可以在从库 show slave status\\G 查看获取 注意： 拉取日志的起点, 需要按照目前从库的已经获取到的二进制日志点为起点 binlogserver 服务可以使用 supervisor 程序管理 ","date":"2021-01-14","objectID":"/posts/mysql-mha/:6:4","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#mha-的-binlogserver-配置项"},{"categories":["mysql"],"content":" 配置 binlogserver mha 的 binlogserver 配置项 ini [binlog1] no_master=1 hostname=10.10.1.4 # 注意此参数须与 [server default] 下配置值不同 master_binlog_dir=/data/mysql/binlog 启动 binlogserver 服务 bash # 必须进入到自己创建好的目录 cd /data/mysql/binlog mysqlbinlog -R --host=10.10.1.10 --user=mha --password=mha --raw --stop-never mysql-bin.000001 \u0026 --host=10.10.1.10: 从主库拉取二进制日志 mysql-bin.000001: 拉取二进制日志的起始日志文件名，可以在从库 show slave status\\G 查看获取 注意： 拉取日志的起点, 需要按照目前从库的已经获取到的二进制日志点为起点 binlogserver 服务可以使用 supervisor 程序管理 ","date":"2021-01-14","objectID":"/posts/mysql-mha/:6:4","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#启动-binlogserver-服务"},{"categories":["mysql"],"content":" 环境检测 检查 ssh 连接 bash root@db3:~# masterha_check_ssh --conf=/etc/mha/app1.conf Tue Dec 29 20:09:18 2020 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping. Tue Dec 29 20:09:18 2020 - [info] Reading application default configuration from /etc/mha/app1.conf.. Tue Dec 29 20:09:18 2020 - [info] Reading server configuration from /etc/mha/app1.conf.. Tue Dec 29 20:09:18 2020 - [info] Starting SSH connection tests.. Tue Dec 29 20:09:23 2020 - [debug] Tue Dec 29 20:09:19 2020 - [debug] Connecting via SSH from root@10.10.1.4(10.10.1.4:22) to root@10.10.1.2(10.10.1.2:22).. Tue Dec 29 20:09:20 2020 - [debug] ok. Tue Dec 29 20:09:20 2020 - [debug] Connecting via SSH from root@10.10.1.4(10.10.1.4:22) to root@10.10.1.3(10.10.1.3:22).. Tue Dec 29 20:09:22 2020 - [debug] ok. Tue Dec 29 20:09:24 2020 - [debug] Tue Dec 29 20:09:19 2020 - [debug] Connecting via SSH from root@10.10.1.3(10.10.1.3:22) to root@10.10.1.2(10.10.1.2:22).. Tue Dec 29 20:09:22 2020 - [debug] ok. Tue Dec 29 20:09:22 2020 - [debug] Connecting via SSH from root@10.10.1.3(10.10.1.3:22) to root@10.10.1.4(10.10.1.4:22).. Tue Dec 29 20:09:23 2020 - [debug] ok. Tue Dec 29 20:09:24 2020 - [debug] Tue Dec 29 20:09:18 2020 - [debug] Connecting via SSH from root@10.10.1.2(10.10.1.2:22) to root@10.10.1.3(10.10.1.3:22).. Tue Dec 29 20:09:20 2020 - [debug] ok. Tue Dec 29 20:09:20 2020 - [debug] Connecting via SSH from root@10.10.1.2(10.10.1.2:22) to root@10.10.1.4(10.10.1.4:22).. Tue Dec 29 20:09:23 2020 - [debug] ok. Tue Dec 29 20:09:24 2020 - [info] All SSH connection tests passed successfully. 检查 mysql 连接 bash root@db3:~# masterha_check_ssh --conf=/etc/mha/app1.conf Tue Dec 29 20:09:18 2020 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping. Tue Dec 29 20:09:18 2020 - [info] Reading application default configuration from /etc/mha/app1.conf.. Tue Dec 29 20:09:18 2020 - [info] Reading server configuration from /etc/mha/app1.conf.. Tue Dec 29 20:09:18 2020 - [info] Starting SSH connection tests.. Tue Dec 29 20:09:23 2020 - [debug] Tue Dec 29 20:09:19 2020 - [debug] Connecting via SSH from root@10.10.1.4(10.10.1.4:22) to root@10.10.1.2(10.10.1.2:22).. Tue Dec 29 20:09:20 2020 - [debug] ok. Tue Dec 29 20:09:20 2020 - [debug] Connecting via SSH from root@10.10.1.4(10.10.1.4:22) to root@10.10.1.3(10.10.1.3:22).. Tue Dec 29 20:09:22 2020 - [debug] ok. Tue Dec 29 20:09:24 2020 - [debug] Tue Dec 29 20:09:19 2020 - [debug] Connecting via SSH from root@10.10.1.3(10.10.1.3:22) to root@10.10.1.2(10.10.1.2:22).. Tue Dec 29 20:09:22 2020 - [debug] ok. Tue Dec 29 20:09:22 2020 - [debug] Connecting via SSH from root@10.10.1.3(10.10.1.3:22) to root@10.10.1.4(10.10.1.4:22).. Tue Dec 29 20:09:23 2020 - [debug] ok. Tue Dec 29 20:09:24 2020 - [debug] Tue Dec 29 20:09:18 2020 - [debug] Connecting via SSH from root@10.10.1.2(10.10.1.2:22) to root@10.10.1.3(10.10.1.3:22).. Tue Dec 29 20:09:20 2020 - [debug] ok. Tue Dec 29 20:09:20 2020 - [debug] Connecting via SSH from root@10.10.1.2(10.10.1.2:22) to root@10.10.1.4(10.10.1.4:22).. Tue Dec 29 20:09:23 2020 - [debug] ok. Tue Dec 29 20:09:24 2020 - [info] All SSH connection tests passed successfully. root@db3:~# masterha_check_repl --conf=/etc/mha/app1.conf Tue Dec 29 20:09:59 2020 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping. Tue Dec 29 20:09:59 2020 - [info] Reading application default configuration from /etc/mha/app1.conf.. Tue Dec 29 20:09:59 2020 - [info] Reading server configuration from /etc/mha/app1.conf.. Tue Dec 29 20:09:59 2020 - [info] MHA::MasterMonitor version 0.58. Tue Dec 29 20:10:01 2020 - [info] GTID failover mode = 1 Tue Dec 29 20:10:01 2020 - [info] Dead Servers: Tue Dec 29 20:10:01 2020 - [info] Alive Servers: Tue Dec 29 20:10:01 2020 - [info] 10.10.1.2(10.10.1.2:3306) Tue Dec 29 20:10:01 2020 - [info] 10.10.1.3(10.10.1.3:3306) Tue Dec 29 20:10:01 2020 - [info] 10.10.1.4(10.10.1.4:3306) Tue Dec 29 20:10:01 2020 - [info] Alive Slaves: Tue ","date":"2021-01-14","objectID":"/posts/mysql-mha/:6:5","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#环境检测"},{"categories":["mysql"],"content":" 环境检测 检查 ssh 连接 bash root@db3:~# masterha_check_ssh --conf=/etc/mha/app1.conf Tue Dec 29 20:09:18 2020 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping. Tue Dec 29 20:09:18 2020 - [info] Reading application default configuration from /etc/mha/app1.conf.. Tue Dec 29 20:09:18 2020 - [info] Reading server configuration from /etc/mha/app1.conf.. Tue Dec 29 20:09:18 2020 - [info] Starting SSH connection tests.. Tue Dec 29 20:09:23 2020 - [debug] Tue Dec 29 20:09:19 2020 - [debug] Connecting via SSH from root@10.10.1.4(10.10.1.4:22) to root@10.10.1.2(10.10.1.2:22).. Tue Dec 29 20:09:20 2020 - [debug] ok. Tue Dec 29 20:09:20 2020 - [debug] Connecting via SSH from root@10.10.1.4(10.10.1.4:22) to root@10.10.1.3(10.10.1.3:22).. Tue Dec 29 20:09:22 2020 - [debug] ok. Tue Dec 29 20:09:24 2020 - [debug] Tue Dec 29 20:09:19 2020 - [debug] Connecting via SSH from root@10.10.1.3(10.10.1.3:22) to root@10.10.1.2(10.10.1.2:22).. Tue Dec 29 20:09:22 2020 - [debug] ok. Tue Dec 29 20:09:22 2020 - [debug] Connecting via SSH from root@10.10.1.3(10.10.1.3:22) to root@10.10.1.4(10.10.1.4:22).. Tue Dec 29 20:09:23 2020 - [debug] ok. Tue Dec 29 20:09:24 2020 - [debug] Tue Dec 29 20:09:18 2020 - [debug] Connecting via SSH from root@10.10.1.2(10.10.1.2:22) to root@10.10.1.3(10.10.1.3:22).. Tue Dec 29 20:09:20 2020 - [debug] ok. Tue Dec 29 20:09:20 2020 - [debug] Connecting via SSH from root@10.10.1.2(10.10.1.2:22) to root@10.10.1.4(10.10.1.4:22).. Tue Dec 29 20:09:23 2020 - [debug] ok. Tue Dec 29 20:09:24 2020 - [info] All SSH connection tests passed successfully. 检查 mysql 连接 bash root@db3:~# masterha_check_ssh --conf=/etc/mha/app1.conf Tue Dec 29 20:09:18 2020 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping. Tue Dec 29 20:09:18 2020 - [info] Reading application default configuration from /etc/mha/app1.conf.. Tue Dec 29 20:09:18 2020 - [info] Reading server configuration from /etc/mha/app1.conf.. Tue Dec 29 20:09:18 2020 - [info] Starting SSH connection tests.. Tue Dec 29 20:09:23 2020 - [debug] Tue Dec 29 20:09:19 2020 - [debug] Connecting via SSH from root@10.10.1.4(10.10.1.4:22) to root@10.10.1.2(10.10.1.2:22).. Tue Dec 29 20:09:20 2020 - [debug] ok. Tue Dec 29 20:09:20 2020 - [debug] Connecting via SSH from root@10.10.1.4(10.10.1.4:22) to root@10.10.1.3(10.10.1.3:22).. Tue Dec 29 20:09:22 2020 - [debug] ok. Tue Dec 29 20:09:24 2020 - [debug] Tue Dec 29 20:09:19 2020 - [debug] Connecting via SSH from root@10.10.1.3(10.10.1.3:22) to root@10.10.1.2(10.10.1.2:22).. Tue Dec 29 20:09:22 2020 - [debug] ok. Tue Dec 29 20:09:22 2020 - [debug] Connecting via SSH from root@10.10.1.3(10.10.1.3:22) to root@10.10.1.4(10.10.1.4:22).. Tue Dec 29 20:09:23 2020 - [debug] ok. Tue Dec 29 20:09:24 2020 - [debug] Tue Dec 29 20:09:18 2020 - [debug] Connecting via SSH from root@10.10.1.2(10.10.1.2:22) to root@10.10.1.3(10.10.1.3:22).. Tue Dec 29 20:09:20 2020 - [debug] ok. Tue Dec 29 20:09:20 2020 - [debug] Connecting via SSH from root@10.10.1.2(10.10.1.2:22) to root@10.10.1.4(10.10.1.4:22).. Tue Dec 29 20:09:23 2020 - [debug] ok. Tue Dec 29 20:09:24 2020 - [info] All SSH connection tests passed successfully. root@db3:~# masterha_check_repl --conf=/etc/mha/app1.conf Tue Dec 29 20:09:59 2020 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping. Tue Dec 29 20:09:59 2020 - [info] Reading application default configuration from /etc/mha/app1.conf.. Tue Dec 29 20:09:59 2020 - [info] Reading server configuration from /etc/mha/app1.conf.. Tue Dec 29 20:09:59 2020 - [info] MHA::MasterMonitor version 0.58. Tue Dec 29 20:10:01 2020 - [info] GTID failover mode = 1 Tue Dec 29 20:10:01 2020 - [info] Dead Servers: Tue Dec 29 20:10:01 2020 - [info] Alive Servers: Tue Dec 29 20:10:01 2020 - [info] 10.10.1.2(10.10.1.2:3306) Tue Dec 29 20:10:01 2020 - [info] 10.10.1.3(10.10.1.3:3306) Tue Dec 29 20:10:01 2020 - [info] 10.10.1.4(10.10.1.4:3306) Tue Dec 29 20:10:01 2020 - [info] Alive Slaves: Tue ","date":"2021-01-14","objectID":"/posts/mysql-mha/:6:5","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#检查-ssh-连接"},{"categories":["mysql"],"content":" 环境检测 检查 ssh 连接 bash root@db3:~# masterha_check_ssh --conf=/etc/mha/app1.conf Tue Dec 29 20:09:18 2020 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping. Tue Dec 29 20:09:18 2020 - [info] Reading application default configuration from /etc/mha/app1.conf.. Tue Dec 29 20:09:18 2020 - [info] Reading server configuration from /etc/mha/app1.conf.. Tue Dec 29 20:09:18 2020 - [info] Starting SSH connection tests.. Tue Dec 29 20:09:23 2020 - [debug] Tue Dec 29 20:09:19 2020 - [debug] Connecting via SSH from root@10.10.1.4(10.10.1.4:22) to root@10.10.1.2(10.10.1.2:22).. Tue Dec 29 20:09:20 2020 - [debug] ok. Tue Dec 29 20:09:20 2020 - [debug] Connecting via SSH from root@10.10.1.4(10.10.1.4:22) to root@10.10.1.3(10.10.1.3:22).. Tue Dec 29 20:09:22 2020 - [debug] ok. Tue Dec 29 20:09:24 2020 - [debug] Tue Dec 29 20:09:19 2020 - [debug] Connecting via SSH from root@10.10.1.3(10.10.1.3:22) to root@10.10.1.2(10.10.1.2:22).. Tue Dec 29 20:09:22 2020 - [debug] ok. Tue Dec 29 20:09:22 2020 - [debug] Connecting via SSH from root@10.10.1.3(10.10.1.3:22) to root@10.10.1.4(10.10.1.4:22).. Tue Dec 29 20:09:23 2020 - [debug] ok. Tue Dec 29 20:09:24 2020 - [debug] Tue Dec 29 20:09:18 2020 - [debug] Connecting via SSH from root@10.10.1.2(10.10.1.2:22) to root@10.10.1.3(10.10.1.3:22).. Tue Dec 29 20:09:20 2020 - [debug] ok. Tue Dec 29 20:09:20 2020 - [debug] Connecting via SSH from root@10.10.1.2(10.10.1.2:22) to root@10.10.1.4(10.10.1.4:22).. Tue Dec 29 20:09:23 2020 - [debug] ok. Tue Dec 29 20:09:24 2020 - [info] All SSH connection tests passed successfully. 检查 mysql 连接 bash root@db3:~# masterha_check_ssh --conf=/etc/mha/app1.conf Tue Dec 29 20:09:18 2020 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping. Tue Dec 29 20:09:18 2020 - [info] Reading application default configuration from /etc/mha/app1.conf.. Tue Dec 29 20:09:18 2020 - [info] Reading server configuration from /etc/mha/app1.conf.. Tue Dec 29 20:09:18 2020 - [info] Starting SSH connection tests.. Tue Dec 29 20:09:23 2020 - [debug] Tue Dec 29 20:09:19 2020 - [debug] Connecting via SSH from root@10.10.1.4(10.10.1.4:22) to root@10.10.1.2(10.10.1.2:22).. Tue Dec 29 20:09:20 2020 - [debug] ok. Tue Dec 29 20:09:20 2020 - [debug] Connecting via SSH from root@10.10.1.4(10.10.1.4:22) to root@10.10.1.3(10.10.1.3:22).. Tue Dec 29 20:09:22 2020 - [debug] ok. Tue Dec 29 20:09:24 2020 - [debug] Tue Dec 29 20:09:19 2020 - [debug] Connecting via SSH from root@10.10.1.3(10.10.1.3:22) to root@10.10.1.2(10.10.1.2:22).. Tue Dec 29 20:09:22 2020 - [debug] ok. Tue Dec 29 20:09:22 2020 - [debug] Connecting via SSH from root@10.10.1.3(10.10.1.3:22) to root@10.10.1.4(10.10.1.4:22).. Tue Dec 29 20:09:23 2020 - [debug] ok. Tue Dec 29 20:09:24 2020 - [debug] Tue Dec 29 20:09:18 2020 - [debug] Connecting via SSH from root@10.10.1.2(10.10.1.2:22) to root@10.10.1.3(10.10.1.3:22).. Tue Dec 29 20:09:20 2020 - [debug] ok. Tue Dec 29 20:09:20 2020 - [debug] Connecting via SSH from root@10.10.1.2(10.10.1.2:22) to root@10.10.1.4(10.10.1.4:22).. Tue Dec 29 20:09:23 2020 - [debug] ok. Tue Dec 29 20:09:24 2020 - [info] All SSH connection tests passed successfully. root@db3:~# masterha_check_repl --conf=/etc/mha/app1.conf Tue Dec 29 20:09:59 2020 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping. Tue Dec 29 20:09:59 2020 - [info] Reading application default configuration from /etc/mha/app1.conf.. Tue Dec 29 20:09:59 2020 - [info] Reading server configuration from /etc/mha/app1.conf.. Tue Dec 29 20:09:59 2020 - [info] MHA::MasterMonitor version 0.58. Tue Dec 29 20:10:01 2020 - [info] GTID failover mode = 1 Tue Dec 29 20:10:01 2020 - [info] Dead Servers: Tue Dec 29 20:10:01 2020 - [info] Alive Servers: Tue Dec 29 20:10:01 2020 - [info] 10.10.1.2(10.10.1.2:3306) Tue Dec 29 20:10:01 2020 - [info] 10.10.1.3(10.10.1.3:3306) Tue Dec 29 20:10:01 2020 - [info] 10.10.1.4(10.10.1.4:3306) Tue Dec 29 20:10:01 2020 - [info] Alive Slaves: Tue ","date":"2021-01-14","objectID":"/posts/mysql-mha/:6:5","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#检查-mysql-连接"},{"categories":["mysql"],"content":" 启动 MHA由于 masterha_manager 需要手动将程序放入后台运行，这里使用 supervisor 作为进程管理工具 bash # 安装 supervisor root@db3:~# apt install supervisor # 启动 supervisor root@db3:~# systemctl start supervisor.service # 编写 supervisor mha 配置文件 root@db3:~# cd /etc/supervisor/conf.d/ root@db3:/etc/supervisor/conf.d# cat \u003e mha.conf \u003c\u003cEOF [program:mha] command=/usr/bin/masterha_manager --conf=/etc/mha/app1.conf --remove_dead_master_conf --ignore_last_failover process_name=%(program_name)s numprocs=1 directory=/var/log/masterha umask=022 autostart=true startsecs=1 startretries=3 autorestart=unexpected exitcodes=0,2 stopsignal=QUIT stopwaitsecs=10 stopasgroup=false killasgroup=false user=root redirect_stderr=true stdout_logfile=/var/log/masterha/app1.log stderr_logfile=/var/log/masterha/app1.log EOF # 更新 supervisor 配置 root@db3:/etc/supervisor/conf.d# supervisorctl update # 查看 supervisor 管理进程信息 root@db3:/etc/supervisor/conf.d# supervisorctl status ","date":"2021-01-14","objectID":"/posts/mysql-mha/:6:6","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#启动-mha"},{"categories":["mysql"],"content":" 故障测试","date":"2021-01-14","objectID":"/posts/mysql-mha/:7:0","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#故障测试"},{"categories":["mysql"],"content":" 测试故障停止主库进程，查看 masterha_manager 日志信息，检查主从复制状态, 请自行测试！ ","date":"2021-01-14","objectID":"/posts/mysql-mha/:7:1","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#测试故障"},{"categories":["mysql"],"content":" 恢复过程主库宕机后，binlogserver 自动停掉，masterha_manager 也会自动停止 处理思路: 检查主从复制状态 检查 masterha_manager 配置文件，查看前主库信息是否已经删除 (–remove_dead_master_conf 选项会自动删除故障主库配置信息)，如果存在故障切换可能失败。 查看 masterha_manager 日志文件 清理 binlogserver 二进制日志，重新获取新主库的 binlog 到 binlogserver 中 (使用了 vip 连接不需更改，启动服务即可) 修复故障库，手工加入主从。 重新配置 masterha_manager 配置文件 最后再启动 MHA ","date":"2021-01-14","objectID":"/posts/mysql-mha/:7:2","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#恢复过程"},{"categories":["mysql"],"content":" 最后虽然 mha 高可用解决了主库故障问题，但真实使用的只有一台主库别两台从库处于空闲状态，资源得不到有效的利用。 此时为了更好地利用资源，提升效率，我们可以在 mha 高可用的基础上加入读写分离架构进行优化提升效率。 参考资源: https://www.jianshu.com/p/0f7b5a962ba7 MHA 官方文档: https://github.com/yoshinorim/mha4mysql-manager/wiki ","date":"2021-01-14","objectID":"/posts/mysql-mha/:8:0","series":null,"tags":["mysqlmha","mha"],"title":"MySQL MHA 高可用配置","uri":"/posts/mysql-mha/#最后"},{"categories":["mysql"],"content":" 优化参数 ini [mysqld] # 从库配置优化 master_info_repository = TABLE relay_log_info_repository = TABLE relay_log_recovery = 1 relay-log-purge = 1 read_only = 1 super_read_only = 1 master.info: 存储连接主库的信息，已经接收的 binlog 位置点信息 (默认在从库数据目录中) 配置项: master_info_repository = FILE/TABLE master_info_repository 默认值为 FILE 存储文件名为 master.info，值为改为 TABLE 时 master.info 信息将存储在表中，可以提高性能 relay-log.info: 记录从库回放 relay-log 位置点 (默认在从库数据目录中) 配置项: relay_log_info_repository = FILE/TABLE relay_log_info_repository 默认值为 FILE 存储文件名为 relay-log.info，值为改为 TABLE 时 relay-log.info 信息将存储在表中，可以提高性能 relay_log_purge: 自动清理 relay-log 文件 read_only: 禁止写操作，从库配置可以防止误写操作 super_read_only: 禁止管理员写操作，从库配置可以防止误写操作 ","date":"2021-01-13","objectID":"/posts/mysql-replication-optimization/:1:0","series":null,"tags":["mysql-replication"],"title":"MySQL 主从复制优化","uri":"/posts/mysql-replication-optimization/#优化参数"},{"categories":["mysql"],"content":" 延时从库应用场景：普通主从正常情况可以应对物理损坏，但无法应用逻辑损坏。例如: drop 和 delete 等操作。 延时从库可以应对这种逻辑损坏场景： 主库做了某项操作后，等多少秒后从库再应用。 注: 延时从库延时的是 sql 线程回放 relay 日志的时间，不是与主库传输二进制日志的时间 ","date":"2021-01-13","objectID":"/posts/mysql-slave-extend/:1:0","series":null,"tags":["mysql-replication"],"title":"MySQL 从库扩展","uri":"/posts/mysql-slave-extend/#延时从库"},{"categories":["mysql"],"content":" 配置延时从库主要参数: MASTER_DELAY bash mysql\u003e stop slave; mysql\u003e CHANGE MASTER TO MASTER_DELAY=10800; mysql\u003e start slave; ","date":"2021-01-13","objectID":"/posts/mysql-slave-extend/:1:1","series":null,"tags":["mysql-replication"],"title":"MySQL 从库扩展","uri":"/posts/mysql-slave-extend/#配置延时从库"},{"categories":["mysql"],"content":" 恢复思路 1.先停业务，挂维护页 2.停从库 SQL 线程, stop slave sql_thread; 看 relay_log 位置点; stop slave; 这里只是停止 sql 线程，io 线程并没有停，也就是说主库与从库的二进制日志传输是一直存在的。 最后停止从库时注意观察主从复制二进制日志的情况是否一至。 3.追加后续缺失的日志到从库。（相当于手工替代 sql 线程工作） 日志文件: relay-log 日志文件起始位置确认: 查看命令: show slave status\\G 也可以通过查看relay-log.info 文件 cat /data/mysql/3306/relay-log.info 日志文件终点确认: 查看命令: show relaylog events in 'db2-relay-bin.000002' 查看 relaylog 日志事件，只需要看 Pos 列； End_log_pos 列是对应主库的 binlog 位置点。 4.恢复业务，直接将业务指向从库或者将数据导回到主库 ","date":"2021-01-13","objectID":"/posts/mysql-slave-extend/:1:2","series":null,"tags":["mysql-replication"],"title":"MySQL 从库扩展","uri":"/posts/mysql-slave-extend/#恢复思路"},{"categories":["mysql"],"content":" 过滤复制","date":"2021-01-13","objectID":"/posts/mysql-slave-extend/:2:0","series":null,"tags":["mysql-replication"],"title":"MySQL 从库扩展","uri":"/posts/mysql-slave-extend/#过滤复制"},{"categories":["mysql"],"content":" 主库配置binlog_do_db: 需要记录二进制的库 binlog_ignore_db: 不需要记录二进制的库 ini [mysqld] binlog_do_db=test 二选一即可 ","date":"2021-01-13","objectID":"/posts/mysql-slave-extend/:2:1","series":null,"tags":["mysql-replication"],"title":"MySQL 从库扩展","uri":"/posts/mysql-slave-extend/#主库配置"},{"categories":["mysql"],"content":" 从库配置如果使用 replicate-ignore-db 参数设置不同步的库，需要注意: 使用 use 语句选库后执行的操作才会被忽略不同步，如果 sql 直接通过 库名.表名 执行的操作还是会被同步的。 如果希望不管选不选库的操作都会被忽略可以使用 replicate-wild-ignore-table 配置项 库级别 replicate_do_db: 需要复制的库名 replicate_ignore_db: 忽略复制的库名 表级别 replicate_do_table: 需要复制的库中的表 replicate_ignore_table: 忽略复制的库中的表 带有模糊匹配的配置项 replicate_wild_do_table replicate_wild_ignore_table ","date":"2021-01-13","objectID":"/posts/mysql-slave-extend/:2:2","series":null,"tags":["mysql-replication"],"title":"MySQL 从库扩展","uri":"/posts/mysql-slave-extend/#从库配置"},{"categories":["mysql"],"content":" 半同步复制经典主从复制使用的异步复制工作模型，会导致主从数据不一致的情况 MySQL 5.5 版本为了保证主从数据的一致性问题，加入半同步复制的组件(插件) 在主从复制结构中都需要启用半同步复制插件。 半同步复制主要是控制从库io是否将 relay-log 写入磁盘，一旦落盘通过插件返回 ACK 给主库的 ACK_rec， 接收到 ACK 之后，主库的事务才能提交成功。 在默认情况下,如果超过 10s 没有返回 ACK，此次复制行为会切换为异步复制。 半同步复制会影响数据库性能，也并不能完全保证主从复制的数据一致性。并不推荐使用 ","date":"2021-01-13","objectID":"/posts/mysql-slave-extend/:3:0","series":null,"tags":["mysql-replication"],"title":"MySQL 从库扩展","uri":"/posts/mysql-slave-extend/#半同步复制"},{"categories":["mysql"],"content":" 备份主库为了节省恢复的时间我们使用 xtrabackup 备份主库，然后拷贝到从库再将数据恢复到从库中 ","date":"2021-01-13","objectID":"/posts/mysql-restore-gtid-replication/:1:0","series":null,"tags":["mysql-replication","xtrabackup"],"title":"MySQL GTID 从库快速恢复","uri":"/posts/mysql-restore-gtid-replication/#备份主库"},{"categories":["mysql"],"content":" 完整备份主库 bash # 备份 xtrabackup --defaults-file=/usr/local/mysql/etc/my.cnf -S /data/mysql/mysql.sock -u root -p --backup --target-dir=/data/backup ","date":"2021-01-13","objectID":"/posts/mysql-restore-gtid-replication/:1:1","series":null,"tags":["mysql-replication","xtrabackup"],"title":"MySQL GTID 从库快速恢复","uri":"/posts/mysql-restore-gtid-replication/#完整备份主库"},{"categories":["mysql"],"content":" 恢复主从复制","date":"2021-01-13","objectID":"/posts/mysql-restore-gtid-replication/:2:0","series":null,"tags":["mysql-replication","xtrabackup"],"title":"MySQL GTID 从库快速恢复","uri":"/posts/mysql-restore-gtid-replication/#恢复主从复制"},{"categories":["mysql"],"content":" 恢复从库数据 bash # 恢复准备，应用日志 xtrabackup --prepare --target-dir=/data/backup/mysql # 恢复备份 xtrabackup --defaults-file=/usr/local/mysql/etc/my.cnf --copy-back --target-dir=/data/backup/mysql # 修改数据目录的权限 chown -R mysql:mysql /data/mysql # 启动数据库 systemctl start mysqld ","date":"2021-01-13","objectID":"/posts/mysql-restore-gtid-replication/:2:1","series":null,"tags":["mysql-replication","xtrabackup"],"title":"MySQL GTID 从库快速恢复","uri":"/posts/mysql-restore-gtid-replication/#恢复从库数据"},{"categories":["mysql"],"content":" 开始恢复主从复制由于我们使用的是 xtrabackup 工具备份恢复的数据，gtid_purged 值可以从 xtrabackup_binlog_info 文件中获取。 如果是使用是 mysqldump 命令备份加上 --master-data=1 参数就可以在备份文件中看到 SET @@GLOBAL.GTID_PURGED='d6f25a03-5d80-11eb-9fe8-000c29738b1d:1-4'; 语句，此时恢复从库数据时就会自动执行 SET @@GLOBAL.GTID_PURGED='d6f25a03-5d80-11eb-9fe8-000c29738b1d:1-4'; 语句，在恢复主从复制时就不需要在手动执行 set global gtid_purged=... 命令\b啦~ sql stop slave; reset master; reset slave; set global gtid_purged='cdb92087-ac64-11e9-bb08-20040ff98044:1-395071'; change master to master_host='10.10.1.11', master_user='repl', master_password='123456',master_port=3306, master_auto_position=1; start slave; 注意: 设置 gtid_purged 是为了告诉从库与主库进行主从复制时的起始 GITD， 如果不加会默认从 gtid 的1号位置点执行，此时就会出现主从复制错误 ","date":"2021-01-13","objectID":"/posts/mysql-restore-gtid-replication/:2:2","series":null,"tags":["mysql-replication","xtrabackup"],"title":"MySQL GTID 从库快速恢复","uri":"/posts/mysql-restore-gtid-replication/#开始恢复主从复制"},{"categories":["mysql"],"content":" 检查，测试请自行检测，略… ","date":"2021-01-13","objectID":"/posts/mysql-restore-gtid-replication/:3:0","series":null,"tags":["mysql-replication","xtrabackup"],"title":"MySQL GTID 从库快速恢复","uri":"/posts/mysql-restore-gtid-replication/#检查测试"},{"categories":["mysql"],"content":" 环境准备准备两台服务器安装 MySQL 5.7, 参考 安装 MySQL 5.7 服务器列表 master: 10.10.1.11/24 slave1: 10.10.1.12/24 ","date":"2021-01-13","objectID":"/posts/mysql-gtid-replication/:1:0","series":null,"tags":["mysql-replication","mysql-gtid-replication"],"title":"MySQL GTID 主从复制配置","uri":"/posts/mysql-gtid-replication/#环境准备"},{"categories":["mysql"],"content":" 配置 MySQL配置基于 GTID 的主从复制需要启动 gtid 和 binlog 功能，具体配置如下 主库: my.cnf ini [client] port = 3306 socket = /data/mysql/mysql.sock [mysqld] user = mysql port = 3306 basedir = /usr/local/mysql datadir = /data/mysql socket = /data/mysql/mysql.sock pid-file = mysqldb.pid character-set-server = utf8mb4 skip_name_resolve = 1 log-error = /data/mysql/error.log # gtid 配置 server_id=11 gtid_mode=on enforce-gtid-consistency = true master-info-repository = TABLE relay-log-info-repository = TABLE relay_log_recovery = on sync-master-info = 1 # binlog 配置 log-bin = /data/mysql/mybinlog sync_binlog = 1 binlog_cache_size = 4M max_binlog_cache_size = 2G max_binlog_size = 1G expire_logs_days = 7 binlog_format = row binlog_checksum = 1 # 事务模式 transaction_isolation = REPEATABLE-READ # InnoDB 配置 innodb_buffer_pool_size = 128M innodb_buffer_pool_instances = 4 innodb_data_file_path = ibdata1:1G:autoextend innodb_flush_log_at_trx_commit = 0 从库: my.cnf ini [client] port = 3306 socket = /data/mysql/mysql.sock [mysqld] user = mysql port = 3306 basedir = /usr/local/mysql datadir = /data/mysql socket = /data/mysql/mysql.sock pid-file = mysqldb.pid character-set-server = utf8mb4 skip_name_resolve = 1 log-error = /data/mysql/error.log # gtid 配置 server_id=12 gtid_mode=on enforce-gtid-consistency = true master-info-repository = TABLE relay-log-info-repository = TABLE relay_log_recovery = on sync-master-info = 1 # binlog 配置 log-bin = /data/mysql/mybinlog sync_binlog = 1 binlog_cache_size = 4M max_binlog_cache_size = 2G max_binlog_size = 1G expire_logs_days = 7 binlog_format = row binlog_checksum = 1 ## 禁止从库数据写入 read_only = 1 # 事务模式 transaction_isolation = REPEATABLE-READ # InnoDB 配置 innodb_buffer_pool_size = 128M innodb_buffer_pool_instances = 4 innodb_data_file_path = ibdata1:1G:autoextend innodb_flush_log_at_trx_commit = 0 ","date":"2021-01-13","objectID":"/posts/mysql-gtid-replication/:2:0","series":null,"tags":["mysql-replication","mysql-gtid-replication"],"title":"MySQL GTID 主从复制配置","uri":"/posts/mysql-gtid-replication/#配置-mysql"},{"categories":["mysql"],"content":" 配置主从同步","date":"2021-01-13","objectID":"/posts/mysql-gtid-replication/:3:0","series":null,"tags":["mysql-replication","mysql-gtid-replication"],"title":"MySQL GTID 主从复制配置","uri":"/posts/mysql-gtid-replication/#配置主从同步"},{"categories":["mysql"],"content":" 创建主从同步用户在主库上操作 sql create user 'repl'@'10.10.1.%' identified by '123456'; grant replication slave on *.* to 'repl'@'10.10.1.%'; flush privileges; ","date":"2021-01-13","objectID":"/posts/mysql-gtid-replication/:3:1","series":null,"tags":["mysql-replication","mysql-gtid-replication"],"title":"MySQL GTID 主从复制配置","uri":"/posts/mysql-gtid-replication/#创建主从同步用户"},{"categories":["mysql"],"content":" 主从数据同步由于当前 MySQL 环境是全新搭建的，没有任何数据，此步可以忽略。 如果是在已经运行了很久的数据库或者数据库存在数据的情况下，需要对主库进行全备然后恢复到从库，在配置启动主从复制 ","date":"2021-01-13","objectID":"/posts/mysql-gtid-replication/:3:2","series":null,"tags":["mysql-replication","mysql-gtid-replication"],"title":"MySQL GTID 主从复制配置","uri":"/posts/mysql-gtid-replication/#主从数据同步"},{"categories":["mysql"],"content":" 启动主从同步在从库上执行以下命令 sql change master to master_host='10.10.1.11', master_user='repl', master_password='123456', master_port=3306, master_auto_position=1; start slave; GTID 主从复制只需指定 master_auto_position=1 参数即可，相比经典主从复制更简单 ","date":"2021-01-13","objectID":"/posts/mysql-gtid-replication/:3:3","series":null,"tags":["mysql-replication","mysql-gtid-replication"],"title":"MySQL GTID 主从复制配置","uri":"/posts/mysql-gtid-replication/#启动主从同步"},{"categories":["mysql"],"content":" 查看主从同步状态 bash mysql\u003e show slave status\\G *************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 10.10.1.11 Master_User: repl Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mybinlog.000003 Read_Master_Log_Pos: 763 Relay_Log_File: db2-relay-bin.000002 Relay_Log_Pos: 974 Relay_Master_Log_File: mybinlog.000003 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 763 Relay_Log_Space: 1179 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0 Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 10 Master_UUID: d6f25a03-5d80-11eb-9fe8-000c29738b1d Master_Info_File: mysql.slave_master_info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: d6f25a03-5d80-11eb-9fe8-000c29738b1d:1-3 Executed_Gtid_Set: d6f25a03-5d80-11eb-9fe8-000c29738b1d:1-3 Auto_Position: 1 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version: 1 row in set (0.00 sec) ","date":"2021-01-13","objectID":"/posts/mysql-gtid-replication/:3:4","series":null,"tags":["mysql-replication","mysql-gtid-replication"],"title":"MySQL GTID 主从复制配置","uri":"/posts/mysql-gtid-replication/#查看主从同步状态"},{"categories":["mysql"],"content":" 主从同步测试请自行测试, 略… ","date":"2021-01-13","objectID":"/posts/mysql-gtid-replication/:4:0","series":null,"tags":["mysql-replication","mysql-gtid-replication"],"title":"MySQL GTID 主从复制配置","uri":"/posts/mysql-gtid-replication/#主从同步测试"},{"categories":["mysql"],"content":" 安装 MySQL 5.7服务器列表 master: 10.10.1.2/24 slave1: 10.10.1.3/24 ","date":"2021-01-13","objectID":"/posts/mysql-classic-replication/:1:0","series":null,"tags":["mysql-replication","mysql-classic-replication"],"title":"MySQL 经典主从复制配置","uri":"/posts/mysql-classic-replication/#安装-mysql-57"},{"categories":["mysql"],"content":" 下载 MySQL bash root@db2:/usr/local/src# wget https://cdn.mysql.com/archives/mysql-5.7/mysql-5.7.28-linux-glibc2.12-x86_64.tar.gz root@db1:/usr/local/src# tar xzf mysql-5.7.28-linux-glibc2.12-x86_64.tar.gz -C /usr/local/ root@db1:/usr/local# ln -s /usr/local/mysql-5.7.28-linux-glibc2.12-x86_64/ /usr/local/mysql ","date":"2021-01-13","objectID":"/posts/mysql-classic-replication/:1:1","series":null,"tags":["mysql-replication","mysql-classic-replication"],"title":"MySQL 经典主从复制配置","uri":"/posts/mysql-classic-replication/#下载-mysql"},{"categories":["mysql"],"content":" 环境准备 bash # 安装依赖 root@db1:/usr/local/mysql# apt-get install libaio1 # 创建程序用户 root@db1:/usr/local/mysql# useradd -r -s /sbin/nologin mysql # 创建数据目录 root@db1:/usr/local/mysql# mkdir -p /data/mysql/3306 # 更改数据目录权限 root@db1:/usr/local/mysql# chown -R mysql.mysql /data/mysql/3306/ # 配置环境变量 root@db1:/usr/local/mysql# echo 'export PATH=/usr/local/mysql/bin:$PATH' \u003e /etc/profile.d/mysql.sh root@db1:/usr/local/mysql# source /etc/profile ","date":"2021-01-13","objectID":"/posts/mysql-classic-replication/:1:2","series":null,"tags":["mysql-replication","mysql-classic-replication"],"title":"MySQL 经典主从复制配置","uri":"/posts/mysql-classic-replication/#环境准备"},{"categories":["mysql"],"content":" 初始化数据库准备 my.cnf 配置文件 bash root@db1:/usr/local/mysql# mkdir etc root@db1:/usr/local/mysql# cat \u003e etc/my.cnf \u003c\u003c EOF [client] port = 3306 socket = /data/mysql/3306/mysql.sock [mysqld] user = mysql port = 3306 basedir = /usr/local/mysql datadir = /data/mysql/3306 socket = /data/mysql/3306/mysql.sock pid-file = mysqldb.pid character-set-server = utf8mb4 log-error = /data/mysql/3306/error.log skip_name_resolve = 1 # 不同实例设置不同数字，不能相同 server-id = 1 # BINGLO 配置，主从同步必须启用 BINLOG 日志 log-bin = /data/mysql/3306/mybinlog binlog_cache_size = 4M max_binlog_cache_size = 2G max_binlog_size = 1G expire_logs_days = 7 binlog_format = row binlog_checksum = 1 sync_binlog = 1 # 事务模式 transaction_isolation = REPEATABLE-READ # InnoDB 配置 innodb_buffer_pool_size = 128M innodb_buffer_pool_instances = 4 innodb_data_file_path = ibdata1:1G:autoextend innodb_flush_log_at_trx_commit = 0 初始化数据库 bash root@db1:/usr/local/mysql# mysqld --initialize-insecure --user=mysql --basedir=/usr/local/mysql --datadir=/data/mysql/3306 另一台数据库同样的方法安装初始化，就是配置文件 server_id 的值需要修改 ","date":"2021-01-13","objectID":"/posts/mysql-classic-replication/:1:3","series":null,"tags":["mysql-replication","mysql-classic-replication"],"title":"MySQL 经典主从复制配置","uri":"/posts/mysql-classic-replication/#初始化数据库"},{"categories":["mysql"],"content":" 配置主从同步","date":"2021-01-13","objectID":"/posts/mysql-classic-replication/:2:0","series":null,"tags":["mysql-replication","mysql-classic-replication"],"title":"MySQL 经典主从复制配置","uri":"/posts/mysql-classic-replication/#配置主从同步"},{"categories":["mysql"],"content":" 主库操作启用主库的 binlog bash root@db1:/usr/local/mysql# cat etc/my.cnf [mysqld] # 不同实例设置不同数字，不能相同 server-id = 1 # BINGLO 配置，主从同步必须启用 BINLOG 日志 log-bin = /data/mysql/3306/mybinlog binlog_cache_size = 4M max_binlog_cache_size = 2G max_binlog_size = 1G expire_logs_days = 7 binlog_format = row binlog_checksum = 1 sync_binlog = 1 创建同步账号 bash mysql\u003e create user 'repl'@'10.10.1.%' identified by '123456'; mysql\u003e grant replication slave on *.* to 'repl'@'10.10.1.%'; mysql\u003e flush privileges; 导出数据用于创建 slave bash root@db1:~# mysqldump -uroot -p -A -R -E -B -x --master-data=2 | gzip \u003e all.sql.gz -A, –all-databases: 备份所有数据库 -E, –events: 备份事件 -B, –databases: 备份的数据库 -x, –lock-all-tables：锁定所有数据库的所有表 –master-data=2: 等于2时会将 CHANGE MASTER 命令以注释的方式加入备份文件中 将备份文件拷贝到从库还原 ","date":"2021-01-13","objectID":"/posts/mysql-classic-replication/:2:1","series":null,"tags":["mysql-replication","mysql-classic-replication"],"title":"MySQL 经典主从复制配置","uri":"/posts/mysql-classic-replication/#主库操作"},{"categories":["mysql"],"content":" 从库操作配置 my.cnf 从库(slave)如果用于备份可以启用 binlog, 如果用于读操作可以不启用, 只配置 server-id 即可. text [root@slave1 ~]# cat /usr/local/mysql/etc/my.cnf [mysqld] server-id = 2 # binlog 配置 log-bin = /data/mysql/3306/mybinlog binlog_cache_size = 4M max_binlog_cache_size = 2G max_binlog_size = 1G expire_logs_days = 7 binlog_format = row binlog_checksum = 1 sync_binlog = 1 从 master 恢复数据 bash root@db2:~# gzip -d all.sql.gz root@db2:~# mysql -uroot \u003c all.sql 设置主从同步 bash # 从备份文件找到 CHANGE MASTER 命令 root@db2:~# more all.sql -- CHANGE MASTER TO MASTER_LOG_FILE='mybinlog.000002', MASTER_LOG_POS=763; # 配置 slave mysql\u003e CHANGE MASTER TO -\u003e MASTER_HOST='10.10.1.2', -\u003e MASTER_PORT=3306, -\u003e MASTER_USER='repl', -\u003e MASTER_PASSWORD='123456', -\u003e MASTER_LOG_FILE='mybinlog.000002', -\u003e MASTER_LOG_POS=763; mysql\u003e start slave; mysql\u003e show slave status\\G *************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 10.10.1.2 Master_User: repl Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mybinlog.000002 Read_Master_Log_Pos: 763 Relay_Log_File: db2-relay-bin.000002 Relay_Log_Pos: 319 Relay_Master_Log_File: mybinlog.000002 Slave_IO_Running: Yes Slave_SQL_Running: Yes ... 查看从库 Slave_IO_Running 和 Slave_SQL_Running 两IO线程状态是否为 YES，为 YES 表示主从复制成功 ","date":"2021-01-13","objectID":"/posts/mysql-classic-replication/:2:2","series":null,"tags":["mysql-replication","mysql-classic-replication"],"title":"MySQL 经典主从复制配置","uri":"/posts/mysql-classic-replication/#从库操作"},{"categories":["mysql"],"content":" 测试主从同步","date":"2021-01-13","objectID":"/posts/mysql-classic-replication/:3:0","series":null,"tags":["mysql-replication","mysql-classic-replication"],"title":"MySQL 经典主从复制配置","uri":"/posts/mysql-classic-replication/#测试主从同步"},{"categories":["mysql"],"content":" 在主库查看从库 bash mysql\u003e SHOW SLAVE HOSTS; +-----------+------+------+-----------+--------------------------------------+ | Server_id | Host | Port | Master_id | Slave_UUID | +-----------+------+------+-----------+--------------------------------------+ | 2 | | 3306 | 1 | 2cc18b4b-4658-11eb-adf4-000c2955408a | +-----------+------+------+-----------+--------------------------------------+ 1 row in set (0.00 sec) mysql\u003e show processlist; +----+------+-----------------+------+-------------+------+---------------------------------------------------------------+------------------+ | Id | User | Host | db | Command | Time | State | Info | +----+------+-----------------+------+-------------+------+---------------------------------------------------------------+------------------+ | 5 | root | localhost | NULL | Query | 0 | starting | show processlist | | 6 | repl | 10.10.1.3:57800 | NULL | Binlog Dump | 215 | Master has sent all binlog to slave; waiting for more updates | NULL | +----+------+-----------------+------+-------------+------+---------------------------------------------------------------+------------------+ 2 rows in set (0.00 sec) SHOW SLAVE HOSTS: 查看所有从库信息 show processlist: 查看当前所有线程信息， Binlog Dump 是主库和从库主从复制专用线程，如果有多个从库会有多个 Binlog Dump 线程 ","date":"2021-01-13","objectID":"/posts/mysql-classic-replication/:3:1","series":null,"tags":["mysql-replication","mysql-classic-replication"],"title":"MySQL 经典主从复制配置","uri":"/posts/mysql-classic-replication/#在主库查看从库"},{"categories":["mysql"],"content":" 测试主从复制在主从库创建 test 库和 test 表，插入一些数据，然后到从库查看数据是否存在 主库 bash mysql\u003e create database test charset utf8mb4; Query OK, 1 row affected (0.01 sec) mysql\u003e use test; Database changed mysql\u003e create table test (id int, username varchar(60)); Query OK, 0 rows affected (0.05 sec) mysql\u003e insert into test values(1,'lisi'), (2, 'zhangshan'); Query OK, 2 rows affected (0.01 sec) Records: 2 Duplicates: 0 Warnings: 0 从库 bash mysql\u003e show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | | test | +--------------------+ 5 rows in set (0.00 sec) mysql\u003e use test; mysql\u003e select * from test; +------+-----------+ | id | username | +------+-----------+ | 1 | lisi | | 2 | zhangshan | +------+-----------+ 2 rows in set (0.00 sec) ","date":"2021-01-13","objectID":"/posts/mysql-classic-replication/:3:2","series":null,"tags":["mysql-replication","mysql-classic-replication"],"title":"MySQL 经典主从复制配置","uri":"/posts/mysql-classic-replication/#测试主从复制"},{"categories":["mysql"],"content":" GTID 的概述是对一个已提交事务的编号，并且是全局唯一的编号 全局事物标识：global transaction identifieds。 GTID事物是全局唯一性的，且一个事务对应一个GTID。 一个GTID在一个服务器上只执行一次，避免重复执行导致数据混乱或者主从不一致。 GTID 用来代替 经典 (classic) 的复制方法，不在使用 binlog + pos 开启复制。而是使用master_auto_postion=1 的方式自动匹配 GTID 断点进行复制。 MySQL-5.6.5 开始支持的，MySQL-5.6.10 后开始完善。 在传统的 slave 端，binlog 是不用开启的，但是在 GTID 中，slave 端的 binlog 是必须开启的，目的是记录执行过的GTID（强制）. ","date":"2021-01-12","objectID":"/posts/mysql-gtid/:1:0","series":null,"tags":["mysql","mysql-gtid"],"title":"MySQL GITD 模式","uri":"/posts/mysql-gtid/#gtid-的概述"},{"categories":["mysql"],"content":" GTID 的组成部分GTID 由 server_uuid 和 sequence number 组成，通过 : 连接 例如：7800a22c-95ae-11e4-983d-080027de205a:10 server_uuid: 每个mysql实例的唯一ID，由于会传递到 slave，所以也可以理解为源 ID。 sequence number：在每台MySQL服务器上都是从1开始自增长的序列，一个数值对应一个事务。 ","date":"2021-01-12","objectID":"/posts/mysql-gtid/:2:0","series":null,"tags":["mysql","mysql-gtid"],"title":"MySQL GITD 模式","uri":"/posts/mysql-gtid/#gtid-的组成部分"},{"categories":["mysql"],"content":" GTID 比传统复制的优势 更简单的实现 failover，不用以前那样在需要找 log_file 和 log_Pos。 更简单的搭建主从复制。 比传统复制更加安全。 GTID是连续没有空洞的，因此主从库出现数据冲突时，可以用添加空事物的方式进行跳过。 ","date":"2021-01-12","objectID":"/posts/mysql-gtid/:3:0","series":null,"tags":["mysql","mysql-gtid"],"title":"MySQL GITD 模式","uri":"/posts/mysql-gtid/#gtid-比传统复制的优势"},{"categories":["mysql"],"content":" GTID 的工作原理 master 更新数据时，会在事务前产生 GTID，一同记录到 binlog 日志中。 slave 端的 i/o 线程将变更的 binlog，写入到本地的 relay-log 中。 sql 线程从 relay-log 中获取 GTID，然后对比 slave 端的 binlog 是否有记录。 如果有记录，说明该 GTID 的事务已经执行，slave 会忽略(幂等性)。 如果没有记录，slave 就会从 relay-log 中执行该 GTID 的事务，并记录到 binlog。 在解析过程中会判断是否有主键，如果没有就用二级索引，如果没有就用全部扫描。 要点： slave 在接受 master 的 binlog 时，会校验 master 的 GTID 是否已经执行过（一个服务器只能执行一次）。 为了保证主从数据的一致性，多线程只能同时执行一个 GTID。 由于幂等性特点，开启 GTID 后，MySQL 恢复 binlog 时，重复的 GTID 事务不会执行. 所以在导出 binlog 日志时需要加上 --skip-gtid 参数，从而让导出 binlog 语句中不保留全局事务标识符； 而是让服务器像执行新事务一样执行事务。 ","date":"2021-01-12","objectID":"/posts/mysql-gtid/:4:0","series":null,"tags":["mysql","mysql-gtid"],"title":"MySQL GITD 模式","uri":"/posts/mysql-gtid/#gtid-的工作原理"},{"categories":["mysql"],"content":" 配置 GITD启用 GTID 主要配置参数 bash root@db1:~# cat /usr/local/mysql/etc/my.cnf [mysqld] gtid-mode = on enforce-gtid-consistency = true ","date":"2021-01-12","objectID":"/posts/mysql-gtid/:5:0","series":null,"tags":["mysql","mysql-gtid"],"title":"MySQL GITD 模式","uri":"/posts/mysql-gtid/#配置-gitd"},{"categories":["mysql"],"content":" slowlog 慢日志","date":"2021-01-12","objectID":"/posts/mysql-slowlog/:1:0","series":null,"tags":["mysql","slowlog"],"title":"MySQL 慢日志","uri":"/posts/mysql-slowlog/#slowlog-慢日志"},{"categories":["mysql"],"content":" 作用记录 MySQL 运行过程运行过慢的语句，通过一个文本的文件记录下来。 帮助我们进行语句优化工作。 ","date":"2021-01-12","objectID":"/posts/mysql-slowlog/:1:1","series":null,"tags":["mysql","slowlog"],"title":"MySQL 慢日志","uri":"/posts/mysql-slowlog/#作用"},{"categories":["mysql"],"content":" 配置慢日志 bash root@db1:~# cat /usr/local/mysql/etc/my.cnf [mysqld] # 慢语句开关 slow_query_log = 1 # 慢日志存储路径 slow_query_log_file = /data/mysql/3306/slow.log # 定义慢语句时间阈值单位为秒 long_query_time = 1 # 记录不走索引的语句 log_queries_not_using_indexes = 1 ","date":"2021-01-12","objectID":"/posts/mysql-slowlog/:1:2","series":null,"tags":["mysql","slowlog"],"title":"MySQL 慢日志","uri":"/posts/mysql-slowlog/#配置慢日志"},{"categories":["mysql"],"content":" 查看慢日志","date":"2021-01-12","objectID":"/posts/mysql-slowlog/:2:0","series":null,"tags":["mysql","slowlog"],"title":"MySQL 慢日志","uri":"/posts/mysql-slowlog/#查看慢日志"},{"categories":["mysql"],"content":" mysqldumpslow 参数说明 bash root@db1:~# mysqldumpslow -h -s ORDER 日志排序方式, 默认排序为 'at' al: 平均锁定时间 ar: 发送的平均行数 at: 平均查询时间 c: 执行次数 l: 锁定时间 r: 发送行数 t: 查询时间 -r 反向排序 -t NUM 只显示前n个查询 查看执行次数最多的前5条慢语句 bash root@db1:~# mysqldumpslow -s c -t 5 /data/mysql/3306/slow.log ","date":"2021-01-12","objectID":"/posts/mysql-slowlog/:2:1","series":null,"tags":["mysql","slowlog"],"title":"MySQL 慢日志","uri":"/posts/mysql-slowlog/#mysqldumpslow-参数说明"},{"categories":["mysql"],"content":" 可视化展示慢日志 slow-log工具: pt-query-digest + Amemometer ","date":"2021-01-12","objectID":"/posts/mysql-slowlog/:2:2","series":null,"tags":["mysql","slowlog"],"title":"MySQL 慢日志","uri":"/posts/mysql-slowlog/#可视化展示慢日志-slow-log"},{"categories":["mysql"],"content":" mysqlbinlog 参数说明 -d, --database 指定截取日志的库名 --start-position 截取日志起始 position 号 --stop-position 截取日志最终 position 号 --start-datetime 截取日志开始时间 --stop-datetime 截取日志结束时间 --skip-gtids 不保留全局事务标识符； 而是让服务器像执行新事务一样执行事务。 --include-gtids=name 截取日志起始和结束 GTID 号，例如: 09833d3f-4656-11eb-9892-000c2913c78e:1-4 --exclude-gtids=name 截取日志排除的 GTID 号 注: –skip-gtids 在启用 GTID 时需要加上，否则数据无法通过导出的 sql 还原, 这是由于 GTID 的特性（幂等性）导致的。 截取标志可以混用，也可以只指定起始位置点，不指定结束位置点(默认到最新的点) ","date":"2021-01-11","objectID":"/posts/mysql-mysqlbinlog/:1:0","series":null,"tags":["mysqlbinlog"],"title":"MySQL mysqlbinlog 命令使用说明","uri":"/posts/mysql-mysqlbinlog/#mysqlbinlog-参数说明"},{"categories":["mysql"],"content":" 通过 BINLOG 恢复数据BINLOG 一般配合备份一起使用，单独使用 BINLOG 恢复数据在数据量大的情况比较困难。 ","date":"2021-01-11","objectID":"/posts/mysql-mysqlbinlog/:2:0","series":null,"tags":["mysqlbinlog"],"title":"MySQL mysqlbinlog 命令使用说明","uri":"/posts/mysql-mysqlbinlog/#通过-binlog-恢复数据"},{"categories":["mysql"],"content":" binlog 作用主要记录数据库变化(DDL,DML,DCL)性质的日志 用于数据恢复：如果你的数据库出问题了，而你之前有过备份，那么可以看日志文件，找出是哪个命令导致你的数据库出问题了，想办法挽回损失。 主从服务器之间同步数据：主服务器上所有的操作都在记录日志中，从服务器可以根据该日志来进行，以确保两个同步。 ","date":"2021-01-10","objectID":"/posts/mysql-binlog/:1:0","series":null,"tags":["mysql","binlog"],"title":"MySQL bin-log 日志","uri":"/posts/mysql-binlog/#binlog-作用"},{"categories":["mysql"],"content":" 配置MySQL 8.0 版本以前默认都没有开启，生产环境建议开启 配置方法 ini [mysqld] # 主机编号，主从中使用，5.7 版本中 开启 binlog 必须设置 server_id server_id = 1 # binlog 日志名前缀，『/data/mysql/binlog』 binlog 存储目录， 『mysql-bin』 binlog 文件名前缀，便如 mysql-bin.000001 mysql-bin.000002 log_bin = /data/mysql/binlog/mysql-bin # binlog 日志写入磁盘策略，双1参数中的其中一个 sync_binlog = 1 # binlog 日志记录格式为 row binlog_format = row # binlog 保存天数 expire_logs_days = 7 注意: binlog 日志最好和数据分开存储 ","date":"2021-01-10","objectID":"/posts/mysql-binlog/:2:0","series":null,"tags":["mysql","binlog"],"title":"MySQL bin-log 日志","uri":"/posts/mysql-binlog/#配置"},{"categories":["mysql"],"content":" 记录内容binlog 是 SQL 层的功能。记录的是变更 SQL 语句，不记录查询语句。 ","date":"2021-01-10","objectID":"/posts/mysql-binlog/:3:0","series":null,"tags":["mysql","binlog"],"title":"MySQL bin-log 日志","uri":"/posts/mysql-binlog/#记录内容"},{"categories":["mysql"],"content":" 记录 SQL 语句种类 DDL：原封不动记录当前 DDL（statement 语句方式） DML：原封不动记录当前 DDL（statement 语句方式） DCL：只记录已提交事务的 DML (insert, update, delete) ","date":"2021-01-10","objectID":"/posts/mysql-binlog/:3:1","series":null,"tags":["mysql","binlog"],"title":"MySQL bin-log 日志","uri":"/posts/mysql-binlog/#记录-sql-语句种类"},{"categories":["mysql"],"content":" DML 三种语句记录方式 statement (5.6 默认) SBR (statement based replication): 原封不动的记录当前DML ROW (5.7 默认) RBR (ROW based replication): 记录数据行的变化，用户看不懂（需要工具分析） mixed (混合) MBR (mixed based replication): 以上两模式的混合 STATEMENT 模式 可读性较高，日志量小，不够严谨 ROW 模式 可读性很低，日志量大，足够严谨 建议使用 ROW 模式 ","date":"2021-01-10","objectID":"/posts/mysql-binlog/:3:2","series":null,"tags":["mysql","binlog"],"title":"MySQL bin-log 日志","uri":"/posts/mysql-binlog/#dml-三种语句记录方式"},{"categories":["mysql"],"content":" 事件的简介二进制日志的最小单元，对于 DML,DCL，一条语句就是一个事件(event) 对于 DML 语句来讲，只记录已提交的事务 例如: 以下列子，分为4个事件 text begin; 101-320 DML; 320-630 DML; 630-740 commit; 740-810 ","date":"2021-01-10","objectID":"/posts/mysql-binlog/:4:0","series":null,"tags":["mysql","binlog"],"title":"MySQL bin-log 日志","uri":"/posts/mysql-binlog/#事件的简介"},{"categories":["mysql"],"content":" event 的组成三部分构成 事件的开始标识 事件的内容 事件的结束标识 Position 开始标记: at 1262 结束标记: end_log_pos 1312 作用: 为了方便截取日志 ","date":"2021-01-10","objectID":"/posts/mysql-binlog/:4:1","series":null,"tags":["mysql","binlog"],"title":"MySQL bin-log 日志","uri":"/posts/mysql-binlog/#event-的组成"},{"categories":["mysql"],"content":" 查看二进制日志查看一共有几个日志文件 bash mysql\u003e show binary logs; +-----------------+-----------+ | Log_name | File_size | +-----------------+-----------+ | mybinlog.000001 | 177 | | mybinlog.000002 | 1403 | +-----------------+-----------+ 查看当前在用的日志文件 bash mysql\u003e show master status; +-----------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +-----------------+----------+--------------+------------------+-------------------+ | mybinlog.000002 | 1403 | | | | +-----------------+----------+--------------+------------------+-------------------+ 查看二进日志事件 bash mysql\u003e show binlog events in 'mybinlog.000002'; +-----------------+------+----------------+-----------+-------------+-----------------------------------------------------------------------------------------------------------------------+ | Log_name | Pos | Event_type | Server_id | End_log_pos | Info | +-----------------+------+----------------+-----------+-------------+-----------------------------------------------------------------------------------------------------------------------+ | mybinlog.000002 | 4 | Format_desc | 1 | 123 | Server ver: 5.7.28-log, Binlog ver: 4 | | mybinlog.000002 | 123 | Previous_gtids | 1 | 154 | | | mybinlog.000002 | 154 | Anonymous_Gtid | 1 | 219 | SET @@SESSION.GTID_NEXT= 'ANONYMOUS' | | mybinlog.000002 | 219 | Query | 1 | 407 | CREATE USER 'repl'@'10.10.1.%' IDENTIFIED WITH 'mysql_native_password' AS '*6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9' | | mybinlog.000002 | 407 | Anonymous_Gtid | 1 | 472 | SET @@SESSION.GTID_NEXT= 'ANONYMOUS' 导出查看二进制日志 bash root@db1:~# mysqlbinlog /data/mysql/3306/mybinlog.000002 \u003e /tmp/2.sql # 或者， --base64-outpu=decode-rows 解码日志信息 root@db1:~# mysqlbinlog --base64-outpu=decode-rows /data/mysql/3306/mybinlog.000002 \u003e /tmp/2.sql 通过 position 号截取日志 bash root@db1:~# mysqlbinlog --start-position=219 --stop-position=1403 /data/mysql/3306/mybinlog.000002 \u003e /tmp/r.sql ","date":"2021-01-10","objectID":"/posts/mysql-binlog/:5:0","series":null,"tags":["mysql","binlog"],"title":"MySQL bin-log 日志","uri":"/posts/mysql-binlog/#查看二进制日志"},{"categories":["mysql"],"content":" 日志管理","date":"2021-01-10","objectID":"/posts/mysql-binlog/:6:0","series":null,"tags":["mysql","binlog"],"title":"MySQL bin-log 日志","uri":"/posts/mysql-binlog/#日志管理"},{"categories":["mysql"],"content":" 日志滚动 每次重启 MySQL 时 BINLOG 日志会自动滚动生成并使用新的日志文件 bin-log 文件大小达到参数 max_binlog_size 限制； 手动滚动更新 bash mysql\u003e flush logs; root@db1:~# mysqladmin flush-logs mysqldump 的 -F 参数也会触发自动滚动更新 BINLOG 日志文件，不建议使用 ","date":"2021-01-10","objectID":"/posts/mysql-binlog/:6:1","series":null,"tags":["mysql","binlog"],"title":"MySQL bin-log 日志","uri":"/posts/mysql-binlog/#日志滚动"},{"categories":["mysql"],"content":" 日志清理","date":"2021-01-10","objectID":"/posts/mysql-binlog/:7:0","series":null,"tags":["mysql","binlog"],"title":"MySQL bin-log 日志","uri":"/posts/mysql-binlog/#日志清理"},{"categories":["mysql"],"content":" 自动清理方法1：（修改配置文件和在mysql内设置参数可无需重启服务） bash root@db1:~# vim /etc/my.cnf [mysqld] expire_logs_days = 7 // 表示日志保留7天，超过7天则设置为过期的, 默认为 0 永不过期 root@db1:~# mysql -u root -p mysql\u003e show binary logs; mysql\u003e show variables like '%log%'; mysql\u003e set global expire_logs_days = 7; expire_logs_days 一般设置为一个全备周期 + 1，如果全备周期为7天，就设置为 7+1=8 一般生产中至少保留2个全备周期 ","date":"2021-01-10","objectID":"/posts/mysql-binlog/:7:1","series":null,"tags":["mysql","binlog"],"title":"MySQL bin-log 日志","uri":"/posts/mysql-binlog/#自动清理方法1修改配置文件和在mysql内设置参数可无需重启服务"},{"categories":["mysql"],"content":" 手动清理方法2：如果没有主从复制，可以通过下面的命令重置数据库日志，清除之前所有的日志文件： bash mysql\u003e reset master 注: 此操作危险，请谨慎操作！！！ 但是如果存在复制关系，应当通过 PURGE 的名来清理 bin-log 日志，语法如下： bash # mysql -u root -p mysql\u003e purge master logs to 'mysql-bin.010’; //清除 mysql-bin.010 之前所有的日志 mysql\u003e purge master logs before '2016-02-28 13:00:00'; //清除2016-02-28 13:00:00前的日志 mysql\u003e purge master logs before date_sub(now(), interval 3 day); //清除3天前的bin日志 注意，不要轻易手动去删除 binlog，会导致 binlog.index 和真实存在的 binlog 不匹配，而导致 expire_logs_day 失效 ","date":"2021-01-10","objectID":"/posts/mysql-binlog/:7:2","series":null,"tags":["mysql","binlog"],"title":"MySQL bin-log 日志","uri":"/posts/mysql-binlog/#手动清理方法2"},{"categories":["mysql"],"content":" information_schema 库","date":"2021-01-07","objectID":"/posts/mysql-information_schema/:1:0","series":null,"tags":["mysql","information_schema"],"title":"MySQL 数据库信息统计","uri":"/posts/mysql-information_schema/#information_schema-库"},{"categories":["mysql"],"content":" 统计单表占用物理空间大小查询表: information_schema.tables 计算公式: 方法一: 单表占用空间大小 = AVG_ROW_LENGTH * TABLE_ROWS + INDEX_LENGTH 方法二: 单表占用空间大小 = DATA_LENGTH 示例: 查看 employees 库中 salaries 表的占用空间大小 bash mysql\u003e select table_schema,table_name, -\u003e (avg_row_length * table_rows + index_length) / 1024 / 1024 as data_mb -\u003e from tables where table_schema='employees' and table_name = 'salaries'; +--------------+------------+-------------+ | table_schema | table_name | data_mb | +--------------+------------+-------------+ | employees | salaries | 94.74268913 | +--------------+------------+-------------+ ","date":"2021-01-07","objectID":"/posts/mysql-information_schema/:1:1","series":null,"tags":["mysql","information_schema"],"title":"MySQL 数据库信息统计","uri":"/posts/mysql-information_schema/#统计单表占用物理空间大小"},{"categories":["mysql"],"content":" 查看数据库碎片占用最大的表, 前 10 名 bash mysql\u003e select table_schema,table_name, data_free / 1024 / 1024 as data_free_mb from tables order by data_free_mb limit 10; ","date":"2021-01-07","objectID":"/posts/mysql-information_schema/:1:2","series":null,"tags":["mysql","information_schema"],"title":"MySQL 数据库信息统计","uri":"/posts/mysql-information_schema/#查看数据库碎片占用最大的表-前-10-名"},{"categories":["mysql"],"content":"MyISAM 引擎默认是支持通过拷贝文件方式迁移数据，InnoDB 引擎不支持。 如果需要迁移 InnoDB 引擎数据可以先将数据表的引擎由 InnoDB 更改为 MyISAM。 也可以通过管理 MySQL 独立表空间文件实现数据库的迁移。操作步骤如下: ","date":"2021-01-05","objectID":"/posts/mysql-tablespace-restore/:0:0","series":null,"tags":["mysql"],"title":"MySQL 表空间方式(迁移/恢复)数据","uri":"/posts/mysql-tablespace-restore/#"},{"categories":["mysql"],"content":" 准备测试数据可以使用 MySQL 官方提供的测试数据进行实验演示: https://github.com/datacharmer/test_db bash git clone https://github.com/datacharmer/test_db.git cd test_db mysql -t \u003c employees.sql ","date":"2021-01-05","objectID":"/posts/mysql-tablespace-restore/:1:0","series":null,"tags":["mysql"],"title":"MySQL 表空间方式(迁移/恢复)数据","uri":"/posts/mysql-tablespace-restore/#准备测试数据"},{"categories":["mysql"],"content":" 导出库中所有表结构 bash [root@10-13-90-34 ~]# mysqldump -d -B employees \u003e employees_schema.sql ","date":"2021-01-05","objectID":"/posts/mysql-tablespace-restore/:2:0","series":null,"tags":["mysql"],"title":"MySQL 表空间方式(迁移/恢复)数据","uri":"/posts/mysql-tablespace-restore/#导出库中所有表结构"},{"categories":["mysql"],"content":" 在目标数据库中创建与源库一样的表文件 bash [root@10-13-90-34 ~]# mysql -S /data/mysql/3308/mysql.sock mysql\u003e source employees_schema.sql; mysql\u003e show databases; +--------------------+ | Database | +--------------------+ | information_schema | | employees | | mysql | | performance_schema | | sys | +--------------------+ ","date":"2021-01-05","objectID":"/posts/mysql-tablespace-restore/:3:0","series":null,"tags":["mysql"],"title":"MySQL 表空间方式(迁移/恢复)数据","uri":"/posts/mysql-tablespace-restore/#在目标数据库中创建与源库一样的表文件"},{"categories":["mysql"],"content":" 管理表空间文件，恢复数据删除表空间文件 删除表空间文件时可能会由于外键约束导致失败，可以先暂时关闭外键约束 SET foreign_key_checks = 0;, 操作完成后在开启 SET foreign_key_checks = 1; bash alter table employees.departments discard tablespace; alter table employees.dept_emp discard tablespace; alter table employees.dept_manager discard tablespace; alter table employees.employees discard tablespace; alter table employees.salaries discard tablespace; alter table employees.titles discard tablespace; 导入表空间文件 将源库中所有表的 idb 文件拷贝到目标库中并修改权限 bash [root@10-13-90-34 employees]# cp -p /data/mysql/3306/employees/*.ibd /data/mysql/3308/employees 导入表空间文件 bash alter table employees.departments import tablespace; alter table employees.dept_emp import tablespace; alter table employees.dept_manager import tablespace; alter table employees.employees import tablespace; alter table employees.salaries import tablespace; alter table employees.titles import tablespace; 开启外键约束 text SET foreign_key_checks = 1; 验证数据 注意: 此方法操作有风险，不到万不得已不建议使用 ","date":"2021-01-05","objectID":"/posts/mysql-tablespace-restore/:4:0","series":null,"tags":["mysql"],"title":"MySQL 表空间方式(迁移/恢复)数据","uri":"/posts/mysql-tablespace-restore/#管理表空间文件恢复数据"},{"categories":["mysql"],"content":" mysqldump 参数说明-A, –all-databases: 备份所有库 -B, –databases: 使用此参数可以同时备份多个库 单库备份可以加上 -B 参数，这样备份文件中加会加入 create database ... 及 use DATABASE 语句. –master-data=2: 加入此参数可以记录 binlog 日志文件位置和文件名 (生产中建议加上此参数) 备份时会自动记录 binlog 日志信息在备份文件中，值为2时以注释的形式记录，值为1时以语句形式记录。 会自动锁全表及解锁 加 –single-transaction 参数，可以减少锁表时间 --master-data 在生产中建议使用的值为 2 –single-transaction 对于 Innodb引擎表备份时，开启一个独立事务，获取一个一致性快照进行备份。 -R: 备份存储过程，函数 -E: 备份事件 -triggers: 备份触发器 -d, –no-data: 不备份数据，只备份数据结构 -n, –no-create-db: 不生成创建数据库语句 -t, –no-create-info: 不生成创建表语句 mysqldump 可选参数 --max_allowed_packet=64M 建议使用 mysqldump 命令参数: mysqldump -uroot -p --master-data=2 --single-transaction --triggers -R -E ","date":"2021-01-04","objectID":"/posts/mysqldump-backup/:1:0","series":null,"tags":["mysql","mysqldump"],"title":"Mysqldump 备份 MySQL","uri":"/posts/mysqldump-backup/#mysqldump-参数说明"},{"categories":["mysql"],"content":" 数据库备份","date":"2021-01-04","objectID":"/posts/mysqldump-backup/:2:0","series":null,"tags":["mysql","mysqldump"],"title":"Mysqldump 备份 MySQL","uri":"/posts/mysqldump-backup/#数据库备份"},{"categories":["mysql"],"content":" 备份所有库 bash [root@localhost ~]# mysqldump -uroot -p --master-data=2 --single-transaction --triggers -R -E -A \u003e all.sql ","date":"2021-01-04","objectID":"/posts/mysqldump-backup/:2:1","series":null,"tags":["mysql","mysqldump"],"title":"Mysqldump 备份 MySQL","uri":"/posts/mysqldump-backup/#备份所有库"},{"categories":["mysql"],"content":" 只备份所有库的结构 bash [root@localhost ~]# mysqldump -uroot -p -A -d \u003e all.sql ","date":"2021-01-04","objectID":"/posts/mysqldump-backup/:2:2","series":null,"tags":["mysql","mysqldump"],"title":"Mysqldump 备份 MySQL","uri":"/posts/mysqldump-backup/#只备份所有库的结构"},{"categories":["mysql"],"content":" 备份单个数据库 bash [root@localhost ~]# mysqldump -uroot -p --master-data=2 --single-transaction --triggers -R -E -B DATABASENAME \u003e DATABASENAME.sql ","date":"2021-01-04","objectID":"/posts/mysqldump-backup/:2:3","series":null,"tags":["mysql","mysqldump"],"title":"Mysqldump 备份 MySQL","uri":"/posts/mysqldump-backup/#备份单个数据库"},{"categories":["mysql"],"content":" 一次备份多个数据库 (-B, –databases) bash [root@localhost ~]# mysqldump -uroot -p --master-data=2 --single-transaction --triggers -R -E --databases db1 db2 \u003e dbs.sql ","date":"2021-01-04","objectID":"/posts/mysqldump-backup/:2:4","series":null,"tags":["mysql","mysqldump"],"title":"Mysqldump 备份 MySQL","uri":"/posts/mysqldump-backup/#一次备份多个数据库--b---databases"},{"categories":["mysql"],"content":" 备份数据库中指定的表 bash [root@localhost ~]# mysqldump -uroot -p DATABASENAME TABLENAME \u003e DATABASENAME_TABLENAME.sql ","date":"2021-01-04","objectID":"/posts/mysqldump-backup/:2:5","series":null,"tags":["mysql","mysqldump"],"title":"Mysqldump 备份 MySQL","uri":"/posts/mysqldump-backup/#备份数据库中指定的表"},{"categories":["mysql"],"content":" 一次备份数据库中指定的多张表 bash [root@localhost ~]# mysqldump -uroot -p DATABASENAME t1 t2 \u003e DATABASENAME_ts.sql ","date":"2021-01-04","objectID":"/posts/mysqldump-backup/:2:6","series":null,"tags":["mysql","mysqldump"],"title":"Mysqldump 备份 MySQL","uri":"/posts/mysqldump-backup/#一次备份数据库中指定的多张表"},{"categories":["mysql"],"content":" 导出函数或者存储过程 bash mysqldump -h HOSTNAME -u USERNAME -p PASSWORD -ntd --triggers -R -E DATABASENAME \u003e DATABASENAME.sql -ntd 表示不导出数据及创建库和表的语句； ","date":"2021-01-04","objectID":"/posts/mysqldump-backup/:2:7","series":null,"tags":["mysql","mysqldump"],"title":"Mysqldump 备份 MySQL","uri":"/posts/mysqldump-backup/#导出函数或者存储过程"},{"categories":["mysql"],"content":" 数据库恢复当我们需要还原数据时可以通过以下命令进行还原 方法1 直接还原数据库，如果备份语句中没有禁用记录 binlog 会产生大量无用的 binlog 信息增加还原时长 bash [root@localhost ~]# mysql -uroot -p \u003c all.sql 方法2 先连接上数据库，然后临时禁止记录 binlog 日志，再还原数据库文件，最后在开启 binlog 日志记录功能(断开重连也会恢复) bash [root@localhost ~]# mysql -uroot -p mysql\u003e set sql_log_bin=0; mysql\u003e source /data/bak/backup.sql; mysql\u003e set sql_log_bin=0; ","date":"2021-01-04","objectID":"/posts/mysqldump-backup/:3:0","series":null,"tags":["mysql","mysqldump"],"title":"Mysqldump 备份 MySQL","uri":"/posts/mysqldump-backup/#数据库恢复"},{"categories":["mysql","xtrabackup"],"content":"percona-xtrabackup 是物理备份工具，拷贝数据文件。 原生态支持全备和增量备份。 会记录二进制日志文件及位置。 InnoDB 表: 热备份，业务正常发生时，影响较小的备份方式 非 InnoDB 表: 温备份，会锁表 ","date":"2021-01-04","objectID":"/posts/xtrabackup-backup-mysql/:0:0","series":null,"tags":["mysql","xtrabackup"],"title":"Xtrabackup 备份 MySQL (全备)","uri":"/posts/xtrabackup-backup-mysql/#"},{"categories":["mysql","xtrabackup"],"content":" 安装 percona-xtrabackup下载地址: https://www.percona.com/downloads/Percona-XtraBackup-2.4/LATEST/ ","date":"2021-01-04","objectID":"/posts/xtrabackup-backup-mysql/:1:0","series":null,"tags":["mysql","xtrabackup"],"title":"Xtrabackup 备份 MySQL (全备)","uri":"/posts/xtrabackup-backup-mysql/#安装-percona-xtrabackup"},{"categories":["mysql","xtrabackup"],"content":" xtrabackup 使用使用 xtrabackup 命令前提条件 数据库必须启动 能连接上数据库，指定用户名，密码，socket 配置文件 my.cnf 中必须配置 datadir 参数 配置 my.cnf ini [client] # 配置客户端工具连接 socket 文件路径，有此参数 xtrabackup 可以省略 -S 参数 socket = /data/mysql/3306/mysql.sock [mysqld] # 配置数据目录 datadir = /data/mysql/3306 ","date":"2021-01-04","objectID":"/posts/xtrabackup-backup-mysql/:2:0","series":null,"tags":["mysql","xtrabackup"],"title":"Xtrabackup 备份 MySQL (全备)","uri":"/posts/xtrabackup-backup-mysql/#xtrabackup-使用"},{"categories":["mysql","xtrabackup"],"content":" 全量备份 bash root@db1:/data/bak# xtrabackup --defaults-file=/usr/local/mysql/etc/my.cnf -u root -p --backup --target-dir=/data/bak/full-$(date +%F) –defaults-file: 指定 my.cnf 配置文件，此参数必须放在第一位 -u: 数据库用户名 -p: 用户密码 –target-dir: 指定备份存储目录 如果 my.cnf 配置文件的 [client] 配置项中没有指定 socket 参数，需要指定 -S 指定 mysql.sock 文件路径 ","date":"2021-01-04","objectID":"/posts/xtrabackup-backup-mysql/:2:1","series":null,"tags":["mysql","xtrabackup"],"title":"Xtrabackup 备份 MySQL (全备)","uri":"/posts/xtrabackup-backup-mysql/#全量备份"},{"categories":["mysql","xtrabackup"],"content":" 还原数据准备数据 此步操作主要应用那些还没有应用的事务，该回滚的事务回滚，该提交的事务提交。 该步骤可以使文件在单个时间点上完全一致。 bash root@db1:/data/bak# xtrabackup --prepare --target-dir=/data/bak/full-2020-12-25 注: 准备数据操作过程不能被中断，否则备份将不可用。 还原数据 可以直接修改 my.cnf 的 datadir 值，将路径修改为备份路径，然后修改备份目录的权限即可 直接拷贝文件到 MySQL 数据目录中，然后修改数据目录下所有文件的权限即可 可以直接使用 cp or rsync 命令，也可以使用 xtrabackup 命令。 bash root@db1:/data/bak# xtrabackup --defaults-file=/usr/local/mysql/etc/my.cnf --copy-back --target-dir=/data/bak/full-2020-12-25 root@db1:/data/bak# chown -R mysql.mysql /data/mysql/3306/ 也可以使用如下命令 cp -a /data/bak/full-2020-12-25 /data/mysql/3306 rsync -avrP /data/bak/full-2020-12-25/ /data/mysql/3306/ ","date":"2021-01-04","objectID":"/posts/xtrabackup-backup-mysql/:2:2","series":null,"tags":["mysql","xtrabackup"],"title":"Xtrabackup 备份 MySQL (全备)","uri":"/posts/xtrabackup-backup-mysql/#还原数据"},{"categories":["mysql"],"content":" 适用于 MySQL5.6 及之前的版本","date":"2021-01-03","objectID":"/posts/mysql-reset-root-password/:1:0","series":null,"tags":["mysql"],"title":"MySQL root 密码重置","uri":"/posts/mysql-reset-root-password/#适用于-mysql56-及之前的版本"},{"categories":["mysql"],"content":" 1. 停止MySQL服务执行： /etc/init.d/mysql stop，你的机器上不一定是 /etc/init.d/mysql 也可能是 /etc/init.d/mysqld ","date":"2021-01-03","objectID":"/posts/mysql-reset-root-password/:1:1","series":null,"tags":["mysql"],"title":"MySQL root 密码重置","uri":"/posts/mysql-reset-root-password/#1-停止mysql服务"},{"categories":["mysql"],"content":" 2. 跳过验证启动MySQL text /usr/local/mysql/bin/mysqld_safe --skip-grant-tables \u003e/dev/null 2\u003e\u00261 \u0026 注：如果 mysqld_safe 命令所在的路径和上面不一样需要修改成你的，如果不清楚可以用find命令查找。 ","date":"2021-01-03","objectID":"/posts/mysql-reset-root-password/:1:2","series":null,"tags":["mysql"],"title":"MySQL root 密码重置","uri":"/posts/mysql-reset-root-password/#2-跳过验证启动mysql"},{"categories":["mysql"],"content":" 3. 重置密码 等一会儿，然后执行： /usr/local/mysql/bin/mysql -u root 出现mysql提示符后输入：update mysql.user set password=password('要设置的密码') where user='root'; 回车后执行：flush privileges; 刷新 MySQL 系统权限相关的表。再执行：exit; 退出。 ","date":"2021-01-03","objectID":"/posts/mysql-reset-root-password/:1:3","series":null,"tags":["mysql"],"title":"MySQL root 密码重置","uri":"/posts/mysql-reset-root-password/#3-重置密码"},{"categories":["mysql"],"content":" 4. 重启MySQL 杀死 MySQL 进程： killall mysqld 重启 MySQL： /etc/init.d/mysql start ","date":"2021-01-03","objectID":"/posts/mysql-reset-root-password/:1:4","series":null,"tags":["mysql"],"title":"MySQL root 密码重置","uri":"/posts/mysql-reset-root-password/#4-重启mysql"},{"categories":["mysql"],"content":" MySQL5.7 重置 root 密码编辑 my.cnf 文件加入以下配置 text [mysqld] skip-grant-tables 重启 mysql，正常连接 mysql 使用如下命令修改 root 密码 sql update mysql.user set authentication_string=PASSWORD('123456') where user='root'; flush privilegs; 最后在去除 my.cnf 配置文件中的 skip-grant-tables 配置项,重启 mysql 即可。 ","date":"2021-01-03","objectID":"/posts/mysql-reset-root-password/:2:0","series":null,"tags":["mysql"],"title":"MySQL root 密码重置","uri":"/posts/mysql-reset-root-password/#mysql57-重置-root-密码"},{"categories":["mysql"],"content":" 一、用户权限管理","date":"2021-01-01","objectID":"/posts/mysql-manage/:1:0","series":null,"tags":["mysql"],"title":"MySQL 基础管理命令","uri":"/posts/mysql-manage/#一用户权限管理"},{"categories":["mysql"],"content":" 1. 查看帮助信息使用 mysql 命令连接上 MySQL 服务后可以使用 help 命令查看帮助信息，例如: text mysql\u003e help For information about MySQL products and services, visit: http://www.mysql.com/ For developer information, including the MySQL Reference Manual, visit: http://dev.mysql.com/ To buy MySQL Enterprise support, training, or other products, visit: https://shop.mysql.com/ List of all MySQL commands: Note that all text commands must be first on line and end with ';' ? (\\?) Synonym for `help'. clear (\\c) Clear the current input statement. connect (\\r) Reconnect to the server. Optional arguments are db and host. delimiter (\\d) Set statement delimiter. edit (\\e) Edit command with $EDITOR. ego (\\G) Send command to mysql server, display result vertically. exit (\\q) Exit mysql. Same as quit. go (\\g) Send command to mysql server. help (\\h) Display this help. nopager (\\n) Disable pager, print to stdout. notee (\\t) Don't write into outfile. pager (\\P) Set PAGER [to_pager]. Print the query results via PAGER. print (\\p) Print current command. prompt (\\R) Change your mysql prompt. quit (\\q) Quit mysql. rehash (\\#) Rebuild completion hash. source (\\.) Execute an SQL script file. Takes a file name as an argument. status (\\s) Get status information from the server. system (\\!) Execute a system shell command. tee (\\T) Set outfile [to_outfile]. Append everything into given outfile. use (\\u) Use another database. Takes database name as argument. charset (\\C) Switch to another charset. Might be needed for processing binlog with multi-byte charsets. warnings (\\W) Show warnings after every statement. nowarning (\\w) Don't show warnings after every statement. resetconnection(\\x) Clean session context. For server side help, type 'help contents' 例如查看 select 语句的用法 可以使用 help select； 命令查看帮助信息 text mysql\u003e help select; Name: 'SELECT' Description: Syntax: SELECT [ALL | DISTINCT | DISTINCTROW ] [HIGH_PRIORITY] [STRAIGHT_JOIN] [SQL_SMALL_RESULT] [SQL_BIG_RESULT] [SQL_BUFFER_RESULT] [SQL_CACHE | SQL_NO_CACHE] [SQL_CALC_FOUND_ROWS] select_expr [, select_expr ...] [FROM table_references [PARTITION partition_list] [WHERE where_condition] [GROUP BY {col_name | expr | position} [ASC | DESC], ... [WITH ROLLUP]] [HAVING where_condition] [ORDER BY {col_name | expr | position} [ASC | DESC], ...] [LIMIT {[offset,] row_count | row_count OFFSET offset}] [PROCEDURE procedure_name(argument_list)] [INTO OUTFILE 'file_name' [CHARACTER SET charset_name] export_options | INTO DUMPFILE 'file_name' | INTO var_name [, var_name]] [FOR UPDATE | LOCK IN SHARE MODE]] SELECT is used to retrieve rows selected from one or more tables, and can include UNION statements and subqueries. See [HELP UNION], and https://dev.mysql.com/doc/refman/5.7/en/subqueries.html. The most commonly used clauses of SELECT statements are these: o Each select_expr indicates a column that you want to retrieve. There must be at least one select_expr. o table_references indicates the table or tables from which to retrieve rows. Its syntax is described in [HELP JOIN]. o SELECT supports explicit partition selection using the PARTITION with a list of partitions or subpartitions (or both) following the name of the table in a table_reference (see [HELP JOIN]). In this case, rows are selected only from the partitions listed, and any other partitions of the table are ignored. For more information and examples, see https://dev.mysql.com/doc/refman/5.7/en/partitioning-selection.html. SELECT ... PARTITION from tables using storage engines such as MyISAM that perform table-level locks (and thus partition locks) lock only the partitions or subpartitions named by the PARTITION option. For more information, see https://dev.mysql.com/doc/refman/5.7/en/partitioning-limitations-lock ing.html. o The WHERE clause, if given, indicates the condition or conditions that rows must satisfy to be selected. where_condition is an expression that evaluates to true for each row to be selected. The statement selects all rows if there is no WHERE clause. In the WHERE expression, ","date":"2021-01-01","objectID":"/posts/mysql-manage/:1:1","series":null,"tags":["mysql"],"title":"MySQL 基础管理命令","uri":"/posts/mysql-manage/#1-查看帮助信息"},{"categories":["mysql"],"content":" 2. 用户创建 text # 创建用户（默认密码为空） mysql\u003e create user 'username'@'host'; # 创建用户并设置密码 mysql\u003e create user 'username'@'host' identified by 'password'; ","date":"2021-01-01","objectID":"/posts/mysql-manage/:1:2","series":null,"tags":["mysql"],"title":"MySQL 基础管理命令","uri":"/posts/mysql-manage/#2-用户创建"},{"categories":["mysql"],"content":" 3. 删除用户 text mysql\u003e drop user 'username'@'host'; ","date":"2021-01-01","objectID":"/posts/mysql-manage/:1:3","series":null,"tags":["mysql"],"title":"MySQL 基础管理命令","uri":"/posts/mysql-manage/#3-删除用户"},{"categories":["mysql"],"content":" 4. 更改密码 text # 更改密码 （只对当前登录账号有效） mysql\u003e set password=password('123456'); # 2. 更改指定用户的密码 mysql\u003e set password for 'username'@'host'=password('123456'); ","date":"2021-01-01","objectID":"/posts/mysql-manage/:1:4","series":null,"tags":["mysql"],"title":"MySQL 基础管理命令","uri":"/posts/mysql-manage/#4-更改密码"},{"categories":["mysql"],"content":" 5. 查询用户权限 text # 查询当前账号的权限 mysql\u003e show grants; # 查询指定账号的权限 mysql\u003e show grants for 'user'@'host'; ","date":"2021-01-01","objectID":"/posts/mysql-manage/:1:5","series":null,"tags":["mysql"],"title":"MySQL 基础管理命令","uri":"/posts/mysql-manage/#5-查询用户权限"},{"categories":["mysql"],"content":" 6. 用户授权 text # 对用户授权（如果用户存在就增加权限，不存在就创建用户不过密码为空） mysql\u003e grant privileges on databasename.tablename to 'username'@'host'; # 对用户授权并设置密码（如果用户存在就增加权限，不存在就创建用户） # mysql 8.0 版本以后需要先创建用户在授权 mysql\u003e grant privileges on databasename.tablename -\u003e to 'username'@'host' identified by 'password'; privileges: 权限列表以逗号隔开，例如： select, insert, update 注意: 进行数据库基本信息相关更改后请使用 flush privileges; 刷新数据库信息 ","date":"2021-01-01","objectID":"/posts/mysql-manage/:1:6","series":null,"tags":["mysql"],"title":"MySQL 基础管理命令","uri":"/posts/mysql-manage/#6-用户授权"},{"categories":["mysql"],"content":" 7. 用户权限回收 text mysql\u003e revoke privilege on databasename.tablename from 'user'@'host'; 注：数据库名要用反撇号引起，或者不用 ","date":"2021-01-01","objectID":"/posts/mysql-manage/:1:7","series":null,"tags":["mysql"],"title":"MySQL 基础管理命令","uri":"/posts/mysql-manage/#7-用户权限回收"},{"categories":["mysql"],"content":" 二、数据库","date":"2021-01-01","objectID":"/posts/mysql-manage/:2:0","series":null,"tags":["mysql"],"title":"MySQL 基础管理命令","uri":"/posts/mysql-manage/#二数据库"},{"categories":["mysql"],"content":" 1. 数据库的基本操作 text # 显示数据库 mysql\u003e show databases; # 创建数据库 mysql\u003e create database DATABASENAME charset utf8mb4;; # 查看数据库创建语句 mysql\u003e show create database DATABASENAME; # 删除数据库 mysql\u003e drop database DATABASENAME; ","date":"2021-01-01","objectID":"/posts/mysql-manage/:2:1","series":null,"tags":["mysql"],"title":"MySQL 基础管理命令","uri":"/posts/mysql-manage/#1-数据库的基本操作"},{"categories":["mysql"],"content":" 2. 备份数据库数据及表结构 text # 备份整个数据库 [root@localhost ~]# mysqldump -uroot -p -A \u003e all.sql # 备份整个数据库的结构 [root@localhost ~]# mysqldump -uroot -p -A -d \u003e all.sql # 备份单个数据库 [root@localhost ~]# mysqldump -uroot -p DATABASENAME \u003e DATABASENAME.sql # 一次备份多个数据库, 同时备份 db1, db2 二个库的数据 (-B, --databases) [root@localhost ~]# mysqldump -uroot -p --databases db1 db2 \u003e dbs.sql # 备份数据库中指定的表 [root@localhost ~]# mysqldump -uroot -p DATABASENAME TABLENAME \u003e DATABASENAME_TABLENAME.sql # 一次备份数据库中指定的多张表 [root@localhost ~]# mysqldump -uroot -p DATABASENAME t1 t2 \u003e DATABASENAME_ts.sql -B, --databases: 单库备份可以加上 -B 参数，这样备份文件中加会加入 create database ... 及 use DATABASE 语句. -A, --all-databases : 备份所有数据库 -d, --no-data ：只导出表结构 ","date":"2021-01-01","objectID":"/posts/mysql-manage/:2:2","series":null,"tags":["mysql"],"title":"MySQL 基础管理命令","uri":"/posts/mysql-manage/#2-备份数据库数据及表结构"},{"categories":["mysql"],"content":" 3. 导出函数或者存储过程 text mysqldump -hHOSTNAME -uUSERNAME -pPASSWORD -ntd -R DATABASENAME \u003e DATABASENAME.sql -ntd 是表示导出存储过程； -R 是表示导出函数 ","date":"2021-01-01","objectID":"/posts/mysql-manage/:2:3","series":null,"tags":["mysql"],"title":"MySQL 基础管理命令","uri":"/posts/mysql-manage/#3-导出函数或者存储过程"},{"categories":["mysql"],"content":" 4. 恢复数据库数据** 使用系统命令** bash [root@localhost ~]# mysql -uroot DATABASENAME \u003c DATABASENAME.sql 使用 source 命令 text # 禁止记录 binlog 日志，恢复数据就没必要记录 binlog 了 mysql\u003e set sql_log_bin=0 mysql\u003e use lwg; mysql\u003e source /root/lwg.sql; 注意: 恢复数据时，如果数据库不存在需要先创建 ","date":"2021-01-01","objectID":"/posts/mysql-manage/:2:4","series":null,"tags":["mysql"],"title":"MySQL 基础管理命令","uri":"/posts/mysql-manage/#4-恢复数据库数据"},{"categories":["mysql"],"content":" 三、数据表","date":"2021-01-01","objectID":"/posts/mysql-manage/:3:0","series":null,"tags":["mysql"],"title":"MySQL 基础管理命令","uri":"/posts/mysql-manage/#三数据表"},{"categories":["mysql"],"content":" 1. 表的基本操作 text # 查看数据库下所有的表 mysql\u003e show tables; # 创建表 mysql\u003e CREATE TABLE `TABLENAME` ( `id` int(10) NOT NULL PRIMARY KEY AUTO_INCREMENT, `user` varchar(30) NOT NULL, `password` varchar(30) NOT NULL ) ENGINE=MyISAM DEFAULT CHARSET=utf8; # 显示表结构 mysql\u003e desc TABLENAME; # 显示表创建语句 mysql\u003e show create table TABLENAME; # 清空表数据 mysql\u003e truncate table TABLENAME; mysql\u003e delete from TABLENAME; 不带 where 参数的 delete 语句可以删除 mysql 表中所有内容 使用 truncate table 也可以清空 mysql 表中所有内容。 效率上 truncate 比 delete 快，但 truncate 删除后不记录 mysql 日志，不可以恢复数据。 delete 的效果有点像将 mysql 表中所有记录一条一条删除到删完， 而 truncate 相当于保留 mysql 表的结构，重新创建了这个表，所有的状态都相当于新表。 所以 delete 不会重置 ID 列，而 truncat 会重置。 delete 删除是逻辑上的删除，并不会真正的释放硬盘空间，而 truncat 是物理上的删除操作会真正的释放硬盘空间 ","date":"2021-01-01","objectID":"/posts/mysql-manage/:3:1","series":null,"tags":["mysql"],"title":"MySQL 基础管理命令","uri":"/posts/mysql-manage/#1-表的基本操作"},{"categories":["mysql"],"content":" 2. 表 alter 的相关操作 text # 增加一个字段(一列),并放到第一列的位置 (first) mysql\u003e desc users; +------------+----------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +------------+----------+------+-----+---------+-------+ | username | char(30) | NO | PRI | NULL | | | userpasswd | char(20) | NO | | 123456 | | +------------+----------+------+-----+---------+-------+ 2 rows in set (0.00 sec) mysql\u003e alter table users add column id int not null first; Query OK, 0 rows affected (0.08 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql\u003e desc users; +------------+----------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +------------+----------+------+-----+---------+-------+ | id | int(11) | NO | | NULL | | | username | char(30) | NO | PRI | NULL | | | userpasswd | char(20) | NO | | 123456 | | +------------+----------+------+-----+---------+-------+ 3 rows in set (0.00 sec) # 删除一个字段 mysql\u003e alter table users drop userpasswd; Query OK, 0 rows affected (0.05 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql\u003e desc users; +----------+----------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +----------+----------+------+-----+---------+-------+ | id | int(11) | NO | | NULL | | | username | char(30) | NO | PRI | NULL | | +----------+----------+------+-----+---------+-------+ 2 rows in set (0.00 sec) # 更改列的字段类型 mysql\u003e alter table users modify username varchar(100); Query OK, 2 rows affected (0.14 sec) Records: 2 Duplicates: 0 Warnings: 0 mysql\u003e desc users; +----------+--------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +----------+--------------+------+-----+---------+-------+ | id | int(11) | NO | | NULL | | | username | varchar(100) | NO | PRI | | | +----------+--------------+------+-----+---------+-------+ 2 rows in set (0.00 sec) # 更改列名及字段类型 mysql\u003e alter table users change username user varchar(20); Query OK, 2 rows affected (0.03 sec) Records: 2 Duplicates: 0 Warnings: 0 mysql\u003e desc users; +-------+-------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+-------------+------+-----+---------+-------+ | id | int(11) | NO | | NULL | | | user | varchar(20) | NO | PRI | | | +-------+-------------+------+-----+---------+-------+ 2 rows in set (0.00 sec) # 修改表的存储引擎 mysql\u003e show create table users; +-------+---------------------------------------+ | Table | Create Table | +-------+---------------------------------------+ | users | CREATE TABLE `users` ( `id` int(11) NOT NULL, `user` varchar(20) NOT NULL DEFAULT '', PRIMARY KEY (`user`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 | +-------+---------------------------------------+ 1 row in set (0.00 sec) mysql\u003e alter table users ENGINE=myisam; Query OK, 2 rows affected (0.01 sec) Records: 2 Duplicates: 0 Warnings: 0 # 这里我们使用另一种方法查询表的默认引擎 mysql\u003e show table status from lwg where name='users'\\G *************************** 1. row *************************** Name: users Engine: MyISAM Version: 10 Row_format: Dynamic Rows: 2 Avg_row_length: 20 Data_length: 40 Max_data_length: 281474976710655 Index_length: 2048 Data_free: 0 Auto_increment: NULL Create_time: 2017-08-25 04:15:46 Update_time: 2017-08-25 04:15:46 Check_time: NULL Collation: utf8_general_ci Checksum: NULL Create_options: Comment: 1 row in set (0.00 sec) ","date":"2021-01-01","objectID":"/posts/mysql-manage/:3:2","series":null,"tags":["mysql"],"title":"MySQL 基础管理命令","uri":"/posts/mysql-manage/#2-表-alter-的相关操作"},{"categories":["mysql"],"content":"当数据库服务器资源有剩余时，为了充分利用剩余资源可以通过部署 MySQL 多实例提升资源利用率， 下面演示如何在一台机上安装 MySQL 多实例 ","date":"2020-12-24","objectID":"/posts/mysql-multi-instance/:0:0","series":null,"tags":["mysql"],"title":"MySQL 多实例安装","uri":"/posts/mysql-multi-instance/#"},{"categories":["mysql"],"content":" 下载 MySQL 5.7 二进制包 bash [root@10-13-90-34 src]# wget https://cdn.mysql.com/archives/mysql-5.7/mysql-5.7.28-linux-glibc2.12-x86_64.tar.gz ","date":"2020-12-24","objectID":"/posts/mysql-multi-instance/:1:0","series":null,"tags":["mysql"],"title":"MySQL 多实例安装","uri":"/posts/mysql-multi-instance/#下载-mysql-57-二进制包"},{"categories":["mysql"],"content":" 解压并建立软链接(/usr/local/mysql) bash [root@10-13-90-34 src]# tar xzf mysql-5.7.28-linux-glibc2.12-x86_64.tar.gz -C /usr/local/ [root@10-13-90-34 local]# ln -s /usr/local/mysql-5.7.28-linux-glibc2.12-x86_64/ /usr/local/mysql ","date":"2020-12-24","objectID":"/posts/mysql-multi-instance/:2:0","series":null,"tags":["mysql"],"title":"MySQL 多实例安装","uri":"/posts/mysql-multi-instance/#解压并建立软链接usrlocalmysql"},{"categories":["mysql"],"content":" 配置环境变量 bash echo 'export PATH=/urs/local/mysql/bin:$PATH' \u003e /etc/profile.d/mysql.sh source /etc/profile ","date":"2020-12-24","objectID":"/posts/mysql-multi-instance/:3:0","series":null,"tags":["mysql"],"title":"MySQL 多实例安装","uri":"/posts/mysql-multi-instance/#配置环境变量"},{"categories":["mysql"],"content":" 准备多实例环境创建用户 bash [root@10-13-90-34 mysql]# useradd -r -s /sbin/nologin mysql 创建数据目录 bash [root@10-13-90-34 mysql]# mkdir -p /data/mysql/{3306,3307} [root@10-13-90-34 mysql]# chown -R mysql.mysql /data/mysql 准备多实例配置文件 实例1：3307 bash cat \u003e /usr/local/mysql/etc/my-3307.cnf \u003c\u003cEOF [client] port = 3307 socket = /data/mysql/3307/mysql.sock [mysqld] user = mysql port = 3307 basedir = /usr/local/mysql datadir = /data/mysql/3307 socket = /data/mysql/3307/mysql.sock pid-file = mysqldb.pid character-set-server = utf8mb4 skip_name_resolve = 1 log-error = /data/mysql/3307/error.log server-id = 1 # binlog 配置 log-bin = /data/mysql/3307/mybinlog #sync_binlog = 1 binlog_cache_size = 4M max_binlog_cache_size = 2G max_binlog_size = 1G expire_logs_days = 7 binlog_format = row binlog_checksum = 1 # 事务模式 transaction_isolation = REPEATABLE-READ # InnoDB 配置 innodb_buffer_pool_size = 128M innodb_buffer_pool_instances = 4 innodb_data_file_path = ibdata1:1G:autoextend innodb_flush_log_at_trx_commit = 0 EOF 实例2：3308 bash cat \u003e /usr/local/mysql/etc/my-3308.cnf \u003c\u003cEOF [client] port = 3308 socket = /data/mysql/3307/mysql.sock [mysqld] user = mysql port = 3308 basedir = /usr/local/mysql datadir = /data/mysql/3308 socket = /data/mysql/3308/mysql.sock pid-file = mysqldb.pid character-set-server = utf8mb4 skip_name_resolve = 1 log-error = /data/mysql/3308/error.log server-id = 1 # binlog 配置 log-bin = /data/mysql/3308/mybinlog #sync_binlog = 1 binlog_cache_size = 4M max_binlog_cache_size = 2G max_binlog_size = 1G expire_logs_days = 7 binlog_format = row binlog_checksum = 1 # 事务模式 transaction_isolation = REPEATABLE-READ # InnoDB 配置 innodb_buffer_pool_size = 128M innodb_buffer_pool_instances = 4 innodb_data_file_path = ibdata1:1G:autoextend innodb_flush_log_at_trx_commit = 0 EOF ","date":"2020-12-24","objectID":"/posts/mysql-multi-instance/:4:0","series":null,"tags":["mysql"],"title":"MySQL 多实例安装","uri":"/posts/mysql-multi-instance/#准备多实例环境"},{"categories":["mysql"],"content":" 多实例初始化 bash [root@10-13-90-34 3307]# mysqld --defaults-file=/usr/local/mysql/etc/my-3307.cnf --initialize-insecure --user=mysql --basedir=/usr/local/mysql --datadir=/data/mysql/3307 [root@10-13-90-34 3307]# mysqld --defaults-file=/usr/local/mysql/etc/my-3308.cnf --initialize-insecure --user=mysql --basedir=/usr/local/mysql --datadir=/data/mysql/3308 --defaults-file= 参数必须放在最前面或者初始化不会成功 ","date":"2020-12-24","objectID":"/posts/mysql-multi-instance/:5:0","series":null,"tags":["mysql"],"title":"MySQL 多实例安装","uri":"/posts/mysql-multi-instance/#多实例初始化"},{"categories":["mysql"],"content":" 使用 systemd 管理多实例服务3307 bash cat \u003e /usr/lib/systemd/system/mysqld-3307.service \u003c\u003c EOF [Unit] Description=MySQL Server Documentation=man:mysqld(8) Documentation=http://dev.mysql.com/doc/refman/en/using-systemd.html After=network.target After=syslog.target [Install] WantedBy=multi-user.target [Service] User=mysql Group=mysql ExecStart=/usr/local/mysql/bin/mysqld --defaults-file=/usr/local/mysql/etc/my-3307.cnf LimitNOFILE = 5000 EOF 3308 bash cat \u003e /usr/lib/systemd/system/mysqld-3308.service \u003c\u003c EOF [Unit] Description=MySQL Server Documentation=man:mysqld(8) Documentation=http://dev.mysql.com/doc/refman/en/using-systemd.html After=network.target After=syslog.target [Install] WantedBy=multi-user.target [Service] User=mysql Group=mysql ExecStart=/usr/local/mysql/bin/mysqld --defaults-file=/usr/local/mysql/etc/my-3308.cnf LimitNOFILE = 5000 EOF ","date":"2020-12-24","objectID":"/posts/mysql-multi-instance/:6:0","series":null,"tags":["mysql"],"title":"MySQL 多实例安装","uri":"/posts/mysql-multi-instance/#使用-systemd-管理多实例服务"},{"categories":["mysql"],"content":" 启动 MySQL 多实例 bash [root@10-13-90-34 ~]# systemctl start mysqld-3307 [root@10-13-90-34 ~]# systemctl start mysqld-3308 [root@10-13-90-34 ~]# systemctl status mysqld-3307.service ● mysqld-3307.service - MySQL Server Loaded: loaded (/usr/lib/systemd/system/mysqld-3307.service; disabled; vendor preset: disabled) Active: active (running) since 四 2020-12-24 13:44:18 CST; 14s ago Docs: man:mysqld(8) http://dev.mysql.com/doc/refman/en/using-systemd.html Main PID: 40145 (mysqld) CGroup: /system.slice/mysqld-3307.service └─40145 /usr/local/mysql/bin/mysqld --defaults-file=/usr/local/mysql/etc/my-3307.cnf 12月 24 13:44:18 10-13-90-34 systemd[1]: Started MySQL Server. [root@10-13-90-34 ~]# systemctl status mysqld-3308.service ● mysqld-3308.service - MySQL Server Loaded: loaded (/usr/lib/systemd/system/mysqld-3308.service; disabled; vendor preset: disabled) Active: active (running) since 四 2020-12-24 13:44:20 CST; 16s ago Docs: man:mysqld(8) http://dev.mysql.com/doc/refman/en/using-systemd.html Main PID: 40179 (mysqld) CGroup: /system.slice/mysqld-3308.service └─40179 /usr/local/mysql/bin/mysqld --defaults-file=/usr/local/mysql/etc/my-3308.cnf 12月 24 13:44:20 10-13-90-34 systemd[1]: Started MySQL Server. ","date":"2020-12-24","objectID":"/posts/mysql-multi-instance/:7:0","series":null,"tags":["mysql"],"title":"MySQL 多实例安装","uri":"/posts/mysql-multi-instance/#启动-mysql-多实例"},{"categories":["mysql"],"content":" 连接 MySQL 多实例 bash [root@10-13-90-34 ~]# mysql -S /data/mysql/3307/mysql.sock ","date":"2020-12-24","objectID":"/posts/mysql-multi-instance/:8:0","series":null,"tags":["mysql"],"title":"MySQL 多实例安装","uri":"/posts/mysql-multi-instance/#连接-mysql-多实例"},{"categories":["mysql"],"content":" 下载 MySQL 5.7 二进制包 bash wget https://cdn.mysql.com/archives/mysql-5.7/mysql-5.7.28-linux-glibc2.12-x86_64.tar.gz ","date":"2020-12-20","objectID":"/posts/mysql-install/:1:0","series":null,"tags":["mysql"],"title":"MySQL 使用二进制包进行部署","uri":"/posts/mysql-install/#下载-mysql-57-二进制包"},{"categories":["mysql"],"content":" 解压并建立软链接(/usr/local/mysql) bash tar xzf mysql-5.7.28-linux-glibc2.12-x86_64.tar.gz -C /usr/local/ ln -s /usr/local/mysql-5.7.28-linux-glibc2.12-x86_64/ /usr/local/mysql ","date":"2020-12-20","objectID":"/posts/mysql-install/:2:0","series":null,"tags":["mysql"],"title":"MySQL 使用二进制包进行部署","uri":"/posts/mysql-install/#解压并建立软链接usrlocalmysql"},{"categories":["mysql"],"content":" 配置环境变量 bash echo 'export PATH=/usr/local/mysql/bin:$PATH' \u003e /etc/profile.d/mysql.sh source /etc/profile ","date":"2020-12-20","objectID":"/posts/mysql-install/:3:0","series":null,"tags":["mysql"],"title":"MySQL 使用二进制包进行部署","uri":"/posts/mysql-install/#配置环境变量"},{"categories":["mysql"],"content":" 初始化前准备工作 bash # 安装依赖 yum install libaio # 创建 mysql 用户 useradd -r -s /sbin/nologin mysql # 创建数据存储目录 mkdir -p /data/mysql chown -R mysql.mysql /data/mysql/ # 生成配置文件 my.cnf cd /usr/local/mysql mkdir etc cat \u003eetc/my.cnf\u003c\u003cEOF [client] port = 3306 socket = /data/mysql/mysql.sock [mysqld] user = mysql port = 3306 basedir = /usr/local/mysql datadir = /data/mysql socket = /data/mysql/mysql.sock pid-file = mysqldb.pid character-set-server = utf8mb4 skip_name_resolve = 1 log-error = /data/mysql/error.log server-id = 1 # binlog 配置 log-bin = /data/mysql/mybinlog sync_binlog = 1 binlog_cache_size = 4M max_binlog_cache_size = 2G max_binlog_size = 1G expire_logs_days = 7 binlog_format = row binlog_checksum = 1 # 事务模式 transaction_isolation = REPEATABLE-READ # InnoDB 配置 innodb_buffer_pool_size = 128M innodb_buffer_pool_instances = 4 innodb_data_file_path = ibdata1:1G:autoextend innodb_flush_log_at_trx_commit = 0 EOF ","date":"2020-12-20","objectID":"/posts/mysql-install/:4:0","series":null,"tags":["mysql"],"title":"MySQL 使用二进制包进行部署","uri":"/posts/mysql-install/#初始化前准备工作"},{"categories":["mysql"],"content":" 初始化数据库初始化参数 --initialize # 初始化时会提供12位的 root 临时密码，使用mysql前必须重置此密码，密码管理使用严格模式。 --initialize-insecure # 不会为 root 用户生成临时密码 bash mysqld --initialize-insecure --user=mysql --basedir=/usr/local/mysql --datadir=/data/mysql ","date":"2020-12-20","objectID":"/posts/mysql-install/:5:0","series":null,"tags":["mysql"],"title":"MySQL 使用二进制包进行部署","uri":"/posts/mysql-install/#初始化数据库"},{"categories":["mysql"],"content":" 管理 mysql 服务使用自带脚本 MySQL 默认提供服务管理脚本 support-files/mysql.server 使用方法 bash cp support-files/mysql.server /etc/init.d/mysqld /etc/init.d/mysqld start 使用 systemd 管理 MySQL 服务 编写 /usr/lib/systemd/system/mysqld.service 文件，内容如下 bash [Unit] Description=MySQL Server Documentation=man:mysqld(8) Documentation=http://dev.mysql.com/doc/refman/en/using-systemd.html After=network.target After=syslog.target [Service] User=mysql Group=mysql Type=simple EnvironmentFile=-/etc/sysconfig/mysql ExecStart=/usr/local/mysql/bin/mysqld --defaults-file=/usr/local/mysql/etc/my.cnf TimeoutSec=0 PermissionsStartOnly=true LimitNOFILE=5000 Restart=on-failure RestartPreventExitStatus=1 PrivateTmp=false [Install] WantedBy=multi-user.target 以上方法二选一即可 ","date":"2020-12-20","objectID":"/posts/mysql-install/:6:0","series":null,"tags":["mysql"],"title":"MySQL 使用二进制包进行部署","uri":"/posts/mysql-install/#管理-mysql-服务"},{"categories":["mysql"],"content":" 扩展部署多实例 MySQL 方法1: 多份 MySQL 程序，不同的配置文件，不同的数据存储目录 方法2: 一份 MySQL 程序，不同的配置文件，不同的数据存储目录 （推荐） 实现方法 在 MySQL 服务启动命令 mysqld 使用参数（–defaults-file）指定默认使用的配置文件(my.cnf)即可实现，数据存储目录在配置文件中配置. 查看 mysqld 参数方法: mysqld --verbose --help ","date":"2020-12-20","objectID":"/posts/mysql-install/:7:0","series":null,"tags":["mysql"],"title":"MySQL 使用二进制包进行部署","uri":"/posts/mysql-install/#扩展部署多实例-mysql"},{"categories":["mysql"],"content":" 使用 phpMyAdmin 登录任意数据库服务器安装完成 phpMyAdmin 后, 如果你想在页面手动输入服务器地址进行连接，可以参考以下配置项 官方文档: https://docs.phpmyadmin.net/en/latest/config.html#cfg_AllowArbitraryServer 编辑 libraries/config.default.php 找到 $cfg['AllowArbitraryServer'] 配置项，将值改为 true 即可 php $cfg['AllowArbitraryServer'] = true; ","date":"2019-09-24","objectID":"/posts/phpmyadmin/:1:0","series":null,"tags":["phpMyAdmin"],"title":"使用 phpMyAdmin 登录任意数据库服务器","uri":"/posts/phpmyadmin/#使用-phpmyadmin-登录任意数据库服务器"},{"categories":["devops","php"],"content":"众所周知，PHP 是 LAMP 应用程序（WordPress，Joomla，Drupal和Media Wiki等）中最重要的部分。 现在，大多数这些应用程序都需要PHP 7进行安装和配置。 PHP 7.x的主要优点在于，它可以更快地加载Web应用程序，并且消耗更少的服务器资源（例如CPU和RAM）。 默认情况下，PHP 5.4 在 CentOS 7 和 RHEL 7 YUM 存储库中可用。 在本文中，我们将演示如何在 CentOS 7 和 RHEL 7 服务器上安装最新版本的 PHP。 文档出处: https://www.linuxtechi.com/install-php-7-centos-7-rhel-7-server/ ","date":"2019-08-26","objectID":"/posts/php-install/:0:0","series":null,"tags":["php"],"title":"如何在 CentOS 7 和 RHEL 7 服务器上安装 PHP 7.x","uri":"/posts/php-install/#"},{"categories":["devops","php"],"content":" CentOS 7服务器上PHP 7.0、7.1和7.2的安装步骤","date":"2019-08-26","objectID":"/posts/php-install/:1:0","series":null,"tags":["php"],"title":"如何在 CentOS 7 和 RHEL 7 服务器上安装 PHP 7.x","uri":"/posts/php-install/#centos-7服务器上php-7071和72的安装步骤"},{"categories":["devops","php"],"content":" 1）安装 yum-utils 并启用 EPEL 存储库登录到您的服务器并使用以下 yum 命令安装 yum-utils 并启用 epel 存储库 bash [root@linuxtechi ~]# yum install epel-release yum-utils -y ","date":"2019-08-26","objectID":"/posts/php-install/:1:1","series":null,"tags":["php"],"title":"如何在 CentOS 7 和 RHEL 7 服务器上安装 PHP 7.x","uri":"/posts/php-install/#1安装-yum-utils-并启用-epel-存储库"},{"categories":["devops","php"],"content":" 2) 使用yum命令下载并安装remirepo bash [root@linuxtechi ~]# yum install http://rpms.remirepo.net/enterprise/remi-release-7.rpm ","date":"2019-08-26","objectID":"/posts/php-install/:1:2","series":null,"tags":["php"],"title":"如何在 CentOS 7 和 RHEL 7 服务器上安装 PHP 7.x","uri":"/posts/php-install/#2-使用yum命令下载并安装remirepo"},{"categories":["devops","php"],"content":" 3) 根据您的要求，配置PHP 7.x存储库 要配置PHP 7.0存储库，请使用以下命令， bash [root@linuxtechi ~]# yum-config-manager --enable remi-php70 要配置PHP 7.1存储库，请使用以下命令， bash [root@linuxtechi ~]# yum-config-manager --enable remi-php71 要配置PHP 7.2 存储库，请使用以下命令， bash [root@linuxtechi ~]# yum-config-manager --enable remi-php72 ","date":"2019-08-26","objectID":"/posts/php-install/:1:3","series":null,"tags":["php"],"title":"如何在 CentOS 7 和 RHEL 7 服务器上安装 PHP 7.x","uri":"/posts/php-install/#3--根据您的要求配置php-7x存储库"},{"categories":["devops","php"],"content":" 4) 安装PHP 7.2及其依赖项。在本教程中，我将安装最新版本的PHP 7.2及其模块，在yum命令下运行 bash [root@linuxtechi ~]# yum install php php-common php-opcache php-mcrypt php-cli php-gd php-curl php-mysql -y 注意：要搜索所有PHP模块，请使用以下命令： bash [root@linuxtechi ~]# yum search php | more ","date":"2019-08-26","objectID":"/posts/php-install/:1:4","series":null,"tags":["php"],"title":"如何在 CentOS 7 和 RHEL 7 服务器上安装 PHP 7.x","uri":"/posts/php-install/#4-安装php-72及其依赖项"},{"categories":["devops","php"],"content":" 5）验证PHP版本在步骤 4 中安装完所有PHP 7.2及其依赖项之后，请使用以下命令验证已安装的PHP版本， bash [root@linuxtechi ~]# php -v PHP 7.2.7 (cli) (built: Jun 20 2018 08:21:26) ( NTS ) Copyright (c) 1997-2018 The PHP Group Zend Engine v3.2.0, Copyright (c) 1998-2018 Zend Technologies with Zend OPcache v7.2.7, Copyright (c) 1999-2018, by Zend Technologies ","date":"2019-08-26","objectID":"/posts/php-install/:1:5","series":null,"tags":["php"],"title":"如何在 CentOS 7 和 RHEL 7 服务器上安装 PHP 7.x","uri":"/posts/php-install/#5验证php版本"},{"categories":["devops","php"],"content":" PHP 7.x在RHEL 7 Server上的安装步骤","date":"2019-08-26","objectID":"/posts/php-install/:2:0","series":null,"tags":["php"],"title":"如何在 CentOS 7 和 RHEL 7 服务器上安装 PHP 7.x","uri":"/posts/php-install/#php-7x在rhel-7-server上的安装步骤"},{"categories":["devops","php"],"content":" 1）启用EPEL，RHEL 7 Server可选存储库并安装remirepo rpm登录到RHEL 7 Server并依次运行以下命令以启用EPEL存储库，安装remirepo并启用RHEL 7 Server可选存储库 bash [root@linuxtechi ~]# rpm -Uvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm [root@linuxtechi ~]# wget http://rpms.remirepo.net/enterprise/remi-release-7.rpm [root@linuxtechi ~]# rpm -Uvh remi-release-7.rpm epel-release-latest-7.noarch.rpm [root@linuxtechi ~]# subscription-manager repos --enable=rhel-7-server-optional-rpms ","date":"2019-08-26","objectID":"/posts/php-install/:2:1","series":null,"tags":["php"],"title":"如何在 CentOS 7 和 RHEL 7 服务器上安装 PHP 7.x","uri":"/posts/php-install/#1启用epelrhel-7-server可选存储库并安装remirepo-rpm"},{"categories":["devops","php"],"content":" 2）配置PHP 7.x存储库 bash [root@linuxtechi ~]# yum install yum-utils [root@linuxtechi ~]# yum-config-manager --enable remi-php72 ","date":"2019-08-26","objectID":"/posts/php-install/:2:2","series":null,"tags":["php"],"title":"如何在 CentOS 7 和 RHEL 7 服务器上安装 PHP 7.x","uri":"/posts/php-install/#2配置php-7x存储库"},{"categories":["devops","php"],"content":" 3）安装PHP 7.2及其依赖项 bash [root@linuxtechi ~]# yum install php php-common php-opcache php-mcrypt php-cli php-gd php-curl php-mysql -y ","date":"2019-08-26","objectID":"/posts/php-install/:2:3","series":null,"tags":["php"],"title":"如何在 CentOS 7 和 RHEL 7 服务器上安装 PHP 7.x","uri":"/posts/php-install/#3安装php-72及其依赖项"},{"categories":["devops","php"],"content":" 4）验证PHP版本 bash [root@linuxtechi ~]# php -v ","date":"2019-08-26","objectID":"/posts/php-install/:2:4","series":null,"tags":["php"],"title":"如何在 CentOS 7 和 RHEL 7 服务器上安装 PHP 7.x","uri":"/posts/php-install/#4验证php版本"},{"categories":["php"],"content":" redis 插件 bash wget http://pecl.php.net/get/redis-4.2.0.tgz tar xzf redis-4.2.0.tgz cd redis-4.2.0 /usr/local/php/bin/phpize ./configure --with-php-config=/usr/local/php/bin/php-config make \u0026\u0026 make install cat \u003e /etc/php/conf.d/redis.ini \u003c\u003c EOF [redis] extension=redis.so EOF ","date":"2019-08-26","objectID":"/posts/php-plugin/:1:0","series":null,"tags":["php","pecl"],"title":"PHP 插件安装","uri":"/posts/php-plugin/#redis-插件"},{"categories":["php"],"content":" RabbitMQ 插件安装 rabbitmq-c bash wget -O rabbitmq-c-0.9.0.tar.gz https://github.com/alanxz/rabbitmq-c/archive/v0.9.0.tar.gz tar xzf rabbitmq-c-0.9.0.tar.gz cd rabbitmq-c-0.9.0 mkdir build \u0026\u0026 cd build cmake -DCMAKE_INSTALL_PREFIX=/usr/local/rabbitmq-c .. cmake --build . --target install 到这里就已经安装完成了。不过这里有一个坑。你可以看一下/usr/local/rabbitmq-c下的目录只有include和lib64。因为后面编译安装amqp扩展的时候系统会到/usr/local/rabbitmq-c/lib目录下搜索依赖库，导致错误。所以这里需要加一步 bash cd /usr/local/rabbitmq-c ln -s lib64 lib 安装 amqp bash wget https://pecl.php.net/get/amqp-1.9.4.tgz tar xzf amqp-1.9.4.tgz cd amqp-1.9.4 /usr/local/php/bin/phpize ./configure --with-php-config=/usr/local/php/bin/php-config / --with-amqp --with-librabbitmq-dir=/usr/local/rabbitmq-c make \u0026\u0026 make install cat \u003e /etc/php/conf.d/amqp.ini \u003c\u003c EOF [amqp] extension=amqp.so EOF ","date":"2019-08-26","objectID":"/posts/php-plugin/:2:0","series":null,"tags":["php","pecl"],"title":"PHP 插件安装","uri":"/posts/php-plugin/#rabbitmq-插件"},{"categories":["php"],"content":" 安装 mcrypt bash yum install libmcrypt libmcrypt-devel mcrypt mhash wget https://pecl.php.net/get/mcrypt-1.0.2.tgz tar xzf mcrypt-1.0.2.tgz cd mcrypt-1.0.2 /usr/local/php/bin/phpize ./configure --with-php-config=/usr/local/php/bin/php-config make \u0026\u0026 make install cat \u003e /etc/php/conf.d/mcrypt.ini \u003c\u003c EOF [mcrypt] extension=mcrypt.so EOF ","date":"2019-08-26","objectID":"/posts/php-plugin/:3:0","series":null,"tags":["php","pecl"],"title":"PHP 插件安装","uri":"/posts/php-plugin/#安装-mcrypt"},{"categories":["php"],"content":" 使用 pecl 安装扩展使用 pecl 命令可以快速帮我们安装 PHP 扩展，使用方法如下 以安装 redis 扩展为例 bash pecl install redis pecl install redis-4.2.0 pecl install https://pecl.php.net/get/redis-4.2.0.tgz cat \u003e /etc/php/conf.d/redis.ini \u003c\u003c EOF [redis] extension=redis.so EOF 注意: pecl 会自动向 php.ini 文件添加 extension=redis.so，请自行修改 ","date":"2019-08-26","objectID":"/posts/php-plugin/:4:0","series":null,"tags":["php","pecl"],"title":"PHP 插件安装","uri":"/posts/php-plugin/#使用-pecl-安装扩展"},{"categories":["php"],"content":" 环境准备准备编译环境 bash yum install -y gcc gcc-c++ make cmak autoconf 安装相关依赖 bash yum install -y libmcrypt libmcrypt-devel mcrypt mhash yum install -y gmp-devel libxml2-devel openssl-devel bzip2-devel / libcurl-devel libjpeg-devel libpng-devel freetype-devel / libmcrypt-devel readline-devel libxslt-devel libicu-devel / gettext-devel libc-client-devel pam-devel ","date":"2019-08-26","objectID":"/posts/php-install/:1:0","series":null,"tags":["php"],"title":"PHP 源码编译安装","uri":"/posts/php-install/#环境准备"},{"categories":["php"],"content":" 编译安装 bash ./configure --prefix=/usr/local/php / --sysconfdir=/etc/php / --with-config-file-path=/etc/php / --with-config-file-scan-dir=/etc/php/conf.d / --enable-fpm / --with-fpm-user=www / --with-fpm-group=www / --enable-mysqlnd / --with-mysqli=mysqlnd / --with-pdo-mysql=mysqlnd / --with-iconv-dir / --with-freetype-dir / --with-jpeg-dir / --with-png-dir / --with-zlib / --with-curl / --with-gettext / --with-imap / --enable-exif / --with-libxml-dir / --enable-xml / --disable-rpath / --enable-bcmath / --enable-shmop / --enable-sysvsem / --enable-inline-optimization / --enable-mbregex / --enable-mbstring / --enable-intl / --enable-pcntl / --enable-ftp / --with-gd / --with-openssl / --with-mhash / --enable-pcntl / --enable-sockets / --with-xmlrpc / --enable-zip / --enable-soap / --with-gettext / --enable-opcache / --with-xsl make make install ","date":"2019-08-26","objectID":"/posts/php-install/:2:0","series":null,"tags":["php"],"title":"PHP 源码编译安装","uri":"/posts/php-install/#编译安装"},{"categories":["php"],"content":" 配置 PHP bash MemTotal=`free -m | grep Mem | awk '{print $2}'` /bin/cp -f php.ini-production /etc/php/php.ini sed -i 's/post_max_size =.*/post_max_size = 50M/g' /etc/php/php.ini sed -i 's/upload_max_filesize =.*/upload_max_filesize = 50M/g' /etc/php/php.ini sed -i 's/;date.timezone =.*/date.timezone = PRC/g' /etc/php/php.ini sed -i 's/short_open_tag =.*/short_open_tag = On/g' /etc/php/php.ini sed -i 's/;cgi.fix_pathinfo=.*/cgi.fix_pathinfo=0/g' /etc/php/php.ini sed -i 's/max_execution_time =.*/max_execution_time = 300/g' /etc/php/php.ini sed -i 's/disable_functions =.*/disable_functions = passthru,exec,system,chroot,chgrp,chown,shell_exec,proc_open,proc_get_status,popen,ini_alter,ini_restore,dl,openlog,syslog,readlink,symlink,popepassthru,stream_socket_server/g' /etc/php/php.ini /bin/cp -f /etc/php/php-fpm.conf.default /etc/php/php-fpm.conf sed -i \"s#^;pid.*#pid = /var/run/php-fpm.pid#\" /etc/php/php-fpm.conf sed -i \"s#^;error_log.*#error_log = /var/log/php-fpm.log#\" /etc/php/php-fpm.conf sed -i \"s#^;log_level.*#log_level = notice#\" /etc/php/php-fpm.conf cat \u003e/etc/php/php-fpm.d/www.conf\u003c\u003cEOF [www] listen = /var/run/php-cgi.sock listen.backlog = -1 listen.allowed_clients = 127.0.0.1 listen.owner = www listen.group = www listen.mode = 0666 user = www group = www pm = dynamic pm.max_children = 10 pm.start_servers = 2 pm.min_spare_servers = 1 pm.max_spare_servers = 6 request_terminate_timeout = 100 request_slowlog_timeout = 0 slowlog = /var/log/slow.log EOF if [[ ${MemTotal} -gt 1024 \u0026\u0026 ${MemTotal} -le 2048 ]]; then sed -i \"s#pm.max_children.*#pm.max_children = 20#\" /etc/php/php-fpm.d/www.conf sed -i \"s#pm.start_servers.*#pm.start_servers = 10#\" /etc/php/php-fpm.d/www.conf sed -i \"s#pm.min_spare_servers.*#pm.min_spare_servers = 10#\" /etc/php/php-fpm.d/www.conf sed -i \"s#pm.max_spare_servers.*#pm.max_spare_servers = 20#\" /etc/php/php-fpm.d/www.conf elif [[ ${MemTotal} -gt 2048 \u0026\u0026 ${MemTotal} -le 4096 ]]; then sed -i \"s#pm.max_children.*#pm.max_children = 40#\" /etc/php/php-fpm.d/www.conf sed -i \"s#pm.start_servers.*#pm.start_servers = 20#\" /etc/php/php-fpm.d/www.conf sed -i \"s#pm.min_spare_servers.*#pm.min_spare_servers = 20#\" /etc/php/php-fpm.d/www.conf sed -i \"s#pm.max_spare_servers.*#pm.max_spare_servers = 40#\" /etc/php/php-fpm.d/www.conf elif [[ ${MemTotal} -gt 4096 \u0026\u0026 ${MemTotal} -le 8192 ]]; then sed -i \"s#pm.max_children.*#pm.max_children = 60#\" /etc/php/php-fpm.d/www.conf sed -i \"s#pm.start_servers.*#pm.start_servers = 30#\" /etc/php/php-fpm.d/www.conf sed -i \"s#pm.min_spare_servers.*#pm.min_spare_servers = 30#\" /etc/php/php-fpm.d/www.conf sed -i \"s#pm.max_spare_servers.*#pm.max_spare_servers = 60#\" /etc/php/php-fpm.d/www.conf elif [[ ${MemTotal} -gt 8192 ]]; then sed -i \"s#pm.max_children.*#pm.max_children = 80#\" /etc/php/php-fpm.d/www.conf sed -i \"s#pm.start_servers.*#pm.start_servers = 40#\" /etc/php/php-fpm.d/www.conf sed -i \"s#pm.min_spare_servers.*#pm.min_spare_servers = 40#\" /etc/php/php-fpm.d/www.conf sed -i \"s#pm.max_spare_servers.*#pm.max_spare_servers = 80#\" /etc/php/php-fpm.d/www.conf fi 复制服务启动文件 CentOS 6.x bash /bin/cp -f sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm chmod +x /etc/init.d/php-fpm sed -i \"s#php_fpm_PID=.*#php_fpm_PID=/var/run/php-fpm.pid#\" /etc/init.d/php-fpm CentOS 7.x bash /bin/cp -f sapi/fpm/php-fpm.service /usr/lib/systemd/system/php-fpm.service ","date":"2019-08-26","objectID":"/posts/php-install/:3:0","series":null,"tags":["php"],"title":"PHP 源码编译安装","uri":"/posts/php-install/#配置-php"},{"categories":["devops","rabbitmq"],"content":"由于 rabbitmq 是 erlang 开发的所以依赖 erlang, 准备三台服务器并配置好主机名, 并以下信息写入三台服务器的 hosts. bash mq1 192.168.1.11 mq2 192.168.1.12 mq3 192.168.1.13 ","date":"2019-08-12","objectID":"/posts/rabbitmq/:0:0","series":null,"tags":["rabbitmq"],"title":"部署 rabbitmq 集群","uri":"/posts/rabbitmq/#"},{"categories":["devops","rabbitmq"],"content":" 1. 配置 erlang, rabbitmq YUM 仓库 bash curl -s https://packagecloud.io/install/repositories/rabbitmq/erlang/script.rpm.sh | bash curl -s https://packagecloud.io/install/repositories/rabbitmq/rabbitmq-server/script.rpm.sh | bash ","date":"2019-08-12","objectID":"/posts/rabbitmq/:1:0","series":null,"tags":["rabbitmq"],"title":"部署 rabbitmq 集群","uri":"/posts/rabbitmq/#1-配置-erlang-rabbitmq-yum-仓库"},{"categories":["devops","rabbitmq"],"content":" 2. 安装 eple 扩展 bash yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-6.noarch.rpm ","date":"2019-08-12","objectID":"/posts/rabbitmq/:2:0","series":null,"tags":["rabbitmq"],"title":"部署 rabbitmq 集群","uri":"/posts/rabbitmq/#2-安装-eple-扩展"},{"categories":["devops","rabbitmq"],"content":" 3. 安装 rabbitmq bash yum install -y erlang rabbitmq-server ","date":"2019-08-12","objectID":"/posts/rabbitmq/:3:0","series":null,"tags":["rabbitmq"],"title":"部署 rabbitmq 集群","uri":"/posts/rabbitmq/#3-安装-rabbitmq"},{"categories":["devops","rabbitmq"],"content":" 4. 开启 rabbitmq WEB 管理 bash rabbitmq-plugins enable rabbitmq_management ","date":"2019-08-12","objectID":"/posts/rabbitmq/:4:0","series":null,"tags":["rabbitmq"],"title":"部署 rabbitmq 集群","uri":"/posts/rabbitmq/#4-开启-rabbitmq-web-管理"},{"categories":["devops","rabbitmq"],"content":" 5. 后台启动 rabbitmq bash rabbitmq-server -detached ","date":"2019-08-12","objectID":"/posts/rabbitmq/:5:0","series":null,"tags":["rabbitmq"],"title":"部署 rabbitmq 集群","uri":"/posts/rabbitmq/#5-后台启动-rabbitmq"},{"categories":["devops","rabbitmq"],"content":" 6. 配置 rabbitmq 集群 bash rabbitmqctl stop_app rabbitmqctl join_cluster --disc rabbit@mq1 rabbitmqctl start_app –ram 为内存节点 ","date":"2019-08-12","objectID":"/posts/rabbitmq/:6:0","series":null,"tags":["rabbitmq"],"title":"部署 rabbitmq 集群","uri":"/posts/rabbitmq/#6-配置-rabbitmq-集群"},{"categories":["devops","rabbitmq"],"content":" 7. 修改 rabbitmq 用户 bash rabbitmqctl add_user jpuser 'G6JzIC3ifipGIMa' rabbitmqctl set_user_tags jpuser administrator rabbitmqctl set_permissions -p '/' jpuser '.*' '.*' '.*' ","date":"2019-08-12","objectID":"/posts/rabbitmq/:7:0","series":null,"tags":["rabbitmq"],"title":"部署 rabbitmq 集群","uri":"/posts/rabbitmq/#7-修改-rabbitmq-用户"},{"categories":["devops","rabbitmq"],"content":" 8. 配置为高可用集群 bash rabbitmqctl set_policy ha-all-queue \"^\" '{\"ha-mode\":\"all\",\"ha-sync-mode\":\"automatic\"}' 设置 policy，以 ha. 开头的队列将会被镜像到集群其他所有节点,一个节点挂掉然后重启后会自动同步队列消息（生产环境采用这个方式） ","date":"2019-08-12","objectID":"/posts/rabbitmq/:8:0","series":null,"tags":["rabbitmq"],"title":"部署 rabbitmq 集群","uri":"/posts/rabbitmq/#8-配置为高可用集群"},{"categories":["devops","rsync"],"content":" 任务需求需要将一台服务器指定目录中的文件实时同步到另一台服务器上，目录路径 /data/www/pic, 此时我们通过 Rsync + Inotify 来实现。 服务器如下 192.168.145.131: 文件发布推送，客户端 192.168.145.132: 文件同步接收，服务端 由于我们需要将 192.168.145.131 上的文件实时同步至 192.168.145.132 服务器，所以 192.168.145.132 为服务端，192.168.145.131 为客户端 ","date":"2017-03-24","objectID":"/posts/rsync-inotify/:1:0","series":null,"tags":["rsync","inotify"],"title":"通过 rsync + inotify 搭建实时文件同步系统","uri":"/posts/rsync-inotify/#任务需求"},{"categories":["devops","rsync"],"content":" 配置服务端","date":"2017-03-24","objectID":"/posts/rsync-inotify/:2:0","series":null,"tags":["rsync","inotify"],"title":"通过 rsync + inotify 搭建实时文件同步系统","uri":"/posts/rsync-inotify/#配置服务端"},{"categories":["devops","rsync"],"content":" 安装 rsync bash yum install rsync ","date":"2017-03-24","objectID":"/posts/rsync-inotify/:2:1","series":null,"tags":["rsync","inotify"],"title":"通过 rsync + inotify 搭建实时文件同步系统","uri":"/posts/rsync-inotify/#安装-rsync"},{"categories":["devops","rsync"],"content":" 配置 rsync编辑文件 /etc/rsyncd.conf，写入如下配置信息 bash # /etc/rsyncd: configuration file for rsync daemon mode # See rsyncd.conf man page for more options. # configuration example: uid = nobody gid = nobody use chroot = yes max connections = 10 pid file = /var/run/rsyncd.pid # exclude = lost+found/ transfer logging = yes timeout = 900 fake super = yes # 不要漏了这项配置，否则会报 Operation not permitted 错误 # ignore nonreadable = yes # dont compress = *.gz *.tgz *.zip *.z *.Z *.rpm *.deb *.bz2 [www] # 同步文件存放目录 path = /data/www/ comment = Files synced in real time ignore errors read only = no write only = no # 允许连接的IP地址 hosts allow = 192.168.145.131 # 拒绝连接的 IP 地址，* 号匹配所有 hosts deny = * list = false # 同步过来文件的属主和属组，记得修改同步目录的的权限： chown -R www.www /data/www uid = www gid = www # 客户端连接使用的用户名 auth users = www # 客户端连接使用的用户名及密码，格式 \u003cusername\u003e:\u003cpassword\u003e 以普通文本文件存放，注意权限 secrets file = /etc/www.pass 生成 rsync 客户端连接使用的验证文件 bash echo 'www:123456' \u003e /etc/www.pass chmod 600 /etc/www.pass 创建同步目录，并授权（根据配置文件的批定的uid，gid）于相应的权限 bash mkdir -p /data/www chown -R www.www /data/www ","date":"2017-03-24","objectID":"/posts/rsync-inotify/:2:2","series":null,"tags":["rsync","inotify"],"title":"通过 rsync + inotify 搭建实时文件同步系统","uri":"/posts/rsync-inotify/#配置-rsync"},{"categories":["devops","rsync"],"content":" 启动 rsync bash systemctl start rsyncd.service systemctl enable rsyncd.service ","date":"2017-03-24","objectID":"/posts/rsync-inotify/:2:3","series":null,"tags":["rsync","inotify"],"title":"通过 rsync + inotify 搭建实时文件同步系统","uri":"/posts/rsync-inotify/#启动-rsync"},{"categories":["devops","rsync"],"content":" 配置客户端由于客户端是文件推送端，需要实时检测文件目录的变化并同步至服务端，所以需要安装 rsync 和 inotify-tools 工具 ","date":"2017-03-24","objectID":"/posts/rsync-inotify/:3:0","series":null,"tags":["rsync","inotify"],"title":"通过 rsync + inotify 搭建实时文件同步系统","uri":"/posts/rsync-inotify/#配置客户端"},{"categories":["devops","rsync"],"content":" 安装 rsync bash yum install rsync ","date":"2017-03-24","objectID":"/posts/rsync-inotify/:3:1","series":null,"tags":["rsync","inotify"],"title":"通过 rsync + inotify 搭建实时文件同步系统","uri":"/posts/rsync-inotify/#安装-rsync-1"},{"categories":["devops","rsync"],"content":" 安装 inotify-tools由于 inotify 特性需要 Linux 内核的支持，在安装 inotify-tools 前要先确认 Linux 系统内核是否达到了 2.6.13 以上，如果 Linux 内核低于 2.6.13 版本，就需要重新编译内核加入 inotify 的支持，也可以用如下方法判断，内核是否支持 inotify bash [root@localhost ~]# uname -r 3.10.0-862.el7.x86_64 [root@localhost ~]# ll /proc/sys/fs/inotify total 0 -rw-r--r-- 1 root root 0 Jun 12 21:10 max_queued_events -rw-r--r-- 1 root root 0 Jun 12 21:10 max_user_instances -rw-r--r-- 1 root root 0 Jun 12 21:10 max_user_watches 如果有上面三项输出，表示系统已经默认支持 inotify，接着就可以开始安装 inotify-tools 了 bash yum install inotify-tools inotify-tools 安装完成后，会生成 inotifywait 和 inotifywatch 两个指令。 inotifywait 用于等待文件或文件集上的一个特定事件，它可以监控任何文件和目录设置，并且可以递归地监控整个目录树。 inotifywatch 用于收集被监控的文件系统统计数据，包括每个 inotify 事件发生多少次等信息。 ","date":"2017-03-24","objectID":"/posts/rsync-inotify/:3:2","series":null,"tags":["rsync","inotify"],"title":"通过 rsync + inotify 搭建实时文件同步系统","uri":"/posts/rsync-inotify/#安装-inotify-tools"},{"categories":["devops","rsync"],"content":" inotify 相关参数inotify 定义了下列的接口参数，可以用来限制 inotify 消耗 kernel memory 的大小。由于这些参数都是内存参数，因此，可以根据应用需求，实时的调节其大小。下面分别做简单介绍。 /proc/sys/fs/inotify/max_queued_evnets：表示调用 inotify_init 时分配给 inotify instance 中可排队的 event 的数目的最大值，超出这个值的事件被丢弃，但会触发 IN_Q_OVERFLOW 事件。 /proc/sys/fs/inotify/max_user_instances: 表示每一个 real user ID可创建的 inotify instatnces 的数量上限。 /proc/sys/fs/inotify/max_user_watches: 表示每个 inotify instatnces 可监控的最大目录数量。 如果监控的文件数目巨大，需要根据情况，适当增加此值的大小, 例如: bash echo 30000000 \u003e /proc/sys/fs/inotify/max_user_watches ","date":"2017-03-24","objectID":"/posts/rsync-inotify/:3:3","series":null,"tags":["rsync","inotify"],"title":"通过 rsync + inotify 搭建实时文件同步系统","uri":"/posts/rsync-inotify/#inotify-相关参数"},{"categories":["devops","rsync"],"content":" inotifywait 相关参数inotifywait 是一个监控等待事件，可以配合 shell 脚本使用它，下面介绍一下常用的一些参数： -m， 即 --monitor，表示始终保持事件监听状态。 -r， 即 --recursive，表示递归查询目录。 -q， 即 --quiet，表示打印出监控事件。 -e， 即 --event，通过此参数可以指定要监控的事件，常见的事件有 modify、delete、create、attrib 等。 更详细的请参看 man inotifywait ","date":"2017-03-24","objectID":"/posts/rsync-inotify/:3:4","series":null,"tags":["rsync","inotify"],"title":"通过 rsync + inotify 搭建实时文件同步系统","uri":"/posts/rsync-inotify/#inotifywait-相关参数"},{"categories":["devops","rsync"],"content":" 配置 inotify在 /data/scripts 目录中写入以下脚本文件，文件名为 inotify-rsync.sh bash #!/bin/bash # #*************************************************************************** # Author: liwanggui # Date: 2017-03-24 # FileName: inotify-rsync.sh # Description: Real-time file synchronization # Copyright (C): 2021 All rights reserved #*************************************************************************** # host=192.168.145.132 src=/data/www/pic # rsyncd.conf 配置项名称 dst=www # 连接验证的用户名 user=www /usr/bin/inotifywait -mrq --timefmt '%y/%m/%d %H:%M:%S ' --format '%T %w%f %e ' -e close_write,delete,create,attrib $src \\ | while read files do /usr/bin/rsync -vzrtopg --delete --progress --password-file=/etc/www.pass $src $user@$host::$dst echo \"${files} was rsynced\" \u0026\u003e\u003e/tmp/rsync.log done ","date":"2017-03-24","objectID":"/posts/rsync-inotify/:3:5","series":null,"tags":["rsync","inotify"],"title":"通过 rsync + inotify 搭建实时文件同步系统","uri":"/posts/rsync-inotify/#配置-inotify"},{"categories":["devops","rsync"],"content":" 启动测试使用 nohup 将脚本以守护进程的方式的运行在后台 bash nohup bash /data/scripts/inotify-rsync.sh \u0026 在 /data/www/pic 目录生成一些文件 bash cp /etc/yum.repos.d/* /data/www/pic/ 查看脚本日志, 使用 cat /tmp/rsync.log 命令查看 bash 17/03/24 22:15:43 /data/www/pic/CentOS-Base.repo CREATE was rsynced 17/03/24 22:15:43 /data/www/pic/CentOS-Base.repo CLOSE_WRITE,CLOSE was rsynced 17/03/24 22:15:43 /data/www/pic/CentOS-CR.repo CREATE was rsynced 17/03/24 22:15:43 /data/www/pic/CentOS-CR.repo CLOSE_WRITE,CLOSE was rsynced 17/03/24 22:15:43 /data/www/pic/CentOS-Debuginfo.repo CREATE was rsynced 17/03/24 22:15:43 /data/www/pic/CentOS-Debuginfo.repo CLOSE_WRITE,CLOSE was rsynced 17/03/24 22:15:43 /data/www/pic/CentOS-fasttrack.repo CREATE was rsynced 17/03/24 22:15:43 /data/www/pic/CentOS-fasttrack.repo CLOSE_WRITE,CLOSE was rsynced 17/03/24 22:15:43 /data/www/pic/CentOS-Media.repo CREATE was rsynced 17/03/24 22:15:43 /data/www/pic/CentOS-Media.repo CLOSE_WRITE,CLOSE was rsynced 17/03/24 22:15:43 /data/www/pic/CentOS-Sources.repo CREATE was rsynced 17/03/24 22:15:43 /data/www/pic/CentOS-Sources.repo CLOSE_WRITE,CLOSE was rsynced 17/03/24 22:15:43 /data/www/pic/CentOS-Vault.repo CREATE was rsynced 17/03/24 22:15:43 /data/www/pic/CentOS-Vault.repo CLOSE_WRITE,CLOSE was rsynced 17/03/24 22:15:43 /data/www/pic/epel.repo CREATE was rsynced 17/03/24 22:15:43 /data/www/pic/epel.repo CLOSE_WRITE,CLOSE was rsynced 17/03/24 22:15:43 /data/www/pic/epel-testing.repo CREATE was rsynced 17/03/24 22:15:43 /data/www/pic/epel-testing.repo CLOSE_WRITE,CLOSE was rsynced 在服务端查看文件同步情况, ls -l /data/www/pic bash -rw-r--r-- 1 www www 1572 Jun 12 22:15 CentOS-Base.repo -rw-r--r-- 1 www www 1309 Jun 12 22:15 CentOS-CR.repo -rw-r--r-- 1 www www 649 Jun 12 22:15 CentOS-Debuginfo.repo -rw-r--r-- 1 www www 314 Jun 12 22:15 CentOS-fasttrack.repo -rw-r--r-- 1 www www 630 Jun 12 22:15 CentOS-Media.repo -rw-r--r-- 1 www www 1331 Jun 12 22:15 CentOS-Sources.repo -rw-r--r-- 1 www www 4768 Jun 12 22:15 CentOS-Vault.repo -rw-r--r-- 1 www www 951 Jun 12 22:15 epel.repo -rw-r--r-- 1 www www 1050 Jun 12 22:15 epel-testing.repo 我们可以看到文件同步过来了，而且文件 UID 和 GID 也是配置文件设置的 www 参考网址：http://ixdba.blog.51cto.com/2895551/580280 ","date":"2017-03-24","objectID":"/posts/rsync-inotify/:3:6","series":null,"tags":["rsync","inotify"],"title":"通过 rsync + inotify 搭建实时文件同步系统","uri":"/posts/rsync-inotify/#启动测试"},{"categories":["devops"],"content":"原因：由于公司使用 CentOS6.5 充当网关，为了避免麻烦给同事们一个个地去配置 IP 地址， 所以决定安装使用 dhcp 来自动分配 IP（之前是真一个一个去给他们配置 IP 地址，真他妈的累，烦，卖力而且不讨好~~） ","date":"2017-03-15","objectID":"/posts/dhcp/:0:0","series":null,"tags":["dhcp"],"title":"配置 DHCP 服务 实现 ip 地址自动分配","uri":"/posts/dhcp/#"},{"categories":["devops"],"content":" 1.安装DHCP bash [root@localhost ~]# yum install -y dhcp ","date":"2017-03-15","objectID":"/posts/dhcp/:1:0","series":null,"tags":["dhcp"],"title":"配置 DHCP 服务 实现 ip 地址自动分配","uri":"/posts/dhcp/#1安装dhcp"},{"categories":["devops"],"content":" 2.配置dhcpd.conf bash [root@localhost ~]# vim /etc/dhcp/dhcpd.conf # # DHCP Server Configuration file. # see /usr/share/doc/dhcp*/dhcpd.conf.sample # see 'man 5 dhcpd.conf' # # 全局配置 # 设置客户端域名 option domain-name \"wgsc.tv\"; option domain-name-servers 192.168.1.60, 192.168.1.61; # 默认租约12h default-lease-time 43200; # 最大租约24h max-lease-time 86400; # 不要ddns设定 ddns-update-style none; # Use this to send dhcp log messages to a different log file (you also # have to hack syslog.conf to complete the redirection). log-facility local7; # 设置DHCP子网段 subnet 192.168.1.0 netmask 255.255.255.0 { range 192.168.1.181 192.168.1.230; option routers 192.168.1.1; } ################### 服务器(设备)静态IP配置 ################### # Java_bug_6 host device_1 { hardware ethernet fc:aa:14:3a:42:f0; fixed-address 192.168.1.6; } # k3-25 host device_2 { hardware ethernet fc:aa:14:48:62:98; fixed-address 192.168.1.25; } # ....省略一大串 ","date":"2017-03-15","objectID":"/posts/dhcp/:2:0","series":null,"tags":["dhcp"],"title":"配置 DHCP 服务 实现 ip 地址自动分配","uri":"/posts/dhcp/#2配置dhcpdconf"},{"categories":["devops"],"content":" 3.配置dhcp监听接口 bash [root@localhost ~]# vim /etc/sysconfig/dhcpd # Command line options here DHCPDARGS=eth0 Tips: CentOS7 以后不需要设置 ","date":"2017-03-15","objectID":"/posts/dhcp/:3:0","series":null,"tags":["dhcp"],"title":"配置 DHCP 服务 实现 ip 地址自动分配","uri":"/posts/dhcp/#3配置dhcp监听接口"},{"categories":["devops"],"content":" 4.关闭iptables bash [root@localhost ~]# /etc/inin.d/iptables stop [root@localhost ~]# chkconfig iptables off ","date":"2017-03-15","objectID":"/posts/dhcp/:4:0","series":null,"tags":["dhcp"],"title":"配置 DHCP 服务 实现 ip 地址自动分配","uri":"/posts/dhcp/#4关闭iptables"},{"categories":["devops"],"content":" 5.启动dhcp服务 bash [root@localhost ~]# /etc/init.d/dhcpd start 注： 启动日志信息可以查看 /var/log/message 租约信息可查看 /var/lib/dhcpd/dhcpd.leases ","date":"2017-03-15","objectID":"/posts/dhcp/:5:0","series":null,"tags":["dhcp"],"title":"配置 DHCP 服务 实现 ip 地址自动分配","uri":"/posts/dhcp/#5启动dhcp服务"},{"categories":["devops"],"content":"有时我们的网络中可能划分了好几个网段，需要同时为多个网段内的主机分配 ip 地址，这时候就需要用到 dhcp 中继了。 在连接多个子网的路由器上启用 dhcp 中继功能允许有针对性地转发 dhcp 广播。 学过网络的都应该知道不同子网段是不允许广播通过的。所有 dhcp 是无法正常在多网段内提供服务的 安装好 dhcpd 软件，通过修改 /etc/sysconfig/dhcrelay 文件来配置 dhcp 中继。 具体操作步骤如下： 1. 开启服务器的路由转发功能。 bash vim /etc/sysctl.conf net.ipv4.ip_forward = 1 sysctl -p 2. 设置允许dhcp中继数据的接口及dhcp服务器的ip地址 bash vim /etc/sysconfig/dhcrelay INTERFACES=\"eth0 eth1\" DHCPSERVERS=\"192.168.1.2\" 3. 启动 dhcrelay 中继服务程序 bash service dhcrelay start chkconfig --level 35 dhcrelay on ","date":"2017-03-14","objectID":"/posts/dhcp-relay/:0:0","series":null,"tags":["dhcp"],"title":"配置 DHCP 中继为多个网段分配 ip 地址","uri":"/posts/dhcp-relay/#"},{"categories":["network"],"content":" 实验环境 VPC1:192.168.1.1 VPC2:192.168.2.2 ","date":"2015-09-24","objectID":"/posts/openswan/:1:0","series":null,"tags":["vpn","openswan"],"title":"配置 openswan ipsecvpn","uri":"/posts/openswan/#实验环境"},{"categories":["network"],"content":" 安装 openswan bash [root@wglee ~]# yum install openswan ","date":"2015-09-24","objectID":"/posts/openswan/:2:0","series":null,"tags":["vpn","openswan"],"title":"配置 openswan ipsecvpn","uri":"/posts/openswan/#安装-openswan"},{"categories":["network"],"content":" 编辑 /etc/ipsec.conf 文件，启用 /etc/ipsec.d/*.conf bash [root@wglee ~]# sudo vi /etc/ipsec.conf # /etc/ipsec.conf - Openswan IPsec configuration file # # Manual: ipsec.conf.5 # # Please place your own config files in /etc/ipsec.d/ ending in .conf version 2.0 # conforms to second version of ipsec.conf specification # basic configuration config setup # Debug-logging controls: \"none\" for (almost) none, \"all\" for lots. # klipsdebug=none # plutodebug=\"control parsing\" # For Red Hat Enterprise Linux and Fedora, leave protostack=netkey protostack=netkey nat_traversal=yes virtual_private= oe=off # Enable this if you see \"failed to find any available worker\" # nhelpers=0 #You may put your configuration (.conf) file in the \"/etc/ipsec.d/\" and uncomment this. include /etc/ipsec.d/*.conf ","date":"2015-09-24","objectID":"/posts/openswan/:3:0","series":null,"tags":["vpn","openswan"],"title":"配置 openswan ipsecvpn","uri":"/posts/openswan/#编辑-etcipsecconf--文件启用-etcipsecdconf"},{"categories":["network"],"content":" 在 /etc/ipsec.d 目录创建以下文件配置VPC1 bash [root@wglee ~]# sudo vi /etc/ipsec.d/vpc1-to-vpc2.conf conn vpc1-to-vpc2 type=tunnel authby=secret left=%defaultroute leftid=\u003cVPC1的外网IP\u003e leftnexthop=%defaultroute leftsubnet=\u003cVPC1 子网地址\u003e right=\u003cVPC2的外网IP\u003e rightsubnet=\u003cVPC2 子网地址\u003e pfs=yes auto=start [root@wglee ~]# sudo vi /etc/ipsec.d/vpc1-to-vpc2.secrets \u003cVPC1 子网地址\u003e \u003cVPC1 子网地址\u003e: PSK \"Put a Preshared Key here!!\" 配置VPC2 bash [root@wglee ~]# sudo vi /etc/ipsec.d/vpc2-to-vpc1.conf conn vpc2-to-vpc1 type=tunnel authby=secret left=%defaultroute leftid=\u003cVPC2的外网IP\u003e leftnexthop=%defaultroute leftsubnet=\u003cVPC2 的子网地址\u003e right=\u003cEIP1\u003e rightsubnet=\u003cVPC1 的子网地址\u003e pfs=yes auto=start [root@wglee ~]# sudo vi /etc/ipsec.d/vpc2-to-vpc1.secrets \u003cVPC2 的子网地址\u003e \u003cVPC1 的子网地址\u003e: PSK \"Put a Preshared Key here!!\" ","date":"2015-09-24","objectID":"/posts/openswan/:4:0","series":null,"tags":["vpn","openswan"],"title":"配置 openswan ipsecvpn","uri":"/posts/openswan/#在-etcipsecd-目录创建以下文件"},{"categories":["network"],"content":" 启动 IPSec/Openswan bash [root@wglee ~]# sudo service ipsec start # Configure IPSec/Openswan to always start on boot [root@wglee ~]# sudo chkconfig ipsec on ","date":"2015-09-24","objectID":"/posts/openswan/:5:0","series":null,"tags":["vpn","openswan"],"title":"配置 openswan ipsecvpn","uri":"/posts/openswan/#启动-ipsecopenswan"},{"categories":["network"],"content":" 编辑 /etc/sysctl.conf bash [root@wglee ~]# sudo vi /etc/sysctl.conf net.ipv4.ip_forward = 1 net.ipv4.conf.all.accept_redirects = 0 net.ipv4.conf.all.send_redirects = 0 ","date":"2015-09-24","objectID":"/posts/openswan/:6:0","series":null,"tags":["vpn","openswan"],"title":"配置 openswan ipsecvpn","uri":"/posts/openswan/#编辑-etcsysctlconf"},{"categories":["network"],"content":" 重启网络 bash [root@wglee ~]# service network restart ","date":"2015-09-24","objectID":"/posts/openswan/:7:0","series":null,"tags":["vpn","openswan"],"title":"配置 openswan ipsecvpn","uri":"/posts/openswan/#重启网络"},{"categories":["network"],"content":" 检查 VPN 状态 bash #下面的命令可以在检查或故障排除VPN状态有所帮助： [root@wglee ~]# sudo ipsec verify #会检查所需的OpenSWAN的服务状态正常运行 [root@wglee ~]# sudo service ipsec status #检查OpenSWAN服务的状态和VPN隧道 来源： https://aws.amazon.com/articles/5472675506466066 ","date":"2015-09-24","objectID":"/posts/openswan/:8:0","series":null,"tags":["vpn","openswan"],"title":"配置 openswan ipsecvpn","uri":"/posts/openswan/#检查-vpn-状态"},{"categories":null,"content":" “浅行” 取自 陆游 《冬夜读书示子聿》 的最后一句。 自知学问尚浅，唯有不断前行，不断学习以充实已身。 冬夜读书示子聿 -宋.陆游 古人学问无遗力，少壮工夫老始成。 纸上得来终觉浅，绝知此事要躬行。 人生三句箴言 有勇气去改变可以改变的事情 有胸怀去接纳不可以改变的事情 用智慧去分辨两者的不同 每日一言 正在加载今日之言…. ","date":"0001-01-01","objectID":"/about/:0:0","series":null,"tags":null,"title":"关于","uri":"/about/#"}]